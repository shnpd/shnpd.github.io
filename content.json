{"posts":[{"title":"2022年十三届蓝桥杯国赛（C&#x2F;C++大学B组）个人题解","text":"​点击阅读更多查看文章内容 2022年十三届蓝桥杯国赛（C/C++大学B组）个人题解 更新：成绩出来了，估分50分左右，最后拿了个国二，还差点到国一，有点出乎意料，挺满意了挺满意了。 去年国赛基本都是暴力，最后国三都没拿到（我是废物 ），今年感觉比去年难了不少，而且时间没有安排好，第一题就被卡了好久，然后G题概率论也分析了好久，导致最后三题都没时间做了，总之就是一点暴力分都没骗到，希望做的题能多对几道吧，希望能拿个国三。 试题 A: 2022 【问题描述】将 2022 拆分成 10 个互不相同的正整数之和，总共有多少种拆分方法？注意交换顺序视为同一种方法，例如 2022 = 1000 + 1022 和 2022 =1022 + 1000 就视为同一种方法。【答案提交】这是一道结果填空的题，你只需要算出结果后提交即可。本题的结果为一个整数，在提交答案时只填写这个整数，填写多余的内容将无法得分。 10个循环暴力明显超时，有一点思路大概是最小数的范围在0-197之间，可能需要根据数的范围来做？然后就不会了。 试题 B: 钟表 【问题描述】在 12 小时制的钟表中，有分针、时针、秒针来表示时间。记分针和时针之间的夹角度数为 A（0 ≤ A ≤ 180）、分针和秒针之间的夹角度数为 B （0 ≤ B ≤ 180）。而恰好在 s 时 f 分 m 秒时，满足条件 A = 2B 且 0 ≤ s ≤ 6； 0 ≤ f &lt; 60；0 ≤ m &lt; 60，请问 s, f, m 分别是多少。注意时针、分针、秒针都围绕中心匀速转动。提交格式为三个由一个空格隔开的整数，分别表示 s, f, m。如 3 11 58表示3 点 11 分 58 秒。【答案提交】这是一道结果填空的题，你只需要算出结果后提交即可。本题的结果为三个由一个空格隔开的整数，在提交答案时只填写为三个由一个空格隔开的整数，填写多余的内容将无法得分。 枚举时分秒，分别计算秒针、分针、时针与0时的夹角度数秒针的夹角度数为：360 * m / 60；（一圈360度，秒针转了m / 60圈）分针的夹角度数为：360 * f / 60 + 6 * m / 60；（分针转了f / 60圈，另外每两分钟之间相差6度（60秒），已经过了m秒，故再加上 6 * m / 60度）时针的夹角度数：360 * s / 12 + 30 * (f * 60 + m) / 3600; （时针转了s / 12圈，另外每两小时之间相差30度（3600秒），已经过了f * 60 + m秒，故再加上30 * (f * 60 + m) / 3600度） 分针与时针之间的夹角度数即为分针与0时的夹角度数减去时针与0时的夹角度数的绝对值，同时要取小于180度的夹角值分针和秒针的夹角同理 结果：4 48 0 代码：123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;cmath&gt;using namespace std;int main(){ double md, fd, sd; for (double m = 0; m &lt; 60; m++) { md = 360 * m / 60; for (double f = 0; f &lt; 60; f++) { fd = 360 * f / 60; fd += 6 * m / 60; for (double s = 0; s &lt;= 6; s++) { sd = 360 * s / 12; sd += 30 * (f * 60 + m) / 3600; double A = fabs(fd - sd); A = min(A, 360 - A); double B = fabs(fd - md); B = min(B, 360 - B); if (A == 2 * B) { cout &lt;&lt; s &lt;&lt; &quot; &quot; &lt;&lt; f &lt;&lt; &quot; &quot; &lt;&lt; m &lt;&lt; endl; } } } } return 0;} 试题 C: 卡牌 【问题描述】这天，小明在整理他的卡牌。他一共有 n 种卡牌，第 i 种卡牌上印有正整数数 i(i ∈ [1, n])，且第 i 种卡牌现有 ai 张。而如果有 n 张卡牌，其中每种卡牌各一张，那么这 n 张卡牌可以被称为一套牌。小明为了凑出尽可能多套牌，拿出了 m 张空白牌，他可以在上面写上数i，将其当做第 i 种牌来凑出套牌。然而小明觉得手写的牌不太美观，决定第 i种牌最多手写 bi 张。请问小明最多能凑出多少套牌？【输入格式】输入共 3 行，第一行为两个正整数 n, m。第二行为 n 个正整数 a1, a2, …, an。第三行为 n 个正整数 b1, b2, …, bn。【输出格式】一行，一个整数表示答案。【样例输入】4 51 2 3 45 5 5 5【样例输出】3【样例说明】这 5 张空白牌中，拿 2 张写 1，拿 1 张写 2，这样每种牌的牌数就变为了3, 3, 3, 4，可以凑出 3 套牌，剩下 2 张空白牌不能再帮助小明凑出一套。【评测用例规模与约定】对于 30% 的数据，保证 n ≤ 2000 ；对于 100% 的数据，保证 n ≤ 2 × 10^5^; ai, bi ≤ n; m ≤ n^2^ 。 比赛的时候忘记sort结构体数组怎么写了，又敲了个vector先按照牌的现有张数排序，然后二分能凑出多少套牌 判断是否能凑出x套牌时，从小到大枚举，如果当前的现有的牌数大于x那么直接退出即可（剩下的也都大于x），如果现有牌数+最多可手写牌数小于x的话直接返回false，剩下的使用x-现有牌数张空白牌转换为当前牌，如果转换后的空白牌小于0说明空白牌不够也返回false 代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;iostream&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;using namespace std;typedef long long ll;const int N = 2e5 + 10;int n;ll m;struct card{ int a, b; card(int aa = 0, int bb = 0) { a = aa; b = bb; }};vector&lt;card&gt; vc;bool cmp(card a, card b){ return a.a &lt; b.a;}bool jd(int x){ ll tm = m; for (int i = 0; i &lt; n; i++) { if (vc[i].a &gt;= x) break; if (vc[i].a + vc[i].b &lt; x) return false; tm -= (x - vc[i].a); if (tm &lt; 0) return false; } return true;}int main(){ cin &gt;&gt; n &gt;&gt; m; for (int i = 0; i &lt; n; i++) { card t; cin &gt;&gt; t.a; vc.push_back(t); } for (int i = 0; i &lt; n; i++) cin &gt;&gt; vc[i].b; sort(vc.begin(), vc.end(), cmp); //二分可能取到的最小值 int l = vc[0].a, r = 5 * n + 5; while (l &lt; r) { int mid = (l + r + 1) / 2; if (jd(mid)) l = mid; else r = mid - 1; } cout &lt;&lt; l; return 0;} 试题 D: 最大数字 【问题描述】给定一个正整数 N。你可以对 N 的任意一位数字执行任意次以下 2 种操作：1.将该位数字加 1。如果该位数字已经是 9，加 1 之后变成 0。2.将该位数字减 1。如果该位数字已经是 0，减 1 之后变成 9。你现在总共可以执行 1 号操作不超过 A 次，2 号操作不超过 B 次。请问你最大可以将 N 变成多少？【输入格式】第一行包含 3 个整数：N, A, B。【输出格式】一个整数代表答案。【样例输入】123 1 2【样例输出】933【样例说明】对百位数字执行 2 次 2 号操作，对十位数字执行 1 次 1 号操作。【评测用例规模与约定】对于 30% 的数据，1 ≤ N ≤ 100; 0 ≤ A, B ≤ 10对于 100% 的数据，1 ≤ N ≤ 10^17^; 0 ≤ A, B ≤ 100 不会，比赛的时候随便敲上了个能过样例的，现在看来有点离谱，不放上来误导大家了 试题 E: 出差 【问题描述】A 国有 N 个城市，编号为 1 . . . N。小明是编号为 1 的城市中一家公司的员工，今天突然接到了上级通知需要去编号为 N 的城市出差。由于疫情原因，很多直达的交通方式暂时关闭，小明无法乘坐飞机直接从城市 1 到达城市 N，需要通过其他城市进行陆路交通中转。小明通过交通信息网，查询到了 M 条城市之间仍然还开通的路线信息以及每一条路线需要花费的时间。同样由于疫情原因，小明到达一个城市后需要隔离观察一段时间才能离开该城市前往其他城市。通过网络，小明也查询到了各个城市的隔离信息。（由于小明之前在城市 1，因此可以直接离开城市 1，不需要隔离）由于上级要求，小明希望能够尽快赶到城市 N，因此他求助于你，希望你能帮他规划一条路线，能够在最短时间内到达城市 N。【输入格式】第 1 行：两个正整数 N, M，N 表示 A 国的城市数量，M 表示未关闭的路线数量第 2 行：N 个正整数，第 i 个整数 Ci 表示到达编号为 i 的城市后需要隔离的时间第 3 . . . M + 2 行：每行 3 个正整数，u, v, c，表示有一条城市 u 到城市 v 的双向路线仍然开通着，通过该路线的时间为 c【输出格式】第 1 行：1 个正整数，表示小明从城市 1 出发到达城市 N 的最短时间（到达城市 N，不需要计算城市 N 的隔离时间）【样例输入】4 45 7 3 41 2 41 3 52 4 33 4 5【样例输出】13【样例说明】[1(5)] –4– [2(7)]| ｜| ｜5 3| ｜| ｜[3(3)] –5– [4(4)]路线 1：1 -&gt; 2 -&gt; 4，时间为 4+7(隔离)+3=14路线 2：1 -&gt; 3 -&gt; 4，时间为 5+3(隔离)+5=13【评测用例规模与约定】对于 100% 的数据，1 ≤ N ≤ 1000 , 1 ≤ M ≤ 10000, 1 ≤ Ci ≤ 200, 1 ≤ u, v ≤ N, 1 ≤ c ≤ 1000 dijkstra求最短路，建图的时候要把隔离时间加上，N点的隔离时间设为0（这大概是本次比赛最简单的一道题了，但是感觉自己对dijkstra的板子还是不熟，希望能做对吧 ） 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;const int N = 1e3 + 10;const int M = 1e4 + 10;int n, m;bool vis[N];int geli[N];int edge[N][N];int dis[N];int dijkstra(){ vis[1] = true; for (int k = 1; k &lt;= n; k++) { int d = 0x3f3f3f3f; int t = -1; for (int i = 1; i &lt;= n; i++) { if (!vis[i]) { if (dis[i] &lt; d) { d = dis[i]; t = i; } } } vis[t] = true; for (int i = 1; i &lt;= n; i++) { if (!vis[i] &amp;&amp; edge[t][i] != 0) { if (dis[t] + edge[t][i] &lt; dis[i]) dis[i] = dis[t] + edge[t][i]; } } } return dis[n];}int main(){ cin &gt;&gt; n &gt;&gt; m; for (int i = 1; i &lt;= n; i++) cin &gt;&gt; geli[i]; geli[n] = 0; memset(dis, 0x3f, sizeof dis); dis[1] = 0; int u, v, c; for (int i = 1; i &lt;= m; i++) { cin &gt;&gt; u &gt;&gt; v &gt;&gt; c; edge[u][v] = c + geli[v]; if (u == 1) dis[v] = min(dis[v], edge[u][v]); edge[v][u] = c + geli[u]; if (v == 1) dis[u] = min(dis[u], edge[v][u]); } cout &lt;&lt; dijkstra(); return 0;} 试题 F: 费用报销 【问题描述】小明在出差结束后返回了公司所在的城市，在填写差旅报销申请时，粗心的小明发现自己弄丢了出差过程中的票据。为了弥补小明的损失，公司同意小明用别的票据进行报销，但是公司财务要求小明提交的票据中任意两张的日期差不小于 K 天，且总金额不得超过实际差旅费用 M。比如财务要求 K = 7 时，若小明提交了一张 1 月 8 日的票据，小明就不能提交 1 月 2 日至 1 月 14 日之间的其他票据，1 月 1 日及之前和 1 月 15 日及之后的票据则可以提交。公司的同事们一起给小明凑了 N 张票据，小明现在想要请你帮他整理一下，从中选取出符合财务要求的票据，并使总金额尽可能接近 M。需要注意，由于这些票据都是同一年的，因此 12 月底的票据不会影响到 1 月初票据的提交。这一年不是闰年。【输入格式】第 1 行：3 个整数，N, M, K 第 2 . . . N + 1 行：每行 3 个整数 mi, di, vi，第 i + 1 行表示第 i 张票据时间的月份 mi 和日期 di，vi 表示该票据的面值【输出格式】第 1 行：1 个整数，表示小明能够凑出的最大报销金额【样例输入】4 16 31 1 11 3 21 4 41 6 8【样例输出】10【样例说明】选择 1 月 3 日和 1 月 6 日的票据【评测用例规模与约定】对于 100% 的评测用例，1 ≤ N ≤ 1000, 1 ≤ M ≤ 5000, 1 ≤ K ≤ 50, 1 ≤ mi ≤12, 1 ≤ di ≤ 31, 1 ≤ vi ≤ 400日期保证合法。 本来以为是背包问题，做了一会发现不知道第二维该如何选择然后想到了下面的方法 先预处理每张票据距离年初的天数，然后根据天数排序，再预处理每张票据之前与他相差小于等于k天的最早的票据然后DP只选择前i张票据所能凑出的最大报销金额，状态转移方程：f[i] = max(f[i - 1],f[minusk[i]] + vc[i].w); 刚刚发现忘记判断总金额是否超过M了，g 代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;#include &lt;map&gt;using namespace std;const int month[13] = {0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31};const int N = 1e3 + 10;int n, m, k;int d[N], w[N];int f[N];map&lt;int, int&gt; minusk;struct card{ int d, w; card(int dd = 0, int ww = 0) { d = dd; w = ww; }};bool cmp(card a, card b){ return a.d &lt; b.d;}vector&lt;card&gt; vc;int main(){ cin &gt;&gt; n &gt;&gt; m &gt;&gt; k; int mm, dd, vv; for (int i = 1; i &lt;= n; i++) { cin &gt;&gt; mm &gt;&gt; dd &gt;&gt; vv; int days = 0; for (int i = 1; i &lt; mm; i++) days += month[i]; days += dd; d[i] = days; w[i] = vv; } card t; vc.push_back(t); for (int i = 1; i &lt;= n; i++) { card t; t.d = d[i]; t.w = w[i]; vc.push_back(t); } sort(vc.begin(), vc.end(), cmp); for (int l = 0, r = 1; r &lt;= n; r++) { if (vc[r].d - vc[l].d &gt; k) l++; minusk[r] = l; } f[0] = 0; for (int i = 1; i &lt;= n; i++) { f[i] = max(f[i - 1], f[minusk[i]] + vc[i].w); } cout &lt;&lt; f[n]; return 0;} 试题 G: 故障 【问题描述】在软件或系统开发中，我们会遇到各种各样的故障。为了从故障现象反推故障原因，工程师们会总结一种叫做相关性矩阵的二维表格，来表示故障原因与故障现象之间的关系。比如： 1 2 3 4 5 A X X X B X X C X X 其中每行表示一种故障原因，每一列表示一种故障现象。该矩阵表示故障原因 A 可能产生故障现象 2、3、4，故障原因 B 可能产生故障现象 1、3。在实际开发过程中，如果出现了故障原因，工程师就可以根据故障现象，去计算每种故障原因产生的概率，并按照概率大小对故障原因进行排查，以达到快速定位故障原因的目的。现在，我们假设系统开发中同一时间只会出现一种故障原因，并且故障原因引起各故障现象是独立事件。举个例子来说：假设系统现在发生了故障原因 A，有$\\frac{1}{3}$的概率出现故障现象 2，有$\\frac{1}{4}$的概率出现故障现象 3，有$\\frac{1}{2}$的概率出现故障现象 4。由于 3 种现象是独立发生的，因此有$\\frac{1}{2×3×4}$的概率同时出现故障 2、3、4。约定若相关性矩阵中没有 ‘x’ 记号，则表示该故障原因一定不会产生某故障现象，比如故障原因 A，一定不会产生故障现象 1。根据历史经验数据，我们统计得到了每一种故障原因出现的概率以及每一种故障原因对应的故障现象产生概率。现在已知系统出现的故障现象，求问各个故障原因发生的概率【输入格式】第 1 行：2 个正整数 N, M，N 表示故障原因的个数（编号 1 . . . N），M 表示故障现象的个数（编号 1 . . . M）第 2 行：N 个整数，第 i 个数表示故障原因 i 产生的概率 Pi.第 3 . . . N + 2 行：每行 M + 1 个整数，第 i + 1 行第 j 个整数 Pij 表示故障原因 i 出现故障现象 j 的概率（百分比）.第 N + 3 行：1 个正整数 K，表示目前出现的故障现象数量第 N + 4 行：K 个正整数，依次为当前出现的故障现象编号，不会重复【输出格式】第 1 . . . N 行：按概率从高到低输出每种故障原因及其可能的概率，若出现概率相同则优先输出编号小的故障原因。第 1 个数为故障原因编号，第 2 个数为故障概率（百分比），保留 2 位小数。【样例输入】3 530 20 500 50 33 25 030 0 35 0 00 0 0 25 6013【样例输出】2 56.891 43.113 0.00【评测用例规模与约定】对于所有测试用例，1 ≤ N ≤ 40, 1 ≤ M ≤ 20, 0 ≤ Pi ≤ 100，∑(Pi) = 100， 0 ≤ Pij ≤ 100 这道题这个样例看了好久才看明白导致最后三道题一点都没做，希望能做对吧 先讲一下样例是怎么输出的 由于发生了故障现象3，而原因3不可能导致故障现象3的发生，所以首先排除原因3 然后分析原因1导致现象3的概率，原因1导致发生故障现象3的概率为（现象1不发生的概率 * 现象2不发生的概率 * 现象3发生的概率 * 现象4不发生的概率 * 现象5不发生的概率），即1 * 1-50/100 * 33/100 * 1-25/100 * 1 = 0.12375 同理分析原因2导致现象3的概率， 1-30/100 * 1 * 35/100 * 1 * 1 = 0.245 上面分析的是发生了原因1导致产生故障现象3的概率，下面还要求原因发生的概率，因为原因3不可能发生了，所以只分析原因1,2原因1的概率为30，原因2的概率为20，所以发生原因1的概率即为30/(30+20)=0.6，同理发生原因2的概率为20/(30+20)=0.4 综上所述原因1导致故障3的概率为0.6 * 0.12375 = 0.07425原因2导致故障3的概率为0.4 * 0.12375 = 0.098原因3导致故障3的概率为0 因为这有这三种原因相加概率应该为1，所以处理一下原因1的结果即为：0.07425/(0.07425+0.098) = 0.4310595原因2的结果即为：0.098/(0.07425+0.098) = 0.56894原因3的结果即为：0 分析出样例来，这道题就比较简单了，下面贴上我的代码，由于比赛的时候时间不多了，所以代码很多地方都没处理好，很混乱，到最后才测试出样例，大家随便看看就好了 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;unordered_map&gt;#include &lt;algorithm&gt;#include &lt;iomanip&gt;using namespace std;const int N = 45;const int M = 45;double p[N][N];int n, m, k;double pgz[N]; //原因概率unordered_map&lt;int, int&gt; gzxx; //发生现象unordered_map&lt;int, int&gt; knyy; //原因struct ans{ int gz; double p; ans(int a = 0, double b = 0) { gz = a; p = b; }};bool cmp(ans a, ans b){ if (a.p == b.p) return a.gz &lt; b.gz; return a.p &gt; b.p;}int main(){ cin &gt;&gt; n &gt;&gt; m; for (int i = 1; i &lt;= n; i++) cin &gt;&gt; pgz[i]; for (int i = 1; i &lt;= n; i++) for (int j = 1; j &lt;= m; j++) cin &gt;&gt; p[i][j]; cin &gt;&gt; k; for (int i = 1; i &lt;= k; i++) { int xx; cin &gt;&gt; xx; gzxx[xx] = 1; } vector&lt;int&gt; kngz; //可能故障原因 for (int i = 1; i &lt;= n; i++) { int j; for (j = 1; j &lt;= m; j++) { if (gzxx[j] &amp;&amp; p[i][j] == 0) break; } if (j == m + 1) { kngz.push_back(i); knyy[i] = 1; } } double zy = 0; //原因总概率 for (int i = 0; i &lt; kngz.size(); i++) zy += pgz[kngz[i]]; vector&lt;double&gt; pkngz; //可能故障的概率 double sumgl = 0; for (int i = 0; i &lt; kngz.size(); i++) { int yy = kngz[i]; double ptemp = pgz[yy] / zy; for (int j = 1; j &lt;= m; j++) { if (p[yy][j] == 0) continue; if (gzxx[j]) ptemp *= (p[yy][j] / 100); else ptemp *= (1 - p[yy][j] / 100); } sumgl += ptemp; pkngz.push_back(ptemp); } vector&lt;ans&gt; vc; for (int i = 0; i &lt; pkngz.size(); i++) { ans tans; tans.gz = kngz[i]; tans.p = pkngz[i] / sumgl; vc.push_back(tans); } for (int i = 1; i &lt;= n; i++) { if (!knyy[i]) { ans tans(i, 0); vc.push_back(tans); } } sort(vc.begin(), vc.end(), cmp); for (int i = 0; i &lt; vc.size() - 1; i++) cout &lt;&lt; vc[i].gz &lt;&lt; &quot; &quot; &lt;&lt; fixed &lt;&lt; setprecision(2) &lt;&lt; vc[i].p * 100 &lt;&lt; endl; cout &lt;&lt; vc[vc.size() - 1].gz &lt;&lt; &quot; &quot; &lt;&lt; fixed &lt;&lt; setprecision(2) &lt;&lt; vc[vc.size() - 1].p * 100 &lt;&lt; endl; return 0;} 试题 H: 机房 【问题描述】这天，小明在机房学习。他发现机房里一共有 n 台电脑，编号为 1 到 n，电脑和电脑之间有网线连接，一共有 n − 1 根网线将 n 台电脑连接起来使得任意两台电脑都直接或者间接地相连。小明发现每台电脑转发、发送或者接受信息需要的时间取决于这台电脑和多少台电脑直接相连, 而信息在网线中的传播时间可以忽略。比如如果某台电脑用网线直接连接了另外 d 台电脑，那么任何经过这台电脑的信息都会延迟 d 单位时间 (发送方和接收方也会产生这样的延迟，当然如果发送方和接收方都是同一台电脑就只会产生一次延迟)。小明一共产生了 m 个疑问：如果电脑 ui 向电脑 vi 发送信息，那么信息从ui 传到 vi 的最短时间是多少？【输入格式】输入共 n + m 行，第一行为两个正整数 n, m。后面 n − 1 行，每行两个正整数 x, y 表示编号为 x 和 y 的两台电脑用网线直接相连。后面 m 行，每行两个正整数 ui, vi 表示小明的第 i 个疑问。【输出格式】输出共 m 行，第 i 行一个正整数表示小明第 i 个疑问的答案。【样例输入】4 31 21 32 42 33 43 3【样例输出】561【样例说明】这四台电脑各自的延迟分别为 2, 2, 1, 1。对于第一个询问，从 2 到 3 需要经过 2, 1, 3，所以时间和为 2 + 2 + 1 = 5。对于第二个询问，从 3 到 4 需要经过 3, 1, 2, 4，所以时间和为 1+2+2+1 = 6。对于第三个询问，从 3 到 3 只会产生一次延迟，所以时间为 1。【评测用例规模与约定】对于 30% 的数据，保证 n, m ≤ 1000；对于 100% 的数据，保证 n, m ≤ 100000 。 没看题，以后再补 试题 I: 齿轮 【问题描述】这天，小明在组装齿轮。他一共有 n 个齿轮，第 i 个齿轮的半径为 ri，他需要把这 n 个齿轮按一定顺序从左到右组装起来，这样最左边的齿轮转起来之后，可以传递到最右边的齿轮，并且这些齿轮能够起到提升或者降低转速 (角速度) 的作用。小明看着这些齿轮，突然有 Q 个疑问：能否按一定顺序组装这些齿轮使得最右边的齿轮的转速是最左边的齿轮的 qi 倍？【输入格式】输入共 Q + 2 行，第一行为两个正整数 n, Q，表示齿轮数量和询问数量。第二行为 n 个正整数 r1,r2, …,rn，表示每个齿轮的半径。后面 Q 行，每行一个正整数 qi 表示询问。【输出格式】Q 行，对于每个询问，如果存在至少一种组装方案满足条件，输出 ‘YES‘，否则输出 ‘NO‘。【样例输入】5 34 2 3 3 1246【样例输出】YESYESNO【样例说明】询问 1 方案之一：2 3 3 4 1询问 2 方案之一：4 2 3 3 1询问 3 没有方案【评测用例规模与约定】对于 15% 的数据，保证 n, Q ≤ 100 ；对于 30% 的数据，保证 n, Q ≤ 2000 ；对于 100% 的数据，保证 n, Q ≤ 2 × 10^5^; ai, qi ≤ 2 × 10^5^ 。 没看题，以后再补 试题 J: 搬砖 【问题描述】这天，小明在搬砖。他一共有 n 块砖，他发现第 i 砖的重量为 wi，价值为 vi。他突然想从这些砖中选一些出来从下到上堆成一座塔，并且对于塔中的每一块砖来说，它上面所有砖的重量和不能超过它自身的价值。他想知道这样堆成的塔的总价值（即塔中所有砖块的价值和）最大是多少。【输入格式】输入共 n + 1 行，第一行为一个正整数 n，表示砖块的数量。后面 n 行，每行两个正整数 wi, vi 分别表示每块砖的重量和价值。【输出格式】一行，一个整数表示答案。【样例输入】54 41 15 25 54 3【样例输出】10【样例说明】选择第 1、2、4 块砖，从上到下按照 2、1、4 的顺序堆成一座塔，总价值为 4 + 1 + 5 = 10【评测用例规模与约定】对于 20% 的数据，保证 n ≤ 10；对于 100% 的数据，保证 n ≤ 1000; wi ≤ 20; vi ≤ 20000 。 没看题以后再补","link":"/2022/06/19/2022%E5%B9%B4%E5%8D%81%E4%B8%89%E5%B1%8A%E8%93%9D%E6%A1%A5%E6%9D%AF%E5%9B%BD%E8%B5%9B%EF%BC%88C!C++%E5%A4%A7%E5%AD%A6B%E7%BB%84%EF%BC%89%E4%B8%AA%E4%BA%BA%E9%A2%98%E8%A7%A3/"},{"title":"802.1x协议简述","text":"​点击阅读更多查看文章内容 802.1x协议简述转载文章：一文读懂802.1x协议 协议简介802.1x协议是一种基于C/S结构的访问「控制协议」，工作在数据链路层，也就是二层协议。 「C/S结构」：server/client的简称，分为服务器和客户机两层结构，其中服务器负责数据的管理，客户机负责用户的交互 「访问控制」：一种控制访问权限的技术，规定谁可以访问谁，谁不可以访问谁 「协议」：网络协议的简称，本质上是一系列的规则，比如两个电脑之间怎么建立连接，怎么互相识别，都需要遵守一定的规则。由于网络环境相当负责，故而将整个网络分为七个部分，也就是我们常说的0SI七层模型，每一层都有对应的协议，某一层的协议发生改变时，不会影响其他层的协议 802.1x协议作用限制未经「授权」的用户/设备通过接入端口访问LAN/WLAN，以确保网络的安全 「端口」：设备与外界通信的出口，分为虚拟端口和物理端口，虚拟端口指不可见端口，如计算机的21,23,80端口；物理端口又称为接口，是可见端口，比如电脑/电话的网线接口 「LAN」:局域网，也就是通过网线将计算机连接起来，构成一个局部的网络范围，范围内的计算机可以互相通信 「WLAN」：Wireless Local Area Network的简称，也就是无线局域网，使用无线通信技术而不是网线将计算机互联起来 逻辑端口IEEE 802.1Xx协议将端口分为「可控端口」和「不可控端口」，交换机利用不可控端口完成对用户的认证和控制，业务报文通过可控端口进行交换，以此来实现业务与认证的分离 802.1x协议认证原理 用户输入用户名和密码，发起连接请求，客户端程序发送请求认证的报文给交换机，开启认证 交换机收到请求认证的数据帧以后，将发出一个请求帧要求客户端发送用户输入的用户名 客户端程序响应交换机的请求，发送一个包含用户名的数据帧给交换机，交换机将收到数据帧后将其封包并发送给认证服务器进行处理 认证服务器收到交换机发送的用户名后，查询数据库进行匹配，匹配成功后找到用户名对应的密码，用随机生成的加密字将其加密后，将加密字发送给交换机，交换机再将加密字传送给客户端程序 客户端程序使用收到的加密字对用户输入的密码进行加密，并将加密后的密码发送给交换机，由交换机发送给认证服务器 认证服务器将收到的密码进行对比，如果相同则为授权用户，返回认证通过的信息，并向交换机发出打开端口的指令，允许用户通过端口访问网络；否则就是未授权用户，只允许认证信息数据通过而不允许业务数据通过","link":"/2022/06/28/802.1x%E5%8D%8F%E8%AE%AE%E7%AE%80%E8%BF%B0/"},{"title":"AcWing1986. 镜子（模拟&#x2F;向量）","text":"​​点击阅读更多查看文章内容 题目链接 题目分析小模拟题，第一遍做的时候越做越复杂，看了y总的题解，发现y总的这种做题方法还蛮不错的，条理清晰，先在main函数中把代码的总体框架敲好，比较复杂或者使用比较多的方法写成函数，这里的函数可以先不去声明，直接在main函数中写，等main函数的总体框架写完之后再去完善其他的函数 总体思路本题的N最大只有200，判断时间复杂度可以到达O(N^3^)我们首先枚举要变换的镜子然后镜子最多只会反射2*(n+1)次然后再遍历所有镜子找到在当前镜子的方向上距离最近的那个总的时间复杂度为O(N^3^) 这里着重解释一下找在当前镜子的方向上距离最近的那个镜子的代码 12345//判断j是否在k定义的方向上 if (m[k].x + abs(m[j].x - m[k].x) * fx[d] != m[j].x) continue;if (m[k].y + abs(m[j].y - m[k].y) * fy[d] != m[j].y) continue; 原理如下：计算距离的代码，这个代码只有当线段平行于坐标轴时才能使用 1int dis = abs(m[k].x - m[j].x) + abs(m[k].y - m[j].y); 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;algorithm&gt;using namespace std;const int N = 210, INF = 1e8;struct Mirror{ int x, y; char c;} m[N];int n;int fx[4] = {0, 1, 0, -1};int fy[4] = {1, 0, -1, 0};bool check(){ int d = 1;//方向 int k = 0;//当前的镜子 //最多会反射2*(n+1)次 for (int i = 0; i &lt; 2 * (n + 1); i++) { int id = -1;//在当前方向上最近的镜子 int len = INF; //找到当前方向上最近的镜子 for (int j = 1; j &lt;= n + 1; j++) { if(k==j) continue; //判断j是否在k定义的方向上 if (m[k].x + abs(m[j].x - m[k].x) * fx[d] != m[j].x) continue; if (m[k].y + abs(m[j].y - m[k].y) * fy[d] != m[j].y) continue; int dis = abs(m[k].x - m[j].x) + abs(m[k].y - m[j].y); if (dis &lt; len) { len = dis; id = j; } } if (id == n + 1) return true; if (id == -1) return false; k = id; if (m[k].c == '\\\\') d ^= 3; else d ^= 1; } return false;}void rotate(char &amp;c){ //'\\'需要转义 if (c == '/') c = '\\\\'; else c = '/';}int main(){ cin &gt;&gt; n; cin &gt;&gt; m[n + 1].x &gt;&gt; m[n + 1].y; for (int i = 1; i &lt;= n; i++) cin &gt;&gt; m[i].x &gt;&gt; m[i].y &gt;&gt; m[i].c; if (check()) { cout &lt;&lt; 0; return 0; } for (int i = 1; i &lt;= n; i++) { rotate(m[i].c); if (check()) { cout &lt;&lt; i&lt;&lt;endl; return 0; } rotate(m[i].c); } cout &lt;&lt; -1; return 0;}","link":"/2022/04/29/AcWing1986.%20%E9%95%9C%E5%AD%90%EF%BC%88%E6%A8%A1%E6%8B%9F!%E5%90%91%E9%87%8F%EF%BC%89/"},{"title":"AcWing 1912. 里程表（逆向思维）","text":"​​点击阅读更多查看文章内容 AcWing 1912. 里程表（逆向思维）题目链接 约翰的奶牛正在公路上旅行。他们汽车上的里程表显示的是整数里程值。旅途开始时里程表显示的里程值为 X，旅途结束时里程表显示的里程值为 Y。每当里程表显示“有趣的”数字（包括开始和结束时显示的数字）时，奶牛们就会发出愉快的叫声。如果一个数除去前导零以外的所有数字中，除了一个数字不同以外，其他所有数字都是相同的，那么这个数就是“有趣的”。例如，33323 和 110 是有趣的，而 9779 和 55555 不是有趣的。请帮助约翰计算奶牛们在旅途中发出叫声的次数。输入格式共一行，包含两个整数 X 和 Y。输出格式输出奶牛们在旅途中发出叫声的次数。数据范围100≤X≤Y≤10^16^ 题目分析“有趣的数”：除了一个数字不同以外，其他所有数字都是相同的，可以分析出有趣的数中一共只有两个不同的数 观察本题的数据范围为10^16^显然不能通过遍历来实现我们可以计算一下在10^16^以内的有趣的数的个数约为：17（数字位数，10^16^共有17位）*10（第一个数一共有0~9十种取值）*9（第二个数与第一个数不能相同故有9种取值）*17（第二个数的出现位置）=26010经过上述计算得出10^16^以内有趣的数共有26010个于是我们可以通过逆向思维枚举这26010个数然后从中找出在X和Y之间的数即可 代码12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;using namespace std;typedef long long LL;int main(){ LL x,y; cin &gt;&gt; x &gt;&gt; y; int cnt=0; for (int i = 3; i &lt;= 17; i ++ ) for (int j = 0; j &lt; 10; j ++ ) for (int k = 0; k &lt; 10; k ++ ) if(j!=k) for (int t = 0; t &lt; i; t ++ ) { string s(i,'0'+j); s[t]='0'+k; if(s[0]=='0') continue; LL ans=stoll(s); if(ans&gt;=x&amp;&amp;ans&lt;=y) cnt++; } cout &lt;&lt; cnt; return 0;}","link":"/2022/04/25/AcWing%201912.%20%E9%87%8C%E7%A8%8B%E8%A1%A8%EF%BC%88%E9%80%86%E5%90%91%E6%80%9D%E7%BB%B4%EF%BC%89/"},{"title":"Bitxhub跨链平台","text":"​​点击阅读更多查看文章内容 BitXHub跨链平台 跨链系统架构过程 在跨链合约中调用统一写好的Broker合约 Broker合约抛出事件由Plugin捕获到 封装成平台统一的数据结构提交到中继链中 目的链的跨链网关从中继链中同步IBTP数据结构 网关将该数据结构通过Plugin提交到目的链 中继链体系架构 中继链的模块和流程 跨链网关 通过动态加载插件的形式适配应用链并随时进行热更新 无需保存跨链状态，重新启动时可直接从应用链和中继链恢复跨链交易相应的状态信息 IBTP协议 IBTP（Inter Blockchain Transfer Protocol）：由平台提出的一种通用的跨链交互的消息传输协议。 所有异构链的跨链交易都可以封装成统一格式的IBTP信息 调用信息（Payload）+证明信息（Proof）字段可以适配所有异构链 跨链验证引擎 应用链在加入时需要为自己编写跨链交易相关的验证规则提前部署到虚拟机中 每次交易都会调用验证规则对proof进行相应的验证 跨链实战跨链系统启动流程 启动中继链 快速启动应用链和部署跨链合约 启动对接应用链的跨链网关 发送跨链交易进行跨链交互","link":"/2023/10/11/Bitxhub%E8%B7%A8%E9%93%BE%E5%B9%B3%E5%8F%B0/"},{"title":"C++快速排序基准插入函数的两种方法","text":"​​点击阅读更多查看文章内容 C++快速排序基准插入函数的两种方法今天做题的时候刷到一种新的快排的实现方法，主要是基准插入函数的不同，这种方法相比于常规方法时间复杂度较高，但是比较容易理解，在这里记录一下。 第一种（最常见的双指针遍历）12345678910111213141516171819int partition(vector&lt;int&gt;&amp;arr, int i, int j) { int key = arr[i]; while (i &lt; j) { while (i &lt; j &amp;&amp; arr[j] &gt;= key) { j--; } if (i &lt; j) { arr[i] = array[j]; } while (i &lt; j &amp;&amp; arr[i] &lt;= key) { i++; } if (i &lt; j) { arr[j] = array[i]; } } arr[i] = key; return i;} 第二种（从头到尾遍历一遍，把小于基准值的依次与最前面的交换）123456789101112131415int partition(vector&lt;int&gt; &amp;arr, int l, int r) { int key = arr[l]; int j = l; for (int i = l + 1; i &lt;= r; i++) { if (arr[i] &lt; key) { j++; swap(arr[i], arr[j]); } } swap(arr[j], arr[l]); return j; }","link":"/2021/09/14/C++%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E5%9F%BA%E5%87%86%E6%8F%92%E5%85%A5%E5%87%BD%E6%95%B0%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/"},{"title":"C++零散易错点总结","text":"​​点击阅读更多查看文章内容 对日常做题中遇到的一些零散的易错点的总结持续更新ing1.string的length方法返回的是无符号数，当与负数比较时需要强制类型转换，否则会报错。**-1&lt;s.length() -&gt; -1&lt;(int)s.length()**2.关于运算符重载，在使用优先队列时，特别注意第二个const不能省略，否则会报错。bool operator&lt;(const type name)const**3.遍历map的方法：**for (auto&amp; [ key , value ] : map)**4.二维向量排序：**sort(people.begin(), people.end(), [](const vector &amp;u, const vector &amp;v) { return u[0] &lt; v[0] || (u[0] == v[0] &amp;&amp; u[1] &gt; v[1]); });5.c++如下声明向量会报错，原因是编译器可能无法区分这是一个成员函数声明还是一个成员变量声明。 123456789class Solution{public: vector&lt;int&gt; F (40, 0); double myPow(double x, int n) { return -1; }}; 解决方法是 1vector&lt;int&gt; F = vector&lt;int&gt;(40,0);//明确这是一个成员变量声明","link":"/2021/08/10/C++%E9%9B%B6%E6%95%A3%E6%98%93%E9%94%99%E7%82%B9%E6%80%BB%E7%BB%93/"},{"title":"Codeforces Reverse Sort","text":"​​点击阅读更多查看文章内容 B. Reverse Sort第一次打codeforces，就做了一道签到题，这道题在看的时候以为挺简单的，看到好多人都出来了，自己想了好久也没做出来，还是看了大佬的解法才有的思路，我还是太菜了。 题目：大概意思就是给一个01字符串，每次操作可以从中选一个子串做一个翻转然后放回原来的位置，问最小经过几次操作可以让字符串变为非递减的字符串（0都在1的前面） 分析总可以通过一次操作解决（太妙了，当时没想到，我是废物）我们可以对字符串的0,1进行一个统计，总可以找到一个位置，使得这个位置之前的1的数目等于这个位置之后的0的数目。例如：101丨00，我们可以从竖线处分开，竖线前的1等于竖线后的0，我们只需要把前面的1和后面的0翻转位置，即可得到非递减的字符串。为什么我们一定能找到这样一个位置呢？我们假设一个位置，在此位置前面的1的数目大于后面的0的数目，那么我们只要把当前位置往前移，如果前面一个是1，那么前面1的数目会减少，后面0的数目不变，如果前面一个是0，那么后面0的数目会增加，前面1的数目不变，由此每向前移动一步，两者之间的差距会减一，当差距减到0的时候，即为要求的位置。 代码先上我自己写的超复杂版用两个vector分别记录1.从前往后在当前点之前1的数目2.从后往前在当前点之后0的数目然后用flag标记有没有找到上述的位置如果没有则已经有序，直接输出0即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;iostream&gt;#include &lt;stack&gt;#include &lt;math.h&gt;#include &lt;vector&gt;using namespace std;int main(){ string s; int n; int T; cin &gt;&gt; T; while (T--) { cin &gt;&gt; n; cin &gt;&gt; s; vector&lt;int&gt; cnt1(n, 0); vector&lt;int&gt; cnt0(n, 0); int len = n; int i; bool flag = false; for (i = 0; i &lt; len; i++) { if (s[i] == '1') { if (i == 0) cnt1[i] = 1; else cnt1[i] = cnt1[i - 1] + 1; } else if (i != 0) cnt1[i] = cnt1[i - 1]; } for (i = len - 1; i &gt;= 0; i--) { if (s[i] == '0') { if (i == len - 1) cnt0[i] = 1; else cnt0[i] = cnt0[i + 1] + 1; } else if (i != len - 1) cnt0[i] = cnt0[i + 1]; } for (i = 1; i &lt; len; i++) { if (cnt1[i - 1] != 0 &amp;&amp; cnt1[i - 1] == cnt0[i]) { cout &lt;&lt; 1 &lt;&lt; endl; flag = true; cout &lt;&lt; cnt1[i - 1] * 2 &lt;&lt; &quot; &quot;; for (int j = 0; j &lt;= i - 1; j++) { if (s[j] == '1') cout &lt;&lt; j + 1 &lt;&lt; &quot; &quot;; } for (int j = i; j &lt; len; j++) { if (s[j] == '0') cout &lt;&lt; j + 1 &lt;&lt; &quot; &quot;; } cout &lt;&lt; endl; break; } } if (!flag) cout &lt;&lt; 0 &lt;&lt; endl; } return 0;} 再上一个大佬的超简单版代码来源 12345678910111213141516171819void solve(){ int n;cin&gt;&gt;n; char c[n+1]; cin&gt;&gt;c; vector&lt;int&gt; v; for(int i=0;i&lt;n;i++) { if(count(c, c+i, '1') == 0) continue; if(count(c, c+i, '1') == count(c+i, c+n, '0')) { cout&lt;&lt;1&lt;&lt;'\\n'&lt;&lt;2*count(c, c+i, '1')&lt;&lt;&quot; &quot;; for(int j=0;j&lt;i;j++) if(c[j] == '1') cout&lt;&lt;j+1&lt;&lt;&quot; &quot;; for(int j=i;j&lt;n;j++) if(c[j] == '0') cout&lt;&lt;j+1&lt;&lt;&quot; &quot;; cout&lt;&lt;'\\n'; return; } } cout&lt;&lt;0&lt;&lt;'\\n';}","link":"/2021/11/14/Codeforces%20Reverse%20Sort/"},{"title":"CSP 202112-3 登机牌条码 （100分详细图解）","text":"​​点击阅读更多查看文章内容 CSP 202112-3 登机牌条码 更新：2023-5-15感谢这位同学提出的代码错误，经过改正后，已经可以满分通过了，博客中出现的相应代码也都改正过了，可以直接提交 题目链接 大模拟做这类题首先一定要读懂题目，这种题往往不会有什么很高深的算法，就是对整个过程的一个模拟，一定要完全理解了题目的整个内容之后再开始写代码 题目整体可以分为两部分，第一部分是求数据码字，第二部分是求校验码，其中数据码字比较好求，看懂题目跟着题目走就可以了，求出数据码字就可以水40分了，后面的难点在于求校验码，这里我的代码只拿到了60分，但没有找到出错的地方，下面给大家详细写一下我的思路，希望能帮助到大家，如果大家找出了我代码中的错误，还请不吝赐教。 数据码字的求解求数据码字就是给你一个字符串然后对其进行一个编码，其中各个字符所对应的值题目中都已经给出了，唯一需要注意的点就是三种模式的切换。 首先可以先写一个transmode函数用来进行三种模式的切换 12345678910111213141516171819202122232425262728void transmode(vector&lt;int&gt; &amp;vec, int &amp;oldm, int newm){ if (oldm == 1) { if (newm == 2) vec.push_back(27); if (newm == 3) vec.push_back(28); } if (oldm == 2) { if (newm == 1) { vec.push_back(28); vec.push_back(28); } if (newm == 3) vec.push_back(28); } if (oldm == 3) { if (newm == 1) vec.push_back(28); if (newm == 2) vec.push_back(27); } oldm = newm;} 有了模式切换之后就可以对字符串进行一个初步的编码，定义一个mode变量用来保存当前的模式，遍历字符串，首先切换到当前字符的模式，然后加入字符的编码即可，最后注意是否需要填充字符，全部字符转换完成后，按照题目要求两两一组计算码字即可 12345678910111213141516171819202122232425262728293031323334353637vector&lt;int&gt; bianma(string s){ vector&lt;int&gt; ret; int mode = 1; //当前模式：1：大写；2：小写；3：数字 for (char c : s) { if (isupper(c)) //大写字母 { //将模式换为大写 if (mode != 1) transmode(ret, mode, 1); ret.push_back(c - 'A'); } if (islower(c)) //小写字母 { //将模式换为小写 if (mode != 2) transmode(ret, mode, 2); ret.push_back(c - 'a'); } if (isdigit(c)) //数字 { if (mode != 3) transmode(ret, mode, 3); ret.push_back(c - '0'); } } if (ret.size() % 2 != 0) ret.push_back(29); vector&lt;int&gt; mazi; for (int i = 0; i &lt; ret.size(); i += 2) { int temp = 30 * ret[i] + ret[i + 1]; mazi.push_back(temp); } return mazi;} 得到码字之后，我们还需要计算数据码字，这里首先求出校验码字的个数（不需要求出），然后求出总数据所占的行数，并进一步求出填充字符的个数，以及数据码字的长度，与原码字组合得到最终的数据码字 123456789101112131415161718vector&lt;int&gt; getsjmz(vector&lt;int&gt; mazi, int w, int s){ int jycnt = 0; if (s != -1) jycnt = pow(2, s + 1); int cnt = 1 + mazi.size() + jycnt; int line = ceil(double(cnt) / w); int tccnt = w * line - cnt; int len = w * line - jycnt; vector&lt;int&gt; ret; ret.push_back(len); for (int i : mazi) ret.push_back(i); for (int i = 0; i &lt; tccnt; i++) ret.push_back(900); return ret;} 校验和的求解求出数据码字后，我们就要开始校验和的求解了，这是本题的难点所在 首先我们先明确一个概念：通过向量来表示多项式，向量的下标是x的幂，对应的值为x的系数，例如向量{1,-2,3}所表达的多项式是：1-2x+3x^2^ 明确了这个概念后我们就可以开始求解校验和了，我们将校验和的求解分成两部分，一是求解g(x)和d(x)多项式，二是进行多项式的取模运算求出r(x) 求解多项式题目中给出：g(x)=(x-3)(x-3^2^)…(x-3^k^)我们先计算第一个(x-3)*(x-3^2^) 这里我们首先通过乘法的分配律将其改写为(x-3)*x+(x-3)*(-3^2^)， 首先计算(x-3)*x，x-3对应的向量是{-3,1}，(x-3)*x的结果为x^2^-3x，即{0,-3,1}。到这里大家应该看出规律了吧，一个多项式乘上x^n^，对应的结果就是向量向右移动n个位置，低位补0。 然后我们计算(x-3)*(-3^2^)，多项式运算的结果为-9x+27，对应的向量由{-3,1}变为{27,-9}即在原来的基础上乘上-9,由此我们又可以得出规律，一个多项式乘上一个系数，对应的结果就是向量的各位同时乘上这个系数 然后我们将这两个结果得到的向量相加最终得到{27,-12,1}，对应的多项式为x^2^-12x+27，正是多项式运算的结果 下面通过一个手写版的可能更好看一些 1234567891011121314151617181920212223242526272829303132333435363738//计算g(x)//计算g(x)vector&lt;int&gt; calcgx(int k){ vector&lt;int&gt; gx(k + 1, 0); // gx[i]表示x的i次方的系数 //初始值为x-3 gx[1] = 1; gx[0] = -3; int A = -9; //初始值依次乘(x-3^i) for (int i = 2; i &lt;= k; i++) { // temp保存原数组的值，将修改加到gx上 vector&lt;int&gt; temp; temp.assign(gx.begin(), gx.end()); //整个数组向前推进一位 gx[0] = 0; for (int j = 1; j &lt;= k; j++) gx[j] = temp[j - 1] % 929; //整个数组都乘上-3^i，并将结果相加 for (int j = 0; j &lt;= k; j++) { temp[j] = (temp[j] * A) % 929; gx[j] = (gx[j] + temp[j]) % 929; } A = (A * 3) % 929; } return gx;}//计算d(x)vector&lt;int&gt; calcdx(vector&lt;int&gt; sjmz){ vector&lt;int&gt; ret; for (int i = sjmz.size() - 1; i &gt;= 0; i--) ret.push_back(sjmz[i]); return ret;} 多项式取模通过上面的方法，我们依次求出x^k^d(x)记为kd(x)以及g(x)后，就要计算kdx模gx的余数 这里我们以模拟竖式的方法来计算，通过下图我们可以将计算分为几个步骤 将除数乘上一个系数，使得被除数减除数之后能消掉最高位 被除数减除数 得到的结果继续按照第一步的方法计算，直到最终结果的最高位小于除数 知道如何计算之后，我们将对多项式的运算换成对向量的运算就可以了，具体过程如下： 12345678910111213141516171819202122232425262728293031323334353637383940//计算校验码vector&lt;int&gt; calcjx(int k, vector&lt;int&gt; sjmz){ // g(x) vector&lt;int&gt; gx = calcgx(k); // d(x) vector&lt;int&gt; dx = calcdx(sjmz); // x^k*d(x);整个数组向前推进x位 vector&lt;int&gt; kdx(dx.size() + k, 0); for (int i = 0; i &lt; dx.size(); i++) kdx[i + k] = dx[i] % 929; //计算kdx模gx的余数 int lenkdx = kdx.size(); int lengx = gx.size(); while (lenkdx &gt;= lengx) { int xs = (kdx[lenkdx - 1] / gx[lengx - 1]) % 929; int idx = 0; for (int i = lenkdx - lengx; i &lt; lenkdx; i++) kdx[i] -= (gx[idx++] % 929 * xs % 929) % 929; lenkdx--; } vector&lt;int&gt; ret; ret.assign(sjmz.begin(), sjmz.end()); int i = lengx - 2; //去掉头部的0 while (kdx[i] == 0) i--; for (; i &gt;= 0; i--) { kdx[i] = (-kdx[i]) % 929; if (kdx[i] &lt; 0) kdx[i] += 929; ret.push_back(kdx[i]); } return ret;} 至此这道题目的各种方法都已经实现完成了，下面放上题目的全部代码，再强调一下，这个代码只有60分，如果大家看完我的方法，发现有什么错误或是不妥的地方，还请不吝赐教。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179#include &lt;bits/stdc++.h&gt;using namespace std;void transmode(vector&lt;int&gt; &amp;vec, int &amp;oldm, int newm){ if (oldm == 1) { if (newm == 2) vec.push_back(27); if (newm == 3) vec.push_back(28); } if (oldm == 2) { if (newm == 1) { vec.push_back(28); vec.push_back(28); } if (newm == 3) vec.push_back(28); } if (oldm == 3) { if (newm == 1) vec.push_back(28); if (newm == 2) vec.push_back(27); } oldm = newm;}vector&lt;int&gt; bianma(string s){ vector&lt;int&gt; ret; int mode = 1; //当前模式：1：大写；2：小写；3：数字 for (char c : s) { if (isupper(c)) //大写字母 { //将模式换为大写 if (mode != 1) transmode(ret, mode, 1); ret.push_back(c - 'A'); } if (islower(c)) //小写字母 { //将模式换为小写 if (mode != 2) transmode(ret, mode, 2); ret.push_back(c - 'a'); } if (isdigit(c)) //数字 { if (mode != 3) transmode(ret, mode, 3); ret.push_back(c - '0'); } } if (ret.size() % 2 != 0) ret.push_back(29); vector&lt;int&gt; mazi; for (int i = 0; i &lt; ret.size(); i += 2) { int temp = 30 * ret[i] + ret[i + 1]; mazi.push_back(temp); } return mazi;}vector&lt;int&gt; getsjmz(vector&lt;int&gt; mazi, int w, int s){ int jycnt = 0; if (s != -1) jycnt = pow(2, s + 1); int cnt = 1 + mazi.size() + jycnt; int line = ceil(double(cnt) / w); int tccnt = w * line - cnt; int len = w * line - jycnt; vector&lt;int&gt; ret; ret.push_back(len); for (int i : mazi) ret.push_back(i); for (int i = 0; i &lt; tccnt; i++) ret.push_back(900); return ret;}//计算g(x)vector&lt;int&gt; calcgx(int k){ vector&lt;int&gt; gx(k + 1, 0); // gx[i]表示x的i次方的系数 //初始值为x-3 gx[1] = 1; gx[0] = -3; int A = -9; //初始值依次乘(x-3^i) for (int i = 2; i &lt;= k; i++) { // temp保存原数组的值，将修改加到gx上 vector&lt;int&gt; temp; temp.assign(gx.begin(), gx.end()); //整个数组向前推进一位 gx[0] = 0; for (int j = 1; j &lt;= k; j++) gx[j] = temp[j - 1] % 929; //整个数组都乘上-3^i，并将结果相加 for (int j = 0; j &lt;= k; j++) { temp[j] = (temp[j] * A) % 929; gx[j] = (gx[j] + temp[j]) % 929; } A = (A * 3) % 929; } return gx;}//计算d(x)vector&lt;int&gt; calcdx(vector&lt;int&gt; sjmz){ vector&lt;int&gt; ret; for (int i = sjmz.size() - 1; i &gt;= 0; i--) ret.push_back(sjmz[i]); return ret;}//计算校验码vector&lt;int&gt; calcjx(int k, vector&lt;int&gt; sjmz){ // g(x) vector&lt;int&gt; gx = calcgx(k); // d(x) vector&lt;int&gt; dx = calcdx(sjmz); // x^k*d(x);整个数组向前推进x位 vector&lt;int&gt; kdx(dx.size() + k, 0); for (int i = 0; i &lt; dx.size(); i++) kdx[i + k] = dx[i] % 929; //计算kdx模gx的余数 int lenkdx = kdx.size(); int lengx = gx.size(); while (lenkdx &gt;= lengx) { int xs = (kdx[lenkdx - 1] / gx[lengx - 1]) % 929; int idx = 0; for (int i = lenkdx - lengx; i &lt; lenkdx; i++) kdx[i] -= (gx[idx++] % 929 * xs % 929) % 929; lenkdx--; } vector&lt;int&gt; ret; ret.assign(sjmz.begin(), sjmz.end()); int i = lengx - 2; while (kdx[i] == 0) i--; for (; i &gt;= 0; i--) { kdx[i] = (-kdx[i]) % 929; if (kdx[i] &lt; 0) kdx[i] += 929; ret.push_back(kdx[i]); } return ret;}int main(){ int w, s; string str; cin &gt;&gt; w &gt;&gt; s &gt;&gt; str; int k = pow(2, s + 1); vector&lt;int&gt; mazi = bianma(str); vector&lt;int&gt; sjmz = getsjmz(mazi, w, s); //计算校验码 if (s != -1) sjmz = calcjx(k, sjmz); for (int i : sjmz) cout &lt;&lt; i &lt;&lt; endl; system(&quot;pause&quot;); return 0;}","link":"/2022/03/11/CSP%20202112-3%20%E7%99%BB%E6%9C%BA%E7%89%8C%E6%9D%A1%E7%A0%81%20%EF%BC%88100%E5%88%86%E8%AF%A6%E7%BB%86%E5%9B%BE%E8%A7%A3%EF%BC%89/"},{"title":"Docker详解","text":"​​点击阅读更多查看文章内容 什么是Docker在认识Docker之前，我们要先学习一下什么是容器？ 什么是容器？不知道大家有没有遇到过，有的时候同样的代码在你的主机上能运行，但是移动到另一台主机上就会报错，究其原因是因为两台主机的运行环境不同。那么我们有没有一种方法，可以在移动代码的时候连同代码的运行环境也一起移动，这样在运行代码的时候就不需要考虑运行环境的问题了。 这种方法就是——容器技术，简单地说，一个容器包含了完整的运行时环境：除了应用程序本身之外，这个应用所需的全部依赖、类库、其他二进制文件、配置文件等，都统一被打入了一个称为容器镜像的包中。通过将应用程序本身和其依赖容器化，操作系统发行版本和其他基础环境造成的差异，都被抽象掉了。 容器在宿主机操作系统中，在用户空间以分离的进程运行。容器技术是实现操作系统虚拟化的一种途径，可以让您在资源受到隔离的进程中运行应用程序及其依赖关系。 容器实际上就是一种资源隔离的进程 注意容器和虚拟化不同虚拟化使得许多操作系统可同时在单个系统上运行。容器则可共享同一个操作系统内核，将应用进程与系统其他部分隔离开。 说完了容器我们就该回到Docker了Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。简单来讲， Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离，相当于是在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker ，就不用担心环境问题。总体来说， Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker的架构Docker的三个基本概念 Image（镜像）：镜像（Image）可以看作是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 Container（容器）：镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 Repository（仓库）：仓库可看成一个代码控制中心，用来保存镜像。 概念 说明 Docker 镜像(Image) 用来创建Docker容器的模板 Docker 容器(Container) 镜像运行的实体 Docker 客户端(Client) 通过命令行或其它工具与Docker的守护进程(daemon)通信 Docker 主机(Host) 一个物理或实体机器用于执行Docker的守护进程和容器 Docker Registry 用来保存Docker镜像，可以理解为代码控制中的代码仓库，一个 Docker Registry 中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 Docker Machine Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。 Docker容器内容 文件系统：容器内有自己的文件系统，通常是镜像中的文件系统，容器内部的文件系统与宿主机是隔离的，但它会共享宿主机的内核。 运行的应用程序：容器内部运行的就是你所指定的应用程序或服务。例如，可能是一个 Web 服务器、数据库、API 服务等。这些应用程序是根据容器镜像中定义的配置启动的。 环境变量：容器通常会设置一些环境变量，这些环境变量可以在容器内部的应用程序中使用。例如，数据库的连接字符串、端口号、API 密钥等。 网络配置：容器内有自己的网络接口，通常通过 Docker 的网络模式（如 bridge, host, overlay）与宿主机或其他容器通信。容器内部可以设置特定的 IP 地址和端口号。容器与宿主机之间的通信是通过 Docker 的端口映射来完成的。 进程与 PID 空间：容器内会启动应用程序进程，每个容器都有独立的进程空间，意味着容器内的进程与宿主机或其他容器的进程是隔离的。容器内部的进程是从容器镜像启动的，并且它们的进程 ID（PID）与宿主机的 PID 不冲突。 日志与输出：容器内的应用程序会产生日志和标准输出。这些日志通常会被 Docker 收集，并可以通过 docker logs 命令查看。如果你没有显式地挂载日志文件到宿主机，日志仅存在于容器内部。 卷 (Volumes)：如果容器需要持久化数据，Docker 卷可以用来将宿主机或外部存储挂载到容器内部。容器对数据卷的访问不会随着容器的删除而丢失。容器内的数据可以通过 挂载卷（如宿主机的文件夹或外部存储）来进行共享和持久化。 Docker容器的使用在启动docker容器后一般通过两种方式使用 直接进入docker容器内部进行交互docker exec -it my-container bash 通过端口映射，在宿主机中访问容器的服务docker run -d -p 8080:80 --name my-container nginx，假设在启动容器时配置了端口映射8080:80，这样可以通过访问宿主机的8080端口来使用docker内监听在80端口上的服务程序 Docker常用命令基础命令 启动Docker systemctl start docker 关闭Dockersystemctl stop docker 查看Docker状态systemctl status docker 镜像命令 列出本机镜像docker images 拉取镜像到本地不加tag即拉取该镜像的最新版本latest，加tag则是拉取该镜像的指定版本，版本号可以在docker hub中查看docker pull 镜像名docker pull 镜像名:tag 查找镜像从docker hub中查找满足要求的镜像，然后可以从中选择合适的镜像下载docker search 镜像名 运行镜像docker run 镜像名(:Tag) 删除镜像docker image rm 镜像名-f 强制删除 设置镜像标签docker tag 镜像名/镜像ID 镜像名:TAG 容器命令 查看正在运行的容器列表docker ps-a 查看所有容器（包括已停止的） 启动一个新的容器docker run -it 镜像名 /bin/bash-i:交互式操作-t:终端-d:指定容器的运行模式，默认不会进入容器/bin/bash:放在镜像后的是命令，这里我们希望有个交互式的Shell，因此用的是/bin/bash 停止容器docker stop 容器名/容器ID 启动已停止的容器docker start 容器名/容器ID 删除容器docker rm -f 容器名/容器ID 进入容器docker exec -it 容器名/容器ID /bin/bash 退出终端exit dockerfiledockfile是一个用于制作docker镜像的源码文件，内容是构建镜像过程的指令，在一个文件夹中，如果有一个名字为Dockfile的文件，其内容满足语法要求，在这个文件夹路径下执行命令:docker build –tag name:tag .，就可以按照描述构建一个镜像了。name是镜像的名称，tag是镜像的版本或者是标签号，不写就是lastest。注意后面有一个空格和点。dockerfile的使用详解 docker-composeCompose是用于定义和运行多容器Docker应用程序的工具。通过Compose，可以使用YAML文件来配置应用程序的服务。然后使用一个命令，就可以从配置中创建并启动所有服务。Docker-Compose是一个容器编排工具，将所有的容器的部署方法、文件映射、容器端口映射等情况写在一个.yml或.yaml文件里，执行docker-compose up命令就像执行脚本一样，一个一个的安装并部署容器。 docker-compose将所管理的容器分为三层：工程（project）：docker compose运行目录下的所有yml文件服务（service）：一个工程包含多个服务，每个服务中定义了容器运行的镜像、参数、依赖。容器（container）：一个服务可包括多个容器实例，所有的容器都通过services来定义 示例： 12345678910version: &quot;3&quot; //指定语法的格式的版本services: //定义服务 nginx: //服务的名称 container_name: web-nginx //容器的名称 image: nginx:latest //所使用的镜像 restart: always //随docker服务的启动而启动 ports: - 80:80 //映射的端口 volumes: - /root/compose/webserver:/usr/share/nginx/html //本地与容器挂载的目录 docker-compose详解常用服务配置参考","link":"/2022/04/26/Docker%E8%AF%A6%E8%A7%A3/"},{"title":"Goland连接服务器&#x2F;虚拟机远程编译开发","text":"​​点击阅读更多查看文章内容 创建SSH连接 SSH用于与远程服务器建立连接 Settings -&gt; Tools -&gt; SSH Configurations添加新的ssh连接，Host为ip地址，Username为用户名，认证方式这里选择密码验证全部填完后可以点击Test Connection测试连接是否成功 创建Deployment Deployment用于构建本地与远程服务器的路径映射 Settings -&gt; Build,Execution,Deployment -&gt; Deployment添加新的Deployment，Type选择SFTP，SSH选择刚刚配置的SSH连接，根目录，URL如图所示选择Mappings设置路径映射，Local path为项目本地目录，Deployed path是在远程服务器上的目录将本地的文件上传到服务器设置每次保存文件时都上传到服务器，在删除本地文件时也同步删除服务器文件 使用服务器环境编译 有的时候我们本地的环境与服务器不一致，导致项目在本地无法运行，在配置完上述步骤后可以修改为在服务器上进行编译 在Run/Debug Configurations中将Run on设置为ssh连接的服务器，同时勾选Build on remote target","link":"/2023/10/30/Goland%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8!%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%9C%E7%A8%8B%E7%BC%96%E8%AF%91%E5%BC%80%E5%8F%91/"},{"title":"Go语言http标准库","text":"​​点击阅读更多查看文章内容 Go语言http标准库 使用http客户端发送请求 使用http.Client控制请求头部 使用httputil简化工作 示例代码 1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;fmt&quot; &quot;net/http&quot; &quot;net/http/httputil&quot;)func main() { request, err := http.NewRequest( http.MethodGet, &quot;http://www.imooc.com&quot;, nil, ) client := http.Client{ CheckRedirect: func( req *http.Request, via []*http.Request) error { fmt.Println(&quot;Redirect:&quot;, req) return nil }, } request.Header.Add(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/10.0 Mobile/14E304 Safari/602.1&quot;) resp, err := client.Do(request) if err != nil { panic(err) } defer resp.Body.Close() s, err := httputil.DumpResponse(resp, true) if err != nil { panic(err) } fmt.Printf(&quot;%s\\n&quot;, s)} http服务器的性能分析 import _ “net/http/pprof”前面加下划线表示虽然没有用到但要load其中一些帮助程序进来 访问/debug/pprof/ 使用go tool pprof分析性能点开net/http/pprof的帮助文档，根据文档来写 查看服务器有关信息查看内存占用 JSON数据格式 结构体的tag用来处理字段名 json的marshal与Unmarshal，用来转换json格式 注意不能直接将属性名改为小写，go语言中小写为private不会显示 示例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot;)type OrderItem struct { ID string `json:&quot;id&quot;` Name string `json:&quot;name&quot;` Price float64 `json:&quot;price&quot;`}//不能直接将属性名改为小写，go语言中小写为private不会显示//可以通过打标签的方式更改json中的属性名//omitempty当属性为空时不显示，如果不加omitempty会显示一个空字段type Order struct { ID string `json:&quot;id&quot;` Items []OrderItem `json:&quot;items&quot;` TotalPrice float64 `json:&quot;total_price&quot;`}func main() { unmarshal()}func marshal() { o := Order{ ID: &quot;1234&quot;, TotalPrice: 20, Items: []OrderItem{ { ID: &quot;item_1&quot;, Name: &quot;learn go&quot;, Price: 15, }, { ID: &quot;item_2&quot;, Name: &quot;interview&quot;, Price: 10, }, }, } b, err := json.Marshal(o) if err != nil { panic(err) } fmt.Printf(&quot;%s\\n&quot;, b)}func unmarshal() { s := `{&quot;id&quot;:&quot;1234&quot;,&quot;items&quot;:[{&quot;id&quot;:&quot;item_1&quot;,&quot;name&quot;:&quot;learn go&quot;,&quot;price&quot;:15},{&quot;id&quot;:&quot;item_2&quot;,&quot;name&quot;:&quot;interview&quot;,&quot;price&quot;:10}],&quot;total_price&quot;:20}` var o Order err := json.Unmarshal([]byte(s), &amp;o) if err != nil { panic(err) } fmt.Printf(&quot;%+v\\n&quot;, o)} gin框架 middleware的使用通过middleware注册一些函数，所有的请求都会经过middleware context的使用关于请求的所有信息，可以自己添加一些key-value 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( &quot;github.com/gin-gonic/gin&quot; &quot;go.uber.org/zap&quot; &quot;math/rand&quot; &quot;time&quot;)func main() { r := gin.Default() logger, err := zap.NewProduction() if err != nil { panic(err) } //middleware const keyRequestId = &quot;requestId&quot; r.Use(func(c *gin.Context) { s := time.Now() c.Next() // path,status,log latency logger.Info(&quot;incoming request&quot;, zap.String(&quot;path&quot;, c.Request.URL.Path), zap.Int(&quot;status&quot;, c.Writer.Status()), zap.Duration(&quot;elapsed&quot;, time.Now().Sub(s))) }, func(c *gin.Context) { //可以在middleware中往context里面塞东西，在具体的handler中拿东西 c.Set(keyRequestId, rand.Int()) c.Next() }) //handler 处理对应的路径 r.GET(&quot;/ping&quot;, func(c *gin.Context) { h := gin.H{ &quot;message&quot;: &quot;pong&quot;, } if rid, exists := c.Get(keyRequestId); exists { h[keyRequestId] = rid } c.JSON(200, h) }) r.GET(&quot;/hello&quot;, func(c *gin.Context) { c.String(200, &quot;hello&quot;) }) r.Run() // listen and serve on 0.0.0.0:8080 (for windows &quot;localhost:8080&quot;)}","link":"/2022/01/30/Go%E8%AF%AD%E8%A8%80http%E6%A0%87%E5%87%86%E5%BA%93/"},{"title":"Golang 信息采集","text":"​​点击阅读更多查看文章内容 Golang信息采集 项目完整内容及使用方法已上传至GitHub，点击传送门即可查看 Go语言的部分硬件信息采集可以通过gopsutil库来实现gopsutil库是python中的psutil库在Golang上的移植版，主要用于收集主机的各种信息，包括网络信息，进程信息，硬件信息等项目地址官方文档具体的引用方法网上有很多教程，这里不再赘述 还有一部分linux信息的采集通过调用linux的命令，经过管道回显实现的具体使用方法 输出形式均为JSON文件 设备信息通过调用linux的dmidecode命令获取设备信息，然后经过管道获取回显，放到bytes内，输出。此命令需要管理员权限 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot; &quot;strings&quot;)func executive_DeviceOrder(attr string) []byte { //name 设备名 //manufacturer 设备厂商 //serial_number 设备编码 //version 设备型号 var cmd *exec.Cmd if attr == &quot;name&quot; { cmd = exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;sudo dmidecode -s system-product-name&quot;) } else if attr == &quot;manufacturer&quot; { cmd = exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;sudo dmidecode -s system-manufacturer&quot;) } else if attr == &quot;serial_number&quot; { cmd = exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;sudo dmidecode -s system-serial-number&quot;) } else if attr == &quot;version&quot; { cmd = exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;sudo dmidecode -s system-version&quot;) } else { fmt.Println(&quot;输入有误！&quot;) return nil } //创建获取命令输出管道 stdout, err := cmd.StdoutPipe() if err != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err) return nil } //执行命令 if err := cmd.Start(); err != nil { fmt.Println(&quot;Error:The command is err&quot;, err) return nil } //读取所有输出 bytes, err := ioutil.ReadAll(stdout) if err != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err.Error()) return nil } if err := cmd.Wait(); err != nil { fmt.Println(&quot;wait:&quot;, err.Error()) return nil } return bytes //fmt.Printf(&quot;stdout:\\n\\n%s&quot;, bytes)}type Device struct { Name string `json:&quot;name&quot;` Manufacturer string `json:&quot;manufacturer&quot;` SerialNumber string `json:&quot;serial_number&quot;` Version string `json:&quot;version&quot;`}func Getdevice() { //name 设备名 //manufacturer 设备厂商 //serial_number 设备编码 //version 设备型号 name := string(executive_DeviceOrder(&quot;name&quot;)) manu := string(executive_DeviceOrder(&quot;manufacturer&quot;)) numb := string(executive_DeviceOrder(&quot;serial_number&quot;)) version := string(executive_DeviceOrder(&quot;version&quot;)) //去掉末尾换行符 name = strings.TrimRight(name, &quot;\\n&quot;) manu = strings.TrimRight(manu, &quot;\\n&quot;) numb = strings.TrimRight(numb, &quot;\\n&quot;) version = strings.TrimRight(version, &quot;\\n&quot;) device := Device{ Name: name, Manufacturer: manu, SerialNumber: numb, Version: version, } deviceJson, err := json.Marshal(device) if err != nil { panic(err) } WriteFile(&quot;device.json&quot;, deviceJson)} CPU1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//获得CPU有关信息package mainimport ( &quot;encoding/json&quot; &quot;github.com/shirou/gopsutil/cpu&quot; &quot;time&quot;)type Cpu struct { Info []cpu.InfoStat `json:&quot;info&quot;` LogicalCount int `json:&quot;logical_count&quot;` PhysicalCount int `json:&quot;physical_count&quot;` Usage []float64 `json:&quot;usage&quot;` Time []cpu.TimesStat `json:&quot;time&quot;`}func getCpu() { //cpu基本信息 cpuInfos, err := cpu.Info() if err != nil { panic(err) } //cpu数量;true逻辑核心数量，false物理核心数量 cpuLogicalCount, err := cpu.Counts(true) if err != nil { panic(err) } cpuPhysicalCount, err := cpu.Counts(false) if err != nil { panic(err) } //cpu利用率;true为每个cpu，false为总的cpu cpuUsage, err := cpu.Percent(time.Second, true) if err != nil { panic(err) } //cpu有关时间信息;true为每个cpu，false为总的cpu cpuTime, err := cpu.Times(true) cpu := Cpu{ Info: cpuInfos, LogicalCount: cpuLogicalCount, PhysicalCount: cpuPhysicalCount, Usage: cpuUsage, Time: cpuTime, } cpuJson, err := json.Marshal(cpu) if err != nil { panic(err) } WriteFile(&quot;cpu.json&quot;, cpuJson)} 通过读取/proc/cpuinfo获取CPU的有关信息 cpu基本信息输出各项的含义：processor ：系统中逻辑处理核的编号。对于单核处理器，则课认为是其CPU编号，对于多核处理器则可以是物理核、或者使用超线程技术虚拟的逻辑核vendor_id ：CPU制造商cpu family ：CPU产品系列代号model ：CPU属于其系列中的哪一代的代号model name：CPU属于的名字及其编号、标称主频stepping ：CPU属于制作更新版本cpu MHz ：CPU的实际使用主频cache size ：CPU二级缓存大小physical id ：单个CPU的标号siblings ：单个CPU逻辑物理核数core id ：当前物理核在其所处CPU中的编号，这个编号不一定连续cpu cores ：该逻辑核所处CPU的物理核数apicid ：用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续fpu ：是否具有浮点运算单元（Floating Point Unit）fpu_exception ：是否支持浮点计算异常cpuid level ：执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容wp ：表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection）flags ：当前CPU支持的功能bogomips ：在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second）clflush size ：每次刷新缓存的大小单位cache_alignment ：缓存地址对齐单位address sizes ：可访问地址空间位数power management ：对能源管理的支持，有以下几个可选支持功能： ts： temperature sensor fid： frequency id control vid： voltage id control ttp： thermal trip tm： stc： 100mhzsteps： hwpstate：CPU信息中flags各项含义：fpu： Onboard (x87) Floating Point Unitvme： Virtual Mode Extensionde： Debugging Extensionspse： Page Size Extensionstsc： Time Stamp Counter: support for RDTSC and WRTSC instructionsmsr： Model-Specific Registerspae： Physical Address Extensions: ability to access 64GB of memory; only 4GB can be accessed at a time thoughmce： Machine Check Architecturecx8： CMPXCHG8 instructionapic： Onboard Advanced Programmable Interrupt Controllersep： Sysenter/Sysexit Instructions; SYSENTER is used for jumps to kernel memory during system calls, and SYSEXIT is used for jumps： back to the user codemtrr： Memory Type Range Registerspge： Page Global Enablemca： Machine Check Architecturecmov： CMOV instructionpat： Page Attribute Tablepse36： 36-bit Page Size Extensions: allows to map 4 MB pages into the first 64GB RAM, used with PSE.pn： Processor Serial-Number; only available on Pentium 3clflush： CLFLUSH instructiondtes： Debug Trace Storeacpi： ACPI via MSRmmx： MultiMedia Extensionfxsr： FXSAVE and FXSTOR instructionssse： Streaming SIMD Extensions. Single instruction multiple data. Lets you do a bunch of the same operation on different pieces of input： in a single clock tick.sse2： Streaming SIMD Extensions-2. More of the same.selfsnoop： CPU self snoopacc： Automatic Clock ControlIA64： IA-64 processor Itanium.ht： HyperThreading. Introduces an imaginary second processor that doesn’t do much but lets you run threads in the same process a bit quicker.nx： No Execute bit. Prevents arbitrary code running via buffer overflows.pni： Prescott New Instructions aka. SSE3vmx： Intel Vanderpool hardware virtualization technologysvm： AMD “Pacifica” hardware virtualization technologylm： “Long Mode,” which means the chip supports the AMD64 instruction settm： “Thermal Monitor” Thermal throttling with IDLE instructions. Usually hardware controlled in response to CPU temperature.tm2： “Thermal Monitor 2″ Decrease speed by reducing multipler and vcore.est： “Enhanced SpeedStep” cpu有关时间输出各项的含义：user:用户态的CPU时间nice：低优先级程序所占用的用户态的cpu时间。system：系统态的CPU时间idle：CPU空闲的时间（不包含IO等待）iowait：等待IO响应的时间irq：处理硬件中断的时间softirq：处理软中断的时间steal:其他系统所花的时间（个人理解是针对虚拟机）guest：运行时间为客户操作系统下的虚拟CPU控制（个人理解是访客控制CPU的时间）guest_nice：低优先级程序所占用的用户态的cpu时间。（访客的） 磁盘1. 获取磁盘分区信息12//获取磁盘分区DiskParti, err := disk.Partitions(false) 2.获取磁盘序列号123456//得到磁盘序列号func GetSerialNumber(name string) string { //获取路径为name的磁盘的序列号 sn := disk.GetDiskSerialNumber(name) return sn} 3.获取磁盘标签12345//得到磁盘标签func GetLabel(name string) string { label := disk.GetLabel(name) return label} 4.获取磁盘使用情况123456789//获取磁盘使用情况func GetUsage(path string) *disk.UsageStat { usage, err := disk.Usage(path) if err == nil { return usage } else { return nil }} 5.获取磁盘IO信息123456789//得到磁盘IO信息func GetIO(name string) map[string]disk.IOCountersStat { IO, err := disk.IOCounters(name) if err == nil { return IO } else { return nil }} 内存获取内存有关信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package mainimport ( &quot;encoding/json&quot; &quot;github.com/shirou/gopsutil/mem&quot;)type Memory struct { SwapMemory *mem.SwapMemoryStat `json:&quot;swap_memory&quot;` VirtualMemory *mem.VirtualMemoryStat `json:&quot;virtual_memory&quot;` VirtualMemoryEx *mem.VirtualMemoryExStat `json:&quot;virtual_memory_ex&quot;`}func getMemory() { swapInfo, err := mem.SwapMemory() if err != nil { panic(err) } memInfo, err := mem.VirtualMemory() if err != nil { panic(err) } memExinfo, err := mem.VirtualMemoryEx() if err != nil { panic(err) } memory := Memory{ SwapMemory: swapInfo, VirtualMemory: memInfo, VirtualMemoryEx: memExinfo, } memoryJson, err := json.Marshal(memory) if err != nil { panic(err) } WriteFile(&quot;Memory.json&quot;, memoryJson)}//获得内存有关信息func GetVirtualMemInfo() *mem.VirtualMemoryStat { memInfo, _ := mem.VirtualMemory() return memInfo}func GetVirtualMemExInfo() *mem.VirtualMemoryExStat { memInfo, _ := mem.VirtualMemoryEx() return memInfo}////func main(){// fmt.Println(GetVirtualMemExInfo())// fmt.Println(GetVirtualMemInfo())//} 包括总内存、已用内存、可用内存、内存占用比例等信息 网卡123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( &quot;encoding/json&quot; &quot;net&quot;)type netInterface struct { Index int `json:&quot;index&quot;` MTU int `json:&quot;mtu&quot;` Name string `json:&quot;name&quot;` HardwareAddr string `json:&quot;hardware_addr&quot;` Flags net.Flags `json:&quot;flags&quot;`}//网络接口信息采集func GetNetInterface() { interfaces, err := net.Interfaces() if err != nil { panic(err) } var netInterfaces []netInterface for _, n := range interfaces { temp := netInterface{ Index: n.Index, MTU: n.MTU, Name: n.Name, HardwareAddr: n.HardwareAddr.String(), Flags: n.Flags, } netInterfaces = append(netInterfaces, temp) } netInterfacesJson, err := json.Marshal(netInterfaces) if err != nil { panic(err) } WriteFile(&quot;NetInterface.json&quot;, netInterfacesJson)} 进程1.获取进程pid12345678//获取进程idfunc ProcessId() (pid []int32) { pids, _ := process.Pids() for _, p := range pids { pid = append(pid, p) } return pid} 2.获取进程名12345678910//获取进程名func ProcessName() (pname []string) { pids, _ := process.Pids() for _, pid := range pids { pn, _ := process.NewProcess(pid) pName, _ := pn.Name() pname = append(pname, pName) } return pname} 3.获取进程的内存占用1234567891011//内存占用func ProcessMemory() (pmemory []string) { pids, _ := process.Pids() for _, pid := range pids { pn, _ := process.NewProcess(pid) pmry, _ := pn.MemoryInfoEx() pMemory := pmry.String() pmemory = append(pmemory, pMemory) } return pmemory} 4. 获取进程的CPU占用12345678910//CPU占用func ProcessCpu() (pcpu []float64) { pids, _ := process.Pids() for _, pid := range pids { pn, _ := process.NewProcess(pid) pCpu, _ := pn.CPUPercent() pcpu = append(pcpu, pCpu) } return pcpu} 日志1.系统日志通过Linux命令行获取系统日志信息，然后经过管道获取回显，放到bytes内，返回。 1234567891011121314151617181920212223242526272829func Syslog() interface{} { //读取系统日志 cmd := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;,&quot;cat /var/log/syslog&quot;) //创建获取命令输出管道 stdout, err := cmd.StdoutPipe() if err != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err) return nil } //执行命令 if err := cmd.Start(); err != nil { fmt.Println(&quot;Error:The command is err,&quot;, err) return nil } //读取所有输出 bytes, err := ioutil.ReadAll(stdout) if err != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err.Error()) return nil } if err := cmd.Wait(); err != nil { fmt.Println(&quot;wait:&quot;, err.Error()) return nil } //返回日志结果，类型为[]byte return bytes } 2.安全日志由于不同版本的Ubuntu中安全日志存放的形式不同，所以这里只查看了auth，回显用户登录信息以及记录通过sudo执行管理员权限的操作。原理同系统日志 12345678910111213141516171819202122232425262728func seculog() interface{}{ //读取安全日志 cmd := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;,&quot;cat /var/log/auth.log&quot;) //创建获取命令输出管道 stdout, err := cmd.StdoutPipe() if err != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err) return nil } //执行命令 if err := cmd.Start(); err != nil { fmt.Println(&quot;Error:The command is err,&quot;, err) return nil } //读取所有输出 bytes, err := ioutil.ReadAll(stdout) if err != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err.Error()) return nil } if err := cmd.Wait(); err != nil { fmt.Println(&quot;wait:&quot;, err.Error()) return nil } //返回安全日志内容 return bytes } 网络信息1.获取本机IP地址1234567891011121314151617181920212223func GetIpAddrs() map[string]string { mpIp := make(map[string]string) //获取网络接口 ifaces, err := net.Interfaces() if err != nil { fmt.Print(fmt.Errorf(&quot;localAddresses: %+v\\n&quot;, err.Error())) return nil } //遍历网络接口 for _, i := range ifaces { addrs, err := i.Addrs() if err != nil { fmt.Print(fmt.Errorf(&quot;localAddresses: %+v\\n&quot;, err.Error())) continue } //获取网络接口的地址 for _, a := range addrs { mpIp[i.Name] = a.String() //fmt.Printf(&quot;%v : %s \\n&quot;, i.Name, a.String()) } } return mpIp} 2.获取本机MAC地址123456789101112131415func GetMacAddrs() map[string]string { mpMac := make(map[string]string) netInterfaces, err := net.Interfaces() if err != nil { panic(err) } for _, netInterface := range netInterfaces { macAddr := netInterface.HardwareAddr.String() if len(macAddr) == 0 { continue } mpMac[netInterface.Name] = macAddr } return mpMac} 3.获取本机网关信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120type rtInfo struct { Dst net.IPNet Gateway, PrefSrc net.IP OutputIface uint32 Priority uint32}type GateWay struct { InterfaceName string `json:&quot;interface_name&quot;` GateWay string `json:&quot;gate_way&quot;` Ip string `json:&quot;ip&quot;`}type routeSlice []*rtInfotype router struct { ifaces []net.Interface addrs []net.IP v4 routeSlice}func getRouteInfo() (*router, error) { rtr := &amp;router{} tab, err := syscall.NetlinkRIB(syscall.RTM_GETROUTE, syscall.AF_INET) if err != nil { return nil, err } msgs, err := syscall.ParseNetlinkMessage(tab) if err != nil { return nil, err } for _, m := range msgs { switch m.Header.Type { case syscall.NLMSG_DONE: break case syscall.RTM_NEWROUTE: rtmsg := (*syscall.RtMsg)(unsafe.Pointer(&amp;m.Data[0])) attrs, err := syscall.ParseNetlinkRouteAttr(&amp;m) if err != nil { return nil, err } routeInfo := rtInfo{} rtr.v4 = append(rtr.v4, &amp;routeInfo) for _, attr:= range attrs { switch attr.Attr.Type { case syscall.RTA_DST: routeInfo.Dst.IP = net.IP(attr.Value) routeInfo.Dst.Mask = net.CIDRMask(int(rtmsg.Dst_len), len(attr.Value)*8) case syscall.RTA_GATEWAY: routeInfo.Gateway = net.IPv4(attr.Value[0], attr.Value[1], attr.Value[2], attr.Value[3]) case syscall.RTA_OIF: routeInfo.OutputIface = *(*uint32)(unsafe.Pointer(&amp;attr.Value[0])) case syscall.RTA_PRIORITY: routeInfo.Priority = *(*uint32)(unsafe.Pointer(&amp;attr.Value[0])) case syscall.RTA_PREFSRC: routeInfo.PrefSrc = net.IPv4(attr.Value[0], attr.Value[1], attr.Value[2], attr.Value[3]) } } } } sort.Slice(rtr.v4, func(i, j int) bool { return rtr.v4[i].Priority &lt; rtr.v4[j].Priority }) ifaces, err := net.Interfaces() if err != nil { return nil, err } for i, iface := range ifaces { if i != iface.Index - 1 { break } if iface.Flags &amp; net.FlagUp == 0{ continue } rtr.ifaces = append(rtr.ifaces, iface) ifaceAddrs, err := iface.Addrs() if err != nil { return nil, err } var addrs net.IP for _, addr := range ifaceAddrs { if inet, ok := addr.(*net.IPNet); ok { if v4 := inet.IP.To4(); v4 != nil { if addrs == nil { addrs = v4 } } } } rtr.addrs = append(rtr.addrs, addrs) } return rtr, nil}func getGateWay() []GateWay { newRoute, err := getRouteInfo() if err != nil { fmt.Println(err) return nil } var gateWays []GateWay for _, rt := range newRoute.v4 { var gateway GateWay if rt.Gateway != nil { gateway.InterfaceName = newRoute.ifaces[rt.OutputIface-1].Name gateway.GateWay = rt.Gateway.String() gateway.Ip = newRoute.addrs[rt.OutputIface-1].String() gateWays = append(gateWays, gateway) } } return gateWays} 防火墙这里的防火墙信息包括iptable和firewall两种防火墙iptables防火墙通过”service iptables status”和”sudo iptables -L”命令来获取其状态和规则firewall防火墙通过”firewall-cmd –state”和”firewall-cmd –list-all”命令来获得其状态和规则其中获取iptables规则以及获取firewall状态的命令需要管理员权限 1. iptables防火墙123456789101112131415161718192021222324252627282930313233343536373839404142434445//iptables防火墙func Getiptables() (string, string) { //iptables防火墙状态 cmd := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;service iptables status&quot;) //iptables防火墙规则 cmd2 := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;sudo iptables -L&quot;) //创建获取命令输出管道 stdout, err := cmd.StdoutPipe() stdout2, err2 := cmd2.StdoutPipe() if err != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err) return &quot;&quot;, &quot;&quot; } if err2 != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err2) return &quot;&quot;, &quot;&quot; } //执行命令 if err := cmd.Start(); err != nil { fmt.Println(&quot;Error:The command is err&quot;, err) return &quot;&quot;, &quot;&quot; } if err2 := cmd2.Start(); err2 != nil { fmt.Println(&quot;Error:The command is err&quot;, err2) return &quot;&quot;, &quot;&quot; } //读取所有输出 bytes, err := ioutil.ReadAll(stdout) bytes2, err2 := ioutil.ReadAll(stdout2) if err != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err.Error()) return &quot;&quot;, &quot;&quot; } if err2 != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err2.Error()) return &quot;&quot;, &quot;&quot; } if err2 := cmd2.Wait(); err2 != nil { fmt.Println(&quot;wait:&quot;, err2.Error()) return &quot;&quot;, &quot;&quot; } return string(bytes), string(bytes2)} 2.firewall防火墙12345678910111213141516171819202122232425262728293031323334353637383940414243//firewall防火墙func Getfirewall() (string, string) { //firewall防火墙状态 cmd := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;firewall-cmd --state&quot;) //firewall防火墙规则 cmd2 := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;firewall-cmd --list-all&quot;) //创建获取命令输出管道 stdout, err := cmd.StdoutPipe() stdout2, err2 := cmd2.StdoutPipe() if err != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err) return &quot;&quot;, &quot;&quot; } if err2 != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err2) return &quot;&quot;, &quot;&quot; } //执行命令 if err := cmd.Start(); err != nil { fmt.Println(&quot;Error:The command is err&quot;, err) return &quot;&quot;, &quot;&quot; } if err2 := cmd2.Start(); err2 != nil { fmt.Println(&quot;Error:The command is err&quot;, err2) return &quot;&quot;, &quot;&quot; } //读取所有输出 bytes, err := ioutil.ReadAll(stdout) bytes2, err2 := ioutil.ReadAll(stdout2) if err != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err.Error()) return &quot;&quot;, &quot;&quot; } if err2 != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err2.Error()) return &quot;&quot;, &quot;&quot; } if err2 := cmd2.Wait(); err2 != nil { fmt.Println(&quot;wait:&quot;, err2.Error()) return &quot;&quot;, &quot;&quot; } return string(bytes), string(bytes2)} 主机、操作系统、内核信息1234567891011121314151617181920212223/*type InfoStat struct { Hostname string `json:&quot;hostname&quot;` Uptime uint64 `json:&quot;uptime&quot;` BootTime uint64 `json:&quot;bootTime&quot;` Procs uint64 `json:&quot;procs&quot;` // number of processes OS string `json:&quot;os&quot;` // ex: freebsd, linux Platform string `json:&quot;platform&quot;` // ex: ubuntu, linuxmint PlatformFamily string `json:&quot;platformFamily&quot;` // ex: debian, rhel PlatformVersion string `json:&quot;platformVersion&quot;` // version of the complete OS KernelVersion string `json:&quot;kernelVersion&quot;` // version of the OS kernel (if available) KernelArch string `json:&quot;kernelArch&quot;` // native cpu architecture queried at runtime, as returned by `uname -m` or empty string in case of error VirtualizationSystem string `json:&quot;virtualizationSystem&quot;` VirtualizationRole string `json:&quot;virtualizationRole&quot;` // guest or host HostID string `json:&quot;hostid&quot;` // ex: uuid}*/func getHostInfo() *host.InfoStat { id, err := host.Info() if err == nil { return id }else{ return nil }} 服务1.获取正在运行的系统服务以及全部系统服务通过Linux命令行获取服务，然后经过管道获取回显，放到bytes内，返回。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot;)type Service struct { RunningService string `json:&quot;running_service&quot;` AllService string `json:&quot;all_service&quot;`}func executive_ServiceOrder(attr string) string { //running:获取正在运行的系统服务 //all:获取全部的系统服务 var cmd *exec.Cmd if attr == &quot;running&quot; { cmd = exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;service --status-all | grep +&quot;) } else if attr == &quot;all&quot; { cmd = exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;service --status-all&quot;) } else { fmt.Println(&quot;输入有误！&quot;) return &quot;&quot; } stdout, err := cmd.StdoutPipe() if err != nil { panic(err) } //执行命令 if err := cmd.Start(); err != nil { panic(err) } //读取所有输出 bytes, err := ioutil.ReadAll(stdout) if err != nil { panic(err) } if err := cmd.Wait(); err != nil { panic(err) } return string(bytes)}func GetService() { //running:获取正在运行的系统服务 //all:获取全部的系统服务 runningService := executive_ServiceOrder(&quot;running&quot;) allService := executive_ServiceOrder(&quot;all&quot;) service := Service{ RunningService: runningService, AllService: allService, } serviceJson, err := json.Marshal(service) if err != nil { panic(err) } WriteFile(&quot;Service.json&quot;, serviceJson)} 流量获取数据量通过Linux命令行进行更新并获取数据量，然后经过管道获取回显，放到bytes内，返回。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot;)type DataAmount struct { DataAmount string `json:&quot;data_amount&quot;`}func GetDataAmount() { cmd1 := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;vnstat -u&quot;) cmd := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;vnstat&quot;) //分别执行更新命令和读取数据量命令 stdout, err := cmd.StdoutPipe() stdout2, err2 := cmd1.StdoutPipe() stdout2 = stdout2 if err != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err) return } if err2 != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err2) return } //执行命令 if err2 := cmd1.Start(); err2 != nil { fmt.Println(&quot;Error:The command is err,&quot;, err2) return } if err := cmd.Start(); err != nil { fmt.Println(&quot;Error:The command is err,&quot;, err) return } //读取所有输出 bytes, err := ioutil.ReadAll(stdout) if err != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err.Error()) return } if err := cmd.Wait(); err != nil { fmt.Println(&quot;wait:&quot;, err.Error()) return } //返回结果 dataAmount := DataAmount{DataAmount: string(bytes)} dataAmountJson, err := json.Marshal(dataAmount) if err != nil { panic(err) } WriteFile(&quot;DataAmount.json&quot;, dataAmountJson)} 应用软件信息分别通过”rpm -qa”、”dpkg -l”、”yum list installed”命令获取deb包、rpm包和yum方法安装的软件的信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot;)type AppInfo struct { DebInstall string `json:&quot;deb_install&quot;` rpmInstall string `json:&quot;rpm_install&quot;` yumInstall string `json:&quot;yum_install&quot;`}func GetAppInfo() { //deb安装 cmd := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;dpkg -l&quot;) //rpm安装 cmd2 := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;rpm -qa&quot;) //yum安装 cmd3 := exec.Command(&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;yum list installed&quot;) //创建获取命令输出管道 stdout, err := cmd.StdoutPipe() stdout2, err2 := cmd2.StdoutPipe() stdout3, err3 := cmd3.StdoutPipe() if err != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err) return } if err2 != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err2) return } if err3 != nil { fmt.Printf(&quot;Error:can not obtain stdout pipe for command:%s\\n&quot;, err3) return } //执行命令 if err := cmd.Start(); err != nil { fmt.Println(&quot;Error:The command is err&quot;, err) return } if err2 := cmd2.Start(); err2 != nil { fmt.Println(&quot;Error:The command is err&quot;, err2) return } if err3 := cmd3.Start(); err3 != nil { fmt.Println(&quot;Error:The command is err&quot;, err3) return } //读取所有输出 bytes, err := ioutil.ReadAll(stdout) bytes2, err2 := ioutil.ReadAll(stdout2) bytes3, err3 := ioutil.ReadAll(stdout3) if err != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err.Error()) return } if err2 != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err2.Error()) return } if err3 != nil { fmt.Println(&quot;ReadAll Stdout:&quot;, err3.Error()) return } if err := cmd.Wait(); err != nil { fmt.Println(&quot;wait:&quot;, err.Error()) return } if err2 := cmd2.Wait(); err2 != nil { fmt.Println(&quot;wait:&quot;, err2.Error()) return } if err3 := cmd3.Wait(); err3 != nil { fmt.Println(&quot;wait:&quot;, err3.Error()) return } appInfo := AppInfo{ DebInstall: string(bytes), rpmInstall: string(bytes2), yumInstall: string(bytes3), } appInfoJson, err := json.Marshal(appInfo) WriteFile(&quot;Application.json&quot;, appInfoJson)}","link":"/2022/01/09/Golang%20%E4%BF%A1%E6%81%AF%E9%87%87%E9%9B%86/"},{"title":"Go语言基础知识1——基础语法","text":"​​点击阅读更多查看文章内容 一、变量变量定义1.使用var关键字定义 变量名在前，变量类型在后 12345678910111213var a,b,c boolvar s1,s2 string=&quot;hello&quot;,&quot;world&quot;//编译器可以自动决定类型var a, b, c, s = 3, 4, true, &quot;def&quot;//使用var()集中定义变量var ( aa = 3 ss =&quot;kkk&quot; bb=true ) 可以放在函数内，也可放在包内，Go语言没有全局变量 2.使用:=定义变量 1a, b, c, s := 3, 4, true, &quot;def&quot; 只能在函数内使用，在包内(函数外)不能使用 变量类型 bool，string (u)int，(u)int8，(u)int16，(u)int32，(u)int64，uintptrGo语言中没有long long类型，用int64可以代替；u代表无符号数 byte，runebyte占8位；rune是字符型相当于char类型，占32位 float32，float64，complex64，complex128complex表示复数，complex64，实部虚部都是float32；complex128，实部虚部都是float64 强制类型转换类型转换是强制的，不存在隐式转换 123var a,b int=3,4var c int = math.Sqrt(a*a+b*b) ×var c int =int(math.Sqrt(float64(a*a+b*b))) √ 二、常量常量定义 使用const关键字用法与var类似，也可使用const()集中定义常量，也可定义在包内 const不定义类型时，可作为各种类型使用，如下：这里a，b不用强制转float 123 const a, b = 3, 4var c intc = int(math.Sqrt(a*a + b*b)) 枚举类型 Go语言没有枚举关键字，通常通过const块来定义 123456const ( cpp = 0 java = 1 python = 2 golang = 3) 可以通过iota实现自增值 123456789101112131415const ( cpp = iota //0 python //1 golang //2 javascript //3)const ( b = 1 &lt;&lt; (10 * iota) //1 kb //1024 mb //1048576 gb //1073741824 tb //1099511627776 pb //1125899906842624) 三、条件语句ifif的条件不需要括号if的条件里可以赋值；赋值的变量作用域就在这个if语句里（赋值语句后加分号，再加判断语句） 12345 if contents, err := ioutil.ReadFile(filename); err != nil { fmt.Println(err)} else { fmt.Printf(&quot;%s\\n&quot;, contents)} switch switch后可以没有表达式case会自动break，除非使用fallthroughcase可以加多个条件 12345678910111213141516func grade(score int) string { g := &quot;&quot; switch { case score &lt; 0 || score &gt; 100: panic(fmt.Sprintf(&quot;Wrong score: %d&quot;, score)) case score &lt; 60: g = &quot;D&quot; case score &lt; 80: g = &quot;C&quot; case score &lt; 90: g = &quot;B&quot; case score &lt;= 100: g = &quot;A&quot; } return g} 四、循环语句for for的条件里不需要括号for的条件里可以省略初始条件，结束条件，递增表达式 整数转二进制，省略初始条件 12345678func convertToBin(n int) string { s := &quot;&quot; for ; n != 0; n /= 2 { t := n % 2 s = strconv.Itoa(t) + s } return s} 省略初始条件和递增条件，相当于while 1234567func main() { i := 1 for i &lt;= 100 { fmt.Println(i) i++ }} 什么都不写，相当于死循环 12345func main() { for { fmt.Println(&quot;abc&quot;) }} 五、函数 与变量定义类似，函数名在前，返回值类型在后 函数可以返回多个值函数返回多个值时可以起名字，比较适用于非常简单的函数，复杂函数体分不清楚返回值何时赋值。多个返回值通常用在返回Error，即一个正确的返回值和一个错误 123456func div(a, b int) (q, r int) { q = a / b r = a % b //return a/b,a%b return} 有多个返回值的函数，只取其中一个返回值时，可以把不需要的返回值使用下划线填充 1q, _ := div(a, b) 函数可以作为参数 1234567891011121314151617func apply(op func(int, int) int, a, b int) int { p := reflect.ValueOf(op).Pointer() opName:=runtime.FuncForPC(p).Name() fmt.Printf(&quot;Calling function %s with args &quot;+ &quot;(%d,%d)\\n&quot;, opName, a, b) return op(a, b)}func pow(a,b int) int { return int(math.Pow(float64(a),float64(b)))}func main() { fmt.Println(apply(pow,3,4))}//输出：//Calling function main.pow with args (3,4)//81//main是包名，pow是函数名 匿名函数 12345678910func main() { fmt.Println(apply( func (a,b int)int{ return int(math.Pow(float64(a),float64(b))) },3,4))}//输出://Calling function main.main.func1 with args (3,4)//81//第一个main是包名，第二个main是主函数名，func1匿名函数名 Go语言没有默认参数、可选参数、函数重载、操作符重载等 可变参数列表 传多少个参数都可以 1234567891011func sum(numbers ...int) int { s := 0 for i := range numbers { s += numbers[i] } return s}func main() { fmt.Println(sum(1, 2, 3, 4, 5))}//15 六、指针 *int代表指针，与C++中的int *相反 1234567func main() { var a int = 2 var pa *int = &amp;a *pa = 3 fmt.Println(a)}//3 Go语言中指针不能运算 参数传递 Go语言只有值传递一种方式 值传递拷贝一份变量传入到函数中 指针传递 Object传递，具体传递方式根据封装类型选择cache中不包含data，而是有一个指向data的指针，将cache拷贝一份传递到函数中，cache中包含有指向data的指针 swap函数的两种实现 1234567func swap(a, b *int) { *a, *b = *b, *a}func swap(a, b int) (int, int) { return b, a}","link":"/2022/01/11/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%861%E2%80%94%E2%80%94%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"},{"title":"Go语言基础知识2——内建容器","text":"​​点击阅读更多查看文章内容 一、数组数组定义 var arr [5]int：变量个数在前，变量类型在后 1234var arr1 [5]intarr2 := [3]int{1, 3, 5} //需赋初值arr3 := [...]int{2, 4, 6, 8, 10} //数量由初始值决定var grid [4][5]int //二维数组，4行5列 range关键字 123456//通过range关键字可以同时获得索引及其对应元素//for _,v:= range arr3 通过_省略变量//如果只要i，可写成for i:=range arr3for i,v :=range arr3{ fmt.Println(i,v)} 数组是值传递 [10]int 和 [20]int 是不同类型 调用func f(arr [10]int)会拷贝数组 (其他大部分语言传数组都是引用传递)， 通过指针可以修改数组的值 12345678910//通过指针可以修改数组的值func printArray(arr *[5]int){ for i,v :=range arr{ fmt.Println(i,v) } arr[0]=100 //不需要加*}//调用函数的时候要用&amp;arr1，不像C语言数组名就是首地址printArray(&amp;arr1) Go语言中一般不直接使用数组 二、Slice（切片）Slice区间前闭后开 arr[2:6]、arr[:6]、arr[2:]、arr[:]都是切片 12345678func main() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} fmt.Println(&quot;arr[2:6] =&quot;, arr[2:6]) //2,3,4,5 fmt.Println(&quot;arr[:6] =&quot;, arr[:6]) //0,1,2,3,4,5 fmt.Println(&quot;arr[2:] =&quot;, arr[2:]) //2,3,4,5,6,7 fmt.Println(&quot;arr[:] =&quot;, arr[:]) //0,1,2,3,4,5,6,7} Slice本身没有数据，是对底层array的一个view 1234arr := [...]int{0,1,2,3,4,5,6,7}s := arr[2:6]s[0] = 10// array变为[0,1,10,3,4,5,6,7] Reslice对slice再求slice 12345arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7}s1 := arr[2:5]fmt.Println(s1) //2,3,4s1 = s1[1:3]fmt.Println(s1) //3,4 Slice的扩展在以下示例中，s1为[2,3,4,5]，如果直接取s1[4]会产生越界错误 使用s2再取s1的切片s1[3:5]，则不会报错 123arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7}s1 := arr[2:6] //2,3,4,5s2 := s1[3:5] //5,6 slice可以向后扩展，不可以向前扩展s[i]不能超过len(s)，向后扩展可以超过len(s)不可以超过cap(s) 1234567func main() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} s1 := arr[2:6] //2,3,4,5 fmt.Println(len(s1), cap(s1)) //4,6 s2 := s1[3:5] //5,6 fmt.Println(len(s2), cap(s2)) //2,3} Slice的操作向Slice添加元素 123456789func main() { arr := [...]int{0, 1, 2, 3, 4, 5, 6, 7} s1 := arr[2:6] //2,3,4,5 s2 := s1[3:5] //5,6 s3 := append(s2, 10) //5,6,10 s4 := append(s3, 11) //5,6,10,11 s5 := append(s4, 12) //5,6,10,11,12 //arr数组为[0,1,2,3,4,5,6,10]} 切片在添加元素时如果超越cap，那么就不再是对原数组的view，系统会重新分配更大的底层数组由于值传递的关系，在append时slice的len和cap都有可能改变，必须接受append的返回值 s=append(s,val) 创建Slice 123456var s []int //Zero value for slice is nil; len = 0; cap = 0s1 := []int{2, 4, 6, 8, 10}s2 := make([]int, 16)s3 := make([]int, 10, 32)//type,len,cap copy 123456//只copy数值arr := []int{0, 1, 2, 3, 4, 5, 6, 7}s1 := arr[2:6] //[2 3 4 5]s2 := make([]int, 10) //[0 0 0 0 0 0 0 0 0 0]copy(s2, s1)fmt.Println(s1, s2) //[2 3 4 5] [2 3 4 5 0 0 0 0 0 0] delete 删除元素没有内建函数 123456//删除下标为3的元素s2=append(s2[:3],s2[4:]...)//使用...将Slice解开逐个append //删除头s2=s2[1:]//删除尾s2=s2[:len(s2) - 1] 三、Mapmap定义：map[Key]Value{}，方括号中是key的类型，后面跟value的类型，大括号中加初始化的值 复合map：map[K1]map[K2]V，外层map的key为K1，value为map[K2]V 创建 12345678910m := map[string]string{ &quot;name&quot;: &quot;ccmouse&quot;, &quot;course&quot;: &quot;golang&quot;, &quot;site&quot;: &quot;imooc&quot;, &quot;quality&quot;: &quot;notbad&quot;,}m2 := make(map[string]int) //m2 == empty mapvar m3 map[string]int //m3 == nil 遍历 使用range遍历使用len获得元素个数 12345//遍历，Map使用哈希表元素无序，每次输出的顺序都不同//如需顺序，需要手动对key排序，全取出来加到slice中for k, v := range m { fmt.Println(k, v)} 取元素，判断是否存在 123456//取元素,判断元素是否存在，若存在ok为true，否则为false//key不存在时获得元素类型的初始值courseName, ok := m[&quot;course&quot;]fmt.Println(courseName, ok) //golang truecauseName, ok := m[&quot;cause&quot;]fmt.Println(causeName, ok) // false,键不存在输出为空 删除元素1delete(m,&quot;name&quot;)map中的keymap使用哈希表，key必须可以比较相等除了slice，map，function的内建类型都可以作为keystruct类型不包含上述字段，也可作为key 四、字符串字符串的实现range []byte(s)：使用[]byte获得字节(底层），字符串采用utf-8编码，英文一字节，中文三字节，直接输出s[idx]获得的是字符串对应位置的字节 range s：获得的是字符的Unicode编码 字符串的不同输出形式 字符串 Y e s 我 爱 慕 课 网 ! UTF-8（range []byte(s)） 59 65 73 E6 88 91 E7 88 B1 E6 85 95 E8 AF BE E7 BD 91 21 Unicode（range s） 0,59 1,65 2,73 3,6211 6,7231 9,6155 12,8BFE 15,7F51 18,21 range []rune(s) 0,59 1,65 2,73 3,6211 4,7231 5,6155 6,8BFE 7,7F51 8,21 Ps，后两行为：下标,字符；即range s中每个中文字符占三个长度，因为字符串底层是由字节存储的，每个中文字符占三个字节，所以占三个长度[]rune(s)中每个中文字符占一个长度，一个rune类型占四个字节，所以一个rune可以存储一个字符， 12345678910111213s := &quot;Yes我爱慕课网!&quot;for i, b := range []byte(s) { fmt.Printf(&quot;(%d %X)&quot;, i, b)}fmt.Println()//结果//(0 59)(1 65)(2 73)(3 E6)(4 88)(5 91)(6 E7)(7 88)(8 B1)(9 E6)(10 85)(11 95)(12 E8)(13 AF)(14 BE)(15 E7)(16 BD)(17 91)(18 21)for i, ch := range s { //ch is a rune fmt.Printf(&quot;(%d %X)&quot;, i, ch)}fmt.Println()//结果 utf8转为Unicode//(0 59)(1 65)(2 73)(3 6211)(6 7231)(9 6155)(12 8BFE)(15 7F51)(18 21) len：返回字节长度utf8.RuneCountInString：返回字符个数 12fmt.Println(len(s))//19fmt.Println(utf8.RuneCountInString(s))//9 使用utf8.DecodeRune解码 func DecodeRune(p []byte) (r rune, size int) {}：输入为UTF-8编码的字节，输出为rune以及字符的所占的字节数，使用%c获得字符，汉字每三个字节进行解码 12345678bytes:=[]byte(s)for len(bytes)&gt;0{ ch,size:=utf8.DecodeRune(bytes) fmt.Printf(&quot;%c &quot;,ch) bytes=bytes[size:]}//结果//Y e s 我 爱 慕 课 网 ! 顶层使用：将s转为[]rune下标从0递增[]rune转换并不是对内存的重新理解，而是会将字节进行解码，将转换后的字符存放在一个新开的rune slice里面 12345for i,ch:=range []rune(s){ //ch is a rune fmt.Printf(&quot;(%d %c)&quot;,i,ch)}//结果//(0 Y)(1 e)(2 s)(3 我)(4 爱)(5 慕)(6 课)(7 网)(8 !) 字符串的有关操作 字符串的有关操作都在strings包中 1234567891011121314151617//字符串分隔、拼接fmt.Println(strings.Fields(&quot;a b c d&quot;))//[a b c d] 空格分割fmt.Println(strings.Split(&quot;abcbde&quot;,&quot;b&quot;))//[a c de]fmt.Println(strings.Join([]string{&quot;aa&quot;,&quot;bb&quot;,&quot;cc&quot;},&quot;A&quot;))//aaAbbAcc//子串查找fmt.Println(strings.Index(&quot;abcec&quot;,&quot;c&quot;))//2fmt.Println(strings.Contains(&quot;abcec&quot;,&quot;c&quot;))//true//大小写转换fmt.Println(strings.ToLower(&quot;AAA&quot;))//aaafmt.Println(strings.ToUpper(&quot;aaAb&quot;))//AAAB//切割首尾字符fmt.Println(strings.Trim(&quot;abcdaaa&quot;,&quot;abc&quot;))//dfmt.Println(strings.TrimLeft(&quot;abcdaaa&quot;,&quot;abc&quot;))//daaafmt.Println(strings.TrimRight(&quot;abcdaaa&quot;,&quot;abc&quot;))//abcd","link":"/2022/01/11/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%862%E2%80%94%E2%80%94%E5%86%85%E5%BB%BA%E5%AE%B9%E5%99%A8/"},{"title":"Go语言基础知识3——面向对象","text":"​​点击阅读更多查看文章内容 go语言仅支持封装，不支持继承和多态 go语言没有class，只有struct 一、结构体和方法结构的创建不论地址还是结构本身，一律使用.来访问成员（在C++中指针通过-&gt;访问成员） 12345678910111213141516171819202122type treeNode struct {value intleft, right *treeNode }func main() { var root treeNode root = treeNode{value: 3} fmt.Println(root) root.left = &amp;treeNode{} root.right = &amp;treeNode{5, nil, nil} root.right.left = new(treeNode) nodes:=[]treeNode{ {value: 3}, {}, {6,nil,&amp;root}, }} Golang中没有构造函数，可以使用工厂函数，注意这里返回了局部变量的地址（在C++中这是一个明显的错误，但是在Golang中可以） 1234func createTreeNode(value int) *treeNode { return &amp;treeNode{value: value}}root.Left.Right = CreateTreeNode(2) 结构创建在堆上还是栈上？在C++中，局部变量创建在栈上，函数一旦退出局部变量就会立刻被销毁，传出函数必须在堆上分配，堆上分配需要手动释放在Java中，几乎所有的东西都是分配在堆上的（都要用new），因此会有垃圾回收机制在Golang中，不一定，是由编译器及运行环境所决定的，以上述函数为例，编译器发现treeNode取地址返回，则会将它在堆上分配。如果treeNode不需要返回出去，则会在栈上分配。 为结构定义方法 在方法名前显式定义和命名方法的接受者 使用指针作为方法接受者可以改变结构内容（Go语言所有的参数都是值传递，不用指针的话不能修改内容） nil指针也可以调用方法 使用.调用方法 12345678func (node treeNode) print() { fmt.Print(node.value)}func (node *treeNode) setValue(value int) { node.value = value} 中序遍历 123456789func (node *treeNode) traverse() { if node==nil{ return } node.left.traverse() node.print() node.right.traverse()} 要改变内容必须使用指针接受者结构过大也考虑使用指针接受者建议：一致性，如有指针接收者，最好都是指针接收者值接受者 是go语言特有值/指针接受者均可接收值/指针，go语言会自动转换 二、包和封装封装 名字一般使用CamelCase 首字母大写：public 首字母小写：private public和private是针对包 而言的 包 每个目录一个包（包名和目录名可以不同） main包包含可执行入口（包含main函数，如果包下有main函数，这个包只能是main包，否则可以取其他名字） 为结构定义的方法必须放在同一个包内，可以是不同的文件 引用其他包时要通过“包名.方法”或“包名.变量名”来使用 如下目录所示，tree\\entry目录为package main，tree目录为package tree，在main包中调用tree包的变量则使用如下语句——tree.Node{} 扩展已有类型go语言没有继承如何扩充系统类型或别人的类型？ 定义别名：最简单 使用组合：最常用 使用内嵌：省下很多代码，但是比较难看懂 组合方式，为原类型添加后序遍历123456789101112131415type myTreeNode struct { node *tree.Node}func (myNode *myTreeNode) postOrder() { if myNode==nil||myNode.node==nil{ return } left:=myTreeNode{myNode.node.Left} left.postOrder() right:=myTreeNode{myNode.node.Right} right.postOrder() myNode.node.Print()} 别名方式，将[]int封装为队列123456789101112131415161718type Queue []intfunc (q *Queue) Push(v int) { fmt.Println(&amp;q) *q = append(*q, v)}func (q *Queue) Pop() int { head := (*q)[0] *q = (*q)[1:] return head}func (q *Queue) IsEmpty() bool { return len(*q)==0} 使用内嵌方式来扩展已有类型组合方式中的myTreeNode中的node删掉，tree.Node的所有成员变量和方法都可以给myTreeNode使用 首先可以通过myTreeNode.Node调用，更进一步可以直接通过myTreeNode.直接调用 123type myTreeNode struct { *tree.Node //Embedding} 方法重载 如果myTreeNode中定义有与tree.Node相同名称的方法则可以使用myTreeNode.调用myTreeNode中的方法，或者使用myTreeNode.Node.调用Node中的方法 12345678func (myNode *myTreeNode)Traverse() { fmt.Println(&quot;this method is shadowed.&quot;)}func main() { root := myTreeNode{&amp;tree.Node{Value: 3}} root.Traverse() //重载函数 root.Node.Traverse() //重载前的函数} 与其他语言不同，以下代码把子类赋值给基类是错误的，这只是组合的一个语法糖，对编译器而言，以下两种类型并没有联系 12var baseRoot *tree.NodebaseRoot := &amp;root 如果想把子类赋值给基类，Go语言是通过接口实现的，而不是继承","link":"/2022/01/12/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%863%E2%80%94%E2%80%94%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"title":"Go语言基础知识4——依赖管理","text":"​​点击阅读更多查看文章内容 依赖：别人写的库，依赖其进行编译 依赖管理的三个阶段：GOPATH，GOVENDOR，go mod GOPATH和GOVENDOR正在向go mod迁移 一、GOPATHGOPATH是一个环境，就是一个目录 默认在~/go（unix，linux），%USERPROFILE%\\go（windows） 管理方式：给一个目录，所有的依赖都到GOPATH下去找 GOPATH要求在目录下必须有一个src目录，文件都放在$GOPATH/src目录下 问题：所有的项目都在GOPATH目录下面，依赖库也放在GOPATH下面，导致GOPATH越来越大 注意： 在使用GOPATH和GOVENDOR管理依赖时GO111MODULE要设置为off在终端输入命令：set GO111MODULE=off（Windows下） 在运行的时候在要进行如下设置，否则他还是会按照on来运行 GO111MODULE=auto 在$GOPATH/src 外面且根目录有go.mod 文件时，开启模块支持GO111MODULE=off 无模块支持，go会从GOPATH 和 vendor 文件夹寻找包GO111MODULE=on 模块支持，go会忽略GOPATH和vendor文件夹，只根据go.mod下载依赖 二、GOVENDOR 所有项目都放在一个path下它们所依赖的库会有冲突（如：不同项目依赖同一个库的不同版本） 每个项目都有自己的vendor目录，存放第三方库GOVENDOR有大量第三方依赖管理工具：glide，dep，go dep 从下图可以看到对依赖会依次查找vendor、GOROOT和GOPATH目录 三、go mod 项目会新建go.mod文件，依赖包到go.mod下找 以zap为例，main包如下 12345678package mainimport &quot;go.uber.org/zap&quot;func main() { logger, _ := zap.NewProduction() logger.Warn(&quot;warning test&quot;)} go.mod如下 123456789module awesomeProject1go 1.17require ( go.uber.org/atomic v1.10.0 // indirect go.uber.org/multierr v1.8.0 // indirect go.uber.org/zap v1.23.0 // indirect) zap.NewProduction()目录为：$GOPATH/pkg/mod/go.uber.org/zap@1.23.0/logger.go 与项目不在同一目录下，由go命令统一的管理，用户不必关心目录结构 初始化：go mod init 增加依赖：使用go get命令拉取在代码中直接import 更新依赖：go get [@v…] (不加版本号默认为最新版本)，go mod tidy(清除多余文件) 项目迁移到go mod：go mod initgo build ./… （当前目录以及其所有子目录全部build一遍） 目录整理一个目录下只能有一个main函数，如果目录下有多个main函数在go build时会报错，因此在目录整理时，应该把各个main函数都分配到不同的目录下","link":"/2022/01/13/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%864%E2%80%94%E2%80%94%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"},{"title":"Go语言编程思想1——面向接口","text":"​点击阅读更多查看文章内容 Go语言编程思想1——面向接口示例 以下示例中包含有两个Retriever分别是实际使用的infra.Retriever以及测试用的testing.Retriever，再两者互换时，传统的方法需要修改多处变量，较为繁琐。 分析本例可以发现Retriever只是一个具有Get方法的变量，即getRetriever只需要返回一个可以调用Get方法的变量即可 这里的retriever即为一个具有Get方法的接口，GetRetriever返回接口，这样在修改变量时只需要修改getRetriever中的返回值即可，而不需每个变量都做修改。 12345678910func getRetriever() retriever { return testing.Retriever{}}type retriever interface { Get(string) string}func main() { var r retriever = getRetriever() fmt.Println(r.Get(&quot;https://www.imooc.com&quot;))} 一、接口的概念duck typing 传统的鸭子指的是真正的有生命的鸭子，必须属于脊索动物门，脊椎动物亚门…duck typing则认为下图中的大黄鸭也是鸭子，只要像鸭子就认为是鸭子 描述事物的外部行为而非内部结构 严格说go属于结构化类型系统，类似duck typing 在download前写一个注释说明必须实现了get方法才能作为函数的参数，如果参数没有实现get方法则会报错 python中的duck typing非常灵活，不管retriever是什么，只要实现了get方法，就可以传入download使用 灵活性与python类似 java中没有duck typing，必须实现Retriever接口，只有get方法也无法调用（与前面说的鸭子必须是指有生命的类似） 缺点：无法实现多个接口 同时需要两个接口、具有灵活性、具有类型检查（无需注释说明） 二、接口定义 定义接口接口由使用者定义 download是使用者，使用者要get，因此我们要在Retriever中定义get方法 接口中定义方法不需要加func关键字，它里面本身就全是函数 1234567type Retriever interface { Get(url string)string }func download(r Retriever)string { return r.Get(&quot;www.imooc.com&quot;)} 实现接口接口的实现是隐式的 只要实现了Retriever接口中的方法就认为实现了Retriever接口 1234567type Retriever struct { Contents string}func (r Retriever) Get(url string) string { return r.Contents} 三、接口的值类型接口变量中包含有实现者的类型和实现者的值 接口变量自带指针 接口变量同样采用值传递，几乎不需要使用接口的指针，因为它可以包含一个指针 指针接受者只能用指针方式使用，值接受者两者都可以 查看接口变量 表示任何类型：interface{}Queue可以传入任何类型12345678910111213//将类型设为interface后，队列可以存放任何类型type Queue []interface{}func (q *Queue) Push(v interface{}) { fmt.Println(&amp;q) *q = append(*q, v)}func (q *Queue) Pop() interface{} { head := (*q)[0] *q = (*q)[1:] return head} 如要将Push()和Pop()的值都限定为intPush的输入限定为intPop的输出为int，返回时通过.()将interface{}转换为int 12345678910111213//将类型设为interface后，队列可以存放任何类型type Queue []interface{}func (q *Queue) Push(int) { fmt.Println(&amp;q) *q = append(*q, v)}func (q *Queue) Pop() int { head := (*q)[0] *q = (*q)[1:] return head.(int)} Type Assertion 12345678910111213 r = &amp;real.Retriever{ UserAgent: &quot;Mozilla/5.0&quot;, TimeOut: time.Minute, }// Type assertion，这里r是&amp;real.Retriever，如下语句ok值为false//通过.(具体的名字)来取得interface中的类型 if mockRetriever, ok := r.(mock.Retriever); ok { fmt.Println(mockRetriever.Contents) } else { fmt.Println(&quot;not a mock retriever&quot;) } Type Switch 123456789func inspect(r Retriever) { fmt.Printf(&quot;%T %v\\n&quot;, r, r) switch v := r.(type) { case mock.Retriever: fmt.Println(&quot;Contents:&quot;, v.Contents) case *real.Retriever: fmt.Println(&quot;UserAgent:&quot;, v.UserAgent) }} 四、接口的组合123456789101112131415161718192021type Retriever interface { Get(url string) string}type Poster interface { Post(url string,form map[string]string)string}type RetrieverPoster interface { Retriever Poster}func session(s RetrieverPoster) string { s.Post(url,map[string]string{ &quot;contents&quot;:&quot;another faked imooc.com&quot;, }) return s.Get(url)} 实现接口只需要把所有方法都定义即可 123456789101112type Retriever struct { Contents string}func (r *Retriever) Post(url string, form map[string]string) string { r.Contents=form[&quot;contents&quot;] return &quot;ok&quot;}func (r *Retriever) Get(url string) string { return r.Contents} 五、常用系统接口 Stringer任何类型只要定义了String()方法，进行Print输出时，就可以得到定制输出。123type Stringer interface { String() string} 1234func (r *Retriever) String() string { return fmt.Sprintf( &quot;Retriever:{Contents=%s}&quot;,r.Contents)} 1234func main() { mk := &amp;mock.Retriever{Contents: &quot;Hello World&quot;} fmt.Println(mk)//Retriever:{Contents=Hello World}} Reader Writer","link":"/2022/01/13/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B31%E2%80%94%E2%80%94%E9%9D%A2%E5%90%91%E6%8E%A5%E5%8F%A3/"},{"title":"Go语言编程思想2——函数式编程","text":"​​点击阅读更多查看文章内容 Go语言编程思想2——函数式编程 函数是一等公民：参数，变量，返回值都可以是函数 高阶函数：函数的参数还可以是函数 函数-&gt;闭包 “正统”函数式编程 不可变性：不能有状态，只有常量和函数 函数只能有一个参数 闭包 下例中，adder()的返回值就是一个函数体，其中v为函数体的局部变量。sum是函数所处的一个环境，是自由变量，编译器会将函数体连接到自由变量，在本例中sum是int型，实际上sum也可以是一个结构继续连接到其他变量，最终函数体会连接到全部的变量组成上图中树的形状，形成闭包。 返回值是一个闭包，不仅是func那段代码，而是这个函数以及对sum的引用，以及保存的sum变量 1234567891011121314func adder() func(int) int { sum := 0 return func(v int) int { sum += v return sum }}func main() { a := adder() for i := 0; i &lt; 10; i++ { fmt.Printf(&quot;0+1+...+%d=%d\\n&quot;, i, a(i)) }} “正统”函数式编程，不存在状态（没有变量sum） 12345678910111213141516type iAdder func(int) (int, iAdder)func adder2(base int) iAdder { return func(v int) (int, iAdder) { return base + v, adder2(base + v) }}func main() { a := adder2(0) for i := 0; i &lt; 10; i++ { var s int s, a = a(i) fmt.Printf(&quot;0+1+...+%d=%d\\n&quot;, i, s) }} 例一：斐波那契数列1234567func fibonacci() func() int { a, b := 0, 1 return func() int { a, b = b, a+b return a }} 例二：为函数实现接口12345678910111213141516171819202122232425262728293031323334func fibonacci() intGen { a, b := 0, 1 return func() int { a, b = b, a+b return a }}type intGen func() int// 函数作为接受者func (g intGen) Read(p []byte) (n int, err error) { next := g() if next&gt;10000{ return 0, io.EOF } s := fmt.Sprintf(&quot;%d\\n&quot;, next) //TODO:incorrect if p is too small! return strings.NewReader(s).Read(p)}func printFileContents(reader io.Reader){ scanner :=bufio.NewScanner(reader) for scanner.Scan(){ fmt.Println(scanner.Text()) }}func main() { f := fibonacci() printFileContents(f)} 例三：使用函数来遍历二叉树将之前的print()换为一个函数，可以实现更多的功能 修改前： 12345678func (node *Node) Traverse() { if node == nil { return } node.Left.Traverse() node.print() node.Right.Traverse()} 修改后 12345678910111213141516func (node *Node) Traverse() { node.TraverseFunc(func(node *Node) { node.Print() }) fmt.Println()}func (node *Node) TraverseFunc(f func(*Node)) { if node == nil { return } node.Left.TraverseFunc(f) f(node) node.Right.TraverseFunc(f)} 将之前的打印换为一个函数，可以实现更多的功能例如：结点计数 1234nodeCount:=0root.TraverseFunc(func(node *tree.Node) { nodeCount++}) go语言闭包的应用 更为自然，不需要修饰如何访问自由变量 没有Lambda表达式，但是有匿名函数","link":"/2022/01/14/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B32%E2%80%94%E2%80%94%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"title":"Go语言编程思想3——错误处理和资源管理","text":"​​点击阅读更多查看文章内容 Go语言编程思想3——错误处理和资源管理 资源管理：及时关闭文件，及时释放资源，如果打开的文件还未关闭就因为出错而在中间跳出，就无法保证有效的资源管理，因此在这里两者一起进行考虑 一、defer调用 调用在函数结束时发生（在return/panic之前执行） 参数在defer语句时计算 defer列表为先进后出（先defer的后执行）12345678910func tryDefer() { for i := 0; i &lt; 100; i++ { defer fmt.Print(i,&quot; &quot;) if i == 30 { panic(&quot;printed too many&quot;) } }}//执行结果:30 29 28 27 26 25 ... 3 2 1 0//退出的时候i是30，但不会全部输出30， i是在执行defer语句时的值 Ex. 将前20个斐波那契数列输出到文件 123456789101112131415func writeFile(filename string) { file, err := os.Create(filename) //新建文件 if err != nil { panic(err) } defer file.Close() //关闭文件 writer := bufio.NewWriter(file) //新建bufio.Newwriter defer writer.Flush() //writer需要Flush //先运行writer.Flush(),再运行file.close() f := fib.Fibonacci() for i := 0; i &lt; 20; i++ { fmt.Fprintln(writer, f()) }} 何时使用defer调用 Open/Close Lock/Unlock PrintHeader/PrintFooter 二、错误处理 尽量用error不用panic 意料之中的：使用error。如：文件打不开 意料之外的：使用panic。如：数组越界，如开了大小为n的数组，明明循环最大到n，但是结果越界，出现了意料之外的错误，这时用panic error的定义 123type error interface { Error() string} 将error当做普通的值类型来处理即可 panic会把程序挂掉，尽量少用panic，遇到错误时可以输出提示语句后return 123456789101112131415161718192021222324func writeFile(filename string) { // 注释表明，OpenFile如果出错那么一定是*PathError // 所以对Error进行判断，如果不是*PathError那么就报panic file, err := os.OpenFile(filename, os.O_EXCL|os.O_CREATE, 0666) if err != nil { if pathError, ok := err.(*os.PathError); !ok { panic(err) } else { fmt.Printf(&quot;%s,%s,%s\\n&quot;, pathError.Op, pathError.Path, pathError.Err) } return } defer file.Close() //关闭文件 writer := bufio.NewWriter(file) //新建bufio.Newwriter defer writer.Flush() //writer需要Flush //先运行writer.Flush(),再运行file.close() f := fib.Fibonacci() for i := 0; i &lt; 20; i++ { fmt.Fprintln(writer, f()) }} 自建error 1err=errors.New(&quot;this is a custom error&quot;) 服务器统一错误处理123456789101112131415161718192021222324252627282930313233343536373839404142package filelistingimport ( &quot;io/ioutil&quot; &quot;net/http&quot; &quot;os&quot; &quot;strings&quot;)const prefix = &quot;/list/&quot;//字符串实现接口type userError stringfunc (e userError) Error() string { return e.Message()}func (e userError) Message() string { return string(e)}func HandleFileList(writer http.ResponseWriter, request *http.Request) error { if strings.Index(request.URL.Path, prefix) != 0 { return userError(&quot;path must start &quot; + &quot;with &quot; + prefix) } path := request.URL.Path[len(prefix):] // /list/fib.txt file, err := os.Open(path) if err != nil { return err } defer file.Close() all, err := ioutil.ReadAll(file) if err != nil { return err } writer.Write(all) return nil} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package mainimport ( &quot;learngo/errhandling/filelistingserver/filelisting&quot; &quot;log&quot; &quot;net/http&quot; &quot;os&quot;)type appHandler func(writer http.ResponseWriter, request *http.Request) error//函数式编程，将输入的函数包装成输出函数来输出func errWrapper( handler appHandler) func( http.ResponseWriter, *http.Request) { return func(writer http.ResponseWriter, request *http.Request) { defer func() { if r := recover(); r != nil { log.Printf(&quot;Panic:%v&quot;, r) http.Error(writer, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError) } }() err := handler(writer, request) //错误处理 if err != nil { log.Printf(&quot;Error occurred&quot;+ &quot;handling request:%s&quot;, err.Error()) if userErr,ok:=err.(userError);ok{ http.Error(writer, userErr.Message(), http.StatusBadRequest) return } code := http.StatusOK switch { case os.IsNotExist(err): code = http.StatusNotFound case os.IsPermission(err): code = http.StatusForbidden default: code = http.StatusInternalServerError } http.Error(writer, http.StatusText(code), code) } }}type userError interface { error //给系统看的 Message() string //给用户看的}func main() { http.HandleFunc(&quot;/&quot;, errWrapper(filelisting.HandleFileList), ) err := http.ListenAndServe(&quot;:8888&quot;, nil) if err != nil { panic(err) }}","link":"/2022/01/15/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B33%E2%80%94%E2%80%94%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E5%92%8C%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86/"},{"title":"Go语言编程思想4——测试与性能调优","text":"​​点击阅读更多查看文章内容 Go语言编程思想4——测试与性能调优 Debugging Sucks! Testing Rocks!多做测试，少做调试 Go语言使用表格驱动测试 一、传统测试正确结果在前，函数结果在后，判断是否相等 测试逻辑和测试数据混在一起 出错信息不明确 一旦一个数据出错测试全部结束 二、表格驱动测试将测试数据写在struct中，a + b = c 卸载for循环中判断add(a,b)是否等于c，若不等于再进一步处理 测试文件命名：测试的东西_test（若不按照标准命名则无法执行测试函数），本例文件命名为Triangle_test 测试函数命名需要为Test+测试名称 分离的测试数据和测试逻辑 明确的出错信息 可以部分失败 go语言的语法使得我们更易实践表格驱动测试 123456789101112131415161718192021222324func calcTriangle(a, b int) int { var c int c = int(math.Sqrt(float64(a*a + b*b))) return c}func TestTriangle(t *testing.T) { tests := []struct{ a, b, c int }{ {3, 4, 5}, {5, 12, 13}, {8, 15, 17}, {12, 35, 37}, {30000, 40000, 50000}, } for _, tt := range tests { if actual := calcTriangle(tt.a, tt.b); actual != tt.c { t.Errorf(&quot;calcTriangle(%d,%d);&quot;+ &quot;got %d;expected %d&quot;, tt.a, tt.b, actual, tt.c) } }} 在命令行中运行测试，进入test文件目录，运行go test . 三、代码覆盖率查看测试代码的代码覆盖率 运行测试函数：run ‘…’ with Coverage 被测试的代码中，绿色的是覆盖到的，红色是没有覆盖到的，点击绿色部分可以看到覆盖了多少次 命令行go test -coverprofile c.outgo tool cover -html c.out 四、性能测试在Triangle_test文件中继续创建下列函数 注意函数命名需要为Benchmark+测试名称 b.N为测试次数 12345678910111213func BenchmarkTriangle(b *testing.B) { aa := 30000 bb := 40000 cc := 50000 for i := 0; i &lt; b.N; i++ { actual := calcTriangle(aa, bb) if actual != cc { b.Errorf(&quot;calcTriangle(%d,%d);&quot;+ &quot;got %d;expected %d&quot;, aa, bb, actual, cc) } }} 结果： 命令行 go test -bench . 五、pprof性能调优命令行命令： go test -bench . -cpuprofile cpu.out 获得cpu性能的日志文件cpu.out go tool pprof cpu.out 查看日志文件 执行完pprof后会进入命令行，再执行web命令可以进入web页面可视化日志文件，这里需要先安装Graphviz，链接放在下面直接下载安装即可。Graphviz 可视化结果： 方框越大，箭头越粗，耗时越长 优化map的方法 map是哈希表实现会有判重等操作可以使用空间换时间a:=make([]int,0xffff)假设中文字符最大就是0xFFFF，这里开一个0xFFFF大小的数组可以存储所有字符使用：a[‘e’]=1（实质：a[0x65]=1）;a[‘课’]=1（实质：a[0x8BFE]=1） 性能调优的步骤 -cpuprofile：获取性能数据 go tool pprof：查看性能数据（web可视化） 分析慢在哪里（哪个框最大） 优化代码 再用-cpuprofile获取性能数据，查看优化结果，继续优化 六、http测试两种方法 通过使用假的Request/Response 通过起服务器 测试的函数参考之前笔记7中的服务器统一错误处理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283func errPanic(writer http.ResponseWriter, request *http.Request) error { panic(123)}type testingUserError stringfunc (e testingUserError) Error() string { return e.Message()}func (e testingUserError) Message() string { return string(e)}func errUserError(writer http.ResponseWriter, request *http.Request) error { return testingUserError(&quot;user error&quot;)}func errNotFound(writer http.ResponseWriter, request *http.Request) error { return os.ErrNotExist}func errNotPermission(writer http.ResponseWriter, request *http.Request) error { return os.ErrPermission}func errUnknown(writer http.ResponseWriter, request *http.Request) error { return errors.New(&quot;unknown error&quot;)}func noError(writer http.ResponseWriter, request *http.Request) error { fmt.Fprintln(writer, &quot;no error&quot;) return nil}var tests = []struct { h appHandler code int message string}{ {errPanic, 500, &quot;Internal Server Error&quot;}, {errUserError, 400, &quot;user error&quot;}, {errNotFound, 404, &quot;Not Found&quot;}, {errNotPermission, 403, &quot;Forbidden&quot;}, {errUnknown, 500, &quot;Internal Server Error&quot;}, {noError, 200, &quot;no error&quot;},}//用假的request，response，速度快func TestErrWrapper(t *testing.T) { for _, tt := range tests { f := errWrapper(tt.h) response := httptest.NewRecorder() request := httptest.NewRequest( http.MethodGet, &quot;http://www.imooc.com&quot;, nil) f(response, request) verifyResponse(response.Result(), tt.code, tt.message, t) }}//真正起一个server，测试力度更大func TestErrWrapperInServer(t *testing.T) { for _, tt := range tests { f := errWrapper(tt.h) server := httptest.NewServer(http.HandlerFunc(f)) resp, _ := http.Get(server.URL) verifyResponse(resp, tt.code, tt.message, t) }}func verifyResponse(resp *http.Response, expectedCode int, expectMsg string, t *testing.T) { b, _ := ioutil.ReadAll(resp.Body) body := strings.Trim(string(b), &quot;\\n&quot;) if resp.StatusCode != expectedCode || body != expectMsg { t.Errorf(&quot;expected(%d,%s);&quot;+ &quot;got(%d,%s)&quot;, expectedCode, expectMsg, resp.StatusCode, body) }} 七、生成文档用注释写文档在测试中加入Example使用go doc/godoc 来查看/生成文档 -http :6060```生成文档，通过访问1234567891011121314151617181920212223242526**注释**```go// An FIFO queue.type Queue []int// Pushes the element into the queue.// e.g. q.Push(123)func (q *Queue) Push(v int) { *q = append(*q, v)}// Pops element from head.func (q *Queue) Pop() int { head := (*q)[0] *q = (*q)[1:] return head}// Returns if the queue is empty or not.func (q *Queue) IsEmpty() bool { return len(*q)==0} 示例代码：也可以当做测试来做 函数命名为ExampleQueue_+函数名 注释为标准答案，先写Output，格式必须严格一致 123456789101112131415161718func ExampleQueue_Pop() { q := Queue{1} q.Push(2) q.Push(3) fmt.Println(q.Pop()) fmt.Println(q.Pop()) fmt.Println(q.IsEmpty()) fmt.Println(q.Pop()) fmt.Println(q.IsEmpty()) // Output: // 1 // 2 // false // 3 // true} 生成文档： Example可以看作是特别的test，可以执行函数进行测试（注释为想要得到的结果），同时也可以生成文档的example若将注释中的false删掉e，执行函数得到以下结果","link":"/2022/01/25/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B34%E2%80%94%E2%80%94%E6%B5%8B%E8%AF%95%E4%B8%8E%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"title":"Go语言编程思想5——Goroutine","text":"​​点击阅读更多查看文章内容 Go语言编程思想5——Goroutine并发编程 I/O操作本身有等待的过程会进行协程间的切换 go 建立一个goroutine，并发的执行后面的函数，主程序依然在运行。 以下函数不会输出任何内容，main函数和匿名函数同时执行，匿名函数还没来得及输出，main函数就执行完退出了，因此没有任何输出 123456789func main() { for i := 0; i &lt; 10; i++ { go func(i int) { for { fmt.Printf(&quot;Hello from goroutine %d\\n&quot;, i) } }(i) }} main 本身也是一个goroutine 1234567891011121314func main() { var a [10]int fmt.Println(a) for i := 0; i &lt; 10; i++ { go func(i int) { for { a[i]++ runtime.Gosched()//手动交出控制权 } }(i) } time.Sleep(time.Millisecond) fmt.Println(a)} 协程goroutine实际上是一种协程 协程 Coroutine 轻量级“线程”（可以开1000个goroutine） 非抢占式多任务处理，由协程主动交出控制权 编译器/解释器/虚拟机层面的多任务（不是OS层面的，OS只有线程没有协程） 多个协程可能在一个或多个线程上运行 子程序是协程的一个特例普通函数main调用doWork函数，执行完成后将控制权交还给main函数，执行下一条语句协程的main和doWork之间有一条双向的通道，数据和控制权都可以双向流通，相当于并发执行的两个线程，可以互相通信，交换控制权，main和doWork可能运行在一个线程也可能运行在多个线程，程序员只需要开两个协程即可，由调度器进行调度。 其他语言中的协程 C++：Boost.Coroutine Java：不支持 python：yield关键字实现协程，python3.5加入了async def对协程原生支持 Go：原生支持 Go语言中的协程 调度器负责调度协程一个线程可能包含多个协程 任何函数只需加上go就能变成协程送给调度器运行 不需要在定义时区分是否是异步函数（python 需要加async def） 调度器在合适的点进行切换 可能的切换点 I/O，select channel 等待锁 函数调用（有时） runtime.Gosched() 只是参考，不能保证切换，不能保证在其他地方不切换 使用-race来检测数据访问冲突","link":"/2022/01/25/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B35%E2%80%94%E2%80%94Goroutine/"},{"title":"Go语言编程思想6——Channel","text":"​​点击阅读更多查看文章内容 Go语言编程思想6——Channel Channel：goroutine和goroutine之间双向的通道 一、基本语法 创建int类型的channel c := make(chan int) 发送数据 c &lt;- 1 接受数据 n := &lt;-c 1234567891011121314func chanDemo() { //创建int类型的channel c := make(chan int) //接收数据 go func() { for { n := &lt;-c fmt.Println(n) } }() //发送数据 c &lt;- 1 c &lt;- 2} channel发数据必须有goroutine接受，否则会发生死锁 123456789101112func chanDemo() { cha := make(chan int) cha &lt;- 1}/*fatal error: all goroutines are asleep - deadlock!goroutine 1 [chan send]: main.chanDemo(...) D:/goworkstation/src/learngo/test.go:19 main.main() D:/goworkstation/src/learngo/test.go:22 +0x31*/ Channel是一等公民Channel可以作为参数或返回值 chan&lt;- int 只能向channel发数据&lt;-chan int 只能从channel收数据 1234567891011121314151617181920212223242526func createWorker(id int) chan&lt;- int { //发数据 c := make(chan int) go func(){ for{ fmt.Printf(&quot;Worked %d received %c\\n&quot;, id, &lt;-c) } }() return c}func chanDemo() { //创建10个channel分发给10个worker var channels [10]chan&lt;- int for i := 0; i &lt; 10; i++ { channels[i] = createWorker(i) } //给10个channel分发数据 for i := 0; i &lt; 10; i++ { channels[i] &lt;- 'a' + i } for i := 0; i &lt; 10; i++ { channels[i] &lt;- 'A' + i } time.Sleep(time.Millisecond)} Channel缓冲区发数据必须有人收，否则会deadlock缓冲区大小设为3，只有在发送三个以上数据时才会出现deadlock以下代码不会出现死锁 1234567func bufferedChannel() { c := make(chan int, 3) c &lt;- 'a' c &lt;- 'b' c &lt;- 'c' time.Sleep(time.Millisecond)} Channel的close 发送方close：close(c) ，结束后若channel为空接收方依旧会接收到数据——(channel具体类型的零值) 接收方判断channel是否还有值的两种方法：n, ok := &lt;-c ，判断是否还有值，如果没有值了ok为falsefor n := range c {}，若没有值会自己跳出 12345678910111213141516171819202122232425262728func worker(id int, c chan int) { //读完channel内的数据就退出的两种方法 for n := range c { fmt.Printf(&quot;Worker %d received %c\\n&quot;, id, n) } /* for { n, ok := &lt;-c //如果没有值了ok为false if !ok { break } fmt.Printf(&quot;Worker %d received %c\\n&quot;, id, n) } */}func channelClose() { c := make(chan int) go worker(0, c) c &lt;- 'a' c &lt;- 'b' c &lt;- 'c' c &lt;- 'd' //发送方可以close //接收方有两种判断方法 ok，range close(c) //结束后依旧会接收到数据——(channel具体类型的零值) time.Sleep(time.Millisecond)} Go语言并发执行理论基础：Communication Sequential Process (CSP) 不要用共享内存实现通信，而要用通信实现共享内存 Channel阻塞发送者角度：对于同一个通道，发送操作（协程或者函数中的），在接收者准备好之前是阻塞的。如果chan中的数据无人接收，就无法再给通道传入其他数据。因为新的输入无法在通道非空的情况下传入。所以发送操作会等待 chan 再次变为可用状态：就是通道值被接收时（可以传入变量）。接收者角度：对于同一个通道，接收操作是阻塞的（协程或函数中的），直到发送者可用：如果通道中没有数据，接收者就阻塞了。通过一个简单的例子来说明： 123456789func f1(in chan int) { fmt.Println(&lt;-in)}func main() { out := make(chan int) out &lt;- 2 go f1(out)} 运行结果：fatal error: all goroutines are asleep - deadlock! 这是由于out &lt;- 2之前不存在对out的接收，所以，对于out &lt;- 2来说，永远是阻塞的，即一直会等下去。 将out &lt;- 2与go f1(out)互换 123456789func f1(in chan int) { fmt.Println(&lt;-in)}func main() { out := make(chan int) go f1(out) out &lt;- 2} 运行结果：2 out &lt;- 2前存在对通道的读操作，所以out &lt;- 2 是合法的。就像前文说的，发送操作在接收者准备好之前是阻塞的。 二、使用Channel等待goroutine的结束一个死锁的例子 channel的发送和接收都是阻塞式的发送操作在接受者准备好之前是阻塞的，这里doWork中打印完小写字母之后给done发送了一个true，此时等待接受这个true的接受程序在后面，并没有准备好所以造成阻塞，而此时又向channel中发送打印大写字母，故造成死锁。 1234567891011121314151617181920212223242526272829303132333435type worker struct { in chan int done chan bool}func doWork(id int, c chan int, done chan bool) { for { fmt.Printf(&quot;Worker %d received %c\\n&quot;, id, &lt;-c) done &lt;- true }}func createWorker(id int) worker { w := worker{ in: make(chan int), done: make(chan bool), } go doWork(id, w.in, w.done) return w}//所有channel的发送的都是阻塞式的func chanDemo() { var workers [10]worker for i := 0; i &lt; 10; i++ { workers[i] = createWorker(i) } for i, worker := range workers{ worker.in &lt;- 'a' + i } for i, worker := range workers { worker.in &lt;- 'A' + i } for _, worker := range workers { &lt;-worker.done &lt;-worker.done }} 解决方法：再开一个goroutine并行 123456func doWork(id int, c chan int, done chan bool) { for { fmt.Printf(&quot;Worker %d received %c\\n&quot;, id, &lt;-c) go func() { done &lt;- true }() }} WaitGroup的使用等待多人完成任务 方法Add(delta int)：添加任务个数Wait()：等待任务完成Done()：任务完成 1234567891011121314151617181920212223242526272829303132333435363738394041424344type worker struct { in chan int done func()}func doWork(id int, w worker) { for n := range w.in { fmt.Printf(&quot;Worker %d received %c\\n&quot;, id, n) //函数式编程，只调用done方法，具体执行什么函数由外面的createWorker来控制 w.done() }}func createWorker(id int, wg *sync.WaitGroup) worker { w := worker{ in: make(chan int), done: func() { wg.Done() }, } go doWork(id, w) return w}//所有channel的发送的都是阻塞式的func chanDemo() { var wg sync.WaitGroup var workers [10]worker for i := 0; i &lt; 10; i++ { workers[i] = createWorker(i, &amp;wg) } wg.Add(20) for i, worker := range workers { worker.in &lt;- 'a' + i } for i, worker := range workers { worker.in &lt;- 'A' + i } wg.Wait()} 三、Select select 是 Go 中的一个控制结构，类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。select 随机执行一个可运行的 case。如果没有 case 可运行，它将阻塞，直到有 case 可运行。一个默认的子句应该总是可运行的。 每个 case 都必须是一个通信 所有 channel 表达式都会被求值 所有被发送的表达式都会被求值 如果任意某个通信可以进行，它就执行，其他被忽略。如果有多个 case 都可以运行，Select 会随机公平地选出一个执行。其他不会执行。否则：如果有 default 子句，则执行该语句。如果没有 default 子句，select 将阻塞，直到某个通信可以运行；Go 不会重新对 channel 或值进行求值。 在Select中可以使用Nil Channel，当数据还没准备好的时候可以把Channel置为nil，这样case就不会执行 select+default可以实现类似于非阻塞式的获取，如下示例输出结果为“no value” 123456789func main() { c1 := make(chan int) select { case n := &lt;-c1: fmt.Println(n) default: fmt.Println(&quot;no value&quot;) }} 示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func generator() chan int { out := make(chan int) go func() { i := 0 for { time.Sleep(time.Duration(rand.Intn(1500)) * time.Millisecond) out &lt;- i i++ } }() return out}func worker(id int, c chan int) { for n := range c { time.Sleep(time.Second) fmt.Printf(&quot;Worker %d received %d\\n&quot;, id, n) }}func createWorker(id int) chan&lt;- int { c := make(chan int) go worker(id, c) return c}func main() { var c1, c2 chan int = generator(), generator() worker := createWorker(0) var values []int tm := time.After(10 * time.Second) tick := time.Tick(time.Second) for { var activeWorker chan&lt;- int var activeValue int //values中存有数据，对activeWorker初始化 if len(values) &gt; 0 { activeWorker = worker activeValue = values[0] } select { case n := &lt;-c1: values = append(values, n) case n := &lt;-c2: values = append(values, n) //activeWorker没有值的时候为nil，此时阻塞不会执行 case activeWorker &lt;- activeValue: values = values[1:] //相邻两个请求之间超过800ms即select阻塞时间超过800ms，则输出timeout case &lt;-time.After(800 * time.Millisecond): fmt.Println(&quot;timeout&quot;) //每隔一秒输出长度 case &lt;-tick: fmt.Println(&quot;queue len =&quot;, len(values)) //总时间10s后退出 case &lt;-tm: fmt.Println(&quot;bye&quot;) return } }} time.After():是本次监听动作的超时时间， 意思就说，只有在本次select 操作中会有效， 再次select 又会重新开始计时 四、传统的同步机制 WaitGroup Mutex Cond 传统同步机制（共享内存实现通信）较少使用，一般使用channel进行通信（通信实现共享内存） 示例 1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)type atomicInt struct { value int lock sync.Mutex}func (a *atomicInt) increment() { fmt.Println(&quot;safe increment&quot;) func() { a.lock.Lock() defer a.lock.Unlock() a.value++ }()}func (a *atomicInt) get() int { a.lock.Lock() defer a.lock.Unlock() return a.value}func main() { var a atomicInt a.increment() go func() { a.increment() }() time.Sleep(time.Millisecond) fmt.Println(a.get())} 五、并发编程模式 生成器，可以将其抽象为服务/任务 同时等待多个服务：两种方法 select：知道channel的具体数量 给每个channel开一个goroutine：不知道channel的具体数量（注意循环变量的坑，全局只有一份全局变量，在执行的时候只会向最后一个channel发送数据，可以通过拷贝一份变量或者通过函数传参来解决） 示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func msgGen(name string) chan string { c := make(chan string) go func() { i := 0 for { time.Sleep(time.Duration(rand.Intn(2000)) * time.Millisecond) c &lt;- fmt.Sprintf(&quot;service %s message %d&quot;, name, i) i++ } }() return c}//不知道有多少个channel的时候用这种fanInfunc fanIn(chs ...chan string) chan string { c := make(chan string) for _, ch := range chs { //如果直接用ch的话，ch只有一个值，只会取最后一个channel的值送给c //所以要通过一个参数拷贝ch进行传递 go func(in chan string) { for { c &lt;- &lt;-in } }(ch) } /* 变量chCopy在全局有两份，通过chCopy拷贝ch for _, ch := range chs { chCopy := ch go func() { for { c &lt;- &lt;-chCopy } }() } */ return c}//明确channel个数时用selectfunc fanInBySelect(c1, c2 chan string) chan string { c := make(chan string) go func() { for { select { case m := &lt;-c1: c &lt;- m case m := &lt;-c2: c &lt;- m } } }() return c}func main() { m1 := msgGen(&quot;service1&quot;) m2 := msgGen(&quot;service2&quot;) m3 := msgGen(&quot;service3&quot;) m := fanIn(m1, m2, m3) for { fmt.Println(&lt;-m) }} 六、任务的控制 非阻塞等待 超时机制 任务中断/退出 优雅退出 示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func msgGen(name string, done chan struct{}) chan string { c := make(chan string) go func() { i := 0 for { select { case &lt;-time.After(time.Duration(rand.Intn(5000)) * time.Millisecond): c &lt;- fmt.Sprintf(&quot;service %s message %d&quot;, name, i) case &lt;-done: fmt.Println(&quot;cleaning up&quot;) time.Sleep(2 * time.Second) fmt.Println(&quot;cleanup done&quot;) done&lt;- struct{}{}//双向通信，对方收到done才退出 return } } }() return c}//非阻塞等待//等到返回true，没等到返回falsefunc nonBlockingWait(c chan string) (string, bool) { select { case m := &lt;-c: return m, true default: //一旦阻塞就进入default return &quot;&quot;, false }}//超时机制func timeoutWait(c chan string, timeout time.Duration) (string, bool) { select { case m := &lt;-c: return m, true case &lt;-time.After(timeout): return &quot;&quot;, false }}func main() { done := make(chan struct{}) m1 := msgGen(&quot;service1&quot;, done) for i := 0; i &lt; 5; i++ { if m, ok := timeoutWait(m1, time.Second); ok { fmt.Println(m) } else { fmt.Println(&quot;timeout&quot;) } } done &lt;- struct{}{} &lt;-done}","link":"/2022/01/26/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B36%E2%80%94%E2%80%94Channel/"},{"title":"Hyperledger Fabric学习笔记——3.测试网络的启动分析","text":"​​点击阅读更多查看文章内容 1. 启动网络执行以下指令均要以管理员身份运行，请首先执行su root命令 查看目录cd /home/gopath/src/github.com/hyperledger/fabric-samples/first-network.env:存储一些环境变量base:存储docker-compose的一些公共服务byfn.sh:执行脚本configtx.yaml和crypto-config.yaml:根据之前生成的2个工具，生成相应的配置文件，用来启动网络，放到当前目录的channel-artifacts和crypto-config里面docker-compose:用来启动网络scripts:存放测试脚本，做的事：创建通道、加入通道、安装链码、实例化链码、链码交互 生成配置 ./byfn.sh -m generate -i 1.0.0 注意！！！！一定要记得把gopath中的bin目录添加到环境变量中，否则可能无法调用刚才编译好的configtxgen和cryptogen工具可以通过 export PATH=$PATH:/home/gopath/bin 来临时添加或者使用vim ~/.bash_profile修改PATH 一行，之后使用source ~/.bash_profile生效。 启动网络 ./byfn.sh -m up -i 1.0.0 关闭网络，自动清除配置和docker进程 ./byfn.sh -m down -i 1.0.0 2.分析网络 查看crypto-config配置peer与order分离peer又按照组织或主体分离每个组织生成ca(存储证书和私钥),msp(存储管理员证书和中间证书),peers(存储每一个peer相关的证书),users(存储每一个用户的证书)users的内容，最少包含两个用户——你创建的用户和admin用户peers的内容，组织1中存储的peer0和peer1 查看channel-artifacts配置genesis.block:整个网络的创世区块channel.tx:创建的通道的配置Org1MSPanchors.tx和Org2MSPanchors.tx:两个主体的锚节点的配置 启动网络，分析日志./byfn.sh -m up -i 1.0.0 启动网络 指定通道名称和一些变量，通道创建完成 4个peer加入通道 组织中的锚节点在通道update成功 链码安装到peer 链码实例化 在peer0进行查询操作，成功，查询结果为100 进行修改操作，返回200，修改成功 再次查询结果为90 查看docker容器，3个dev开头的就是链码，4个peer开头的就是每一个peer3个链码会生成3个image 查看脚本找到脚本对应位置的链码 查看go的代码实现了Init和Invoke接口，就代表是一个fabric智能合约Init：首先获取参数，不为4就报错，然后把参数存入数据库中Invoke：设置了3个方法（invoke，delete，query）invoke：转账操作delete：从数据库删除query：查询操作，以JSON形式返回 查看脚本a初始有100元，b初始有200元查询a有多少钱，所以打印了100a给b转10元 总结根据下面配置运行一个网络网络执行了一个链码，实现了初始化、查询、删除、转账等操作按照下面的脚本执行，首先进行初始化，然后查询a账户余额，然后a给b转账10元，然后再执行一个查询a账户余额的操作 关闭网络，清除image和容器","link":"/2022/04/29/Hyperledger%20Fabric%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%943.%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C%E7%9A%84%E5%90%AF%E5%8A%A8%E5%88%86%E6%9E%90/"},{"title":"Hyperledger Fabric学习笔记——1.基础概念","text":"​​点击阅读更多查看文章内容 hyperledger官网：https://www.hyperledger.org/ hyperledger与数字货币 都是基于区块链技术实现的 比特币1秒7笔交易，以太坊1分钟几百笔，hyperledger理论上一分钟50万笔交易 hyperledger因为不用挖矿，不需要很强的硬件支持，也不耗费资源 hyperledger没有51%攻击问题，加入链中的成员要经过CA认证，是有许可的网络 fabric是什么 目标：做企业级联盟链的基础设施 公有链：全网公开，没有类似CA的用户验证 联盟链：只针对某个特定群体的成员和有限的第三方，内部指定多个预选节点为记账人，每个块的生成由所有的预选节点共同决定 私有链：所有网络中的结点都掌握在一家机构手中 联盟链和私有链可统称为许可链 可插拔的共识机制（solo和kafka等） 多链多通道隔离，可以做业务隔离，保护业务数据隐私 fabric的重要组件 fabric CA 自动生成认证证书 创建账户 是一个工具集 fabric Peer- 可以有很多Peer，是Ledger和blockchain存储的位置- 一个peer可以加入不同的channel fabric ordering service- 提供排序服务，用来做共识- 创建block区块- 使用solo排序，配置成使用kafka排序（优先状态机） fabric的开发语言 智能合约 go java SDK- java- node.js（官方推荐，效率）- go（大坑，支持是最差的）- python fabric的channel 每个channel可以理解成独立的fabric实例 不同的channel是私有的子网，类似于微信群，隔离业务数据 peer是微信里的人，peer可以加入不同的channel 还可以设置允许什么人加入 fabric的chaincode chaincode(链码)就是智能合约，是一个应用程序 用于更新账本数据，由peer去执行chaincode 在fabric里，chaincode是数据唯一的更新方式 chaincode属于某一个channel chaincode的生命周期- 安装链码- 实例化（调用init方法）- 调用使用（调用invoke方法） 每个chaincode有不同的背书策略（如何去达成共识）- 可能有的chaincode是所有人都同意才可以- 可能有的chaincode是至少有一个人同意才可以- 可能有的chaincode是有4个人同意才可以- 适应企业复杂应用场景 fabric的msp 是一组重要的密码学签名工具 定义了你是谁，你在哪（在哪个channel中） CA去颁发证书 术语回顾 channel数据通道，独立的fabric实例，不同channel数据是隔离的 world state 是世界状态，是ledger里面存放的数据，是KV（key-value）数据的存储，可以用leveldb和couchdb存储 ledger：账本，记录当前所有的世界状态，从底层架构上保证了数据一致性，不可篡改性 chaincode：链码，编写智能合约，ledger的变化只能通过调用链码实现 peer：是整个网络的基础，每一个peer的可以持有一个或多个ledger，每一个peer也可以有一个或多个chaincode network：是有peer组成的网络，形成区块链网络，在同一个网络中peer实现同步记账，保证了peer的数据一致性 ordering service：排序服务，进行排序和验证，验证通过的数据，写入peer节点的ledger，具体还要看背书策略 msp：peer节点的认证和标识","link":"/2022/04/29/Hyperledger%20Fabric%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%941.%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"title":"Hyperledger Fabric学习笔记——2.开发环境搭建","text":"​​点击阅读更多查看文章内容 1.需要的环境 docker docker-compose go JDK npm和node.js 2.下载fabric组件的Docker镜像下载地址 baseos下载0.3.1，其余都下载1.0.0，标记为latest baseos: docker pull hyperledger/fabric-baseos:x86_64-0.3.1 tools: docker pull hyperledger/fabric-tools:x86_64-1.0.0 peer: docker pull hyperledger/fabric-peer:x86_64-1.0.0 ccenv: docker pull hyperledger/fabric-ccenv:x86_64-1.0.0 ca: docker pull hyperledger/fabric-ca:x86_64-1.0.0 orderer: docker pull hyperledger/fabric-orderer:x86_64-1.0.0 镜像下载完成之后注意要给每个镜像添加一个latest标签 添加标签的方法：docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] 1234567891011docker tag hyperledger/fabric-tools:x86_64-1.0.0 hyperledger/fabric-tools:latestdocker tag hyperledger/fabric-ccenv:x86_64-1.0.0 hyperledger/fabric-ccenv:latestdocker tag hyperledger/fabric-ca:x86_64-1.0.0 hyperledger/fabric-ca:latestdocker tag hyperledger/fabric-orderer:x86_64-1.0.0 hyperledger/fabric-orderer:latestdocker tag hyperledger/fabric-peer:x86_64-1.0.0 hyperledger/fabric-peer:latestdocker tag hyperledger/fabric-baseos:x86_64-0.3.1 hyperledger/fabric-baseos:latest 3.下载fabric源码库github项目地址 下载：在github.com的hyperledger目录下git clone git://github.com/hyperledger/fabric.git 切换版本：cd fabric；git checkout release-1.0 进入目录 ：cd /home/gopath/src/github.com/hyperledger/fabric/common/configtx/tool/configtxgen(其中workstation是gopath目录) 编译工具 ：go install –tags=nopkcs11 进入目录 ：cd /home/gopath/src/github.com/hyperledger/fabric/common/tools/cryptogen 编译工具： go install –tags=nopkcs11， 编译好的工具在gopath的bin目录下 编译工具时可能会出现找不到文件的错误，这里需要检查一下gopath设置是否正确，目录结构是否正确，有时候即使通过 go en查到的gopath与命令实际查找的gopath不一致，建议通过以下方法再设置一遍：在shell里面输入“sudo vi /etc/environment”，在打开的文件末尾加入：“export GOPATH=/home/gopath”。注意：这个目录是我选中的目录，替换成你使用的目录！ 4.下载fabric-samplesgithub项目地址 下载： cd /home/gopath/src/github.com/hyperledger;git clone https://github.com/hyperledger/fabric-samples.git 进入目录：cd fabric-samples 切换版本：git checkout release-1.0 备份一下","link":"/2022/04/29/Hyperledger%20Fabric%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%942.%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"Hyperledger Fabric学习笔记——4.系统架构","text":"​​点击阅读更多查看文章内容 一、架构图 1、应用层 API：提供GRPC，RPC框架 SDK：在API基础上封装的SDK，go、java、python、nodejs 事件：分布式系统中，达成共识需要一定的时间，fabric使用异步通信模式开发，触发回调函数执行 身份：依托于底层的成员服务，是联盟链的认证功能，例如CA 账本：区块链的查询数据，是账本中查出来的，区块高度+交易ID，不重复 交易：对区块链数据进行修改，先提交交易到背书节点，签名认证之后再执行 智能合约：做合约的安装、实例化和升级 2、区块链底层 成员服务：提供证书，用于加密和签名 共识服务：CAP（不能全满足，只能满足两个，一致性、可用性和分区容忍性），实际上区块链弱化了一致性，所以需要共识算法保证一致性，fabric的共识大概分为3个阶段 首先客户端向背书节点发送一个背书提案，背书节点进行交易模拟，将背书结果和签名返回客户端 客户端将背书后的交易交给排序节点进行排序，由排序节点生成区块，向全网广播，网络节点收到广播后，先验证区块交易的正确性 验证通过后，存入本地账本 PS：排序节点与组织的锚节点使用的是GRPC通信，组织内使用的是gossip协议通信； 排序服务：顺序一样就认为状态是一样的，达成一个分布式一致性 链码服务：提供安全的、可隔离的交易环境，所以fabric使用docker，链码直接与docker通信，目前阶段对k8s支持的不好，会出问题 安全及密码服务：fabric定义了一个BCCSP接口，定义签名、加密解密等功能，默认实现了一套国际通用的密码服务，如sha256等 二、网络拓扑图 1、概念 客户端节点：应用程序和底层的交互媒介，与上层和peer和orderer连接发挥作用，连接peer做交易模拟 peer节点： 锚节点（主节点），在一个组织内可以有多个peer，一个组织中锚节点只有一个，锚节点的作用是与orderer进行通信，锚节点需要HA支持，若锚节点挂了，组织内会选举新的节点与orderer进行通信 背书节点（endorse）理解为担保，与智能合约绑定，每一个智能合约安装到区块链中，会有一个专属的背书策略，适应企业复杂的业务需求 记账节点（committer）所有的peer结点都是记账节点，用于验证从orderer接收到的区块，验证交易的有效性，验证通过后，同步到本地账本 orderer节点：排序节点，接受全网客户端节点的交易信息，按照一定规则进行排序，将排序好的交易，按照固定的时间间隔打包成区块，与其他组织的主节点进行通信，排序可以用solo（整个网络中只有一个排序节点，适用于开发和测试）和kafka（生产环境下使用，分布式消息队列）模式 CA节点：可选的，作用：颁发证书，只有被CA认证的节点才能进行交易，因此，fabric不存在51%攻击问题。 2、动作和行为 注册登记：由客户端发起，向CA机构表明自己的身份，获取证书，上图中是第三方的CA，也可以使用官方提供的CA 交易提案：向组织的背书节点提交请求，背书节点实际上就是peer节点，组织是独立的，可以理解为现实中的商业主体（京东、淘宝）；组织的数据来源有两个（客户端来的数据用来做模拟，排序节点来的数据用来执行） 提交交易：客户端节点向排序节点发请求，orderer内部进行排序打包成区块，广播给其他组织的锚节点，上图是基于kafka实现的，每个组织会选择一个orderer节点进行通信 三、交易流程图 客户端提交交易，最终到记账节点同步数据 智能合约安装要指定背书节点，正常情况下，背书节点返回相同的结果，但签名是不一样的 背书节点是模拟的过程，不会持久化 1，2，3步是交易模拟；4，5步是交易排序；6，7，8，9是交易同步和记账，交易模拟对应智能合约，交易排序对应共识机制，同步和记账对应账本存储","link":"/2022/04/29/Hyperledger%20Fabric%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%944.%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"},{"title":"Hyperledger Fabric学习笔记——5.fabric共识排序","text":"​​点击阅读更多查看文章内容 fabric不需要依赖挖矿，通过交易排序达成共识 1.共识机制 达成共识需要3个阶段，交易背书，交易排序，交易验证 交易背书：模拟交易 交易排序：确定交易顺序，最终将排序好的交易打包区块分发 交易验证：区块存储前要进行一下交易验证 2.orderer节点的作用 交易排序 目的：保证系统的最终一致性（有限状态机） solo：单节点排序 kafka：外置的分布式消息队列 区块分发 orderer中的区块并不是最终持久化的区块 是一个中间状态的区块 包含了所有交易，不管是否有效，都会打包传给组织的锚节点 多通道的数据隔离 3. 源码目录 bccsp：与密码学相关的，加密、数字签名、证书，将密码学中的函数抽象成了接口，方便调用和扩展 bddtests：行为驱动开发，从需求直接到开发 common：公共库、错误处理、日志处理、账本存储、相关工具 core：是fabric的核心库，子目录是各个模块的目录 comm：网络通信相关 devenv：官方提供的开发环境，使用的是Vagrant docs：文档 events：事件监听机制 examples：官方提供的例子程序 gossip：通信协议，组织内部的通信，区块同步 gotools：用于编译 images：docker镜像相关 msp：成员服务管理，member service provider，读取证书做签名 orderer：排序节点 peer：peer节点 proposals：用于扩展，新功能的提案 protos：数据结构的定义 4.共识机制源码 main.go是入口，orderer节点的初始化 manager.go是控制中枢，是对链的操作，拿到chainsupport对象 chainsupport.go链对象的代理，与链是对应的 cut()方法：区块切割 solo和kafka相关的配置 server.go有两个Handle，是交易收集和区块广播的方法 将共识简化为排序，达成最终一致性","link":"/2022/04/29/Hyperledger%20Fabric%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%945.fabric%E5%85%B1%E8%AF%86%E6%8E%92%E5%BA%8F/"},{"title":"Hyperledger Fabric学习笔记——7.链码安装、实例化、执行","text":"​​点击阅读更多查看文章内容 1.智能合约 执行环境：以太坊虚拟智能合约执行环境EVM，fabric执行环境是docker 链码 是应用层和区块链底层的中间点 每一个链码执行环境是一个独立的docker 使用GRPC协议与背书节点通信，只有背书节点才能运行智能合约 链码的生命周期 打包：智能合约的编写和编译 安装：将打包好的文件，上传到背书节点 实例化：实际安装，执行Init方法，只执行一次，构造函数 升级：升级和修复链码 交互：自己定义的方法的调用 链码的交互流程 系统链码（CC：chaincode） LSCC：管理链码的生命周期 CSCC：配置管理链码，管理链的配置 QSCC：查询账本存储，是一个区块索引的外部服务 ESCC：交易背书的链码，交易执行后的链码进行封装签名，给客户端返回背书交易结果 VSCC：交易验证的链码 链码编程的接口 Init()：链码初始化，只执行一次 Invoke() ：链码的业务逻辑的编写 上面2个方法参数一样，参数是SDK的接口 链码SDK的接口 写代码再看 一些注意点 分布式多机多节点执行，链码会执行多次 不写随机函数，交易会无效，多次执行不一样 不写系统时间，多机时间不一定一样 2.网络搭建配置的实现 crypto-config.yaml：用于配置节点的个数，参考firstnetwork编写 编写好后，传到linux对应目录 进入deploy目录，设置工作目录为当前目录export FABRIC_CFG_PATH=$GOPATH/src/fabric_asset/deploy 指定按照yaml文件生成配置cryptogen generate --config=./crypto-config.yaml configtx.yaml：用于区块联盟中的组织信息，配置名字和证书等的位置，参考firstnetwork编写 编写好后，传到linux对应目录 创建用于存放配置的目录mkdir config 生成系统链的创世区块-profile：指定联盟配置-outputBlock：指定存放的位置configtxgen -profile OneOrgsOrdererGenesis -outputBlock ./config/genesis.block 生成通道的创世交易-profile：指定业务联盟-outputCreateChannelTx：指定存放路径-channelID：指定创建名字configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./config/mychannel.tx -channelID mychannel 生成两个组织锚节点的交易信息configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./config/Org0MSPanchors.tx -channelID mychannel -asOrg Org0MSPconfigtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./config/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP 新建docker-compose.yaml文件并移动到deploy目录下 3.启动网络 启动docker，后台运行（要以管理员身份运行）docker-compose up -d 查看orderer节点的运行日志docker logs orderer.example.com 与客户端交互操作docker exec -it cli bash 创建通道-o：指定与哪个orderer节点通信-c：指定创建的通道名称-f：指定使用的文件peer channel create -o orderer.example.com:7050 -c mychannel -f /etc/hyperledger/config/mychannel.tx 加入通道peer channel join -b mychannel.block 查看peer加入的通道列表peer channel list 指定主节点peer channel update -o orderer.example.com:7050 -c mychannel -f /etc/hyperledger/config/Org1MSPanchors.tx 安装链码-n：安装的名字-v: version-l：使用语言-p：pathpeer chaincode install -n badexample -v 1.0.0 -l golang -p github.com/chaincode/badexample 克隆一个会话，交互执行peer0，查看安装的链码docker exec -it peer0.org1.example.com bashcd /var/hyperledger/production/chaincodes/ 链码实例化peer chaincode instantiate -o orderer.example.com:7050 -C mychannel -n badexample -l golang -v 1.0.0 -c '{&quot;Args&quot;:[&quot;init&quot;]}' 链码交互执行peer chaincode query -C mychannel -n badexample -c '{&quot;Args&quot;:[]}' 多次执行查询，得到的结果不同，因为invoke()中使用了随机数，不要这么做 4.网络关闭 退出客户端exit 在deploy目录下关闭dockerdocker-compose down","link":"/2022/04/29/Hyperledger%20Fabric%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%947.%E9%93%BE%E7%A0%81%E5%AE%89%E8%A3%85%E3%80%81%E5%AE%9E%E4%BE%8B%E5%8C%96%E3%80%81%E6%89%A7%E8%A1%8C/"},{"title":"Hyperledger Fabric学习笔记——6.账本存储","text":"​​点击阅读更多查看文章内容 1.账本存储概念 peer节点做账本存储 orderer是临时存储区块，peer节点是账本存储的持久化，会改变世界状态 文件系统：区块是存储为文件的 区块索引：用于查询区块，是用levelDB实现的 状态数据库：一般存放区块链最新状态，数据不需要HA，可以从文件系统再次获取，couchDB支持模糊查询 2. 交易读写集 交易流程 交易模拟 在背书节点执行模拟时，最终返回交易读写集（RWset），告诉区块链在交易中读写了哪些数据 交易排序 交易验证，交易验证后，更新世界状态，更新的就是读写集中的写集 读写集的3个概念 读集：包含键的列表，键的提交版本，读取对应的值，返回的是已提交的状态的值（读已提交的内容，不能读取当前交易写入的数据） 写集：包含键的列表，写入的数据的值，如果多次写入，以最后一次为准 版本号：用区块高度和交易编号组成 交易验证阶段是对读写集进行验证（验证读集） 验证读集的版本号是否等于世界状态的版本号 3.账本存储相关概念 世界状态 交易执行后，所有键的最新值 历史数据索引（可选） 区块存储 按照文件存储 blocfile_xxxxxx 文件大小是64M，若修改，需要重新编译peer源码 账本最大容量64M* 区块读取 区块文件流 区块流 迭代器 区块索引 键：区块高度、区块哈希、交易哈希 值：区块文件编号、文件内的偏移量、区块数据的长度 区块提交 保存到文件 4. 账本存储相关源码 从4方面看，读写集、状态数据、历史数据、区块文件 可以先从core/ledger下的ledger_interface.go中看大体结构 读写集，分为交易读写集生成和交易读写集验证两个部分去看 交易读写集生成 core/ledger/kvledger/txmgmt/txmgr/lockbasedtxmgr/lockbased_tx_simulator.go 交易读写集验证 core/ledger/kvledger/txmgmt/validator/statebasedval/state_based_validator.go 状态数据库：看levelDB的实现 core/ledger/kvledger/txmgmt/statedb/stateleveldb/stateleveldb.go 历史数据库：看levelDB的实现 core/ledger/kvledger/history/historydb/historyleveldb/historyleveldb.go 区块文件读取 common/ledger/blkstorage/fsblkstorage/fs_blockstore.go 区块流：common/ledger/blkstorage/fsblkstorage/block_stream.go 5.账本存储相关源码总结 首先看了账本存储的根目录的接口，从宏观上把握 交易读写集的生成和验证 数据库增删改查 还有一个没有实现的方法，数据裁剪的接口，可能去解决数据无限增长的处理","link":"/2022/04/29/Hyperledger%20Fabric%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%946.%E8%B4%A6%E6%9C%AC%E5%AD%98%E5%82%A8/"},{"title":"HyperledgerFabric资产案例链码实例","text":"​​点击阅读更多查看文章内容 案例分析 功能 用户开户和销户 资产登记，资产上链，与具体的用户绑定 资产转让，资产所有权变更 查询功能，用户查询，资产查询，资产变更的历史查询 业务实体 用户 名字 身份证（标识） 资产列表 资产 名字 标识 特殊属性列表（车：排量、品牌、座位） 资产变更记录 资产标识 资产的原始拥有者 资产变更后的拥有者 交互方法 用户开户 参数：名字、标识 用户销户 参数：标识 资产登记 参数：名字、标识、特殊属性列表、拥有者 资产转让 参数：拥有者、资产标识、受让者 用户查询 参数：用户标识；返回值：用户实体 资产查询 参数：资产标识；返回值：资产实体 资产的变更历史查询 参数：资产标识；返回值：资产的变更记录列表 案例测试 创建通道的创世交易（channel名字不能有大写）configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./config/assetschannel.tx -channelID assetschannel 启动网络docker-compose up -d 交互执行docker exec -it cli bash 创建通道peer channel create -o orderer.example.com:7050 -c assetschannel -f /etc/hyperledger/config/assetschannel.tx 加入通道(一个peer可以加入多个通道)peer channel join -b assetschannel.block 安装链码peer chaincode install -n assets -v 1.0.0 -l golang -p github.com/chaincode/assetsExchange 实例化链码peer chaincode instantiate -o orderer.example.com:7050 -C assetschannel -n assets -v 1.0.0 -l golang -c'{&quot;Args&quot;:[&quot;init&quot;]}' 测试方法 用户开户peer chaincode invoke -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;userRegister&quot;,&quot;user1&quot;,&quot;user1&quot;]}' 用户查询peer chaincode query -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;queryUser&quot;,&quot;user1&quot;]}' 资产登记peer chaincode invoke -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;assetEnroll&quot;,&quot;asset1&quot;,&quot;asset1&quot;,&quot;metadate&quot;,&quot;user1&quot;]}' 资产查询peer chaincode query -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;queryAsset&quot;,&quot;asset1&quot;]}'再查询用户，可以看到用户资产已经改变peer chaincode query -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;queryUser&quot;,&quot;user1&quot;]}'- 资产转让新建用户user2peer chaincode invoke -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;userRegister&quot;,&quot;user2&quot;,&quot;user2&quot;]}'资产转让，user1的资产asset1转给user2peer chaincode invoke -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;assetExchange&quot;,&quot;user1&quot;,&quot;asset1&quot;,&quot;user2&quot;]}' 查询资产变更历史peer chaincode query -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;queryAssetHistory&quot;,&quot;asset1&quot;]}' 删除用户，用户的资产会被同时删除peer chaincode invoke -C assetschannel -n assets -c '{&quot;Args&quot;:[&quot;userDestroy&quot;,&quot;user2&quot;]}' 案例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487package mainimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;github.com/hyperledger/fabric/core/chaincode/shim&quot; pb &quot;github.com/hyperledger/fabric/protos/peer&quot;)//定义链码type AssetsExchangeCC struct {}//资产默认的原始拥有者const ( originOwner = &quot;originOwnerPlaceholder&quot;)//资产type Asset struct { Name string `json:&quot;name&quot;` Id string `json:&quot;id&quot;` Metadata string `json:&quot;metadata&quot;`}//用户type User struct { Name string `json:&quot;name&quot;` Id string `json:&quot;id&quot;` Assets []string `json:&quot;assets&quot;`}//资产变更记录type AssetHistory struct { //资产标识 AssetId string `json:&quot;asset_id&quot;` //资产的原始拥有者 OriginOwnerId string `json:&quot;origin_owner_id&quot;` //变更后的拥有者 CurrentOwnerId string `json:&quot;current_owner_id&quot;`}//链码的初始化func (c *AssetsExchangeCC) Init(stub shim.ChaincodeStubInterface) pb.Response { return shim.Success(nil)}//链码交互func (c *AssetsExchangeCC) Invoke(stub shim.ChaincodeStubInterface) pb.Response { //得到方法名 funcName, args := stub.GetFunctionAndParameters() //根据不同方法去判断 switch funcName { case &quot;userRegister&quot;: //用户开户 return userRegister(stub, args) case &quot;userDestroy&quot;: //用户销户 return userDestroy(stub, args) case &quot;assetEnroll&quot;: //资产登记 return assetEnroll(stub, args) case &quot;assetExchange&quot;: //资产转让 return assetExchange(stub, args) case &quot;queryUser&quot;: //用户查询 return queryUser(stub, args) case &quot;queryAsset&quot;: //资产查询 return queryAsset(stub, args) case &quot;queryAssetHistory&quot;: //资产变更历史查询 return queryAssetHistory(stub, args) default: return shim.Error(fmt.Sprintf(&quot;不支持的方法：%s&quot;, funcName)) }}//用户开户func userRegister(stub shim.ChaincodeStubInterface, args []string) pb.Response { //判断个数必须为2个 if len(args) != 2 { return shim.Error(&quot;参数个数错误&quot;) } //判断传过来的参数是a否为空 name := args[0] id := args[1] if name == &quot;&quot; || id == &quot;&quot; { return shim.Error(&quot;无效的参数&quot;) } //判断用户是否存在，若存在，则报错 if userBytes, err := stub.GetState(constructUserKey(id)); err == nil &amp;&amp; len(userBytes) != 0 { return shim.Error(&quot;用户已存在&quot;) } //写入世界状态，传过来的是用户的名字和id，绑定User结构体 make([]string,0) user := &amp;User{ Name: name, Id: id, Assets: make([]string, 0), } //序列化 userBytes, err := json.Marshal(user) if err != nil { return shim.Error(fmt.Sprintf(&quot;序列化与用户失败 %s&quot;, err)) } //将对象状态写入数据库 if err := stub.PutState(constructUserKey(id), userBytes); err != nil { return shim.Error(fmt.Sprintf(&quot;存入用户失败 %s&quot;, err)) } //返回成功 return shim.Success(nil)}func constructUserKey(userId string) string { return fmt.Sprintf(&quot;user_%s&quot;, userId)}//用户销户func userDestroy(stub shim.ChaincodeStubInterface, args []string) pb.Response { //参数个数1个 if len(args) != 1 { return shim.Error(&quot;参数个数不对&quot;) } //校验参数正确性 id := args[0] if id == &quot;&quot; { return shim.Error(&quot;无效的参数&quot;) } //判断用户是否存在 userBytes, err := stub.GetState(constructUserKey(id)) if err != nil &amp;&amp; len(userBytes) == 0 { return shim.Error(&quot;找不到用户&quot;) } //写入状态 if err := stub.DelState(constructUserKey(id)); err != nil { return shim.Error(fmt.Sprintf(&quot;删除用户失败 %s&quot;, err)) } //删除用户名下的资产 user := new(User) if err := json.Unmarshal(userBytes, user); err != nil { return shim.Error(fmt.Sprintf(&quot;反序列化失败 %s&quot;, err)) } for _, assetid := range user.Assets { if err := stub.DelState(constructAssetKey(assetid)); err != nil { return shim.Error(fmt.Sprintf(&quot;删除资产失败 %s&quot;, err)) } } return shim.Success(nil)}//使用组合键来区分//所有的资产，用asset开头func constructAssetKey(assetId string) string { return fmt.Sprintf(&quot;asset_%s&quot;, assetId)}//资产登记func assetEnroll(stub shim.ChaincodeStubInterface, args []string) pb.Response { if len(args) != 4 { return shim.Error(&quot;参数个数不对&quot;) } //验证正确性 assetName := args[0] assetId := args[1] metadata := args[2] ownerId := args[3] //metadata可以为空 if assetName == &quot;&quot; || assetId == &quot;&quot; || ownerId == &quot;&quot; { return shim.Error(&quot;无效的参数&quot;) } //验证拥有者是否存在,拥有者必须存在 userBytes, err := stub.GetState(constructUserKey(ownerId)) if err != nil || len(userBytes) == 0 { return shim.Error(&quot;找不到用户&quot;) } //验证资产是否存在,资产必须不存在 if assetBytes, err := stub.GetState(constructAssetKey(assetId)); err == nil &amp;&amp; len(assetBytes) != 0 { return shim.Error(&quot;资产已经存在&quot;) } //写入状态 asset := &amp;Asset{ Name: assetName, Id: assetId, Metadata: metadata, } //序列化 assetBytes, err := json.Marshal(asset) if err != nil { return shim.Error(fmt.Sprintf(&quot;序列化失败 %s&quot;, err)) } //保存资产 if err := stub.PutState(constructAssetKey(assetId), assetBytes); err != nil { return shim.Error(fmt.Sprintf(&quot;保存失败 %s&quot;, err)) } //拥有者 user := new(User) if err := json.Unmarshal(userBytes, user); err != nil { return shim.Error(fmt.Sprintf(&quot;反序列化失败 %s&quot;, err)) } user.Assets = append(user.Assets, assetId) if userBytes, err = json.Marshal(user); err != nil { return shim.Error(fmt.Sprintf(&quot;序列化用户失败 %s&quot;, err)) } //存储用户状态 if err := stub.PutState(constructUserKey(user.Id), userBytes); err != nil { return shim.Error(fmt.Sprintf(&quot;保存用户失败 %s&quot;, err)) } //资产历史变更 history := &amp;AssetHistory{ AssetId: assetId, OriginOwnerId: originOwner, CurrentOwnerId: ownerId, } historyBytes, err := json.Marshal(history) if err != nil { return shim.Error(fmt.Sprintf(&quot;序列化失败 %s&quot;, err)) } //使用fabric内置的组合键机制 historyKey, err := stub.CreateCompositeKey(&quot;history&quot;, []string{ assetId, originOwner, ownerId, }) if err != nil { return shim.Error(fmt.Sprintf(&quot;创建key失败 %s&quot;, err)) } //资产变更存储 if err := stub.PutState(historyKey, historyBytes); err != nil { return shim.Error(fmt.Sprintf(&quot;保存变更历史失败 %s&quot;, err)) } return shim.Success(nil)}//资产转让func assetExchange(stub shim.ChaincodeStubInterface, args []string) pb.Response { //参数个数为3个 if len(args) != 3 { return shim.Error(&quot;参数个数不对&quot;) } //参数校验 ownerId := args[0] assetId := args[1] currentOwnerId := args[2] if ownerId == &quot;&quot; || assetId == &quot;&quot; || currentOwnerId == &quot;&quot; { return shim.Error(&quot;无效的参数&quot;) } //验证当前和受让后的用户是否存在 originOwnerBytes, err := stub.GetState(constructUserKey(ownerId)) if err != nil || len(originOwnerBytes) == 0 { return shim.Error(&quot;用户找不到&quot;) } currentOwnerBytes, err := stub.GetState(constructUserKey(currentOwnerId)) if err != nil || len(currentOwnerBytes) == 0 { return shim.Error(&quot;用户找不到&quot;) } //验证资产存在 assetBytes, err := stub.GetState(constructAssetKey(assetId)) if err != nil || len(assetBytes) == 0 { return shim.Error(&quot;资产找不到&quot;) } //校验原始拥有者确实拥有当前变更的资产 originOwner := new(User) if err := json.Unmarshal(originOwnerBytes, originOwner); err != nil { return shim.Error(fmt.Sprintf(&quot;反序列化失败 %s&quot;, err)) } //定义标记，标识资产是否存在 aidexist := false for _, aid := range originOwner.Assets { if aid == assetId { //若找到该资产，则变更状态，结束循环 aidexist = true break } } if !aidexist { return shim.Error(&quot;资产所有者不匹配&quot;) } //写入状态 //1.将资产的原始拥有者资产id删除 //2.新拥有者写入资产id,资产绑定 //3.资产变更记录 assetIds := make([]string, 0) for _, aid := range originOwner.Assets { if aid == assetId { //遍历到了要转让的资产 continue } assetIds = append(assetIds, aid) } originOwner.Assets = assetIds //序列化 originOwnerBytes, err = json.Marshal(originOwner) if err != nil { return shim.Error(fmt.Sprintf(&quot;序列化失败 %s&quot;, err)) } //存储原始拥有者 if err := stub.PutState(constructUserKey(ownerId), originOwnerBytes); err != nil { return shim.Error(fmt.Sprintf(&quot;存储用户失败 %s&quot;, err)) } //当前拥有者 currentOwner := new(User) if err := json.Unmarshal(currentOwnerBytes, currentOwner); err != nil { return shim.Error(fmt.Sprintf(&quot;反序列化失败 %s&quot;, err)) } //绑定资产 currentOwner.Assets = append(currentOwner.Assets, assetId) currentOwnerBytes, err = json.Marshal(currentOwner) if err != nil { return shim.Error(fmt.Sprintf(&quot;序列化失败 %s&quot;, err)) } //存储 if err := stub.PutState(constructUserKey(currentOwnerId), currentOwnerBytes); err != nil { return shim.Error(&quot;保存用户失败&quot;) } //插入资产变更记录 history := &amp;AssetHistory{ AssetId: assetId, OriginOwnerId: ownerId, CurrentOwnerId: currentOwnerId, } historyBytes, err := json.Marshal(history) if err != nil { return shim.Error(fmt.Sprintf(&quot;序列化失败 %s&quot;, err)) } historyKey, err := stub.CreateCompositeKey(&quot;history&quot;, []string{ assetId, ownerId, currentOwnerId, }) if err != nil { return shim.Error(fmt.Sprintf(&quot;创建key失败 %s&quot;, err)) } //存储历史变更记录 if err := stub.PutState(historyKey, historyBytes); err != nil { return shim.Error(fmt.Sprintf(&quot;保存失败 %s&quot;, err)) } return shim.Success(nil)}//用户查询func queryUser(stub shim.ChaincodeStubInterface, args []string) pb.Response { //参数个数1个 if len(args) != 1 { return shim.Error(&quot;参数个数不对&quot;) } //校验正确性 ownerId := args[0] if ownerId == &quot;&quot; { return shim.Error(&quot;无效的参数&quot;) } userBytes, err := stub.GetState(constructUserKey(ownerId)) if err != nil || len(userBytes) == 0 { return shim.Error(&quot;找不到用户&quot;) } return shim.Success(userBytes)}//资产查询func queryAsset(stub shim.ChaincodeStubInterface, args []string) pb.Response { //参数个数1个 if len(args) != 1 { return shim.Error(&quot;参数个数不对&quot;) } //校验正确性 assetId := args[0] if assetId == &quot;&quot; { return shim.Error(&quot;无效的参数&quot;) } assetBytes, err := stub.GetState(constructAssetKey(assetId)) if err != nil || len(assetBytes) == 0 { return shim.Error(&quot;找不到资产&quot;) } return shim.Success(assetBytes)}//资产历史变更查询func queryAssetHistory(stub shim.ChaincodeStubInterface, args []string) pb.Response { //参数个数1个 if len(args) != 1 &amp;&amp; len(args) != 2 { return shim.Error(&quot;参数个数不对&quot;) } //校验参数的正确性 assetId := args[0] if assetId == &quot;&quot; { return shim.Error(&quot;无效的参数&quot;) } //queryType：all //默认为all queryType := &quot;all&quot; if len(args) == 2 { //变为用户传的值 queryType = args[1] } //参数校验 if queryType != &quot;all&quot; &amp;&amp; queryType != &quot;exchange&quot; &amp;&amp; queryType != &quot;enroll&quot; { return shim.Error(fmt.Sprintf(&quot;未知的查询类型 %s&quot;, queryType)) } //校验资产是否存在 assetBytes, err := stub.GetState(constructAssetKey(assetId)) if err != nil || len(assetBytes) == 0 { return shim.Error(&quot;资产找不到&quot;) } keys := make([]string, 0) keys = append(keys, assetId) switch queryType { case &quot;enroll&quot;: //资产登记 keys = append(keys, originOwner) case &quot;exchange&quot;, &quot;all&quot;: default: return shim.Error(fmt.Sprintf(&quot;不支持的类型 %s&quot;, queryType)) } //组合键 //得到迭代器 result, err := stub.GetStateByPartialCompositeKey(&quot;history&quot;, keys) if err != nil { return shim.Error(fmt.Sprintf(&quot;查询历史错误 %s&quot;, err)) } //关闭 defer result.Close() histories := make([]*AssetHistory, 0) for result.HasNext() { historyVal, err := result.Next() if err != nil { return shim.Error(fmt.Sprintf(&quot;查询错误 %s&quot;, err)) } history := new(AssetHistory) if err := json.Unmarshal(historyVal.GetValue(), history); err != nil { return shim.Error(fmt.Sprintf(&quot;反序列化失败 %s&quot;, err)) } //过滤，不是资产转让的记录过滤 if queryType == &quot;exchange&quot; &amp;&amp; history.OriginOwnerId == originOwner { continue } histories = append(histories, history) } historiesBytes, err := json.Marshal(histories) if err != nil { return shim.Error(fmt.Sprintf(&quot;序列化失败 %s&quot;, err)) } return shim.Success(historiesBytes)}func main() { err := shim.Start(new(AssetsExchangeCC)) if err != nil { fmt.Println(&quot;启动链码失败&quot;) }}","link":"/2022/04/29/HyperledgerFabric%E8%B5%84%E4%BA%A7%E6%A1%88%E4%BE%8B%E9%93%BE%E7%A0%81%E5%AE%9E%E4%BE%8B/"},{"title":"IDEA使用小技巧","text":"​​点击阅读更多查看文章内容 常用的基本设置 界面字体 File | Settings | Appearance &amp; Behavior | Appearance 编辑区字体 File | Settings | Editor | Color Scheme | Color Scheme Font Use color scheme font instead of the default 控制台字体 File | Settings | Editor | Color Scheme | Console Font Use console font instead of the default 通过ctrl+鼠标滚轮控制字体大小File | Settings | Editor | General 勾选 change font size with Ctrl+Mouse Wheel 将编码全部改为UTF-8在settings中搜索encode，将编码都改为utf-8 JDK设置Project Structure - Project Settings - Project - SDK 单击目录的文件自动打开并定位在编辑区 项目目录始终定位在编辑区打开的文件 自动导入(import)File | Settings | Editor | General | Auto Import 编辑区设置 显示行号File | Settings | Editor | General | AppearanceShow line numbers tabs位置File | Settings | Editor | General | Editor TabsTab placement tabs排序File | Settings | Editor | General | Editor TabsSort tabs alphabetically 代码编辑 复制复制一行代码时，可以直接把光标放在该行任意位置，Ctrl+C复制文件名时，直接在左侧的项目目录选择文件，Ctrl+C复制光标所在行，Ctrl+D复制多行，先选中多行，Ctrl+D查看复制历史，Ctrl+shift+V，双击即可粘贴内容 粘贴普通粘贴，会自动格式化，Ctrl+V纯文本粘贴，不会格式化，Ctrl+alt+shift+V 格式化代码文件格式化：Ctrl+alt+L局部格式化：选中需要格式化的部分，Ctrl+alt+L 剪切剪切光标所在行（不需要选中），可以当删除用，Ctrl+X 移动Alt+Shift+上/下：当前行向上/下移动一行Ctrl+Shift+上/下：带格式移动选中多行可以移动多行 快速跳转 行内跳转Home键跳到行首，End键跳到行尾Ctrl+左/右：光标一次跳过一个词Ctrl+Shift+左/右：选中一个词 根据行号定位 Ctrl+G：跳到指定行 Tabs快速切换Alt+左/右：左/右切换Tabs 查看最近浏览过的文件Ctrl+E 快速查找和替换 当前文件查找Ctrl+F 当前文件替换Ctrl+R 全局搜索（Find in Files）Ctrl+Shift+F（可以选择项目或目录等） 全局替换Ctrl+Shift+R 万能查找Shift+Shift，可以查找文件、操作、文本等 万能快捷键Alt+Enter智能辅助提示。给出的提示与当前光标所在的位置有关系。 见到红色报错就按 见到波浪线警告就按 没报错没警告也可以按（删除无用变量，自动生成构造方法） 键鼠配合 竖向选择alt+鼠标左键拖动 进入方法Ctrl+鼠标左键跳回刚才的位置：Ctrl+Alt+方向键左 调试项目 Step Over：执行到当前方法的下一句 Step Into：进入当前行调用的方法体里 Step Out：执行完当前的方法 Run to Cursor：运行到光标所在处 删除断点、失效断点、条件断点 Mute Breakpoints：失效所有断点 异常断点：当抛出某个异常时执行断点 代码生成Generate在类中使用快捷键Alt+Insert 或者 右键-Generate 生成Get/Set方法Getter and Setter 生成构造函数Constructor toStringtoString()：默认使用+拼接，建议使用stringbuffer equals() and hashCode()生成时可以选择判断相等或生成哈希的属性 代码重构 重命名选中后，Shift+F6或右键-Refactor-Rename变量、函数、类在改动函数名时，idea会同步选择项目中相同的地方进行修改，如果idea筛选的改动位置不是我们希望改动的，可以右键-exclude，排除当前行，如果某个包下都不想改，可以在包上右键-exclude，统一排除。 抽取方法将部分代码抽取出一个新的方法选中代码-右键-Refactor-Extract Method 生成变量Ctrl+Alt+V：调用方法自动生成返回值；实例化对象自动生成变量 文件移动/复制/删除移动：选中文件，F6 或 右键-Refactor-Move复制：F5删除：Delete 代码模板File | Settings | Editor | Live Templates（可以自定义）live templates （直接打快捷键） 生成Main函数psvm 生成输出语句sout 生成for循环fori File | Settings | Editor | General | Postfix Completion（不能自定义）postfix（先打变量或表达式，再打.快捷键） 10.fori：for (int i = 0; i &lt; 10; i++) { } i==1.if：if (i==1) { } user.null：if (user == null) { } user.sout：System.out.println(user); 更多实用技巧 tab分屏和独立右键-splittab变为独立窗口：拖动出idea/选择文件 Shift+F4 本地修改历史选择文件-右键Local History-Show History 查看方法调用情况选择方法 Ctrl+Alt+H 或 点击Hierarchy窗口Caller：调用该方法的Callee：该方法调用的 多选选择文件中出现的所有同一字符串：选择字符串-Ctrl+Alt+Shift+J 常用插件git插件","link":"/2023/12/12/IDEA%E4%BD%BF%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"title":"IDEA运行单个java文件，忽略其他文件错误","text":"​​点击阅读更多查看文章内容 IDEA运行单个java文件，忽略其他文件错误使用idea想单独运行一段测试程序，但是直接run的话会报其他程序的错误，使用以下方法可以实现单独运行一段测试程序。 File | Settings | Build, Execution, Deployment | Compiler | Java Compiler，将compiler修改为Eclipse（注意这里有一个Project bytecode version后面可能会报错）设置完成之后如果直接编译会报错：java: java.lang.IllegalArgumentException: source level should be in ‘1.1’…’1.8’,’9’…’18’ (or ‘5.0’..’18.0’): 21这里是因为默认的版本21不支持，按照错误信息，我们将Project bytecode version修改为18即可。 修改Run/Debug Configurations，添加Add before launch task，去掉默认的Build，添加Build，no error check 直接run测试代码即可","link":"/2023/12/26/IDEA%E8%BF%90%E8%A1%8C%E5%8D%95%E4%B8%AAjava%E6%96%87%E4%BB%B6%EF%BC%8C%E5%BF%BD%E7%95%A5%E5%85%B6%E4%BB%96%E6%96%87%E4%BB%B6%E9%94%99%E8%AF%AF/"},{"title":"IPFS简述","text":"​​点击阅读更多查看文章内容 IPFS概述参考视频：9分钟简单理解IPFS 背景传统的网络信息都是中心化存储的，通常都存储在大型的服务器群中，由一家公司控制，如果公司的服务器出现问题，很容易造成信息的丢失。同时，中心化的存储还存在政府审查的问题，由于内容只托管在少数几台服务器上，政府很容易就能够阻止对它们的访问（2017年，土耳其政府下令互联网封锁维基百科）。但为什么我们一直使用这样的模型呢？那是因为我们对网络有很高的期望，我们希望网页、图像和视频实时加载，并且是高质量加载（例如高清晰度、流畅度等等），中心化服务器允许公司完全控制提供所有这些内容的速度。我们使用这种模式的另一个原因是，没有一个好的和快速的替代方案。 如何寻址基于地址寻址：传统的网络是基于地址寻址，假设你想从网上下载一张照片，传统的网络是你告诉电脑照片的IP地址或者是域名，然后到这个地址去下载照片，但如果这个地址无法访问，你就无法获取照片。然而，很有可能其他人之前已经下载了这张照片，并且仍然有他的副本，而你的电脑无法从那个人那里获取副本。为了解决这个问题，IPFS从“基于位置”寻址改为“基于内容”寻址。基于内容寻址：每个文件都有唯一的哈希值，可以比作指纹。当你想要下载某个文件时，可以问网络“谁拥有带有这个散列的文件”，IPFS网络上的其他人会提供给你。同时，因为使用散列值来请求文件，当你收到文件时，可以检查文件的散列值与你想要的散列是否匹配，以此可以检查你收到的文件有没有被篡改。使用散列值处理内容的另一个很好的特性是重复数据删除，当多人在IPFS上发布相同的文件时，它只会被创建一次，这使得网络非常高效。 如何存储文件文件存储在IPFS对象中，这些对象可以存储最多256kb的数据，并可以包含到其他IPFS对象的链接，一个非常小的“Hello World”文本文件可以存储在一个IPFS对象中 大于256kb的数据可以被分成多个IPFS对象，大小都是256kb，然后系统将创建一个空的IPFS对象，将对象链接到文件的所有其他部分。 IPFS的数据架构允许我们像使用文件系统一样使用它，例如下面是一个简单的目录结构，其中包含一些文件，我们也可以将其转换为IPFS对象，为每个文件和目录创建一个对象 如何修改文件IPFS使用基于内容的寻址，一旦添加了一些东西，就不能再更改了，它是一个不可变的数据结构，很像区块链。但是你怎么改变上面的内容呢？IPFS支持文件版本控制，当你处理一个希望通过IPFS与所有人共享的重要文档时，IPFS将为你创建一个新的“Commit对象”。这个对象非常基本，它只是告诉IPFS在它之前进行了哪些提交，并且链接到文件的IPFS对象，当你要更新文件时，你只需要将更新后的文件添加到IPFS网络，软件将为你的文件创建一个新的Commit对象，这个对象链接到前一个Commit，这个过程可以无限重复，IPFS将确保网络上的其他节点可以访问您的文件及其整个历史记录 局限性IPFS面临的最大问题是保持文件可用，网络上的每个节点都保存着下载文件的缓存，并在其他人需要时帮助分享这些文件。但是，如果保存一个文件的所有节点都脱机了，那么这个文件就不可用了，没有人可以获取到这个文件的副本。这个问题有两种可能的解决方案，一是鼓励人们储存文件，让他们可以使用。二是鼓励人们主动分发文件，确保网络上总有一定数量的副本，而这就是FileCoin想做的事情 FileCoinFileCoin是由创建IPFS的同一组人创建的，它基本是一个构建在IPFS之上的区块链，希望为存储创建一个去中心化的市场，如果你有一些空闲的空间，你可以把它租给别人，在这个过程中赚钱。FileCoin为节点创建了一个强大的激励机制，让它们尽可能长时间地保持文件在线，否则它们将得不到奖励，系统还确保文件被复制到许多节点上，这样它们就不会变得不可用","link":"/2022/06/27/IPFS%E7%AE%80%E8%BF%B0/"},{"title":"JavaWeb实现简单的用户注册登录（入门级）","text":"​​点击阅读更多查看文章内容 JavaWeb实现简单的用户注册登录代码主要参考的以下博客，我自己修改了一些，可以让刚入门的同学（我自己）更好的理解。https://blog.csdn.net/caojianhua2018/article/details/92412453 项目结构dao：这个包下主要是一些关于数据库的操作dao.DButils：数据库的创建和删除dao.LoginDaolmp：数据库与用户的交互操作，包括检验用户登录的账号是否合法，当用户注册时将账号插入数据库。 Servlet：实现javaweb的前后端交互UserRegister：用户注册，当注册新用户时会跳转到此，实现将新用户的账号密码插入数据库中。UserServlet：用户登录，当用户登录账号时会跳转到此，实现对用户账号密码的合法性检验。 Servlet（Server Applet），全称Java Servlet，未有中文译文。是用Java编写的服务器端程序。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。狭义的Servlet是指Java语言实现的一个接口，广义的Servlet是指任何实现了这个Servlet接口的类，一般情况下，人们将Servlet理解为后者。 NewFile：登录页面register：注册页面welcome：登陆成功页面 初始数据库这里我用的可视化工具是Navicat 前端页面设计登录界面： 12345678910111213141516171819202122232425262728293031&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;script&gt;// function submit(){// document.login.action=&quot;jiaoyan.jsp&quot;;// document.login.submit();// }function zhuce(){ document.login.action=&quot;register.jsp&quot;; document.login.submit();}&lt;/script&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;登录页面&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form id=&quot;form1&quot; name=&quot;login&quot; action=&quot;UserServlet&quot; method=&quot;post&quot; &gt;用户：&lt;input name=&quot;username&quot; type=&quot;text&quot;&gt;&lt;br&gt;&lt;br&gt;密码：&lt;input name=&quot;userpwd&quot; type=&quot;password&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;input type=&quot;submit&quot; value=&quot;提交查询&quot; &gt;&lt;input type=&quot;button&quot; value=&quot;注册用户&quot; onclick=zhuce()&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 这个页面有两个按钮，一个是提交按钮，点击后转入UserServlet执行，一个是注册按钮，点击后转到注册页面。 注册界面： 12345678910111213141516&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html;charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;注册页面&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form id=&quot;form1&quot; action=&quot;UserRegister&quot; method=&quot;post&quot;&gt;用户名：&lt;input name=&quot;username&quot; type=&quot;text&quot;&gt;密码：&lt;input name=&quot;userpwd&quot; type=&quot;password&quot;&gt;&lt;input value=&quot;注册&quot; type=&quot;submit&quot; name=&quot;submit&quot;&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 本页面只有一个注册按钮，点击后转入UserRegister执行。 登陆成功界面： 12345678910111213141516171819202122&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;&gt;&lt;title&gt;欢迎页面&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% if(session.getAttribute(&quot;check&quot;)!=null){%&gt; 欢迎 &lt; &lt;%=session.getAttribute(&quot;username&quot;) %&gt; &gt;&lt;% }else{%&gt; &lt;jsp:forward page=&quot;NewFile.jsp&quot;&gt;&lt;/jsp:forward&gt; &lt;% }%&gt;&lt;/body&gt;&lt;/html&gt; 登陆成功后转入本页面，其中username保存的是登陆时的用户名，check用于检查是否是由登录页面转来，如果是直接运行的此页面则会跳转至登录页面。 Dao数据访问对象DButils.java 1234567891011121314151617181920212223242526272829303132package dao;import java.sql.*;public class DButils { static final String JDBC_DRIVER=&quot;com.mysql.jdbc.Driver&quot;; static final String DB_URL=&quot;jdbc:mysql://127.0.0.1:3306/jdb?user=xxxx&amp;password=xxxx&amp;useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=true&quot;; static Connection conn=null; //连接数据库 public static Connection getConnection() { try { Class.forName(JDBC_DRIVER); conn=DriverManager.getConnection(DB_URL); System.out.println(&quot;连接成功&quot;); }catch(Exception e) { e.printStackTrace(); } return conn; } //关闭数据库连接 public static void Close() { try { if(conn!=null) { conn.close(); } }catch(SQLException e) { e.printStackTrace(); } }} 此类实现数据库连接的建立和关闭，其中DB_URL是你数据库的url地址这里把jdb改成你自己数据库的名字，user和password分别是你创新数据库时使用的用户名和密码，其他的不需要改，具体的使用方法可以自己搜一下。 LoginDaolmp.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445package dao;import java.sql.*;public class LoginDaolmp { //检查登录的用户是否合法 public boolean searchName(String loginName,String loginpwd) { Connection conn=DButils.getConnection(); String sql=&quot;select * from 用户列表 where 用户名=? and 密码=?&quot;; try { PreparedStatement ps=conn.prepareStatement(sql); ps.setString(1, loginName); ps.setString(2, loginpwd); ResultSet rs=ps.executeQuery(); while(rs.next()) { return true; } }catch(SQLException e) { e.printStackTrace(); } return false; } //注册时将用户信息插入数据库 public boolean RegisterName(String loginName,String loginpwd) { Connection conn=DButils.getConnection(); PreparedStatement ps=null; String sql=&quot;insert into 用户列表 values(?,?)&quot;; try { ps=conn.prepareStatement(sql); ps.setString(1, loginName); ps.setString(2, loginpwd); int result=ps.executeUpdate(); if(result==1) { return true; } }catch(SQLException e) { e.printStackTrace(); } return false; }} searchName方法实现对登录用户的合法性检验，注意这里要用PreparedStatement实现动态的检查这里的具体参数可以对照着上面的数据库看，不再赘述，有不懂的可以私信我。RegisterName同理实现的是对注册用户信息的插入。 Servlet容器接收响应处理这是本实验最麻烦的地方，如果大家不知道servlet的话可以先简单的了解一下servlet再看本代码下面代码有许多冗余注释，不需要看这里注意创建文件的时候可以直接创建Servlet UserRegister 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package Servlet;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import dao.LoginDaolmp;/** * Servlet implementation class UserRegiste */@WebServlet(&quot;/UserRegiste&quot;)public class UserRegister extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public UserRegister() { super(); // TODO Auto-generated constructor stub } /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub response.getWriter().append(&quot;Served at: &quot;).append(request.getContextPath()); } /** * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response) */ protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.setCharacterEncoding(&quot;utf-8&quot;); response.setContentType(&quot;text/html;charset=utf-8&quot;); String username=request.getParameter(&quot;username&quot;); String userpwd=request.getParameter(&quot;userpwd&quot;); LoginDaolmp dl=new LoginDaolmp(); PrintWriter out=response.getWriter(); boolean isHave=dl.RegisterName(username, userpwd); if(isHave) { out.println(&quot;&lt;script&gt;alert('RegisterSucceed');window.location.href='NewFile.jsp'&lt;/script&gt;&quot;);// request.setAttribute(&quot;username&quot;, username);// System.out.print(&quot;注册成功!&quot;);// request.getRequestDispatcher(&quot;NewFile.jsp&quot;).forward(request, response); }else { out.println(&quot;&lt;script&gt;alert('RegisterFailed');window.location.href='NewFile.jsp'&lt;/script&gt;&quot;);// request.getSession().setAttribute(&quot;info&quot;,&quot;account does not right&quot;);// response.sendRedirect(&quot;NewFile.jsp&quot;); } }} UserServlet 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package Servlet;import java.io.IOException;import java.io.PrintWriter;import javax.security.auth.message.callback.PrivateKeyCallback.Request;import javax.servlet.ServletException;import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import com.mysql.cj.Session;import dao.LoginDaolmp;/** * Servlet implementation class UserServlet */@WebServlet(&quot;/UserServlet&quot;)public class UserServlet extends HttpServlet { private static final long serialVersionUID = 1L; /** * @see HttpServlet#HttpServlet() */ public UserServlet() { super(); // TODO Auto-generated constructor stub } /** * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response) */ protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub response.getWriter().append(&quot;Served at: &quot;).append(request.getContextPath()); } /** * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response) */ protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // TODO Auto-generated method stub doGet(request,response); String username=request.getParameter(&quot;username&quot;); String userpwd=request.getParameter(&quot;userpwd&quot;); LoginDaolmp dl=new LoginDaolmp(); boolean isHave=dl.searchName(username, userpwd); if(isHave) { request.setCharacterEncoding(&quot;UTF-8&quot;); response.setCharacterEncoding(&quot;UTF-8&quot;); request.setAttribute(&quot;username&quot;, username); request.setAttribute(&quot;check&quot;, 1); request.getSession().setAttribute(&quot;username&quot;, username); request.getSession().setAttribute(&quot;check&quot;, 1); response.setContentType(&quot;text/html;charset=UTF-8&quot;); PrintWriter out=response.getWriter(); out.println(&quot;&lt;script&gt;alert('LoginSucceed');window.location.href='welcome.jsp'&lt;/script&gt;&quot;); }else { request.setCharacterEncoding(&quot;UTF-8&quot;); response.setCharacterEncoding(&quot;UTF-8&quot;); request.getSession().setAttribute(&quot;info&quot;,&quot;account does not right&quot;); PrintWriter out=response.getWriter(); response.setContentType(&quot;text/html;charset=UTF-8&quot;); out.println(&quot;&lt;script&gt;alert('LoginFailed');window.location.href='NewFile.jsp'&lt;/script&gt;&quot;);// response.sendRedirect(&quot;NewFile.jsp&quot;); } }} XML文件的配置注意一定要配置XML文件不然会报404,，如果你在创建文件的时候没有生成xml文件可以通过以下方法自动生成我这里已经有了所以是灰色的，注意xml文件，要放在WEB-INF下具体配置如下 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot;&gt; &lt;display-name&gt;example2&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;servlet&gt; &lt;servlet-name&gt;UserRegister&lt;/servlet-name&gt; &lt;servlet-class&gt;Servlet.UserRegister&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;UserRegister&lt;/servlet-name&gt; &lt;url-pattern&gt;/UserRegister&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 结语完成以上步骤就可以实现用户登录注册了，这里面只有最简单的实现，没有任何多余页面的设计，看起来比较容易，但是因为笔者能力有限，这些代码远远算不上优美，以上代码尚且存在许多问题，比如中文乱码等等，如果有大佬可以解决，还请不吝赐教。 这篇文章有许多东西也还没有讲到（因为我也不会），比如xml文档为何如此配置等等，大家可以自己再去查一下有关的资料。 如果你按照以上步骤走下来仍然存在问题，欢迎私信我或在评论区留言。 希望这篇文章能帮助到你。","link":"/2021/10/24/JavaWeb%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E7%94%A8%E6%88%B7%E6%B3%A8%E5%86%8C%E7%99%BB%E5%BD%95%EF%BC%88%E5%85%A5%E9%97%A8%E7%BA%A7%EF%BC%89/"},{"title":"LeetCode260.只出现一次的数字 III（位运算）","text":"​​点击阅读更多查看文章内容 LeetCode260.只出现一次的数字 III（位运算）题目传送门 一、题目解析 给定一个整数数组 nums，其中恰好有两个元素只出现一次，其余所有元素均出现两次。 找出只出现一次的那两个元素。你可以按 任意顺序 返回答案。进阶：你的算法应该具有线性时间复杂度。你能否仅使用常数空间复杂度来实现？ 题意很简单不再赘述，比较容易想到的一种方法是用哈希表来存储每个数字出现的次数，然后遍历一边哈希表找到两个只出现一次的即可，但是本题还要求仅使用常数空间复杂度来实现，此时就需要用到另一种方法——位运算。 二、位运算首先我们观察数组，除了两个仅出现一次的元素外，其他所有元素都是出现两次的，我们可以想到异或运算的性质——两个相同的数异或结果为0，且任何数和0异或都不变，那么我们可以将数组全部元素异或起来，得到的最终结果即为两个仅出现一次的元素的异或记为x。 得到两元素的异或后，我们进一步考虑，因为两元素不同，那么x肯定不会为0，至少有一位是为1，根据异或运算的性质，只有当两数不同时异或结果才会为1，我们可以通过x&amp;-x求得x中最低位的1（求解原理在文章最后）记为y。 至此，我们可以得知要求的两个数在第y位上数字不同，一个为0，一个为1。我们可以将原数组分成两部分，分别是第y位上数字为0，和第y位上数字为1，此时这两部分分别包含两解，以及若干个两两相同的数。将这两部分分别异或，即可求得两解。 三、代码注意溢出问题 12345678910111213141516171819202122232425class Solution{public: vector&lt;int&gt; singleNumber(vector&lt;int&gt; &amp;nums) { int x = 0; for (int i : nums) { x ^= i; } int y = x &amp; -x; int a = 0, b = 0; for (int i : nums) { if (i &amp; y) a ^= i; else b ^= i; } vector&lt;int&gt;ret; ret.push_back(a); ret.push_back(b); return ret; }}; 关于x&amp;-x的结果为何是最低位1，可参考如下博客https://blog.csdn.net/oyoung_2012/article/details/79932394","link":"/2021/10/30/LeetCode260.%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E6%95%B0%E5%AD%97%20III%EF%BC%88%E4%BD%8D%E8%BF%90%E7%AE%97%EF%BC%89/"},{"title":"LeetCode1871 跳跃游戏（dp、前缀和、滑动窗口）","text":"​​点击阅读更多查看文章内容 LeetCode1871 跳跃游戏（dp、前缀和、滑动窗口）题目传送门 给你一个下标从 0 开始的二进制字符串 s 和两个整数 minJump 和 maxJump 。一开始，你在下标 0 处，且该位置的值一定为 ‘0’ 。当同时满足如下条件时，你可以从下标 i 移动到下标 j 处：i + minJump &lt;= j &lt;= min(i + maxJump, s.length - 1) 且s[j] == ‘0’.如果你可以到达 s 的下标 s.length - 1 处，请你返回 true ，否则返回 false 。 一、dp+前缀和用dp[i]表示能否跳到i点dp[i]=1表示可以跳到，dp[i]=0表示不能跳到由题意可知要想跳到i点，s[i]的值要为’0’且要能跳到i-max到i-min中的一点我们定义left为i-max,right为i-min，即若能到达i点则区间[left,right]中至少有一个点可以到达，此时如果直接遍历此区间的话会超时，需要使用前缀和来优化。我们定义pre[i]表示dp在区间[0,i]的和，此时要判断区间[left,right]中是否有点可以到达只需要判断pre[right]-pre[left-1]是否大于0即可。代码 12345678910111213141516171819202122232425class Solution{public: bool canReach(string s, int minJump, int maxJump) { vector&lt;int&gt; dp(s.length(), 0); vector&lt;int&gt; pre(s.length(), 0); dp[0] = 1; for (int i = 0; i &lt; minJump; i++) pre[i] = 1; for (int i = minJump; i &lt;= s.length() - 1; i++) { int left = i - maxJump; int right = i - minJump; if (s[i] == '0') { int total = pre[right] - (left-1&gt;=0?pre[left-1]:0); if (total &gt; 0) dp[i] = 1; } pre[i] = pre[i - 1] + dp[i]; } return dp[s.length() - 1]; }}; 二、滑动窗口如果能跳到i点，s[i]的值要为’0’且要能跳到i-max到i-min中的一点。区间[i-max,i-min]的长度为max-min，我们可以定义变量cnt来记录次区间中能到达的点的数目。我们从min开始遍历（因为0和min之间的点都不会到达），此时初始的区间为[min-max,min-min]此区间能到达的点只有0点，此时cnt=1依次向后遍历，首先判断当前点能不能到，然后将区间向右移一位，如果区间右端点的下一位能到达则cnt+1，如果当前区间左端点能到达则cnt-1（因为当前左端点要被移出）。 代码 1234567891011121314151617181920class Solution{public: bool canReach(string s, int minJump, int maxJump) { vector&lt;int&gt; dp(s.length()); dp[0] = 1; int cnt = 1; for (int i = minJump; i &lt; s.length(); i++) { if (s[i] == '0' &amp;&amp; cnt &gt; 0) dp[i] = 1; if (dp[i - minJump + 1] == 1) cnt++; if (i - maxJump &gt;= 0 &amp;&amp; dp[i - maxJump] == 1) cnt--; } return dp[s.length() - 1]; }};","link":"/2021/11/04/LeetCode1871%20%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F%EF%BC%88dp%E3%80%81%E5%89%8D%E7%BC%80%E5%92%8C%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%EF%BC%89/"},{"title":"KMP算法（严蔚敏数据结构第二版）","text":"​​点击阅读更多查看文章内容 KMP算法之前看过一次，看了好久才看明白，今天又学的时候发现啥也不会了，又看了好久，在这里整理一下思路，方便以后复习。 算法介绍在我们常规的模式匹配算法中，每当匹配失败时，模式串都从第一个字符开始重新比较，KMP算法的改进在于：当匹配中出现字符不相等时，主串指针不回溯，模式串指针根据部分匹配的结果，尽可能的向右“滑动”一段距离，从而减少匹配次数。kmp算法可以在O(n+m)的时间数量级上完成串的模式匹配操作。算法匹配过程如下：这里可以看到第三次匹配时，模式串没有从头开始，而是直接比较了b，这是KMP算法的难点之一，即当匹配过程中产生失配时，主串中的第i个字符应该与模式中哪个字符比较呢？ 这里我们以模式串s=”abaab”为例，假设在比较s[3]处失配了，那么这时再比较可以从s[1]处开始，因为我们知道s[0]~s[2]匹配成功，即s[2]对应的主串位置应为’a’，s[0]=s[2]所以s[0]不需要再次匹配直接放到之前s[2]所在的位置即可，不难发现，这里移动的位置应该与模式串的前缀字符串和后缀字符串有关，这就是下面要讲的next数组。 next数组next[j]=k：表示当模式中的第j个字符与主串中相应字符失配时，在模式串中需重新和主串中该字符进行比较的字符位置。 注：下标从1开始 j 1 2 3 4 5 6 7 8 模式串 a b a a b c a c next[j] 0 1 1 2 2 3 1 2 KMP代码123456789101112131415161718192021int Index_KMP(string S, string T, int pos){ //利用模式串T的next函数求T在主串S中第pos个字符之后的位置 //其中T非空，1&lt;=pos&lt;=S.length int i = pos; int j = 1; while (i &lt;= S.length() &amp;&amp; j &lt;= T.length()) { if (j == 0 || S[i] == T[j])//匹配成功，继续比较后续字符 { ++i; ++j; } else j = next[j];//模式串右移 } if (j &gt; T.length()) return i - T.length();//匹配成功 else return 0;//匹配失败} 求解next函数 先放一个b站的视频，使用图解法解释代码，非常形象，建议大家直接看视频就好了https://www.bilibili.com/video/BV16X4y137qw/ next[j]=k,表明在模式串中“t[1]t[2]…t[k-1]”=”t[j-k+1]t[j-k+2]…t[j-1]”(假设下标从1开始)此时求解next[j+1]有以下两种情况1.t[k]=t[j]则在模式串中有”t[1]t[2]…t[k-1]t[k]”=”t[j-k+1]t[j-k+2]…t[j-1]t[j]”此时next[j+1]=next[j]+12.t[k]≠t[j]此时可以把求next函数值的问题看成是一个模式匹配的问题，整个模式串既是主串又是模式串，在之前的匹配过程中已经有”t[1]t[2]…t[k-1]”=”t[j-k+1]t[j-k+2]…t[j-1]”，则当t[k]≠t[j]时应将模式串向右滑动，比较t[next[k]]和t[j]，若t[next[k]]与t[j]相等，则next[j+1]=next[k]+1,若不相等，继续滑动比较t[next[next[k]]]与t[j]，如不存在任何相等，则next[j+1]=1。下面举个例子简单的描述一下这个过程（字有点难看） next数组求解代码1234567891011121314151617void get_next(string T, int next[]){ int i = 1; next[1] = 0; int j = 0; while (i &lt; T.length()) { if (j == 0 || T[i] == T[j]) { ++i; ++j; next[i] = j; } else j = next[j]; }} next数组的修正——nextval数组前面定义的next函数在某些情况下尚有缺陷。例如模式”aaaab”在和主串”aaabaaaab”匹配的过程中，当i=4，j=4时，s[4]≠t[4]，根据next数组还需进行j=3,j=2,j=1这三次比较，实际上这三个字符与第四个字符都是相同的，因此不再需要比较，可以直接比较i=5,j=1。也就是说按上述定义得到next[j]=k，而模式中t[j]=t[k]，则当主串中s[i]≠t[j]时，不需要再和t[k]比较，直接和t[next[k]]比较。 j 1 2 3 4 5 模式串 a a a a b next[j] 0 1 2 3 4 nextval[j] 0 0 0 0 4 1234567891011121314151617181920void get_nextval(string T, int nextval[]){ int i = 1; nextval[1] = 0; int j = 0; while (i &lt; T.length()) { if (j == 0 || T[i] == T[j]) { i++; j++; if (T[i] != T[j]) nextval[i] = j; else nextval[i] = nextval[j]; } else j = nextval[j]; }}","link":"/2021/04/09/KMP%E7%AE%97%E6%B3%95%EF%BC%88%E4%B8%A5%E8%94%9A%E6%95%8F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89/"},{"title":"LeetCode519. 随机翻转矩阵","text":"​​点击阅读更多查看文章内容 LeetCode519. 随机翻转矩阵题目传送门 题目 给你一个 m x n 的二元矩阵 matrix ，且所有值被初始化为 0 。请你设计一个算法，随机选取一个满足 matrix[i][j] == 0 的下标 (i, j) ，并将它的值变为 1 。所有满足 matrix[i][j] == 0 的下标 (i, j) 被选取的概率应当均等。尽量最少调用内置的随机函数，并且优化时间和空间复杂度。实现 Solution 类：Solution(int m, int n) 使用二元矩阵的大小 m 和 n 初始化该对象int[] flip() 返回一个满足 matrix[i][j] == 0 的随机下标 [i, j] ，并将其对应格子中的值变为 1void reset() 将矩阵中所有的值重置为 0数据范围：1 &lt;= m, n &lt;= 10^4^每次调用flip 时，矩阵中至少存在一个值为 0 的格子。最多调用 1000 次 flip 和 reset 方法。 解析这里m,n的取值上限为10^4^，显然不可能存储所有的数据，但是flip方法最多只会调用1000次，这里容易想到用map来存储已经选取的下标。首先我们可以把二维数组映射为一个一维数组即下标为（i,j）的元素我们可以用（i*n+j）来表示。 我们模拟的过程是将m×n个0元素排成一行，从前m×n个元素中随机选一个下标将其的值设为1，然后把这个下标和最后一个元素交换，下次选取的时候再从前m×n-1个元素中选取，把最后一个元素（即刚刚选取的元素）去掉，这样保证我们每次选取的元素都是未被选取的。 具体实现方法为：我们将选取的下标的值映射到最后一个元素，这样下次再取到这个下标时，如果这个下标在map中，我们就取它的映射来替换它的值。 模拟图 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution{public: int m, n, total; map&lt;int, int&gt; mp; Solution(int m, int n) { this-&gt;m = m; this-&gt;n = n; this-&gt;total = m * n; srand(time(NULL)); } vector&lt;int&gt; flip() { int idx = rand() % total; total--; vector&lt;int&gt; ret; if (mp.count(idx)) { ret.push_back(mp[idx] / n); ret.push_back(mp[idx] % n); } else { ret.push_back(idx / n); ret.push_back(idx % n); } if (mp.count(total)) { mp[idx] = mp[total]; } else { mp[idx] = total; } return ret; } void reset() { total = m * n; mp.clear(); }};","link":"/2021/11/27/LeetCode519.%20%E9%9A%8F%E6%9C%BA%E7%BF%BB%E8%BD%AC%E7%9F%A9%E9%98%B5/"},{"title":"LeetCode486.预测赢家（递归+动态规划+博弈）","text":"​​点击阅读更多查看文章内容 LeetCode486.预测赢家（递归+动态规划+博弈）题目传送门 题目解析 给你一个整数数组 nums 。玩家 1 和玩家 2 基于这个数组设计了一个游戏。玩家 1 和玩家 2 轮流进行自己的回合，玩家 1 先手。开始时，两个玩家的初始分值都是 0 。每一回合，玩家从数组的任意一端取一个数字（即，nums[0] 或 nums[nums.length - 1]），取到的数字将会从数组中移除（数组长度减 1 ）。玩家选中的数字将会加到他的得分上。当数组中没有剩余数字可取时，游戏结束。如果玩家 1 能成为赢家，返回 true 。如果两个玩家得分相等，同样认为玩家 1 是游戏的赢家，也返回 true 。你可以假设每个玩家的玩法都会使他的分数最大化。 两个玩家轮流从一个数组中取数字，每次只能取两端的数字，如果先手取得的数字总和大于等于后手，则返回true，否则返回false，每个玩家的玩法都是最优的。 递归这里我们采用净胜分来判断，如果是玩家1得分，则净胜分加上得分，如果是玩家2得分，则净胜分减去得分，最终如果净胜分大于等于0，则玩家1获胜。我们用一个solve(vectornums,int start,int end)函数来求当前玩家的最大得分，当前玩家有两种选择：一、选择首部的数字，此时他的最大得分为：nums[start]-solve(vector&lt;int&gt;nums,start+1,end)其中solve(vector&lt;int&gt;nums,start+1,end)为下一个玩家的得分，当前玩家的净胜分应该减去下一个玩家的得分。二、选择尾部的数字，此时他的最大得分为：nums[end]-solve(vector&lt;int&gt;nums,start,end-1)得到当前玩家的两种可能得分后，取最大值即可。代码 123456789101112131415161718class Solution{public: bool PredictTheWinner(vector&lt;int&gt; &amp;nums) { return solve(nums, 0, nums.size()-1) &gt;= 0; } int solve(vector&lt;int&gt; &amp;nums, int start, int end) { if (start == end) { return nums[start]; } int stasco = nums[start] - solve(nums, start + 1, end); int endsco = nums[end] - solve(nums, start, end - 1); return max(stasco, endsco); }}; 动态规划首先我们假设dp[i][j]为nums[i]到nums[j]中玩家的最大得分通过上面递归的解法我们可以得到状态转移方程为：dp[i][j]=max(nums[i]-dp[i+1][j],nums[j]-dp[i][j-1])当i&gt;j时：dp[i][j]无意义当i=j时：dp[i][j]=nums[i]当i&lt;j时：dp[i][j]=max(nums[i]-dp[i+1][j],nums[j]-dp[i][j-1])要求dp[i][j]我们首先要求dp[i+1][j]以及dp[i][j-1]，因此我们需要从下往上，从左往右求解。代码 12345678910111213141516171819class Solution{public: bool PredictTheWinner(vector&lt;int&gt; &amp;nums) { int n = nums.size(); vector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(n, 0)); for (int i = 0; i &lt; nums.size(); i++) dp[i][i] = nums[i]; for(int i=n-2;i&gt;=0;i--) { for(int j=i+1;j&lt;=n-1;j++) { dp[i][j]=max(nums[i]-dp[i+1][j],nums[j]-dp[i][j-1]); } } return dp[0][n-1]&gt;=0; }}; 博弈（数组个数为偶数，先手必胜）这里代码有一个优化的点就是当数组个数为偶数时，先手必胜。假设当前数组为{1,7,5,26,8,4}我们将数组数组分为奇数列{1,5,8}和偶数列{7,26,4}比较两个数列之和显然偶数列大，那么只要我们先手一直选择偶数列的数，就可以获胜。因为当我们先手选了偶数列时，此时数列的两端都只剩下奇数列的数，对方只能选择奇数列，对方选完之后我们继续选择偶数列的数，最终我们可以得到全部偶数列的数，进而获得胜利。同理，当奇数列大时，我们选择奇数列即可。当两数列之和相同时，我们可以任意选择，因为平局也认为是我们获胜。","link":"/2021/11/02/LeetCode486.%E9%A2%84%E6%B5%8B%E8%B5%A2%E5%AE%B6%EF%BC%88%E9%80%92%E5%BD%92+%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92+%E5%8D%9A%E5%BC%88%EF%BC%89/"},{"title":"PKI详解","text":"​​点击阅读更多查看文章内容 应用场景公钥密码算法一般包括加解密、数字签名两种使用模型，在加解密模型中，Alice想要和Bob通信，需要用Bob的公钥对明文进行加密。这里就存在一个问题，如何判断某个公钥是Bob的公钥呢？如果存在攻击者自行生成公私钥对并谎称是Bob的公钥，那么攻击者就可以窃听到属于Alice和Bob的秘密信息，Bob反而不能解密这些信息。 PKI概念PKI（Public Key Infrastructure）通过数字证书，可以很好的解决上述的公钥归属问题，PKI中文译为公钥基础设施，是基于公钥密码学建立起的一种普遍使用的基础设施，其主要功能是绑定证书持有者的身份和相关的密钥对（通过为公钥及相关的用户身份信息签发数字证书），为用户提供方便的证书申请、证书作废、证书获取、证书状态查询的途径，并利用数字证书及相关的各种服务（证书发布，黑名单发布，时间戳服务等）实现通信中各实体的身份认证、完整性、抗抵赖性和保密性。 PKI基本组件 公钥证书：包含了用于签名和加密数据的公钥的电子凭证，是PKI的核心元素 证书颁发机构（CA）：数字证书的申请及签发机关，CA必须具备权威性 注册机构（RA）：CA的前端代理，减轻CA的负担，主要完成接收证书请求，验证请求着的身份 证书资料库（Reposity）：存储已签发的数字证书和公钥，以及相关证书目录，用户可由此获得所需的其他用户的证书及公钥 证书吊销列表（CRL）：在有效期内吊销的证书列表，在线证书状态协议OCSP是获得证书状态的国际协议 署名用户（Subscriber）：作为主体署名证书并依据策略使用证书和相应密钥的实体 依赖方（Relying party）：一个接收包括证书和签名信息的人或者机构，利用证书提供的公钥验证其有效性，与持证人建立保密通信，接收处于依赖的地位 数字证书数字证书是PKI最基本的元素，其回答了“公钥属于谁”的问题，证书中最基本的内容是证书持有者的身份信息和公钥数据，以及用于验证证书完整性的CA签名结果。X.509证书是通用的PKI数字证书格式，如下图所示： 一张X.509数字证书由证书内容、签名算法和签名结果组成。需要使用他人证书的用户依照签名算法，用CA的公钥验证签名结果，从而保证证书的完整性，安全地获取公钥。- 版本号：证书格式可能会不断改进，版本号给出了证书遵从的格式。- 证书主体：证书的持有者- 主体公钥信息：指明所用的公钥算法和公钥信息本身- 签发者：签发该证书的CA- 序列号：每个CA用来唯一标识其所签发的证书，也就是说，对于某一个CA而言，其签发的每一张证书的序列号必须互不相同。“签发者”+“序列号”可以唯一地标识一张数字证书- 有效期：包括开始日期和结束日期，只有在有效期内的证书才是有效的- 证书扩展：满足实际应用中的更多需求，证书可能携带的更多信息，证书扩展和上述内容一起被CA签名 参考链接 CA证书认证流程 下面是我在查资料的时候找到的两种流程一个是侧重于证书内容的一个是侧重于通信流程的，大家可以都看一看加深理解证书内容参考链接通信流程参考链接 证书内容 以下流程实现server申请证书，并将得到的证书发送给client，使client得到可信的server的公钥 1. 申请认证（证书）- 服务端S向第三方权威机构CA申请证书，服务器S先生成公私钥对- 确认信息里面绑定我们当前使用哪个域名，以及申请者以及公钥- 生成请求文件.csr（csr是我们服务端S向CA提交申请的文件）注意：提交信息里不包含私钥 2. 审核信息- CA收到服务端S发送的信息先去审核（CA通过线上、线下等多种手段验证申请者提供信息的真实性）- 审核通过，CA会向申请者签发认证文件-证书 3. 签发证书- 签名证书里的明文信息通过哈希算法加密生成摘要1- CA机构用自己的私钥对摘要1进行加密，得到其对应的签名- 签名+明文信息组成了证书，把这个证书发给服务端S 4. 返回证书 服务端S把CA证书发送给客户端C 5. 验证证书 客户端会内置信任CA的证书信息（包含公钥），如果CA不被信任，则找不到对应CA的证书，证书会被判定为非法 客户端C利用对应CA的公钥解密签名数据，拿到了摘要1 客户端C读取证书中的相关的明文信息，采用哈希算法加密得到信息摘要2 对比证书的信息摘要，如果一致，则可以确认证书的合法性，即公钥合法 提取出公钥pub_server，至此就认可了服务端S，拿到了服务端的公钥 详细通信过程 下图展示了Alice向Bob发送密文的场景，在生成密文时所使用的Bob的公钥是通过认证机构获取的。认证机构必须是可信的，对于“可信的第三方”，下图中会使用Trent这个名字，这个词是从trust（信任）一词演变而来的。 1. Bob生成密钥对 要使用公钥密码进行通信，首先需要生成密钥对。Bob生成了一对公钥和私钥，并将私钥自行妥善保管。在这里，密钥对是由Bob自己生成的，也可以由认证机构代为生成。 2. Bob在认证机构Trent注册自己的公钥 在这里Bob则将公钥发送给了认证机构Trent，这是因为Bob需要请认证机构Trent对他的公钥加上数字签名（也就是生成证书）。 Trent收到Bob的公钥后，会确认所收到的公钥是否为Bob本人所有（通过线上+线下的方式） 3. 认证机构Trent用自己的私钥对Bob的公钥施加数字签名并生成证书 Trent对Bob的公钥加上数字签名。为了生成数字签名，需要Trent自身的私钥，因此Trent需要事先生成好密钥对。 4. Alice得到带有认证机构Trent的数字签名的Bob的公钥（证书） 现在Alice需要向Bob发送密文，因此她从Trent处获取证书。证书中包含了Bob的公钥。 5. Alice使用认证机构Trent的公钥验证数字签名，确认Bob的公钥的合法性 Alice使用认证机构Trent的公钥对证书中的数字签名进行验证。如果验证成功，就相当于确认了证书中所包含的公钥的确是属于Bob的。到这里，Alice就得到了合法的Bob的公钥。 6.Alice用Bob的公钥加密消息并发送给Bob Alice用Bob的公钥加密要发送的消息，并将消息发送给Bob。 7.Bob用自己的私钥解密密文得到Alice的消息 Bob收到Alice发送的密文，然后用自己的私钥解密，这样就能够看到Alice的消息了。 上面就是利用认证机构Trent进行公钥密码通信的流程。其中1、2、3这几个步骤仅在注册新公钥时才会进行，并不是每次通信都需要。此外，步骤 4 仅在Alice第一次用公钥密码向Bob发送消息时才需要进行，只要Alice将Bob的公钥保存在电脑中，在以后的通信中就可以直接使用了。","link":"/2022/05/08/PKI%E8%AF%A6%E8%A7%A3/"},{"title":"LeetCode629.K个逆序对数组（dp）","text":"​​点击阅读更多查看文章内容 LeetCode629.K个逆序数组（dp）题目传送门 给出两个整数 n 和 k，找出所有包含从 1 到 n 的数字，且恰好拥有 k 个逆序对的不同的数组的个数。逆序对的定义如下：对于数组的第i个和第 j个元素，如果满i &lt; j且 a[i] &gt; a[j]，则其为一个逆序对；否则不是。由于答案可能很大，只需要返回 答案 mod 109 + 7 的值。 解析本题主要参考的官方题解，但是官方题解有些地方当时理解的时候有些困难，在这里再记录一下，便于理解。官方题解f[i][j]表示长度为i的数组，恰好包含j个逆序对的方案数，第i个元素的所有可能取值为1~i中的一个数字，我们假设第i个元素为k，那么数组中逆序对的个数为一下两部分之和：1.数字k与另外i-1个元素产生的逆序对的个数2.另外i-1个元素内部产生的逆序对的个数 对第一部分：数字k放在最后一位，数组中有i-k个比数字k大的数，所以k贡献的逆序对个数为i-k对第二部分：因为f[i][j]表示的有j个逆序对的情况，所以我们希望第二部分的逆序对个数为j-(i-k)，这里逆序对的个数只与元素的相对大小有关，不包含k的数组元素为1,…,k-1和k+1,…i。我们可以把后半部分整体减一，此时逆序对的个数不变，我们的目标变成了1,…i-1，希望它有j-(i-k)个逆序对，由此我们可以得到状态转移方程。边界条件为：f[0][0]=1，不用任何数字构成一个空数组，包含0个逆序对f[i][j&lt;0]=0，逆序对的数量一定是非负整数最终的答案为f[n][k] 优化这里的优化非常巧妙，需要着重理解首先上述动态规划的状态数量为O(nk)，而求出每一个f[i][j]需要经过O(n)的时间复杂度，总时间复杂度会超时注意f[[i][j-1]和f[i][j]的状态转移方程：简单展开f[i][j]=f[i-1][j]+f[i-1][j-1]+…+f[i-1][j-i+1]f[i][j-1]=f[i-1][j-1]+f[i-1][j-2]+…+f[i-1][j-i]不难看出f[i][j]=f[i][j-1]+f[i-1][j]-f[i-1][j-i]这样我们就可以在常数时间内求出f[i][j]此外，我们可以发现，对f[i][j]的求解只会用到f[i][…]和f[i-1][…]，因此我们可以再对空间进行优化，用两个一维数组交替进行状态转移，此步对应代码中now=i&amp;1,prev=now^1，now表示当前要求的数组，prev则是前一个数组，now随着i增大是1,0交替变化，prev则是随着now的变化0,1交替变化，最开始now为1，此时prev为0，当i增加时，now变为0，prev变为1，此时dp[prev]的值即是上一个now的值，由此实现两数组的交替状态转移。 代码123456789101112131415161718192021222324class Solution{public: int kInversePairs(int n, int k) { int mod = 1e9 + 7; int dp[2][1010]; memset(dp, 0, sizeof(dp)); dp[0][0] = 1; for (int i = 1; i &lt;= n; i++) { int now = i &amp; 1, prev = now ^ 1; for (int j = 0; j &lt;= k; j++) { dp[now][j] = (j - 1 &gt;= 0 ? dp[now][j - 1] : 0) - (j - i &gt;= 0 ? dp[prev][j - i] : 0) + dp[prev][j]; if (dp[now][j] &gt;= mod) dp[now][j] -= mod; else if (dp[now][j] &lt; 0) dp[now][j] += mod; } } return dp[n &amp; 1][k]; }};","link":"/2021/11/11/LeetCode629.K%E4%B8%AA%E9%80%86%E5%BA%8F%E5%AF%B9%E6%95%B0%E7%BB%84%EF%BC%88dp%EF%BC%89/"},{"title":"LeetCode5912. 每一个查询的最大美丽值（排序+优先队列）","text":"​​点击阅读更多查看文章内容 LeetCode5912. 每一个查询的最大美丽值（排序+优先队列）题目传送门 题目 给你一个二维整数数组 items ，其中 items[i] = [pricei, beautyi] 分别表示每一个物品的 价格 和 美丽值 。同时给你一个下标从 0 开始的整数数组 queries 。对于每个查询 queries[j] ，你想求出价格小于等于 queries[j] 的物品中，最大的美丽值 是多少。如果不存在符合条件的物品，那么查询的结果为 0 。请你返回一个长度与 queries 相同的数组 answer，其中 answer[j]是第 j 个查询的答案。提示：1 &lt;= items.length, queries.length &lt;= 1e5items[i].length == 21 &lt;= pricei, beautyi, queries[j] &lt;= 1e9 给定一组数字，对每一个数字求所有价格小于当前数字的物品中对应的最大的美丽值是多少。 分析这里问对给定的每一个数字，显然如果我们对每一个数字都遍历一遍items数组求和的话必然会超时，要想其他的方法。对于给定的数字，我们知道大数所能购买的美丽值一定是大于小数的，在这里我们用的方法是首先对queries数组进行排序，每次把当前数字所能购买的所有物品放入一个优先队列中，如果不能购买当前物品，则用下一个数字尝试，这样的话我们不必每次都从头遍历items数组，只需遍历一遍即可。当我们要求当前数字所对应的最大美丽值，只需输出当前优先队列的头部元素即可。这里需要注意的是，我们到最后的返回值是要与queries数组一一对应的，但是当我们对queries数组排序时会打乱原数组，这里我们需要对数组的项和索引之间建立一一对应的关系（注意这里不能用值和索引建立，因为值可能会重复），我用的方法是通过pair来保存当前项的值和索引，这样在排序的时候，索引也会一起排列，我们可以通过排序后项的索引来找到它之前的位置。 代码1234567891011121314151617181920212223242526272829class Solution{public: vector&lt;int&gt; maximumBeauty(vector&lt;vector&lt;int&gt;&gt; &amp;items, vector&lt;int&gt; &amp;queries) { sort(items.begin(), items.end()); vector&lt;pair&lt;int, int&gt;&gt; queries2; for (int i = 0; i &lt; queries.size(); i++) { queries2.push_back({queries[i],i}); } sort(queries2.begin(), queries2.end()); priority_queue&lt;int&gt; pq; vector&lt;int&gt; ret(queries.size(), 0); int j = 0; for (int i = 0; i &lt; queries2.size(); i++) { int pri = queries2[i].first; while (j &lt; items.size()&amp;&amp;items[j][0]&lt;=pri) { pq.push(items[j][1]); j++; } if(!pq.empty()) ret[queries2[i].second]=pq.top(); } return ret; }};","link":"/2021/11/14/LeetCode5912.%20%E6%AF%8F%E4%B8%80%E4%B8%AA%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%9C%80%E5%A4%A7%E7%BE%8E%E4%B8%BD%E5%80%BC%EF%BC%88%E6%8E%92%E5%BA%8F+%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%EF%BC%89/"},{"title":"Shell脚本编写教程【一】——Shell 变量","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程【一】——Shell 变量 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash Shell变量变量定义1name=&quot;shn&quot; 注意：变量名和等号之间不能有空格 变量名只能使用英文字母，数字和下划线，首个字符不能以数字开头 不能使用bash里的关键字（可用help命令查看保留关键字） 除了显式的直接赋值，还可以用语句给变量赋值12name=$(ls)name=`ls`变量使用 使用一个定义过的变量，只需要在变量名前加美元符号$即可 123name=&quot;shn&quot;echo $name echo ${name} 变量名外面的花括号在这里是可选的，加花括号是为了区分变量的边界，推荐给所有使用的变量都加上花括号 1echo &quot;I am ${name}hahaha&quot; 上面这种情况如果不加花括号写成echo &quot;I am $namehahaha&quot;就无法区分变量name 已定义的变量可以被重新定义，重新定义时不需要加$符号，只有在使用变量的时候才需要 1234your_name=&quot;tom&quot;echo $your_nameyour_name=&quot;alibaba&quot;echo $your_name 只读变量 使用readonly命令可以将变量定义为只读变量 只读变量的值不能被改变，执行以下脚本会报错 1234your_name=&quot;tom&quot;readonly your_nameyour_name=&quot;alibaba&quot;# script.sh: line 3: your_name: readonly variable 删除变量 使用unset命令可以删除变量 变量被删除后不能再次使用。unset 命令不能删除只读变量。 执行以下命令不会有任何输出123your_name=&quot;tom&quot;unset your_nameecho ${your_name}Shell字符串字符串表示可以用单引号，双引号，也可以不用引号 单引号12345678910111213name='bob'str='this is a string'echo ${str}# this is a stringstr2='hello ${name}'echo ${str2}# hello ${name}str3='this is a \\'string'echo ${str3}# unexpected EOF while looking for matching `''str4='this is ''a string'echo ${str4}# this is a string 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的 单引号字符串中不能出现单独的一个单引号（即使转义也不行），但可以成对出现，作为字符串拼接使用 要包含单引号可以将其包含在双引号字符串内 双引号12345678910111213141516name=&quot;bob&quot;str=&quot;this is a string&quot;echo ${str}# this is a stringstr2=&quot;hello ${name}&quot;echo ${str2}# hello bobstr3=&quot;this is a \\&quot;string&quot;echo ${str3}# this is a &quot;stringstr4=&quot;this is &quot;&quot;a string&quot;echo ${str4}# this is a stringstr5=&quot;this is a\\tstring&quot;echo -e ${str5}# this is a string 双引号里可以有变量 双引号里可以出现转义字符 echo -e 解释\\t \\a \\b \\n等转义字符 拼接字符串123456789101112your_name=&quot;bob&quot;# 使用双引号拼接greeting=&quot;hello, &quot;$your_name&quot; !&quot;greeting_1=&quot;hello, ${your_name} !&quot;echo $greeting $greeting_1# hello, bob ! hello, bob !# 使用单引号拼接greeting_2='hello, '$your_name' !'greeting_3='hello, ${your_name} !'echo $greeting_2 $greeting_3# hello, bob ! hello, ${your_name} ! 获取字符串长度 使用#获取 变量为字符串时，${#string} 等价于 ${#string[0]} 123456string=&quot;abcd&quot;echo ${#string}# 4string=&quot;abcd&quot;echo ${#string[0]} # 4 提取子字符串 string:n:m提取字符串string中从第n个字符开始的m个字符 注意：第一个字符的索引为01234string=&quot;helloworld&quot;str2=${string:2:4}echo ${str2}# llow查找子字符串查找字符i或o的位置（哪个字母先出现就计算哪个） 123string=&quot;runoob is a great site&quot;echo `expr index &quot;$string&quot; io`# 4","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E4%B8%80%E3%80%91%E2%80%94%E2%80%94Shell%20%E5%8F%98%E9%87%8F/"},{"title":"Shell脚本编写教程【三】——Shell 注释","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程【三】——Shell 注释 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash 以 # 开头的行就是注释，会被解释器忽略。 通过每一行加一个 # 号设置多行注释 如果在开发过程中，遇到大段的代码需要临时注释起来，过一会儿又取消注释，怎么办呢？每一行加个#符号太费力了，可以把这一段要注释的代码用一对花括号括起来，定义成一个函数，没有地方调用这个函数，这块代码就不会执行，达到了和注释一样的效果。 多行注释多行注释还可以使用以下格式 12345:&lt;&lt;EOF注释内容...注释内容...注释内容...EOF EOF可以使用任意符号代替 1234567891011:&lt;&lt;'注释内容...注释内容...注释内容...':&lt;&lt;!注释内容...注释内容...注释内容...!","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E4%B8%89%E3%80%91%E2%80%94%E2%80%94Shell%20%E6%B3%A8%E9%87%8A/"},{"title":"Shell脚本编写教程【七】——Shell test命令","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程【七】——Shell test命令 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash Shell中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试 数值测试 参数 说明 -eq 等于则为真 -ne 不等于则为真 -gt 大于则为真 -ge 大于等于则为真 -lt 小于则为真 -le 小于等于则为真 实例： 123456789num1=100num2=100if test $[num1] -eq $[num2]then echo '两个数相等！'else echo '两个数不相等！'fi# 两个数相等！ 代码中的[]执行基本的算术运算 123456a=5b=6result=$[a+b] # 注意等号两边不能有空格echo &quot;result 为： $result&quot;# result 为： 11 字符串测试 参数 说明 = 等于则为真 != 不相等则为真 -z 字符串 字符串的长度为零则为真 -n 字符串 字符串的长度不为零则为真 实例： 123456789num1=&quot;ru1noob&quot;num2=&quot;runoob&quot;if test $num1 = $num2then echo '两个字符串相等!'else echo '两个字符串不相等!'fi# 两个字符串不相等! 文件测试 参数 说明 -e 文件名 如果文件存在则为真 -r 文件名 如果文件存在且可读则为真 -w 文件名 如果文件存在且可写则为真 -x 文件名 如果文件存在且可执行则为真 -s 文件名 如果文件存在且至少有一个字符则为真 -d 文件名 如果文件存在且为目录则为真 -f 文件名 如果文件存在且为普通文件则为真 -c 文件名 如果文件存在且为字符型特殊文件则为真 -b 文件名 如果文件存在且为块特殊文件则为真 实例（在本文开头的在线编辑器中测试）： 12345678cd /binif test -e ./bashthen echo '文件已存在!'else echo '文件不存在!'fi# 文件已存在! 另外，shell还提供了与（-a）或（-o）非（!）三个逻辑操作符用于将测试条件连接起来，其优先级为：! 最高， -a 次之， -o 最低。例如： 12345678cd /binif test -e ./notFile -o -e ./bashthen echo '至少有一个文件存在!'else echo '两个文件都不存在'fi# 至少有一个文件存在!","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E4%B8%83%E3%80%91%E2%80%94%E2%80%94Shell%20test%E5%91%BD%E4%BB%A4/"},{"title":"Shell脚本编写教程【九】——Shell 函数","text":"​点击阅读更多查看文章内容 Shell脚本编写教程【九】——Shell 函数 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash linux shell 可以用户定义函数，然后在shell脚本中可以随便调用。 shell中函数的定义格式如下： 123456789[ function ] funname [()]{ action; [return int;]} 可以带function fun() 定义，也可以直接fun() 定义,不带任何参数。 参数返回，可以显式加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。 return后跟数值n(0-255 实例： 123456789function demoFun(){ echo &quot;这是我的第一个 shell 函数!&quot;}echo &quot;-----函数开始执行-----&quot;demoFunecho &quot;-----函数执行完毕-----&quot;# -----函数开始执行-----# 这是我的第一个 shell 函数!# -----函数执行完毕----- 带有return语句的函数 1234567891011funWithReturn(){ echo &quot;这个函数会对输入的两个数字进行相加运算...&quot; echo &quot;输入第一个数字: &quot; read aNum echo &quot;输入第二个数字: &quot; read anotherNum echo &quot;两个数字分别为 $aNum 和 $anotherNum !&quot; return $(($aNum+$anotherNum))}funWithReturnecho &quot;输入的两个数字之和为 $? !&quot; 函数返回值在调用该函数后通过 $? 来获得。 注意：所有函数在使用前必须定义。这意味着必须将函数放在脚本开始部分，直至shell解释器首次发现它时，才可以使用。调用函数仅使用其函数名即可。 函数参数在Shell中，调用函数时可以向其传递参数。在函数体内部，通过 $n 的形式来获取参数的值，例如，$1表示第一个参数，$2表示第二个参数. 实例： 1234567891011121314151617funWithParam(){ echo &quot;第一个参数为 $1 !&quot; echo &quot;第二个参数为 $2 !&quot; echo &quot;第十个参数为 $10 !&quot; echo &quot;第十个参数为 ${10} !&quot; echo &quot;第十一个参数为 ${11} !&quot; echo &quot;参数总数有 $# 个!&quot; echo &quot;作为一个字符串输出所有参数 $* !&quot;}funWithParam 1 2 3 4 5 6 7 8 9 34 73# 第一个参数为 1 !# 第二个参数为 2 !# 第十个参数为 10 !# 第十个参数为 34 !# 第十一个参数为 73 !# 参数总数有 11 个 !# 作为一个字符串输出所有参数 1 2 3 4 5 6 7 8 9 34 73 ! 注意，$10 不能获取第十个参数，获取第十个参数需要${10}。当n&gt;=10时，需要使用${n}来获取参数 另外，还有几个特殊字符用来处理参数：（以下内容在前面Shell传参中有详细解释） 参数处理 说明 $# 传递到脚本或函数的参数个数 $* 以一个单字符串显示所有向脚本传递的参数 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数 $- 显示Shell使用的当前选项，与set命令功能相同 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E4%B9%9D%E3%80%91%E2%80%94%E2%80%94Shell%20%E5%87%BD%E6%95%B0/"},{"title":"Shell脚本编写教程【二】——Shell 数组","text":"​点击阅读更多查看文章内容 Shell脚本编写教程【二】——Shell 数组 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash bash支持一维数组（不支持多维数组），并且没有限定数组的大小类似于 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。 创建数组 Shell 数组用括号来表示，元素用”空格”符号分割开，语法格式如下：array_name=(value1 value2 … valuen) 1my_array=(A B &quot;C&quot; D) 也可以使用数字下标来定义数组 123array_name[0]=value0array_name[1]=value1array_name[2]=value2 读取数组 读取数组元素值的一般格式是：${array_name[index]} 123456my_array=(A B &quot;C&quot; D)echo &quot;第一个元素为: ${my_array[0]}&quot;echo &quot;第二个元素为: ${my_array[1]}&quot;echo &quot;第三个元素为: ${my_array[2]}&quot;echo &quot;第四个元素为: ${my_array[3]}&quot; 关联数组（字典） 关联数组可以使用任意的字符串或者整数作为下标来访问数组元素 关联数组使用declare命令来声明，语法格式如下：declare -A array_name -A：用于声明一个关联数组 关联数组的键是唯一的 实例： 1declare -A site=([&quot;google&quot;]=&quot;www.google.com&quot; [&quot;runoob&quot;]=&quot;www.runoob.com&quot; [&quot;taobao&quot;]=&quot;www.taobao.com&quot;) 也可以先声明一个关联数组（自己试的不声明也可以（发现不声明的话还是有问题，在后面取数组所有元素时，如果没有声明那么只会取到最后一个元素）），再设置键和值： 1234declare -A sitesite[&quot;google&quot;]=&quot;www.google.com&quot;site[&quot;runoob&quot;]=&quot;www.runoob.com&quot;site[&quot;taobao&quot;]=&quot;www.taobao.com&quot; 访问关联数组元素时使用指定的键，格式如下：array_name[&quot;index&quot;] 1234567declare -A sitesite[&quot;google&quot;]=&quot;www.google.com&quot;site[&quot;runoob&quot;]=&quot;www.runoob.com&quot;site[&quot;taobao&quot;]=&quot;www.taobao.com&quot;echo ${site[&quot;runoob&quot;]}# www.runoob.com 获取数组中的所有元素使用@或*可以获取数组中的所有元素 实例： 123456789my_array[0]=Amy_array[1]=Bmy_array[2]=Cmy_array[3]=Decho &quot;数组的元素为: ${my_array[*]}&quot;echo &quot;数组的元素为: ${my_array[@]}&quot;# 数组的元素为: A B C D# 数组的元素为: A B C D 关联数组： 123456789declare -A sitesite[&quot;google&quot;]=&quot;www.google.com&quot;site[&quot;runoob&quot;]=&quot;www.runoob.com&quot;site[&quot;taobao&quot;]=&quot;www.taobao.com&quot;echo &quot;数组的元素为: ${site[*]}&quot;echo &quot;数组的元素为: ${site[@]}&quot;# 数组的元素为: www.google.com www.taobao.com www.runoob.com# 数组的元素为: www.google.com www.taobao.com www.runoob.com 在数组前面加一个感叹号!可以获取数组的所有键 123456789declare -A sitesite[&quot;google&quot;]=&quot;www.google.com&quot;site[&quot;runoob&quot;]=&quot;www.runoob.com&quot;site[&quot;taobao&quot;]=&quot;www.taobao.com&quot;echo &quot;数组的键为: ${!site[*]}&quot;echo &quot;数组的键为: ${!site[@]}&quot;# 数组的键为: google taobao runoob# 数组的键为: google taobao runoob 获取数组的长度 获取数组长度的方法与获取字符串长度的方法相同，在数组名前加#获取 #my_array[*]：获取数组元素个数#my_array[@]：获取数组元素个数#my_array[i]：获取数组中第i个元素的长度 123456789101112my_array[0]=Amy_array[1]=Bmy_array[2]=Cmy_array[3]=Decho &quot;数组元素个数为: ${#my_array[*]}&quot;echo &quot;数组元素个数为: ${#my_array[@]}&quot;echo &quot;数组第0个元素的长度为: ${#my_array[0]}&quot;# 数组元素个数为: 4# 数组元素个数为: 4# 数组第0个元素的长度为: 1","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E4%BA%8C%E3%80%91%E2%80%94%E2%80%94Shell%20%E6%95%B0%E7%BB%84/"},{"title":"Shell脚本编写教程【五】——Shell 基本运算符","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程【五】——Shell 基本运算符 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash Shell支持多种运算符，包括：算术运算符、关系运算符、布尔运算符、字符串运算符、文件测试运算符 原生bash不支持简单的数学运算，但是可以通过expr命令实现expr是一款表达式计算工具，使用它能完成表达式的求值操作 例如： 123value=`expr 2 + 2`echo ${value}# 4 表达式和运算符之间要有空格，例如2+2是不对的，必须写成2 + 2 完整的表达式要被``包含 算数运算符假定a为10，b为20 运算符 说明 举例 + 加法 `expr $a + $b`结果为30 - 减法 `expr $a - $b`结果为-10 * 乘法 `expr $a \\* $b`结果为200 / 除法 `expr $b / $a`结果为2 % 取余 `expr $b % $a`结果为0 = 赋值 a=$b 把变量b的值赋给a == 相等。用于比较两个数字，相同则返回true [ $a == $b ]返回false != 不相等。用于比较两个数字，不相同则返回true [ $a != $b ]返回true 条件表达式要放在方括号中，并且要有空格（等号前后和左方括号后以及右方括号前都要有空格），例如:[$a==$b]是错误的，必须写成[ $a == $b ] 实例： 123456789101112131415161718192021222324252627282930a=10b=20val=`expr $a + $b`echo ${val}# 30val=`expr $a - $b`echo ${val}# -10val=`expr $a \\* $b`echo ${val}# 200val=`expr $b / $a`echo ${val}# 2val=`expr $b % $a`echo ${val}# 0a=$bif [ $a == $b ]then echo &quot;a 等于 b&quot;fi# a 等于 bif [ $a != $b ]then echo &quot;a 不等于 b&quot;fi 乘号*前必须加反斜杠\\才能实现乘法运算 if…then…fi是条件语句，后续会讲解 在MAC中shell的expr语法是：$((表达式))，此处表达式中的*不需要转义符号”\\“（个人测试结果除了$((表达式))命令外，上述其他的命令在MAC中也均兼容） 关系运算符 关系运算符只支持数字，不支持字符串，除非字符串的值是数字 假定a为10，b为20 运算符 说明 举例 -eq 检测两个数是否相等，相等返回true [ $a -eq $b ]返回false -ne 检测两个数是否不相等，不相等返回true [ $a -ne $b ]返回true -gt 检测左边的数是否大于右边的，如果是，则返回true [ $a -gt $b ]返回false -lt 检测左边的数是否小于右边的，如果是，则返回 true [ $a -lt $b ] 返回 true -ge 检测左边的数是否大于等于右边的，如果是，则返回 true [ $a -ge $b ] 返回 false -le 检测左边的数是否小于等于右边的，如果是，则返回 true [ $a -le $b ] 返回 true 注意：关系运算符前后，左方括号后以及右方括号前都要有空格（一共四个空格） 实例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546a=10b=20if [ $a -eq $b ]then echo &quot;$a -eq $b : a 等于 b&quot;else echo &quot;$a -eq $b: a 不等于 b&quot;fiif [ $a -ne $b ]then echo &quot;$a -ne $b: a 不等于 b&quot;else echo &quot;$a -ne $b : a 等于 b&quot;fiif [ $a -gt $b ]then echo &quot;$a -gt $b: a 大于 b&quot;else echo &quot;$a -gt $b: a 不大于 b&quot;fiif [ $a -lt $b ]then echo &quot;$a -lt $b: a 小于 b&quot;else echo &quot;$a -lt $b: a 不小于 b&quot;fiif [ $a -ge $b ]then echo &quot;$a -ge $b: a 大于或等于 b&quot;else echo &quot;$a -ge $b: a 小于 b&quot;fiif [ $a -le $b ]then echo &quot;$a -le $b: a 小于或等于 b&quot;else echo &quot;$a -le $b: a 大于 b&quot;fi# 10 -eq 20: a 不等于 b# 10 -ne 20: a 不等于 b# 10 -gt 20: a 不大于 b# 10 -lt 20: a 小于 b# 10 -ge 20: a 小于 b# 10 -le 20: a 小于或等于 b 布尔运算符假定a为10，b为20 运算符 说明 举例 ! 非运算，表达式为true则返回false，否则返回true [ ! false ]返回true -o 或运算，有一个表达式为true则返回true [ $a -lt 20 -o $b -gt 100 ]返回true -a 与运算，两个表达式都为true才返回true [ &amp;a -lt 20 -a &amp;b -gt 100]返回false 实例： 1234567891011121314151617181920212223242526272829303132a=10b=20if [ $a != $b ]then echo &quot;$a != $b : a 不等于 b&quot;else echo &quot;$a == $b: a 等于 b&quot;fiif [ $a -lt 100 -a $b -gt 15 ]then echo &quot;$a 小于 100 且 $b 大于 15 : 返回 true&quot;else echo &quot;$a 小于 100 且 $b 大于 15 : 返回 false&quot;fiif [ $a -lt 100 -o $b -gt 100 ]then echo &quot;$a 小于 100 或 $b 大于 100 : 返回 true&quot;else echo &quot;$a 小于 100 或 $b 大于 100 : 返回 false&quot;fiif [ $a -lt 5 -o $b -gt 100 ]then echo &quot;$a 小于 5 或 $b 大于 100 : 返回 true&quot;else echo &quot;$a 小于 5 或 $b 大于 100 : 返回 false&quot;fi# 10 != 20 : a 不等于 b# 10 小于 100 且 20 大于 15 : 返回 true# 10 小于 100 或 20 大于 100 : 返回 true# 10 小于 5 或 20 大于 100 : 返回 false 逻辑运算符假定a为10，b为20 运算符 说明 举例 &amp;&amp; 逻辑的AND [[ &amp;a -lt 100 &amp;&amp; $b -gt 100 ]] 返回false || 逻辑的OR [[ $a -lt 100 || $b -gt 100 ]]返回true 注意有两层方括号包裹 实例： 12345678910111213141516171819a=10b=20if [[ $a -lt 100 &amp;&amp; $b -gt 100 ]]then echo &quot;返回 true&quot;else echo &quot;返回 false&quot;fiif [[ $a -lt 100 || $b -gt 100 ]]then echo &quot;返回 true&quot;else echo &quot;返回 false&quot;fi# 返回 false# 返回 true 字符串运算符假定变量a为”abc”，b为”efg” 运算符 说明 举例 = 检测两个字符串是否相等，相等返回true [ $a = $b ]返回false != 检测两个字符串是否不相等， 不相等返回true [ $a != $b ]返回true -z 检测字符串长度是否为0，为0返回true [ -z $a ]返回false -n 检测字符串长度是否不为0，不为0返回true [ -n $a ]返回true $ 检测字符串是否不为空，不为空返回true [ $a ]返回true 实例： 123456789101112131415161718192021222324252627282930313233343536373839a=&quot;abc&quot;b=&quot;efg&quot;if [ $a = $b ]then echo &quot;$a = $b : a 等于 b&quot;else echo &quot;$a = $b: a 不等于 b&quot;fiif [ $a != $b ]then echo &quot;$a != $b : a 不等于 b&quot;else echo &quot;$a != $b: a 等于 b&quot;fiif [ -z $a ]then echo &quot;-z $a : 字符串长度为 0&quot;else echo &quot;-z $a : 字符串长度不为 0&quot;fiif [ -n &quot;$a&quot; ]then echo &quot;-n $a : 字符串长度不为 0&quot;else echo &quot;-n $a : 字符串长度为 0&quot;fiif [ $a ]then echo &quot;$a : 字符串不为空&quot;else echo &quot;$a : 字符串为空&quot;fi# abc = efg: a 不等于 b# abc != efg : a 不等于 b# -z abc : 字符串长度不为 0# -n abc : 字符串长度不为 0# abc : 字符串不为空 文件测试运算符 操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true [ -b $file ] 返回false -c file 检测文件是否是字符设备文件，如果是，则返回 true [ -c $file ] 返回 false -d file 检测文件是否是目录，如果是，则返回 true [ -d $file ] 返回 false -f file 检测文件是否是普通文件(既不是目录，也不是设备文件)，如果是，则返回true [ -f $file ] 返回 true -g file 检测文件是否设置了 SGID 位，如果是，则返回 true [ -g $file ] 返回 false -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true [ -k $file ] 返回 false -p file 检测文件是否是有名管道，如果是，则返回 true [ -p $file ] 返回 false -u file 检测文件是否设置了 SUID 位，如果是，则返回 true [ -u $file ] 返回 false -r file 检测文件是否可读，如果是，则返回 true [ -r $file ] 返回 true -w file 检测文件是否可写，如果是，则返回 true [ -w $file ] 返回 true -x file 检测文件是否可执行，如果是，则返回 true [ -x $file ] 返回 true -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true [ -s $file ] 返回 true -e file 检测文件（包括目录）是否存在，如果是，则返回 true [ -e $file ] 返回 true 其他检查符： -S: 判断某文件是否 socket。 -L: 检测文件是否存在并且是一个符号链接。 实例：变量 file 表示文件 /var/www/runoob/test.sh，它的大小为 100 字节，具有 rwx 权限 12345678910111213141516171819202122232425262728293031323334353637383940414243file=&quot;/var/www/runoob/test.sh&quot;if [ -r $file ]then echo &quot;文件可读&quot;else echo &quot;文件不可读&quot;fiif [ -w $file ]then echo &quot;文件可写&quot;else echo &quot;文件不可写&quot;fiif [ -x $file ]then echo &quot;文件可执行&quot;else echo &quot;文件不可执行&quot;fiif [ -f $file ]then echo &quot;文件为普通文件&quot;else echo &quot;文件为特殊文件&quot;fiif [ -d $file ]then echo &quot;文件是个目录&quot;else echo &quot;文件不是个目录&quot;fiif [ -s $file ]then echo &quot;文件不为空&quot;else echo &quot;文件为空&quot;fiif [ -e $file ]then echo &quot;文件存在&quot;else echo &quot;文件不存在&quot;fi","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E4%BA%94%E3%80%91%E2%80%94%E2%80%94Shell%20%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%AE%97%E7%AC%A6/"},{"title":"Shell脚本编写教程【八】——Shell流程控制","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程【八】——Shell流程控制 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash shell的流程控制不可为空 以下写法是错误的，如果else分支没有语句执行，就不要写这个else1234567if [ true ]then echo &quot;hello&quot;else fiif elseif 语句语法格式 1234567if conditionthen command1 command2 ... commandN fi 写成一行（适用于终端命令提示符） 1if [ $(ps -ef | grep -c &quot;ssh&quot;) -gt 1 ]; then echo &quot;true&quot;; fi if else 语法格式 123456789if conditionthen command1 command2 ... commandNelse commandfi if else-if else 语法格式 123456789if condition1then command1elif condition2 then command2else commandNfi if else 的 […] 判断语句中大于使用 -gt，小于使用 -lt 123if [ &quot;$a&quot; -gt &quot;$b&quot; ]; then ...fi 如果使用 ((…)) 作为判断语句，大于和小于可以直接使用 &gt; 和 &lt;。 123if (( a &gt; b )); then ...fi 实例： 123456789101112131415a=10b=20if [ $a == $b ]then echo &quot;a 等于 b&quot;elif [ $a -gt $b ]then echo &quot;a 大于 b&quot;elif [ $a -lt $b ]then echo &quot;a 小于 b&quot;else echo &quot;没有符合的条件&quot;fi# a 小于 b 使用 ((…)) 作为判断语句: 123456789101112131415a=10b=20if (( $a == $b ))then echo &quot;a 等于 b&quot;elif (( $a &gt; $b ))then echo &quot;a 大于 b&quot;elif (( $a &lt; $b ))then echo &quot;a 小于 b&quot;else echo &quot;没有符合的条件&quot;fi# a 小于 b if else 语句经常与 test 命令结合使用，如下所示： 123456789num1=$[2*3]num2=$[1+5]if test $[num1] -eq $[num2]then echo '两个数字相等!'else echo '两个数字不相等!'fi# 两个数字相等! for循环格式： 1234567for var in item1 item2 ... itemNdo command1 command2 ... commandNdone 写成一行： 1for var in item1 item2 ... itemN; do command1; command2… done; 当变量值在列表里，for 循环即执行一次所有命令，使用变量名获取列表中的当前取值。命令可为任何有效的 shell 命令和语句。in 列表可以包含替换、字符串和文件名。 in列表是可选的，如果不用它，for循环使用命令行的位置参数。 例如，顺序输出当前列表中的数字： 123456789for loop in 1 2 3 4 5do echo &quot;The value is: $loop&quot;done# The value is: 1# The value is: 2# The value is: 3# The value is: 4# The value is: 5 顺序输出字符串中的字符：12345678for str in This is a stringdo echo $strdone# This# is# a# stringwhile循环while 循环用于不断执行一系列命令，也用于从输入文件中读取数据。其语法格式为： 1234while conditiondo commanddone 实例 1234567891011int=1while(( $int&lt;=5 ))do echo $int let &quot;int++&quot;done# 1# 2# 3# 4# 5 以上实例使用了 Bash let 命令，它用于执行一个或多个表达式，变量计算中不需要加上 $ 来表示变量，具体可查阅：Bash let 命令 while循环可用于读取键盘信息。下面的例子中，输入信息被设置为变量FILM，按结束循环。123456echo '按下 &lt;CTRL-D&gt; 退出'echo -n '输入你最喜欢的网站名: 'while read FILMdo echo &quot;是的！$FILM 是一个好网站&quot;done无限循环语法格式： 1234while :do commanddone 或者 1234while truedo commanddone 或者 1for (( ; ; )) until循环until 循环执行一系列命令直至条件为 true 时停止。 until 循环与 while 循环在处理方式上刚好相反。 一般 while 循环优于 until 循环，但在某些时候—也只是极少数情况下，until 循环更加有用。 语法格式： 1234until conditiondo commanddone condition 一般为条件表达式，如果返回值为 false，则继续执行循环体内的语句，否则跳出循环。 实例： 1234567891011121314151617a=0until [ ! $a -lt 10 ]do echo $a a=`expr $a + 1`done# 0# 1# 2# 3# 4# 5# 6# 7# 8# 9 case…esaccase … esac 为多选择语句，与其他语言中的 switch … case 语句类似，是一种多分支选择结构，每个 case 分支用右圆括号开始，用两个分号 ;; 表示 break，即执行结束，跳出整个 case … esac 语句，esac（就是 case 反过来）作为结束标记。 可以用 case 语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。 语法格式 1234567891011121314case 值 in模式1) command1 command2 ... commandN ;;模式2) command1 command2 ... commandN ;;esac case 工作方式如上所示，取值后面必须为单词 in，每一模式必须以右括号结束。取值可以为变量或常数，匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 实例： 123456789101112131415echo '输入 1 到 4 之间的数字:'echo '你输入的数字为:'read aNumcase $aNum in 1) echo '你选择了 1' ;; 2) echo '你选择了 2' ;; 3) echo '你选择了 3' ;; 4) echo '你选择了 4' ;; *) echo '你没有输入 1 到 4 之间的数字' ;;esac 匹配字符串： 1234567891011site=&quot;runoob&quot;case &quot;$site&quot; in &quot;runoob&quot;) echo &quot;菜鸟教程&quot; ;; &quot;google&quot;) echo &quot;Google 搜索&quot; ;; &quot;taobao&quot;) echo &quot;淘宝网&quot; ;;esac# 菜鸟教程 跳出循环break命令break 命令允许跳出所有循环（终止执行后面的所有循环）。 实例：脚本进入死循环直至用户输入数字大于5。要跳出这个循环，返回到shell提示符下，需要使用break命令。 12345678910111213141516while :do echo -n &quot;输入 1 到 5 之间的数字:&quot; read aNum case $aNum in 1|2|3|4|5) echo &quot;你输入的数字为 $aNum!&quot; ;; *) echo &quot;你输入的数字不是 1 到 5 之间的! 游戏结束&quot; break ;; esacdone# 输入 1 到 5 之间的数字:3# 你输入的数字为 3!# 输入 1 到 5 之间的数字:7# 你输入的数字不是 1 到 5 之间的! 游戏结束 continue命令continue 命令与 break 命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。 实例：当输入大于5的数字时，该例中的循环不会结束，语句 echo “游戏结束” 永远不会被执行。 12345678910111213while :do echo -n &quot;输入 1 到 5 之间的数字: &quot; read aNum case $aNum in 1|2|3|4|5) echo &quot;你输入的数字为 $aNum!&quot; ;; *) echo &quot;你输入的数字不是 1 到 5 之间的!&quot; continue echo &quot;游戏结束&quot; ;; esacdone","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E5%85%AB%E3%80%91%E2%80%94%E2%80%94Shell%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/"},{"title":"Shell脚本编写教程【六】——Shell echo和printf命令","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程【六】——Shell echo和printf命令 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash Shell echo命令 命令格式：echo string 1、显示普通字符串 双引号可以省略 1234echo &quot;It is a test&quot;echo It is a test# It is a test# It is a test 2、显示转义字符双引号也可以省略 1234echo \\&quot;It is a test\\&quot;echo &quot;\\&quot;It is a test\\&quot;&quot;# &quot;It is a test&quot;# &quot;It is a test&quot; 3、显示变量read命令从标准输入中读取一行并赋值给变量 12read name echo &quot;$name It is a test&quot; 4、显示换行-e：开启转义 12345echo -e &quot;OK! \\n&quot; # -e 开启转义echo &quot;It is a test&quot;# OK! # # It is a test 5、显示不换行-e：开启转义\\c：不换行 123echo -e &quot;OK! \\c&quot; # -e 开启转义 \\c 不换行echo &quot;It is a test&quot;# OK! It is a test 6、显示结果重定向至文件 123echo &quot;It is a test&quot; &gt; myfilecat ./myfile# It is a test 7、原样输出字符串，不进行转义或取变量用单引号包裹字符串 12echo '$name\\&quot;'# $name\\&quot; 8、显示命令执行结果注意：使用反引号` 12echo `date`# Tue 04 Jul 2023 01:30:02 PM UTC Shell printf命令 printf命令的语法：printf format-string [arguments]format-string：格式控制字符串arguments：参数列表 1234echo &quot;Hello, Shell&quot;printf &quot;Hello, Shell\\n&quot;# Hello, Shell# Hello, Shell 实例： 12345678printf &quot;%-10s %-8s %-4s\\n&quot; 姓名 性别 体重kg printf &quot;%-10s %-8s %-4.2f\\n&quot; 郭靖 男 66.1234printf &quot;%-10s %-8s %-4.2f\\n&quot; 杨过 男 48.6543printf &quot;%-10s %-8s %-4.2f\\n&quot; 郭芙 女 47.9876# 姓名 性别 体重kg# 郭靖 男 66.12# 杨过 男 48.65# 郭芙 女 47.99 %s %c %d %f 都是格式替代符，％s 输出一个字符串，％d 整型输出，％c 输出一个字符，％f 输出实数，以小数形式输出。 %-10s 指一个宽度为 10 个字符（- 表示左对齐，没有则表示右对齐），任何字符都会被显示在 10 个字符宽的字符内，如果不足则自动以空格填充，超过也会将内容全部显示出来（一个汉字占三个字符）。 %-4.2f 指格式化为小数，其中 .2 指保留2位小数。 123456789101112131415161718# format-string为双引号printf &quot;%d %s\\n&quot; 1 &quot;abc&quot;# 单引号与双引号效果一样printf '%d %s\\n' 1 &quot;abc&quot;# 没有引号也可以输出printf %s abcdef# 格式只指定了一个参数，但多出的参数仍然会按照该格式输出，format-string 被重用printf %s abc defprintf &quot;%s\\n&quot; abc defprintf &quot;%s %s %s\\n&quot; a b c d e f g h i j# 如果没有 arguments，那么 %s 用NULL代替，%d 用 0 代替printf &quot;%s and %d \\n&quot; 以下实例的第三行输出abcdefabcdefabc来自：printf %s abcdefprintf %s abc defprintf “%s\\n” abc def 截止到此命令输出一个abc后才会输出一个换行 1234567891011121314151617181920212223242526272829# format-string为双引号printf &quot;%d %s\\n&quot; 1 &quot;abc&quot;# 单引号与双引号效果一样printf '%d %s\\n' 1 &quot;abc&quot;# 没有引号也可以输出printf %s abcdef# 格式只指定了一个参数，但多出的参数仍然会按照该格式输出，format-string 被重用printf %s abc defprintf &quot;%s\\n&quot; abc defprintf &quot;%s %s %s\\n&quot; a b c d e f g h i j# 如果没有 arguments，那么 %s 用NULL代替，%d 用 0 代替printf &quot;%s and %d \\n&quot;# 1 abc# 1 abc# abcdefabcdefabc# def# a b c# d e f# g h i# j # and 0 printf的转义序列 序列 说明 \\a 警告字符，通常为ASCII的BEL字符 \\b 后退 \\c 抑制（不显示）输出结果中任何结尾的换行字符（只在%b格式指示符控制下的参数字符串中有效），而且，任何留在参数里的字符、任何接下来的参数以及任何留在格式字符串中的字符，都被忽略 \\f 换页（formfeed） \\n 换行 \\r 回车（Carriage return） \\t 水平制表符 \\v 垂直制表符 \\\\ 一个字面上的反斜杠字符 \\ddd 表示1到3位数八进制值的字符。仅在格式字符串中有效 \\0ddd 表示1到3位的八进制值字符","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E5%85%AD%E3%80%91%E2%80%94%E2%80%94Shell%20echo%E5%92%8Cprintf%E5%91%BD%E4%BB%A4/"},{"title":"Shell脚本编写教程【十】——Shell 输入输出重定向","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程【十】——Shell 输入/输出重定向 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash 大多数 UNIX 系统命令从你的终端接受输入并将所产生的输出发送回​​到您的终端。一个命令通常从一个叫标准输入的地方读取输入，默认情况下，这恰好是你的终端。同样，一个命令通常将其输出写入到标准输出，默认情况下，这也是你的终端 重定向命令列表如下： 命令 说明 command &gt; file 将输出重定向到 file command &lt; file 将输入重定向到 file command &gt;&gt; file 将输出以追加的方式重定向到 file n &gt; file 将文件描述符为 n 的文件重定向到 file n &gt;&gt; file 将文件描述符为 n 的文件以追加的方式重定向到 file n &gt;&amp; m 将输出文件 m 和 n 合并 n &lt;&amp; m 将输入文件 m 和 n 合并 &lt;&lt; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入 需要注意的是文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR） 输出重定向 重定向一般通过在命令间插入特定的符号来实现。 1command1 &gt; file1 &gt;：重定向内容覆盖原文件&gt;&gt;：重定向内容追加到原文件 实例（执行下面的 who 命令，它将命令的完整的输出重定向在用户文件中(users)） 1who &gt; users 输入重定向和输出重定向一样，Unix 命令也可以从文件获取输入，语法为： 1command1 &lt; file1 这样，本来需要从键盘获取输入的命令会转移到文件读取内容 实例（统计 users 文件的行数） 12wc -l users# 2 users 也可以将输入重定向到 users 文件 12wc -l &lt; users# 2 注意：上面两个例子的结果不同：第一个例子，会输出文件名；第二个不会，因为它仅仅知道从标准输入读取内容。 1command1 &lt; infile &gt; outfile 同时替换输入和输出，执行command1，从文件infile读取内容，然后将输出写入到outfile中","link":"/2023/09/16/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E5%8D%81%E3%80%91%E2%80%94%E2%80%94Shell%20%E8%BE%93%E5%85%A5!%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91/"},{"title":"Shell脚本编写教程【四】——Shell 传参","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程【四】——Shell 传参 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash 在执行Shell脚本时，可以向脚本传递参数，脚本内获取参数的格式为：$n。n代表一个数字，1为执行脚本的第一个参数，2为执行脚本的第二个参数，以此类推…… 实例以下实例我们向脚本传递三个参数，并分别输出，其中 $0 为执行的文件名（包含文件路径） 12345echo &quot;Shell 传递参数实例！&quot;echo &quot;执行的文件名：$0&quot;echo &quot;第一个参数为：$1&quot;echo &quot;第二个参数为：$2&quot;echo &quot;第三个参数为：$3&quot; 执行结果： 特殊参数说明 参数处理 说明 $# 传递到脚本的参数个数 $* 用一个字符串显示所有参数 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$@类似，区别在下文提及 $- 显示Shell使用的当前选项，与set命令功能相同 $? 显示最后命令的退出状态，0表示没有错误，其他任何值表明有错误 实例： 123456789#!/bin/bashecho &quot;Shell 传递参数实例！&quot;echo &quot;$#&quot;echo &quot;$*&quot;echo &quot;$$&quot;echo &quot;$!&quot;echo &quot;$@&quot;echo &quot;$-&quot;echo &quot;$?&quot; 执行结果： $* 与 $@ 区别：相同点：都是引用所有参数不同点：只有在双引号中体现出来，假设脚本运行时传递了三个参数1、2、3，则”*”等价于”1 2 3”(传递了一个参数)，而”@”等价于”1” “2” “3”(传递了三个参数) 实例： 123456789echo &quot;-- \\$* 演示 ---&quot;for i in &quot;$*&quot;; do echo $idoneecho &quot;-- \\$@ 演示 ---&quot;for i in &quot;$@&quot;; do echo $idone 执行结果：","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E3%80%90%E5%9B%9B%E3%80%91%E2%80%94%E2%80%94Shell%20%E4%BC%A0%E5%8F%82/"},{"title":"Shell脚本编写教程目录检索","text":"​​点击阅读更多查看文章内容 Shell脚本编写教程目录检索 目录：https://blog.csdn.net/shn111/article/details/131590488 参考教程：https://www.runoob.com/linux/linux-shell.html 在线编辑器：https://www.runoob.com/try/runcode.php?filename=helloworld&type=bash Shell脚本编写教程【一】——Shell 变量Shell脚本编写教程【二】——Shell 数组Shell脚本编写教程【三】——Shell 注释Shell脚本编写教程【四】——Shell 传参Shell脚本编写教程【五】——Shell 基本运算符Shell脚本编写教程【六】——Shell echo和printf命令Shell脚本编写教程【七】——Shell test命令Shell脚本编写教程【八】——Shell流程控制Shell脚本编写教程【九】——Shell 函数Shell脚本编写教程【十】——Shell 输入/输出重定向","link":"/2023/07/07/Shell%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%95%99%E7%A8%8B%E7%9B%AE%E5%BD%95%E6%A3%80%E7%B4%A2/"},{"title":"UVA11134 Fabled Rooks","text":"​​点击阅读更多查看文章内容 UVA11134 Fabled Rooks题目链接 问题解析在n行n列的棋盘上放n个车，第i个车在给定的矩形Ri之内，且任意两个车不能相互攻击，即任意两个车不在同一行或同一列。求每个车的位置坐标。 首先，一个车所在的行不会影响它所在的列，可以分别求一个车的横坐标和纵坐标，将一个二维的问题转化为一个一维的问题。 现在，我们面临的问题是如何将这n个点分给n个车。以横坐标xi为例，每个车的x都被限定在了一个区间[xli,xri]之内，不难看出应该应用贪心算法求解。 这里我最开始做的是按照xli从小到大排序，如果相同就按照xri从小到大排序，然后从每个区间的最左端开始遍历，找到比前一个点的x大的就取出。但会遗漏一种情况，即当输入数据为31 1 3 31 1 3 32 2 2 2（这里大家可以自己代入看一下，因为是错误方法就不多解释了） 下面是正确的解题思路，因为我们是从左往右取点，如果一个点被多个区间包含，不难判断，我们应该取右端点最小的区间，因为右端点越大，它所能取的值就越多，所以对区间的排序，应该是按照右端点从小到大，如果相同就按左端点从小到大。取点时按照区间从左往右，注意判断当前所取的点之前没有取过。 代码以下代码可以AC，但时间复杂度较高代码比较繁琐，大家看看思路即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123#include&lt;bits/stdc++.h&gt;using namespace std;const int maxn = 5000 + 10;typedef pair&lt;int, int&gt; pos;int N;struct point { int num; pos resx; pos resy; int x, y;};point points[maxn];bool cmp1(point a, point b){ if (a.resx.second == b.resx.second) return a.resx.first &lt; b.resx.first; return a.resx.second &lt; b.resx.second;}bool cmp2(point a, point b){ if (a.resy.second == b.resy.second) return a.resy.first&lt; b.resy.first; return a.resy.second &lt; b.resy.second;}bool sortx(){ sort(points, points + N, cmp1); points[0].x = points[0].resx.first; int i, j; bool flag = false; for (i = 1; i &lt; N; i++) { for ( j = points[i].resx.first; j &lt;= points[i].resx.second; j++) { flag = false; for (int t = 0; t &lt; i; t++) { if (j == points[t].x) { flag = true; break; } } if (!flag) { points[i].x = j; break; } } if (j &gt; points[i].resx.second) return false; } return true;}bool sorty(){ sort(points, points + N, cmp2); points[0].y = points[0].resy.first; int i, j; bool flag = false; for (i = 1; i &lt; N; i++) { for (j = points[i].resy.first; j &lt;= points[i].resy.second; j++) { flag = false; for (int t = 0; t &lt; i ; t++) { if (j == points[t].y) { flag = true; break; } } if (!flag) { points[i].y = j; break; } } if (j &gt; points[i].resy.second) return false; } return true;}void output(){ for (int i = 0; i &lt; N; i++) { for (int j = 0; j &lt; N; j++) { if (points[j].num == i) { cout &lt;&lt; points[j].x &lt;&lt; &quot; &quot; &lt;&lt;points[j].y&lt;&lt; endl; break; } } }}int main(){ int x1, y1, x2, y2; while (cin &gt;&gt; N &amp;&amp; N != 0) { for (int i = 0; i &lt; N; i++) { cin &gt;&gt; x1 &gt;&gt; y1 &gt;&gt; x2 &gt;&gt; y2; points[i].num = i; points[i].resx = make_pair(x1, x2); points[i].resy = make_pair(y1, y2); } if (!sortx()) cout &lt;&lt; &quot;IMPOSSIBLE&quot;&lt;&lt;endl; else { if (!sorty()) cout &lt;&lt; &quot;IMPOSSIBLE&quot;&lt;&lt;endl; else output(); } }}","link":"/2021/04/02/UVA11134%20Fabled%20Rooks/"},{"title":"UVA11212 Editing a Book（编辑书稿）","text":"​​点击阅读更多查看文章内容 UVA11212 Editing a Book题目链接 这道题有一定的难度，参考了一些大佬的代码，在这里写一篇题解巩固一下。 问题分析首先，本题采用IDA*算法求解，参考紫皮书上的解释，这道题启发函数的求解是解题的一个关键。 其次是三个加速的策略：1.每次只剪切一段连续的数字。2.假设剪切片段的第一个数字为a，最后一个数字为b，这个片段要么粘贴到a-1下一个位置，要么粘贴到b+1的前一个位置。3.已经排好序的数字不要分开剪切，始终看做一个整体。（以上解释纯属搬书，下面结合代码具体分析） 最后，启发函数的求解，设最多剪切maxd次，d是已经剪切的次数，后继不正确的数字还有h个，不难发现，每次剪切最多可以改变3个数字的直接后继。如下图，把2移到3之后，只有1后继变为3,3后继变为2,2后继变为4.由此可得当h&gt;3*(maxd-d)时可以剪枝。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#define _CRT_SECURE_NO_WARNINGS#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;vector&gt;#include&lt;algorithm&gt;using namespace std;int geth(vector&lt;int&gt;&amp; nums){ int cnt = 0; for (int i = 1; i &lt; nums.size(); ++i) { if (nums[i - 1] + 1 != nums[i]) ++cnt; } return cnt;}bool dfs(int d, vector&lt;int&gt;&amp; nums, int maxd){ int i = 0, cnt = geth(nums); //剪枝 if (cnt == 0) return true; if (cnt &gt; 3 * (maxd - d)) return false; for (i = 0; i &lt; nums.size();) { int j = i + 1; while (j &lt; nums.size() &amp;&amp; nums[j - 1] + 1 == nums[j]) ++j; for (; j &lt;= nums.size(); ++j) { vector&lt;int&gt;tmp = nums; vector&lt;int&gt;in(nums.begin() + i, nums.begin() + j); tmp.erase(tmp.begin() + i, tmp.begin() + j); vector&lt;int&gt;lhs = tmp, rhs = tmp; auto lp = find(lhs.begin(), lhs.end(), in.front() - 1); auto rp = find(rhs.begin(), rhs.end(), in.back() + 1); lhs.insert(lp == lhs.end() ? lhs.begin() : next(lp), in.begin(), in.end()); rhs.insert(rp, in.begin(), in.end()); if (dfs(d + 1, lhs, maxd) || dfs(d + 1, rhs, maxd)) return true; } i++; while (i &lt; nums.size() &amp;&amp; nums[i - 1] + i == nums[i]) ++i; } return false;}int main(){ int N, kase = 0; while (scanf(&quot;%d&quot;, &amp;N) != EOF &amp;&amp; N) { vector&lt;int&gt;nums(N + 1, 0); for (int i = 1; i &lt;= N; i++) scanf(&quot;%d&quot;, &amp;nums[i]); for (int maxd = 0;; ++maxd) { if (dfs(0, nums, maxd)) { printf(&quot;Case %d: %d\\n&quot;, ++kase, maxd); break; } } } return 0;} 代码是借鉴的大佬的，如果大家有什么不明白的地方，可以在评论区交流一下。","link":"/2021/03/22/UVA11212%20Editing%20a%20Book%EF%BC%88%E7%BC%96%E8%BE%91%E4%B9%A6%E7%A8%BF%EF%BC%89/"},{"title":"UVA1025 A Spy in the Metro","text":"​​点击阅读更多查看文章内容 UVA1025 A Spy in the Metro题目链接 刚开始接触DP题，感觉还是有一定的难度，在这里再理一遍思路。 DP的核心就是状态和状态转移方程首先状态的确定就是找到影响当前决策的因素，本题是当前时间和所处车站两个，所以可以用d[i][j]表示i时刻在j站最少还要等待的时间。 其次是状态转移方程，取决于决策的形式，本题主要有以下三种决策：1.在当前车站等待一分钟。2.搭乘向右开的车。3.搭乘向左开的车。找出决策后即可列出相对应的状态转移方程。1.dp[i][j]=min(dp[i][j],dp[i+1][j]+1)2.dp[i][j]=min(dp[i][j],dp[i+t[j][j+1])3.dp[i][j]=min(dp[i][j],dp[i+t[j-1]][j-1]) 下一步要找出边界条件和计算顺序（递推法）这两步就要结合题意来做具体的分析本题的边界条件为T时刻到达车站n即dp[T][n]=0计算顺序不难判断应该从后往前，这里有一个小技巧，可以根据状态转移方程，不难看出T小的值要根据T大的求出，所以应该先求T大的值。 AC代码注意数组范围尽量开大一些，防止越界（Runtime error） #include&lt;iostream&gt; #include&lt;algorithm&gt; #include&lt;cstring&gt; #define INF 0x3f3f3f3f using namespace std; const int MAXN = 50+10; const int MAXM = 50+10; const int MAXT = 300; int n, T, t[MAXN], M1, tr[MAXM], M2, tl[MAXM]; bool has_train[MAXT][MAXN][2]; int dp[MAXT][MAXN]; bool init() { cin &gt;&gt; n; if (n == 0) return false; int time; memset(dp, INF, sizeof(dp)); memset(has_train, false, sizeof(has_train)); memset(t, 0, sizeof(t)); cin &gt;&gt; T; for (int i = 1; i &lt; n; i++) cin &gt;&gt; t[i]; cin &gt;&gt; M1; time = 0; for (int i = 0; i &lt; M1; i++) { cin &gt;&gt; tr[i]; time = tr[i]; has_train[time][1][0] = true; for (int i = 1; i &lt; n; i++) { time += t[i]; has_train[time][i + 1][0] = true; } } cin &gt;&gt; M2; for (int i = 0; i &lt; M2; i++) { cin &gt;&gt; tl[i]; time = tl[i]; has_train[time][n][1] = true; for (int i = 1; i &lt; n; i++) { time += t[n - i]; has_train[time][n - i][1] = true; } } return true; } void solve() { for (int i = 1; i &lt; n; i++) dp[T][i] = INF; dp[T][n] = 0; for (int i = T-1; i &gt;= 0; i--) { for (int j = 1; j &lt;= n; j++) { dp[i][j] = min(dp[i][j], dp[i + 1][j] + 1); if (j &lt; n &amp;&amp; has_train[i][j][0] &amp;&amp; i + t[j] &lt;= T) dp[i][j] = min(dp[i][j], dp[i + t[j]][j + 1]); if (j &gt; 1 &amp;&amp; has_train[i][j][1] &amp;&amp; i + t[j - 1] &lt;= T) dp[i][j] = min(dp[i][j], dp[i + t[j - 1]][j - 1]); } } } int main() { int cnt = 0; while (init()) { solve(); cout &lt;&lt; &quot;Case Number &quot; &lt;&lt; ++cnt &lt;&lt; &quot;: &quot;; if (dp[0][1] &gt;= INF) cout &lt;&lt; &quot;impossible\\n&quot;; else cout &lt;&lt; dp[0][1] &lt;&lt; &quot;\\n&quot;; } return 0; }","link":"/2021/05/21/UVA1025%20A%20Spy%20in%20the%20Metro/"},{"title":"UVA1153 Keep the Customer Satisfied","text":"​​点击阅读更多查看文章内容 UVA1153 Keep the Customer Satisfied题目链接 第一次做这种题，没有丝毫头绪，查了一下要用优先队列+贪心，在这里再记录一下。 题目大概意思就是给定n个工作的耗费时间和截止时间，求最多能完成的工作的个数。 解题方法首先将输入按照截止时间从前往后排列，截止时间靠前的肯定要先完成。 然后维护一个时间和优先队列，时间就是记录当前工作的时间，优先队列存放已经完成的工作，按照所耗费的时间排序，耗时长的先出队。 方法解释我们按照截止时间的升序向优先队列中push，每次向队列中插入元素时，如果插入的工作可以完成（维护时间+工作时间&lt;=截止时间），那么直接插入即可，若当前插入的工作无法完成（维护时间+工作时间&gt;截止时间），我们就应该贪心，可不可以用当前工作去替换一个队列中耗时更多的工作呢？以此类推，插入每个工作前都进行一次判断，最后队列的大小即为最多能完成的工作个数。 注意要判断队列是否为空，可能工作本身就不符合 AC代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include&lt;iostream&gt;#include&lt;queue&gt;#include&lt;algorithm&gt;using namespace std;const int MAX = 8e5+10;int T;int N;struct work{ int x, y; work(int a=0, int b=0) { x = a; y = b; }};work works[MAX];bool cmp(work a, work b){ if (a.y == b.y) return a.x &lt; b.x; return a.y &lt; b.y;}int main(){ int time; cin &gt;&gt; T; while (T--) { time = 0; priority_queue&lt;int&gt;pq; cin &gt;&gt; N; for (int i = 0; i &lt; N; i++) { cin &gt;&gt; works[i].x &gt;&gt; works[i].y; } sort(works, works + N, cmp); for (int i = 0; i &lt; N; i++) { if (time + works[i].x &lt;= works[i].y) { pq.push(works[i].x); time += works[i].x; } else if (!pq.empty()) { if (pq.top() &gt;= works[i].x) { time = time - pq.top() + works[i].x; pq.pop(); pq.push(works[i].x); } } } cout &lt;&lt; pq.size() &lt;&lt; endl; if (T != 0) cout &lt;&lt; endl; }}","link":"/2021/05/10/UVA1153%20Keep%20the%20Customer%20Satisfied/"},{"title":"UVA11988 破碎的键盘（悲剧文本）","text":"​​点击阅读更多查看文章内容 UVA11988 破碎的键盘紫皮书例题6-4刚开始学链表想了好久这道题，做个简单的总结。就用书上的代码 1234567891011121314151617181920212223242526272829303132333435363738#include&lt;iostream&gt;#include&lt;cstring&gt;#include&lt;cstdio&gt;using namespace std;const int maxn = 100000 + 5;int last, cur, nextt[maxn]; //光标位于cur号字符的后面char s[maxn];int main(){ while (scanf(&quot;%s&quot;, s + 1) == 1) { int n = strlen(s + 1); last = cur = 0; nextt[0] = 0; for (int i = 1; i &lt;= n; ++i) {//这里是将i打印在cur的后面 if (s[i] == '[') cur = 0; else if (s[i] == ']') cur = last; else { nextt[i] = nextt[cur]; nextt[cur] = i; //前面两行，是将i插入cur后面，这里分了两步，首先把cur后面的字符放到i的后面，然后把i插入cur后面。后面附了一张图，看起来清楚一点。 if (cur == last) last = i;//这里s[last]代表最后一个字符，如果cur等于last，代表插入的i在last的后面，所以最后一个字符更新为i。 cur = i; //移动光标，cur=i，代表i已经插入、 } } for (int i = nextt[0]; i != 0; i = nextt[i]) printf(&quot;%c&quot;, s[i]); printf(&quot;\\n&quot;); } return 0;} 插入字符e，首先把c放在e的后面，再把e放在b的后面。","link":"/2021/02/24/UVA11988%20%E7%A0%B4%E7%A2%8E%E7%9A%84%E9%94%AE%E7%9B%98%EF%BC%88%E6%82%B2%E5%89%A7%E6%96%87%E6%9C%AC%EF%BC%89/"},{"title":"UVA12166 Equilibrium Mobile","text":"​​点击阅读更多查看文章内容 VJ传送门 一道思维题，刚开始看的时候没什么思路，在博客园上参考了大佬的解析，在这里总结一下。 一、分析这道题要求让天平平衡所需要的最小改动次数，至少有一个不变，我们可以先选定一个不变的基准，然后改变其他的秤砣，得到以此为基准的天平的总重量，如果以深度为d重量为w的秤砣为基准，那么整个天平的重量就是w * pow(2, d)，即w &lt;&lt; d。 当然，可能会有一些秤砣算出的以各自为基准的天平总重量相同，设天平总重量为sumw，那么这些秤砣的数量就表示了如果使天平的总重量为sumw需要使多少个秤砣保持不变。 以题目所给[[3,7],6]为例，如果将3看做基准，则将7改为3即可，天平总重量为12，再将6看做基准，将7改为3即可，天平总重量为12,即有两个秤砣作为基准得到的天平总重量相同为12，则如果使天平的总重量为12需要使两个秤砣保持不变。 基于以上算法，求出所有可能的sumw值以及其对应的秤砣数量，然后在这些sumw值中找到相对应的最大的秤砣数量maxn，那么sum - maxn即为所求。 二、代码#include&lt;iostream&gt; #include&lt;string&gt; #include&lt;map&gt; using namespace std; map&lt;long long, int&gt;mp; int sum = 0;//叶子个数 string s; void dfs(int depth, int a, int b)//depth:深度，a：起点，b：终点 { if (s[a] == '[') { int p = 0; for (int i = a + 1; i != b; i++) { if (s[i] == '[') p++; if (s[i] == ']') p--; if (p == 0 &amp;&amp; s[i] == ',') { dfs(depth + 1, a + 1, i - 1);//搜索左子树 dfs(depth + 1, i + 1, b - 1);//搜索右子树 } } } else { long long w = 0; //这里是将string类型的数字转化为long long类型 for (int i = a; i &lt;= b; i++) { w = w * 10 + s[i] - '0'; } sum++; mp[w * (1 &lt;&lt; depth)]++; } } int main() { int T; cin &gt;&gt; T; while (T--) { sum = 0; mp.clear(); cin &gt;&gt; s; dfs(0, 0, s.length() - 1); int maxn = 0; for (map&lt;long long, int&gt;::iterator it = mp.begin(); it != mp.end(); it++) { maxn = max(maxn, it-&gt;second); } cout &lt;&lt; sum - maxn &lt;&lt; endl; } }","link":"/2021/03/13/UVA12166%20Equilibrium%20Mobile/"},{"title":"UVA1347 Tour","text":"​​点击阅读更多查看文章内容 2021.5.22刷题的时候突然看到手机推送，袁隆平院士逝世，心中一颤，后来得到辟谣，心情稍微放松几分，正在刷着辟谣的文章时，央视新闻发文，13点07分，袁隆平院士逝世，没过多久又看到吴孟超院士逝世的新闻，心情难以平复，特在本文的开头，向两位院士致敬。历史浩荡，国士无双。 UVA1347 Tour题目链接 dp题，按照紫书上的分析做下来的，下面主要也是跟着紫书走一遍。 题目分析“从左到右再回来”不太方便思考，可以改成：两个人同时从最左点出发，沿着两条不同的路径走，最后都走到最右点，且除了起点和终点外其余每个点恰好被一个人经过。这样，就可以用d(i,j)表示一个人走到i，另一个人走到j，还需要走的距离。但是，如此定义，很难保证两个人不会走到同一点。下面修改一下，d(i,j)表示从1~max(i,j)全部走过，且当前两人一个在i一个在j还需要走的距离，并且规定下一步只能走到i+1，即下一个状态为d(i+1,j)或d(i+1,i)（相当于从j点到i+1）我们规定把大的序号放在前面，否则可能会出现死循环。边界条件是d(n-1,j)=dist(n-1,n)+dist(j,n),dist表示两点间的距离状态转移方程为d(i,j) = min(d(i + 1, j) + dist(i, i + 1), d(i + 1, i) + dist(j, i + 1)) AC代码#include&lt;iostream&gt; #include&lt;cmath&gt; #include&lt;iomanip&gt; #include&lt;cstring&gt; #include&lt;algorithm&gt; using namespace std; const int MAXN = 1000 + 10; struct point { int x, y; point(int a = 0, int b = 0) { x = a; y = b; } }; point points[MAXN]; double distance(int i, int j) { point a = points[i]; point b = points[j]; double dis = sqrt(pow((a.x - b.x), 2) + pow((a.y - b.y), 2)); return dis; } int n; double dp[MAXN][MAXN]; double d(int i, int j) { if (dp[i][j] &gt; 0) return dp[i][j]; if (i == n - 1) return dp[i][j] = distance(i, n) + distance(j, n); return dp[i][j] = min(d(i + 1, j) + distance(i, i + 1), d(i + 1, i) + distance(j, i + 1)); } int main() { while (cin &gt;&gt; n) { memset(dp, 0, sizeof(dp)); for (int i = 1; i &lt;= n; i++) { cin &gt;&gt; points[i].x &gt;&gt; points[i].y; } cout &lt;&lt; fixed &lt;&lt; setprecision(2) &lt;&lt; d(2, 1) + distance(1, 2) &lt;&lt; endl; } }","link":"/2021/05/22/UVA1347%20Tour/"},{"title":"UVA1613 K-GraphOddity","text":"​​点击阅读更多查看文章内容 UVA1613 K-GraphOddity题目传送门 刚看第一眼一点思路都没有，后面看了大佬的题解发现这道题其实是一道水题，用到的方法就是DFS遍历图。我是废物 题目意思很简单，就不分析了，下面直接说方法。 首先求出k，然后dfs遍历一遍图，给每个点分一个数字即可。这里注意每次dfs判断的是当前结点的所有相邻接点，“分配颜色”时从1到k遍历一遍找到合适的即可。 代码#include&lt;iostream&gt; #include&lt;vector&gt; #include&lt;cstring&gt; using namespace std; vector&lt;int&gt; gp[10010];//保存边 int ans[10010];//保存每个结点的染色 int k; bool judge(int c, int p)//判断点p能不能染c色 { for (int i = 0; i &lt; gp[p].size(); i++) { if (ans[gp[p][i]] == c) return false; } return true; } void dfs(int x) { for (int i = 0; i &lt; gp[x].size(); i++) { if (ans[gp[x][i]] != 0) continue; for (int j = 1; j &lt;= k; j++) { if (judge(j, gp[x][i])) { ans[gp[x][i]] = j; break; } } dfs(gp[x][i]); } } int main() { int a, b; int n, m; while (cin &gt;&gt; n &gt;&gt; m) { for (int i = 0; i &lt; m; i++) { cin &gt;&gt; a &gt;&gt; b; gp[a].push_back(b); gp[b].push_back(a); } k = gp[1].size(); for (int i = 1; i &lt;= n; i++)//求k { if (gp[i].size() &gt; k) k = gp[i].size(); } if (k % 2 == 0) k++; cout &lt;&lt; k &lt;&lt; endl; ans[1] = 1; dfs(1); for (int i = 1; i &lt;= n; i++) { cout &lt;&lt; ans[i] &lt;&lt; endl; } cout &lt;&lt; endl; for (int i = 1; i &lt;= n; i++) { gp[i].clear(); } memset(ans, 0,sizeof(ans)); } }```","link":"/2021/05/08/UVA1613%20K-GraphOddity/"},{"title":"UVA1614 Hell on the Markets","text":"​​点击阅读更多查看文章内容 UVA1614 Hell on the Markets题目传送门 这道题主要考察的数学推理能力，一点思路都没有，大佬的分析都看了好久。 这道题主要用到的是数学归纳法，用sum[i]表示前i项的和，从1到sum[i]之间的任意一个数，都可以用a[1]到a[i]中的若干个数表示出来。 具体证明方法以及选数的方法可以看下面这篇文章https://blog.csdn.net/weixin_30820151/article/details/101380416 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;const int MAXN = 1e5 + 10;int A[MAXN];int fh[MAXN];int main(){ int n; while (cin &gt;&gt; n) { long long sum = 0; memset(fh, 0, sizeof(fh)); memset(A, 0, sizeof(A)); for (int i = 0; i &lt; n; i++) { cin &gt;&gt; A[i]; sum += A[i]; } if (sum &amp; 1) { cout &lt;&lt; &quot;No&quot; &lt;&lt; endl; continue; } cout &lt;&lt; &quot;Yes&quot; &lt;&lt; endl; sum /= 2; for (int j =n-1; j &gt;= 0; j--) { if (sum - A[j] &gt;= 0) { sum -= A[j]; fh[j] = 1; } else { fh[j] = -1; } } for (int i = 0; i &lt; n; i++) { cout &lt;&lt; fh[i] &lt;&lt; &quot; &quot;; } cout &lt;&lt; endl; }}","link":"/2021/05/08/UVA1614%20Hell%20on%20the%20Markets/"},{"title":"UVA1615 Highway","text":"​​点击阅读更多查看文章内容 UVA1615 Highway题目链接 这道题不算难，就是一道贪心题，下面介绍两种方法。 第一种方法主要的思路就是在x轴上向右选取距离当前点的长度为D的点，即最靠右的点，这样选可以尽可能的满足后面的点。 选点前先将每个点从左向右排序，横坐标相同则从上往下排，这里注意要把纵坐标小的放在后面，因为纵坐标小所选取的点更靠右，如果把纵坐标小的放在前面那么下一个纵坐标大的点距离这个点一定大于D不满足，会多选一个点。（这里表达不太清楚，可以自己画个图看一下） 第二种方法主要的思路就是区间选点，每个点在x轴上都有一个选点的区间，我们把这N个区间选取出来，然后选取最少的点保证每个区间都有点即可。 AC代码方法一 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cmath&gt;using namespace std;const int MAXN = 1e5;int L, D;struct point{ int x; int y; point(int a = 0, int b = 0) { x = a; y = b; }};point points[MAXN];double getp(int a, int b)//在x轴上向右找到距离(a,b)小于等于L的最远的点{ double x = sqrt(pow(D, 2) - pow(b, 2)) + a;//距离等于L的点 if (x &gt;L) return L; return x;}bool judge(point p, int x)//判断p点距离(x,0)是否小于D{ int a = p.x; int b = p.y; double dis =pow(x - a, 2) + pow(b, 2); if (dis &lt;= pow(D, 2)) return true; return false;}bool cmp(point a, point b){ if (a.x == b.x) return a.y &gt; b.y; return a.x &lt; b.x;}int main(){ while (cin &gt;&gt; L) { cin &gt;&gt; D; int N; cin &gt;&gt; N; int cnt = 0; double x; for (int i = 0; i &lt; N; i++) { cin &gt;&gt; points[i].x &gt;&gt; points[i].y; } sort(points, points + N, cmp); cnt++; x = getp(points[0].x, points[0].y); for (int i = 0; i &lt; N; i++) { if (judge(points[i], x)) continue; else { x = getp(points[i].x, points[i].y); cnt++; } } cout &lt;&lt; cnt &lt;&lt; endl; } return 0;} 方法二 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;#include&lt;cmath&gt;using namespace std;const int MAXN = 1e5;int L, D;struct qu{ double l; double r; qu(double x=0, double y=0) { l = x; r = y; }};qu qujian[MAXN];bool cmp(qu a, qu b){ if (a.l == b.l) return a.r &lt; b.r; return a.l &lt; b.l;}int xuandian(int n){ int cnt = 1; double r = qujian[0].r; for (int i = 0; i &lt; n; i++) { if (qujian[i].l &lt;= r) continue; else { r = qujian[i].r; cnt++; } } return cnt;}int main(){ while (cin &gt;&gt; L) { memset(qujian, 0, sizeof(qujian)); int a, b, N; cin &gt;&gt; D &gt;&gt; N; for (int i = 0; i &lt; N; i++) { cin &gt;&gt; a &gt;&gt; b; double r = a + sqrt(pow(D, 2) - pow(b, 2));//右端点 double l = a - sqrt(pow(D, 2) - pow(b, 2));//左端点 qujian[i].l = l; qujian[i].r = r; } sort(qujian, qujian + N, cmp); cout&lt;&lt;xuandian(N)&lt;&lt;endl; } return 0;}","link":"/2021/05/09/UVA1615%20Highway/"},{"title":"UVA1601 The Morning after Halloween","text":"​​点击阅读更多查看文章内容 UVA1601 The Morning after Halloween题目链接 做这道题的时候看到一个写的很好的代码，在这里保存下来，以便以后学习。 题目分析这道题和普通的bfs有所不同，解题方法也有些差别，主要是这里有三个移动的“小鬼”，每个小鬼有五种移动状态（上下左右和不动），最主要的是可以看出在地图上大部分的点都是障碍物，所以可以把所有的空格都提出来建立一张图，而不必每次判断五种方法是否合法，以此来优化算法。 代码解析本题代码中用到的变量较多，为便于理解，先把主要变量的含义解释一下。 x[i] :第i个空格的横坐标y[i] :第i个空格的纵坐标id[i][j] :坐标为(i,j)的空格的编号s[i]:初始小鬼所在空格的编号t[i]:小鬼所要到达的目标位置的空格编号deg[i]:在第i个空格所能走的步数G[i][j]:在第i个空格所能到达的第j个位置的空格编号 注意事项：main函数中最后两个if语句的作用是当小鬼的数量小于三个时，默认多出的小鬼初始位置即为目标位置，且他们只能原地不动。ID函数的作用是将三个变量合成一个变量一次性存到队列中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#define _CRT_SECURE_NO_WARNINGS#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;queue&gt;#include &lt;cstring&gt;using namespace std;int w, h, n, s[3], t[3];char dataset[20][20];int G[200][5], vis[200][200][200], dist[200][200][200];int deg[200];int dx[] = { 0,-1,1,0,0 };int dy[] = { 0,0,0,-1,1 };inline int ID(int a, int b, int c){ return(a &lt;&lt; 16) | (b &lt;&lt; 8) | c;}inline bool conflict(int a, int b, int a2, int b2){ return((a2 == b2) || (a == b2 &amp;&amp; b == a2));}int bfs(){ queue&lt;int&gt;q; q.push(ID(s[0], s[1], s[2])); dist[s[0]][s[1]][s[2]] = 0; while (!q.empty()) { int u = q.front(); q.pop(); int a = (u &gt;&gt; 16) &amp; 0xff; int b = (u &gt;&gt; 8) &amp; 0xff; int c = u &amp; 0xff; if (a == t[0] &amp;&amp; b == t[1] &amp;&amp; c == t[2]) return dist[a][b][c]; for (int i = 0; i &lt; deg[a]; i++) { int a2 = G[a][i]; for (int j = 0; j &lt; deg[b]; j++) { int b2 = G[b][j]; if (conflict(a, b, a2, b2)) continue; for (int k = 0; k &lt; deg[c]; k++) { int c2 = G[c][k]; if (conflict(a, c, a2, c2) || conflict(b, c, b2, c2)) continue; if (dist[a2][b2][c2] == -1) { dist[a2][b2][c2] = dist[a][b][c] + 1; q.push(ID(a2, b2, c2)); } } } } } return -1;}int main(){ while (~scanf(&quot;%d%d%d\\n&quot;, &amp;w, &amp;h, &amp;n) &amp;&amp; n) { for (int i = 0; i &lt; h; i++) fgets(dataset[i], 20, stdin); int cnt = 0, x[200], y[200], id[20][20]; for (int i = 0; i &lt; h; i++) { for (int j = 0; j &lt; w; j++) { if (dataset[i][j] != '#') { x[cnt] = i;//第cnt个空格的横坐标 y[cnt] = j;//第cnt个空格的纵坐标 id[i][j] = cnt;//坐标为(i,j)的空格的编号 if (islower(dataset[i][j])) s[dataset[i][j] - 'a'] = cnt;//初始小鬼位置 else if (isupper(dataset[i][j])) t[dataset[i][j] - 'A'] = cnt;//目标小鬼位置 cnt++; } } } for (int i = 0; i &lt; cnt; i++) { deg[i] = 0;//在第i个空格所能走的步数 for (int j = 0; j &lt; 5; j++) { int nx = x[i] + dx[j]; int ny = y[i] + dy[j]; if (dataset[nx][ny] != '#') G[i][deg[i]++] = id[nx][ny];//第i个空格所能到达的位置编号 } } if (n &lt;= 2) { deg[cnt] = 1; G[cnt][0] = cnt; s[2] = t[2] = cnt++; } if (n &lt;= 1) { deg[cnt] = 1; G[cnt][0] = cnt; s[1] = t[1] = cnt++; } memset(dist, -1, sizeof(dist)); printf(&quot;%d\\n&quot;, bfs()); } return 0;}","link":"/2021/03/22/UVA1601%20The%20Morning%20after%20Halloween/"},{"title":"UVA1616 Caravan Robbers","text":"​​点击阅读更多查看文章内容 UVA1616 Caravan Robbers题目链接 二分+小数转分数 题意：给定n个区间，把它们变成等长的不想交的区间，求区间的最大长度。注意本题精度要求较高，注意浮点数的比较方式。 思路1.二分通过对题目的分析，我们不难发现，所有小于最大长度的数都满足不相交，所有大于最大长度的数都会相交，满足单调性，可以通过二分来求解最大长度。 通过二分来求区间的最大长度，首先选定左端点l=0，右端点r为n各区间中最靠右的点，然后求mid=(r+l)/2,判断此时的mid是否满足各区间不想交，若不满足，则mid应该大于最大长度，向前二分。反之，则mid应该小于等于最大长度，向后二分，最后左端点即为最大长度。 2.小数转分数一共有n个区间，开始时这n个区间的长度都是整数，我们假设最极端的情况这n个区间都在[0,1]中，此时最大长度为1/n，所以分母一共只有1~n这n种情况(这一段是从网上找的，我也没弄明白为什么只有n种情况，有明白的大佬可以在评论区留言讨论一下)。然后枚举分母即可。 AC代码#include&lt;iostream&gt; #include&lt;cstring&gt; #include&lt;cmath&gt; #include&lt;algorithm&gt; using namespace std; const int MAXN = 1e5 + 10; const double eps = 1e-11; struct line { int l, r; line(int a = 0, int b = 0) { l = a; r = b; } bool operator &lt; (const line x) { if (l == x.l) return r &lt; x.r; return l &lt; x.l; } }; int n; line lines[MAXN]; bool judge(long double x) { long double ans = 0;//区间起点 for (int i = 0; i &lt; n; i++) { ans = max(ans, (long double)lines[i].l); ans += x;//区间终点 if (ans - lines[i].r&gt;eps) return false; } return true; } int main() { int maxr = 0; while (cin &gt;&gt; n &amp;&amp; n) { for (int i = 0; i &lt; n; i++) { cin &gt;&gt; lines[i].l &gt;&gt; lines[i].r; maxr = max(maxr, lines[i].r); } sort(lines, lines + n); long double ll = 0, rr = maxr; while (rr - ll &gt; eps) { long double mid = (rr + ll) / 2; if (judge(mid))//如果符合mid可能小于等于最大长度，向后找 ll = mid; else//不符合mid大于最大长度,向前找 rr = mid; } int t, k; for (k = 1; k &lt;= n; k++) { t = ll * k + 0.5; if (fabs((long double)t / k - ll) &lt; eps) break; } cout &lt;&lt; t &lt;&lt; '/' &lt;&lt; k &lt;&lt; endl; } }","link":"/2021/05/12/UVA1616%20Caravan%20Robbers/"},{"title":"UVA1617 Laptop","text":"​​点击阅读更多查看文章内容 UVA1617 Laptop题目链接 题意这里引用紫皮书上的解释 给定n条长度为1的线段，确定它们的起点，使得第i条线段在[ri,di]之间。输入保证ri≤rj，当且仅当di≤dj，且保证有解。输出空隙数目的最小值。 对这个题目有一点疑问，给定的样例中有[1,3]和[0,3]两个区间，假定[1,3]为第i条线段[0,3]为第j条线段，di≤dj，但是ri&gt;dj，不满足题意所述，猜想可能是题目有误（VJ上的题目也是此条件）。 思路一道蛮简单的贪心题，首先按照左端点小的在前排序，若左端点相等，则对右端点小的在前排序，然后尽量靠右选点，维护最右端的点ri。 不难判断，当前所选线段与前一个有空隙的情况只有当前线段的左端点大于ri。此时必定有空隙，只需对当前尽量靠右选点即可。 当没有空隙时，首先判断是否可以选ri右边的点，此时需满足当前线段的右端点大于ri。如果右端点等于ri则将ri前移一个，将ri位置空出来给当前线段使用（不必考虑ri是否可以前移，因为题目中提到必定有解），此时最右端的点仍是之前ri的值，如果右端点小于ri，则当前线段选的点在ri左边，ri仍不变。 AC代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;struct line{ int l, r; line(int a = 0, int b = 0) { l = a; r = b; } bool operator &lt;(const line a) { if (l == a.l) return r &lt; a.r; return l &lt; a.l; }};const int MAXN = 1e5 + 10;int T, N;line lines[MAXN];int main(){ int ri; cin &gt;&gt; T; while (T--) { cin &gt;&gt; N; for (int i = 0; i &lt; N; i++) { cin &gt;&gt; lines[i].l &gt;&gt; lines[i].r; } sort(lines, lines + N); ri = lines[0].r; int cnt = 0; for (int i = 1; i &lt; N; i++) { if (lines[i].l &gt; ri) { cnt++; ri = lines[i].r; continue; } if (lines[i].r &gt; ri) { ri++; continue; } } cout &lt;&lt; cnt &lt;&lt; endl; }}","link":"/2021/05/17/UVA1617%20Laptop/"},{"title":"UVA208 Firetruck","text":"​​点击阅读更多查看文章内容 UVA208 Firetruck题目链接 刚开始做，有些细节掌握的还不太够，代码写的有些繁琐了，主要还是巩固一下思路，大家随便看看就好了。 问题解析这道题理解起来不难，在这里就用紫皮书上的解释输入一个n(n&lt;=20)个结点的无向图以及某个结点k，按照字典序从小到大顺序输出从结点1到结点k的所有路径，要求结点不能重复经过。提示：要事先判断结点1是否可以到达结点k，否则会超时。 代码分析首先用BFS判断是否连通然后用DFS寻找路径即可这里要注意一些实现的小细节1.在s输入1后记得把vis[1]标记为12.字典序输出要先排序3.dfs之后不光要清楚标记，还要把s中刚刚插入的元素删除（因为这个卡了好久）4.输出每行最后一个数字后没有空格 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#define _CRT_SECURE_NO_WARNINGS#include&lt;bits/stdc++.h&gt;using namespace std;const int maxn = 30 + 5;int vis[maxn];vector&lt;int&gt; mp[maxn];int mb;int countt = 0;int cnt = 0;void init(){ memset(vis, 0, sizeof(vis)); for (int i = 0; i &lt; maxn; i++) { mp[i].clear(); } cnt = 0; return;}void dfs(vector&lt;int&gt;s){ int point = s[s.size()-1]; if (point == mb) { cnt++; int j; for ( j = 0; j &lt; s.size()-1; j++) { cout &lt;&lt; s[j] &lt;&lt; &quot; &quot;; } cout &lt;&lt; s[j]; cout &lt;&lt; endl; } for (int t = 0; t &lt; mp[point].size(); t++) { if (vis[mp[point][t]] == 1) continue; s.push_back( mp[point][t]); vis[mp[point][t]] = 1; dfs(s); vis[mp[point][t]] = 0; s.erase(s.end()-1); }}bool bfs() { memset(vis, 0, sizeof(vis)); queue&lt;int&gt; q; q.push(1); vis[1] = 1; while (!q.empty()) { int t = q.front(); q.pop(); vector&lt;int&gt;::iterator it = mp[t].begin(); while (it != mp[t].end()) { if (!vis[*it]) { vis[*it] = 1; if (*it == mb) return true; q.push(*it); } it++; } } return false;}int main(){ int a, b; while (cin &gt;&gt; mb) { vector&lt;int&gt;s; s.push_back(1); init(); while (scanf(&quot;%d%d&quot;, &amp;a, &amp;b) &amp;&amp; (a != 0 || b != 0)) { mp[a].push_back(b); mp[b].push_back(a); } for (int i = 0; i &lt; maxn; i++) { sort(mp[i].begin(), mp[i].end()); } printf(&quot;CASE %d:\\n&quot;, ++countt); if (bfs()) { memset(vis, 0, sizeof(vis)); vis[1] = 1; dfs(s); printf(&quot;There are %d routes from the firestation to streetcorner %d.\\n&quot;, cnt, mb); } else printf(&quot;There are 0 routes from the firestation to streetcorner %d.\\n&quot;, mb); }}","link":"/2021/03/26/UVA208%20Firetruck/"},{"title":"UVA437 The Tower of Babylon","text":"​​点击阅读更多查看文章内容 UVA437 The Tower of Babylon题目链接 动态规划 题目有n(n≤30)种立方体，每种都有无穷多个。要求选一些立方体摞成一根尽量高的柱子(可以自行选择哪一条边作为高)，使得每个立方体的底面长宽分别严格小于它下方立方体的底面长宽。 分析题目中有两句话比较重要，一是每种立方体都有无穷多个，二是可以自行选择哪一条边作为高，所以当输入为n种立方体时，可供我们选择的立方体个数一共是3*n个，每输入一种立方体，对应的就有三种立方体供我们选择（分别以输入的三个数作为高）。然后根据立方体之间能否摞在一起的关系可以建立有向无环图（DAG），利用邻接矩阵存储。最后直接dp，用dp[i]存储从第i个立方体开始最高的高度，最后遍历取得最大值即可。 AC代码#include&lt;iostream&gt; #include&lt;cstring&gt; #include&lt;algorithm&gt; using namespace std; const int MAX = 1000; int n; struct rec { int a, b, h; rec(int x = 0, int y = 0, int z = 0) { a = x; b = y; h = z; } }; rec recs[200]; int t1, t2, t3; int G[200][200]; bool judge(rec x, rec y)//x能否放在y上面 { if ((x.a &lt; y.a &amp;&amp; x.b &lt; y.b) || (x.a &lt; y.b &amp;&amp; x.b &lt; y.a)) return true; return false; } void graph()//如果i能放在j上面则G[i][j]=1 { memset(G, 0, sizeof(G)); for (int i = 0; i &lt; 3 * n; i++) { for (int j = 0; j &lt; 3 * n; j++) { if (judge(recs[i], recs[j])) G[i][j] = 1; } } } int dp[200]; int d(int i) { if (dp[i] &gt; 0) return dp[i]; dp[i] = recs[i].h; for (int j = 0; j &lt; 3 * n; j++) { if (G[j][i]) dp[i] = max(dp[i], d(j) + recs[i].h); } return dp[i]; } int main() { int kase = 0; while (cin &gt;&gt; n &amp;&amp; n) { for (int i = 0; i &lt; n; i++) { cin &gt;&gt; t1 &gt;&gt; t2 &gt;&gt; t3; recs[3 * i].a = t1; recs[3 * i].b = t2; recs[3 * i].h = t3; recs[3 * i + 1].a = t2; recs[3 * i + 1].b = t3; recs[3 * i + 1].h = t1; recs[3 * i + 2].a = t3; recs[3 * i + 2].b = t1; recs[3 * i + 2].h = t2; } graph(); memset(dp, 0, sizeof(dp)); int ans = 0; for (int t = 0; t &lt; 3 * n; t++) { ans = max(ans, d(t)); } printf(&quot;Case %d: maximum height = %d\\n&quot;, ++kase, ans); } }","link":"/2021/05/22/UVA437%20The%20Tower%20of%20Babylon/"},{"title":"UVA548 紫皮书代码解析","text":"​​点击阅读更多查看文章内容 UVA548 紫皮书代码解析刚开始接触二叉树，这道例题的代码花了好长时间才看懂，在这里写一篇关于这个代码的解析，希望能给大家提供一点帮助。 先给出题目中所给三组数据对应的二叉树3 2 1 4 5 7 63 1 2 5 6 7 47 8 11 3 5 16 12 188 3 11 7 16 18 12 5255255 说明一下代码主要变量的含义in_order[maxv]，按输入顺序存储中序遍历的结果。post_order[maxv]，按输入顺序存储后序遍历的结果。lch[maxv],rch[maxv]，这两个数组直接用权值做标号，分别表示对应点的左右两点。例如：lch[7]=0(7没有左子树),rch[7]=11。 解释一下主要函数的运行原理先贴代码 123456789101112bool read_list(int* a){ string line; if (!getline(cin, line)) return false; stringstream ss(line); n = 0; int x; while (ss &gt;&gt; x) a[n++] = x; return n &gt; 0;} 作用：读入输入的一行数组，将其存入a数组中。原理：先将输入的字符串（“3 2 1 4 5 7 6”），存入ss中，然后由stringstream将每个数字单独分出来存入a数组中（这里不懂的可以查一下stringstream分割带空格的字符串）。 12345678910111213int build(int L1, int R1, int L2, int R2){ if (L1 &gt; R1) return 0; int root = post_order[R2]; int p = L1; while (in_order[p] != root) p++; int cnt = p - L1; lch[root] = build(L1, p - 1, L2, L2 + cnt - 1); rch[root] = build(p + 1, R1, L2 + cnt, R2 - 1); return root;} 作用：将存在in_order和post_order中的两组数组建成一棵二叉树，用lch和rch保存。变量含义：L1:中序遍历的第一个数。R1:中序遍历的最后一个数。L2:后序遍历的第一个数。R2:后序遍历的最后一个数。原理：这里使用递归的原理进行建树，首先第一行给出终止条件，找到根节点所在位置（后序遍历的最后一个数），然后找出左右子树的结点个数，然后建立当前根节点的左右子树。 1234567891011121314151617void dfs(int u, int sum){ sum += u; if (!lch[u] &amp;&amp; !rch[u]) { if (sum &lt; best_sum || (sum == best_sum &amp;&amp; u &lt; best)) { best = u; best_sum = sum; } } if (lch[u]) dfs(lch[u], sum); if (rch[u]) dfs(rch[u], sum);} 作用：根据已经建好的二叉树，求出最优解和对应的权和。原理：用dfs从上往下进行搜索，先从根节点开始依次向下加和，u为当前加和的结点，如果该节点为叶子结点，代表当前的和已加完，判断是不是最优解。如果该节点不是叶子结点则继续向下加，直到叶子结点为止。（可以认为，每执行一次dfs就加上一个结点） 下面贴上全部代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include&lt;iostream&gt;#include&lt;sstream&gt;#include&lt;string&gt;#include&lt;algorithm&gt;using namespace std;const int maxv = 10000 + 10;int in_order[maxv], post_order[maxv], lch[maxv], rch[maxv];int n;bool read_list(int* a){ string line; if (!getline(cin, line)) return false; stringstream ss(line); n = 0; int x; while (ss &gt;&gt; x) a[n++] = x; return n &gt; 0;}int build(int L1, int R1, int L2, int R2){ if (L1 &gt; R1) return 0; int root = post_order[R2]; int p = L1; while (in_order[p] != root) p++; int cnt = p - L1; lch[root] = build(L1, p - 1, L2, L2 + cnt - 1); rch[root] = build(p + 1, R1, L2 + cnt, R2 - 1); return root;}int best, best_sum;void dfs(int u, int sum){ sum += u; if (!lch[u] &amp;&amp; !rch[u]) { if (sum &lt; best_sum || (sum == best_sum &amp;&amp; u &lt; best)) { best = u; best_sum = sum; } } if (lch[u]) dfs(lch[u], sum); if (rch[u]) dfs(rch[u], sum);}int main(){ while (read_list(in_order)) { read_list(post_order); build(0, n - 1, 0, n - 1); best_sum = 1000000000; dfs(post_order[n - 1], 0); cout &lt;&lt; best &lt;&lt; &quot;\\n&quot;; } return 0;} 这里build函数的递归建树理解起来可能比较困难，可以自己代入数组debug一遍。如果大家还有不太懂的地方，可以在评论区留言交流一下。","link":"/2021/03/04/UVA548%20%E7%B4%AB%E7%9A%AE%E4%B9%A6%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/"},{"title":"fabric网络搭建","text":"​​点击阅读更多查看文章内容 通用命令进入终端1docker exec -it cli1 bash进入终端2docker exec -it cli2 bash退出终端exit 关闭网络并清除配置docker-compose down -v 命令执行顺序通道操作创建通道peer channel create -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/channel.tx --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/msp/tlscacerts/tlsca.example.com-cert.pem cli1加入通道peer channel join -b mychannel.block 将区块文件复制到cli2exit docker cp cli1:/opt/gopath/src/github.com/hyperledger/fabric/peer/mychannel.block ./ docker cp ./mychannel.block cli2:/opt/gopath/src/github.com/hyperledger/fabric/peer cli2加入通道peer channel join -b mychannel.block 设置锚节点组织1peer channel update -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/Org1MSPanchors.tx --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem组织2peer channel update -o orderer.example.com:7050 -c mychannel -f ./channel-artifacts/Org2MSPanchors.tx --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 链码操作首先从fabric-samples中复制一个链码到chaincode/go目录下以便测试exitcd /home/haonan/hyperledger/fabric-samples/chaincode/sacccp sacc.go /home/haonan/twonodes/chaincode/go/ 回到工作目录，进入终端cd /home/haonan/twonodes/chaincode/go/docker exec -it cli1 bash 移动到链码路径cd /opt/gopath/src/github.com/hyperledger/fabric-cluster/chaincode/go 配置go语言环境go env -w GOPROXY=https://goproxy.cn,directgo mod initgo mod vendor 返回工作目录cd /opt/gopath/src/github.com/hyperledger/fabric/peer/ 打包链码peer lifecycle chaincode package sacc.tar.gz --path /opt/gopath/src/github.com/hyperledger/fabric-cluster/chaincode/go/ --label sacc_1 将打包链码复制到cli2exit docker cp cli1:/opt/gopath/src/github.com/hyperledger/fabric/peer/sacc.tar.gz ./ docker cp sacc.tar.gz cli2:/opt/gopath/src/github.com/hyperledger/fabric/peer 安装链码（两组织都需要）peer lifecycle chaincode install sacc.tar.gz 组织批准链码（两组织都需要）注意这里的package-id是安装链码时最后出现的id，每个人都不同需要更改为自己的idpeer lifecycle chaincode approveformyorg --channelID mychannel --name sacc --version 1.0 --init-required --package-id sacc_1:614c42c332c76568f8d4e839bd77a3b319796003f4e526c10aa907628fe5c541 --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 查看组织是否批准peer lifecycle chaincode checkcommitreadiness --channelID mychannel --name sacc --version 1.0 --init-required --sequence 1 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --output json 提交commit（单个组织提交即可）peer lifecycle chaincode commit -o orderer.example.com:7050 --channelID mychannel --name sacc --version 1.0 --sequence 1 --init-required --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses peer0.org2.example.com:9051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt cli1链码调用peer chaincode invoke -o orderer.example.com:7050 --isInit --ordererTLSHostnameOverride orderer.example.com --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses peer0.org2.example.com:9051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c '{&quot;Args&quot;:[&quot;a&quot;,&quot;bb&quot;]}' cli2链码查询peer chaincode query -C mychannel -n sacc -c '{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}' cli2再次调用peer chaincode invoke -o orderer.example.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n sacc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses peer0.org2.example.com:9051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c '{&quot;Args&quot;:[&quot;set&quot;,&quot;a&quot;,&quot;cc&quot;]}' cli1链码查询peer chaincode query -C mychannel -n sacc -c '{&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]}' 区块链浏览器首先启动上面搭建的区块链网络 随后启动区块链浏览器，移动到testbe目录下docker-compose up -d","link":"/2022/11/12/fabric%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA/"},{"title":"【CSS】CSS基础知识","text":"点击阅读更多查看文章内容 CSS：Cascading Style Sheets 层叠式样式表 原始示例代码： 123456789101112131415161718&lt;div&gt; &lt;div&gt;租辆酷车&lt;/div&gt; &lt;div&gt;css教学&lt;/div&gt;&lt;/div&gt;&lt;div&gt; &lt;div&gt; &lt;div&gt;中关村到天安门&lt;/div&gt; &lt;div&gt;价格: 120元&lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div&gt;陆家嘴到迪士尼&lt;/div&gt; &lt;div&gt;价格: 50元&lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div&gt;天河体育中心到广州塔&lt;/div&gt; &lt;div&gt;价格: 80元&lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 在代码后添加如下片段即可修改所有div元素的字体 12345&lt;style&gt; div{ font-size: xx-large; }&lt;/style&gt; 选择器 element直接选择全部的元素如：div，选择所有的div元素 #id 选择某一id的元素如：#title，选择id为title的元素 .class选择包含某个class的部分元素如：.item，选择class为item的元素（以下三个全选）.item 选择class包含item的元素（以下三个全选） 同时满足 .item.blue 选择class为item及blue的元素，中间无空格（1和3）div.blue 选择class为blue的div元素（1和3） 父子关系中间加上空格.item div 选择class为item的元素的所有div子元素（不只是第一层儿子是所有的子元素）.item &gt;div 添加&gt;选择class为item的元素的第一层div子元素 宽高 height/width：设置高度/宽度，可以设置数值也可以设置百分比（相对于父元素大小的百分比，若父元素没有设置高度，则相对于父元素的父元素设置） 宽度默认填满页面，父元素高度默认为子元素高度之和（display: block;） overflow（当父元素高度小于子元素高度之和时） hidden：隐藏多余元素 scroll：添加滚动条 缩进margin：边框到父元素的距离border：元素的边框宽度padding：元素到边框的距离 元素高度 = height + padding-top + padding-bottom + 2 * border（上下两个边框） 元素宽度 = width + padding-left + padding-right + 2 * border 如下示例 margin-left: 50px; 左边界与父元素的距离border: 2px solid; 元素边界宽度padding-left: 50px 元素与左边界距离height: 100px;元素高度padding-top: 50px; 元素与上边界距离margin-top: 50px; 上边界与父元素的距离 元素高度为 height + padding-top + 2 * border = 154元素宽度为 width + padding-left + 2 * border = 510 Ps：这里的width没有设置，是根据子元素得来的 box-sizing: border-box设置之后元素的高度/宽度直接等于height/width对元素本身的高度进行调整以使得最终高度等于height，默认情况的宽高只针对元素本身，最终宽高还要加上padding和border 位置top\\bottom\\left\\right 与 position 组合使用 position relative：原位置不会被顶替，相对于原位置进行位移 absolute：原位置会被顶替，相对于页面进行位移，会因为滚动条而滚出页面 fixed：原位置会被顶替，相对于页面进行位移，不会因为滚动条而滚出页面，始终固定在同一位置 将父元素设置为position:relative，子元素设置为position:absolute，可以将子元素相对父元素设置 小练习：在陆家嘴到迪士尼的右上角添加一个小方框 在陆家嘴中新建一个div，class设置为star 将陆家嘴position设置为relative 设置star大小和颜色 将star的positon设置为absolute使其飘在上面而不占据空间 将right和top设置为0就移动到右上角了 .item { border: 2px solid; position: relative; } .star { width: 20px; height: 20px; background-color: red; position: absolute; right: 0px; top: 0px; } 文本样式font-size：设置大小font-family：设置字体font-style：设置斜体font-weight：设置粗体color：设置颜色text-align：文字对齐 折行默认情况超宽换行 white-space:nowrap：超出宽度不换行 overflow:hidden：超出部分隐藏 （与前一个结合使用） text-overflow:ellipsis：超出部分省略号截断（与前两个结合使用） word-break：英文换行按照字母/单词 flex布局flex是一种布局方法 display（设置flex） flex 设置为flex布局 flex-direction （确定flex方向） column 竖向排列 column-reverse 反向竖排 row 横向排列（默认） row-reverse 反向横排 以竖排为例 align-items 设置横向的对齐（垂直于排列方向，若元素横向排列则设置纵向对齐） stretch 横向拉伸填满 center 横向居中 justify-content 设置竖向的对齐 flex-end：竖向末尾 (与flex-direction配合，如果flex-direction为reverse那么flex-end就是开头) flex-start：竖向开头 space-around 元素之间的距离为上下距离的二倍 space-between 上下距离为零元素之间距离相等 space-evenly 上下及元素之间的距离都相等 flex可以嵌套使用 align-item：设置内部元素的对齐 align-self：设置自身的对齐 小程序微信小程序中的大小使用rpx相对像素不管机型大小，宽度都是750rpx（高度750rpx，宽度100%，在任何机型上都是正方形，高度可能不同） rpx最初是根据iphone6来的，750rpx对应750/2=375像素","link":"/2022/12/27/%E3%80%90CSS%E3%80%91CSS%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"title":"【Golang】Golang格式化输出","text":"​​点击阅读更多查看文章内容 fmtGo语言用于控制文本输出常用的标准库是fmt fmt中主要用于输出的函数有: Print: 输出到控制台，不接受任何格式化操作 Println: 输出到控制台并换行 Printf: 格式化输出，只可以打印出格式化的字符串，只可以直接输出字符串类型的变量（不可以直接输出别的类型） Sprintf: 格式化并返回一个字符串而不带任何输出 Fprintf: 来格式化并输出到io.Writers而不是os.Stdout 格式化通过Printf函数来测试下Go语言里面的字符串格式化: 1fmt.Sprintf(格式化样式, 参数列表…) 格式样式: 字符串形式，格式化符号以%开头，%s字符串格式，%d十进制的整数格式 参数列表: 多个参数以逗号分隔，个数必须与格式化样式中的个数一一对应，否则运行时会报错 比如: 12username := &quot;boy&quot;fmt.Printf(&quot;welcome, %s&quot;, username) 整数格式化 占 位 符 描 述 %b 整数以二进制方式显示 %o 整数以八进制方式显示 %d 整数以十进制方式显示 %x 整数以十六进制方式显示 %X 整数以十六进制、字母大写方式显示 %c 相应Unicode码点所表示的字符 %U Unicode字符，Unicode格式：123，等同于“U+007B” 123456789func main() { fmt.Printf(&quot;%b \\n&quot;, 123) //1111011 fmt.Printf(&quot;%o \\n&quot;, 123) //173 fmt.Printf(&quot;%d \\n&quot;, 123) //123 fmt.Printf(&quot;%x \\n&quot;, 123) //7b fmt.Printf(&quot;%X \\n&quot;, 123) //7B fmt.Printf(&quot;%c \\n&quot;, 123) //{ fmt.Printf(&quot;%U \\n&quot;, 123) //U+007B } 浮点数格式化 占 位 符 描 述 %e 科学计数法，例如 1.234560e+02 %E 科学计数法，例如 1.234560E+02 %f 有小数点而无指数，例如 123.456 %F 等价于%f %g 根据情况选择 %e 或 %f 以产生更紧凑的（无末尾的0）输出 %G 根据情况选择 %E 或 %F 以产生更紧凑的（无末尾的0）输出 12345678func main() { fmt.Printf(&quot;%e \\n&quot;, 123.456) //1.234560e+02 fmt.Printf(&quot;%E \\n&quot;, 123.456) //1.234560E+02 fmt.Printf(&quot;%f \\n&quot;, 123.456) //123.456000 fmt.Printf(&quot;%F \\n&quot;, 123.456) //123.456000 fmt.Printf(&quot;%g \\n&quot;, 123.456) //123.456 fmt.Printf(&quot;%G \\n&quot;, 123.456) //123.456 } 布尔类型格式化 占 位 符 描 述 %t true 或 false 123func main() { fmt.Printf(&quot;%t&quot;, true) //true} 字符格式化 占 位 符 描 述 %c 相应Unicode码点所表示的字符 123func main() { fmt.Printf(&quot;%c&quot;, 0x4E2D) //中} 字符串格式化 占 位 符 描 述 %s 直接输出字符串或者[]byte %q 双引号围绕的字符串，由Go语法安全地转义 %x 每个字节用两字符十六进制数表示（使用a-f） %X 每个字节用两字符十六进制数表示（使用A-F） 123456func main() { fmt.Printf(&quot;%s \\n&quot;, &quot;Hello world&quot;) //Hello world fmt.Printf(&quot;%q \\n&quot;, &quot;Hello world&quot;) //&quot;Hello world&quot; fmt.Printf(&quot;%x \\n&quot;, &quot;Hello world&quot;) //48656c6c6f20776f726c64 fmt.Printf(&quot;%X \\n&quot;, &quot;Hello world&quot;) //48656C6C6F20776F726C64} 指针格式化 占 位 符 描 述 %p 表示为十六进制，并加上前导的0x %#p 表示为十六进制，没有前导的0x 123456func main() { a := &quot;Hello world&quot; b := &amp;a fmt.Printf(&quot;%p \\n&quot;, b) //0xc000046230 fmt.Printf(&quot;%#p \\n&quot;, b) //c000046230} 通用占位符 占 位 符 描 述 %v 值的默认格式 %+v 类似%v，但输出结构体时会添加字段名 %#v 相应值的Go语法表示 %T 相应值的类型的Go语法表示 %% 百分号,字面上的%,非占位符含义 1234567func main() { fmt.Printf(&quot;%v \\n&quot;, &quot;Hello World&quot;) //Hello World fmt.Printf(&quot;%+v \\n&quot;, &quot;Hello World&quot;) //Hello World fmt.Printf(&quot;%#v \\n&quot;, &quot;Hello World&quot;) //&quot;Hello World&quot; fmt.Printf(&quot;%T \\n&quot;, &quot;Hello World&quot;) //string fmt.Printf(&quot;%%%v \\n&quot;, &quot;Hello World&quot;) //%Hello World} 宽度表示浮点数精度控制宽度通过一个紧跟在百分号后面的十进制数指定，如果未指定宽度，则表示值时除必需之外不作填充。精度通过（可选的）宽度后跟点号后跟的十进制数指定。如果未指定精度，会使用默认精度；如果点号后没有跟数字，表示精度为0。举例如下 1234567func main() { fmt.Printf(&quot;|%f|\\n&quot;, 123.456) //|123.456000| fmt.Printf(&quot;|%12f|\\n&quot;, 123.456) //| 123.456000| fmt.Printf(&quot;|%.3f|\\n&quot;, 123.456) //|123.456| fmt.Printf(&quot;|%12.3f|\\n&quot;, 123.456) //| 123.456| fmt.Printf(&quot;|%12.f|\\n&quot;, 123.456) //| 123|} 字符串长度控制 宽度设置格式：占位符中间加一个数字, 数字分正负, +: 右对齐, -: 左对齐最小宽度：百分号后紧跟十进制数，不够部分可以选择补0最大宽度：小数点后的十进制数，超出的部分会被截断 1234567func main() { fmt.Printf(&quot;|%s|\\n&quot;, &quot;123.456&quot;) //|123.456| fmt.Printf(&quot;|%12s|\\n&quot;, &quot;123.456&quot;) //| 123.456| fmt.Printf(&quot;|%-12s|\\n&quot;, &quot;123.456&quot;) //|123.456 | fmt.Printf(&quot;|%012s|\\n&quot;, &quot;123.456&quot;) //|00000123.456| fmt.Printf(&quot;|%.5s|\\n&quot;, &quot;123.456&quot;) //|123.4|}","link":"/2022/11/16/%E3%80%90Golang%E3%80%91Golang%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA/"},{"title":"【Golang】切片的底层实现（关于slice调用append函数后分配新数组的问题）","text":"​​点击阅读更多查看文章内容 问题描述今天在写代码的时候遇到一个很奇怪的现象，先看下面两段代码 123456789func push(a []int, v int) { a[1] = 2 a = append(a, v)}func main() { a := []int{0, 1, 2} push(a, 3) fmt.Println(a)} 结果：[0 2 2] 123456789func push(a []int, v int) { a = append(a, v) a[1] = 2}func main() { a := []int{0, 1, 2} push(a, 3) fmt.Println(a)} 结果：[0 1 2] 乍一看这两段代码几乎一模一样，唯一的不同在于push函数中两行代码的顺序不一致 这两段代码中有两个问题 为什么第一段代码中赋值语句起到作用，append没有起到作用 为什么第二段代码中的赋值语句和append都没有起到作用 问题分析第一个问题：为什么第一段代码中赋值语句起到作用，append没有起到作用首先我们要清楚Go语言中不存在引用传递，即这里的a []int是值传递，我们不妨输出一下a的地址 可以看到函数内外的a并不是同一个切片，那么既然不是同一个切片，为什么在第一段代码中，修改了函数内的a，函数外的a也会发生改变呢？ 这里我们需要了解go语言中切片是如何实现的 可以看下图，go语言中的切片实际上是对底层数组的一个view切片由三部分组成，分别是指向底层数组的指针ptr，切片的长度len，底层数组的长度cap由此就可以解释为何在第一段代码中修改函数内的切片，函数外的切片也会发生改变，两个切片虽然地址不同，但是它们两个的值是相同的，也就是说它们两个内部的ptr是相同的都指向同一个底层数组，所以修改其中一个，另外一个也就会随之改变。同理，在函数内append时，函数内部的切片len增加了，但由于是值传递，所以函数外部的切片len没有改变，因此函数内部的切片append不会引起函数外部的切片改变。 第二个问题：为什么第二段代码中的赋值语句和append都没有起到作用首先关于append为什么没有起到作用，在上面已经解释过了，这里我们重点关注为什么赋值语句也没有起到作用 原因只有一句话：切片在添加元素时如果超越cap，那么就不再是对原数组的view，系统会重新分配更大的底层数组 继续分析之前的代码，在输出地址的基础上再输出切片的len和cap 可以看到，在执行append之前，切片的len等于cap，执行append后，切片的长度会超过cap，此时系统会重新分配更大的数组。观察输出可以发现，执行完append后切片的cap发生了变化，与我们的设想一致，系统重新分配了一个更大的数组给切片，切片的ptr指针指向了另一个数组，与函数外的切片不再指向同一个数组，因此在函数内修改切片的值的时候对函数外的切片就不会产生影响了 更进一步，我们将切片赋予一个较大的cap，使函数内的切片再执行append后len不会超过cap，观察此时的函数外的切片是否会发生变化 可以看到此时函数内的赋值语句成功修改了函数外的切片的值，因为此时函数内的切片执行append后，切片的len没有超过cap，并不会分配新数组，因此后面再执行赋值语句时修改的还是函数外的数组","link":"/2022/12/09/%E3%80%90Golang%E3%80%91%E5%88%87%E7%89%87%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%EF%BC%88%E5%85%B3%E4%BA%8Eslice%E8%B0%83%E7%94%A8append%E5%87%BD%E6%95%B0%E5%90%8E%E5%88%86%E9%85%8D%E6%96%B0%E6%95%B0%E7%BB%84%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%89/"},{"title":"【Go】slice切片详解","text":"​点击阅读更多查看文章内容 切片详解切片的实现Go 中的切片本质上是一个结构体，包含以下三个部分： 指向底层数组的指针（array）：切片指向一个底层数组，数组中存储着切片的数据。 切片的长度（len）：切片中当前元素的个数。 切片的容量（cap）：底层数组的总容量，即底层数组能够存储的元素个数。 12345type slice struct { array unsafe.Pointer len int cap int} 切片的扩容 切片在添加元素（如append操作）时，如果切片的长度大于容量，那么会重新分配一个新的容量更大的底层数组来存储新切片 切片在初始化的时候长度等于容量，当向切片添加元素时切片的长度就会大于容量，此时就会为其分配一个新的底层数组 12345678910111213func main() { t := []int{1, 2, 3} fmt.Println(cap(t)) fmt.Printf(&quot;%p\\n&quot;, t) t = append(t, 1) fmt.Println(cap(t)) fmt.Printf(&quot;%p\\n&quot;, t) //3 //0xc0000120a8 //6 //0xc00000c360} 在该示例中，初始化切片的长度为3，容量也为3，切片的底层数组的地址为0xc0000120a8，当向其添加一个元素后，切片的容量为6，并指向了一个新的地址0xc00000c360 Tips：使用 fmt.Printf(&quot;%p\\n&quot;, t) 获得的是切片指向的底层数组的地址与 fmt.Printf(&quot;%p\\n&quot;, unsafe.Pointer(&amp;t[0])) 的值相同，使用 fmt.Printf(&quot;%p\\n&quot;, &amp;t) 获得的是切片变量本身的地址 我们可以使用make()创建一个容量大于长度的切片，这样在向切片添加元素时，长度就不会超过容量，就不会分配新的数组 12345678910111213141516func main() { t := make([]int, 3, 5) fmt.Println(len(t)) fmt.Println(cap(t)) fmt.Printf(&quot;%p\\n&quot;, t) t = append(t, 1) fmt.Println(cap(t)) fmt.Printf(&quot;%p\\n&quot;, t) //3 //5 //0xc00000c360 //5 //0xc00000c360} 在该示例中，我们使用make([]int, 3, 5)创建了一个长度为3，容量为5的切片，随后我们向其添加了一个元素，长度为4没有超过容量，此时底层数组的地址与添加元素前的地址一致，并没有分配新的数组。 切片扩容的实现在第一个示例中，当我们向一个容量为3的切片添加一个元素后，新分配的切片容量为6，这个是如何得出的呢？ 切片扩容的代码为 growslice： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110func growslice(oldPtr unsafe.Pointer, newLen, oldCap, num int, et *_type) slice { oldLen := newLen - num if raceenabled { callerpc := getcallerpc() racereadrangepc(oldPtr, uintptr(oldLen*int(et.Size_)), callerpc, abi.FuncPCABIInternal(growslice)) } if msanenabled { msanread(oldPtr, uintptr(oldLen*int(et.Size_))) } if asanenabled { asanread(oldPtr, uintptr(oldLen*int(et.Size_))) } if newLen &lt; 0 { panic(errorString(&quot;growslice: len out of range&quot;)) } if et.Size_ == 0 { // append should not create a slice with nil pointer but non-zero len. // We assume that append doesn't need to preserve oldPtr in this case. return slice{unsafe.Pointer(&amp;zerobase), newLen, newLen} } newcap := nextslicecap(newLen, oldCap) var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.Size. // For 1 we don't need any division/multiplication. // For goarch.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. noscan := !et.Pointers() switch { case et.Size_ == 1: lenmem = uintptr(oldLen) newlenmem = uintptr(newLen) capmem = roundupsize(uintptr(newcap), noscan) overflow = uintptr(newcap) &gt; maxAlloc newcap = int(capmem) case et.Size_ == goarch.PtrSize: lenmem = uintptr(oldLen) * goarch.PtrSize newlenmem = uintptr(newLen) * goarch.PtrSize capmem = roundupsize(uintptr(newcap)*goarch.PtrSize, noscan) overflow = uintptr(newcap) &gt; maxAlloc/goarch.PtrSize newcap = int(capmem / goarch.PtrSize) case isPowerOfTwo(et.Size_): var shift uintptr if goarch.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.TrailingZeros64(uint64(et.Size_))) &amp; 63 } else { shift = uintptr(sys.TrailingZeros32(uint32(et.Size_))) &amp; 31 } lenmem = uintptr(oldLen) &lt;&lt; shift newlenmem = uintptr(newLen) &lt;&lt; shift capmem = roundupsize(uintptr(newcap)&lt;&lt;shift, noscan) overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift) newcap = int(capmem &gt;&gt; shift) capmem = uintptr(newcap) &lt;&lt; shift default: lenmem = uintptr(oldLen) * et.Size_ newlenmem = uintptr(newLen) * et.Size_ capmem, overflow = math.MulUintptr(et.Size_, uintptr(newcap)) capmem = roundupsize(capmem, noscan) newcap = int(capmem / et.Size_) capmem = uintptr(newcap) * et.Size_ } // The check of overflow in addition to capmem &gt; maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // type T [1&lt;&lt;27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d) // print(len(s), &quot;\\n&quot;) // } if overflow || capmem &gt; maxAlloc { panic(errorString(&quot;growslice: len out of range&quot;)) } var p unsafe.Pointer if !et.Pointers() { p = mallocgc(capmem, nil, false) // The append() that calls growslice is going to overwrite from oldLen to newLen. // Only clear the part that will not be overwritten. // The reflect_growslice() that calls growslice will manually clear // the region not cleared here. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can't use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) if lenmem &gt; 0 &amp;&amp; writeBarrier.enabled { // Only shade the pointers in oldPtr since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. // // It's safe to pass a type to this function as an optimization because // from and to only ever refer to memory representing whole values of // type et. See the comment on bulkBarrierPreWrite. bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(oldPtr), lenmem-et.Size_+et.PtrBytes, et) } } memmove(p, oldPtr, lenmem) return slice{p, newLen, newcap}} oldPtr unsafe.Pointer：指向当前切片的底层数组的指针。 newLen int：扩展后的切片的目标长度。 oldCap int：当前切片的容量。 num int：额外需要的空间量，通常用于处理切片扩容时的新数据量。 et *_type：元素的类型，用来确定切片元素的大小和是否是指针类型（如 int、*struct）。 首先处理一些边界条件，随后调用nextslicecap方法计算新切片的容量，具体细节如下 123456789101112131415161718192021222324252627282930313233func nextslicecap(newLen, oldCap int) int { newcap := oldCap doublecap := newcap + newcap if newLen &gt; doublecap { return newLen } const threshold = 256 if oldCap &lt; threshold { return doublecap } for { // Transition from growing 2x for small slices // to growing 1.25x for large slices. This formula // gives a smooth-ish transition between the two. newcap += (newcap + 3*threshold) &gt;&gt; 2 // We need to check `newcap &gt;= newLen` and whether `newcap` overflowed. // newLen is guaranteed to be larger than zero, hence // when newcap overflows then `uint(newcap) &gt; uint(newLen)`. // This allows to check for both with the same comparison. if uint(newcap) &gt;= uint(newLen) { break } } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 { return newLen } return newcap} 注意，以上计算出的容量并不是新切片最终的容量，在接下来的33行的switch中，还会进行一些内存管理的操作，因为内存都是成块分配的，所以实际分配的容量可能会由于内存对齐等原因大于nextslicecap计算出的newcap； 最后使用mallogc分配实际的内存大小capmem 切片传参go语言中只有值传递，没有引用传递，也就是说任何变量在传递时都会复制一份副本 12345678910111213141516func main() { t := []int{1, 2, 3} fmt.Printf(&quot;slice array address: %p\\n&quot;, t) fmt.Printf(&quot;slice address: %p\\n&quot;, &amp;t) test(t) //slice array address: 0xc0000120a8 //slice address: 0xc000008030 //slice array address(in function): 0xc0000120a8 //slice address(in function): 0xc000008060}func test(t []int) { fmt.Printf(&quot;slice array address(in function): %p\\n&quot;, t) fmt.Printf(&quot;slice address(in function): %p\\n&quot;, &amp;t)} 以上示例可以看到函数内外的切片地址并不相同，但是他们指向的底层数组是相同的，这符合值传递的特征。 这里我们在结合之前提到的切片扩容进行分析 12345678910111213141516func main() { t := []int{1, 2, 3} fmt.Printf(&quot;%p\\n&quot;, t) test(t) fmt.Printf(&quot;%p\\n&quot;, t) //0xc0000120a8 //0xc0000120a8 //0xc00000c360 //0xc0000120a8}func test(t []int) { fmt.Printf(&quot;%p\\n&quot;, t) t = append(t, 1) fmt.Printf(&quot;%p\\n&quot;, t)} 以上示例中，方法中接收的切片在开始时与原始切片指向同一个数组，但是在添加一个元素后，切片的容量超过了长度，此时为方法内的切片分配了一个新的底层数组，但是由于是值传递，两个切片本身指向不同的地址，所以方法外的切片的数组并没有改变。 12345678910111213141516func main() { t := make([]int, 3, 10) fmt.Printf(&quot;%p\\n&quot;, t) test(t) fmt.Printf(&quot;%p\\n&quot;, t) //0xc000014140 //0xc000014140 //0xc000014140 //0xc000014140}func test(t []int) { fmt.Printf(&quot;%p\\n&quot;, t) t = append(t, 1) fmt.Printf(&quot;%p\\n&quot;, t)} 以上示例中切片的容量足够，所以不会分配新的数组，但是要注意的是虽然没有分配新的数组，但是切片的长度发生了改变。 123456789101112func main() { t := make([]int, 3, 10) test(t) fmt.Println(t) //[0 0 0 1] //[0 0 0]}func test(t []int) { t = append(t, 1) fmt.Println(t)} 以上示例可以看出，在函数内外输出的切片并不一致，这是因为值传递，函数内的切片的长度发生了改变并不会改变函数外的切片长度 12345678910111213141516func main() { t := make([]int, 3, 10) test(t) fmt.Println(t) newt := t[0:4] fmt.Println(newt) //[0 0 0 1] //[0 0 0] //[0 0 0 1]}func test(t []int) { t = append(t, 1) fmt.Println(t)} 这里我们通过将t赋值给一个新的切片来取出它的第4个元素可以看到与函数内的修改一致，证明他们确实是同一个底层数组，注意这里不能通过下标的方式直接取值会报越界错误。","link":"/2024/11/28/%E3%80%90Go%E3%80%91%20slice%E5%88%87%E7%89%87%E8%AF%A6%E8%A7%A3/"},{"title":"【Go】字符串遍历数据类型问题","text":"​点击阅读更多查看文章内容 字符串遍历问题在使用for i,v:=range str遍历字符串时 str[i]是unit8（byte）类型，返回的是单个字节字符串在Go中是以字节序列的形式存储的，而 str[i] 直接访问了这个字节序列中的第 i 个字节。如果字符串中的字符是单字节的ASCII字符，那么 s[i] 就足以表示该字符。但是，如果字符是多字节的Unicode字符，那么 s[i] 就只是该字符的第一个字节，而不是整个字符。 v是int32（rune）类型，返回的是字符的unicode编码 123456789101112func main() { str := &quot;hello,world!你好，世界！&quot; for i, _ := range str { fmt.Print(str[i], &quot; &quot;) } //104 101 108 108 111 44 119 111 114 108 100 33 228 229 239 228 231 239 fmt.Println() for _, v := range str { fmt.Print(v, &quot; &quot;) } //104 101 108 108 111 44 119 111 114 108 100 33 20320 22909 65292 19990 30028 65281}","link":"/2024/07/09/%E3%80%90Go%E3%80%91%20%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%81%8D%E5%8E%86%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E9%97%AE%E9%A2%98/"},{"title":"【Go语言例题】迷宫的广度优先搜索","text":"​​点击阅读更多查看文章内容 【Go语言例题】迷宫的广度优先搜索 用循环创建二维slice 使用slice来实现队列 用Fscanf读取文件 对Point的抽象 Fscanf在遇到\\n才结束遇到\\r时就会把\\r替换成0这就有个问题，要注意自己的文本换行符是什么，在Windows下就是\\r\\n，在Linux,Mac下就是\\n，也就是说这里有个坑，代码在Linux和Mac下读取数据文件是正常的，在Windows下就会遇到各种行末尾有个0，可以使用自带IDE将打开的数据文件集换行符改成LF（Linux,Mac换行符）即可 广度优先搜索可以求得最短路径，深度优先搜索无法求得 例题：只能上下左右前进，1的位置是墙不能走，起点为左上角，终点为右下角文件内容6 50 1 0 0 00 0 0 1 00 1 0 1 01 1 1 0 00 1 0 0 10 1 0 0 0 示例代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package mainimport ( &quot;fmt&quot; &quot;os&quot;)func readMaze(filename string) [][]int { file, err := os.Open(filename) if err != nil { panic(err) } var row, col int fmt.Fscanf(file, &quot;%d %d&quot;, &amp;row, &amp;col) maze := make([][]int, row) for i := range maze { maze[i] = make([]int, col) for j := range maze[i] { fmt.Fscanf(file, &quot;%d&quot;, &amp;maze[i][j]) } } return maze}type point struct { i, j int}var dirs = [4]point{ {-1, 0}, {0, -1}, {1, 0}, {0, 1},}func (p point) add(r point) point { return point{p.i + r.i, p.j + r.j}}func (p point) at(grid [][]int) (int, bool) { if p.i &lt; 0 || p.i &gt;= len(grid) { return 0, false } if p.j &lt; 0 || p.j &gt;= len(grid[p.i]) { return 0, false } return grid[p.i][p.j], true}func walk(maze [][]int, start, end point) [][]int { //初始化steps数组，记录步数 steps := make([][]int, len(maze)) for i := range steps { steps[i] = make([]int, len(maze[0])) } Q := []point{start} for len(Q) &gt; 0 { cur := Q[0] Q = Q[1:] //到达终点，退出循环 if cur == end { break } for _, dir := range dirs { next := cur.add(dir) //next不是墙，maze为0 val, ok := next.at(maze) if !ok || val == 1 { continue } //next没有走过，steps为0 val, ok = next.at(steps) if !ok || val != 0 { continue } //next不是起点，next不等于start if next == start { continue } //步数加一 curSteps, _ := cur.at(steps) steps[next.i][next.j] = curSteps + 1 //添加到队列 Q = append(Q, next) } } ////打印路径 //cur := end //for a, _ := cur.at(steps); a != 0; { // fmt.Printf(&quot;(%d,%d)-&gt;&quot;, cur.i, cur.j) // for _, dir := range dirs { // next := cur.add(dir) // if s, _ := next.at(steps); s == a-1 { // cur = next // break // } // } // a, _ = cur.at(steps) //} //fmt.Printf(&quot;(%d,%d)\\n&quot;, start.i, start.j) return steps}func main() { maze := readMaze(&quot;maze/maze.in&quot;) steps := walk(maze, point{0, 0}, point{len(maze) - 1, len(maze[0]) - 1}) for _, row := range steps { for _, val := range row { fmt.Printf(&quot;%3d&quot;, val) } fmt.Println() }}","link":"/2022/01/27/%E3%80%90Go%E8%AF%AD%E8%A8%80%E4%BE%8B%E9%A2%98%E3%80%91%E8%BF%B7%E5%AE%AB%E7%9A%84%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"title":"【TypeScript】TypeScript基础","text":"​点击阅读更多查看文章内容 数据类型 const常量，不能改变，类型可以通过初始化的值由编译器推断，也可以自己以 变量名 : 数据类型 的方式指定 123const a = 'abc'const a : string = 'abc'const a : number = 'abc' //报错：Type 'string' is not assignable to type 'number'. number整型，浮点型，表示所有数字类型 123let a = 123let b : number = 123.456 boolean布尔型，true/false 1let a : boolean = true string字符串，可以用单引号也可以用双引号 12let a : string = 'abc'let b : string = &quot;abc&quot; literal类型把变量的所有可能取值都列出来 1let httpStatus : 200 | 404 | 500 | '200' | '404' | '500' = '200' 类型的并集使变量可以支持多种类型 123function f(s: 200 | 404 | 500 | '200' | '404' | '500'){ let status : string | number = s} any类型相当于JavaScript，可以对变量进行任何操作，编译器都不会报错（运行可能出错） 123let a : any = 'abc'a = 123 // 不会报错，a为123a.name = 'John' //运行出错 undefined类型定义为undefined类型，值也只能为undefined 1let a : undefined = undefined 逻辑控制if/else等于一律使用：===不等于一律使用：!==undefined作为条件为false 1234567891011121314151617function processHttpStatus(s : 200 | 404 | 500 | '200' | '404' | '500') { // 一律使用=== 以及 !== if (s === 200) { console.log('ok') } else if (s === 404) { console.log('not found') } else if (s === 500){ console.log('internal server error') } else if (s === '200') { console.log('ok') } else if (s === '404') { console.log('not found') } else if (s === '500'){ console.log('internal server error') } //无需再判断其他情况，因为传入的参数只有以上六种情况} 问号表达式：typeof s === 'string' ? parseInt(s) : sa?b|c，条件a为true返回b，否则返回c 123456789101112function processHttpStatus(s : 200 | 404 | 500 | '200' | '404' | '500') { // 将 string 转为对应的 number const statusNum = typeof s === 'string' ? parseInt(s) : s // 一律使用=== 以及 !== if (statusNum === 200) { console.log('ok') } else if (statusNum === 404) { console.log('not found') } else if (statusNum === 500){ console.log('internal server error') } } switch12345678910111213141516171819function processHttpStatus(s : 200 | 404 | 500 | '200' | '404' | '500') { // string 转 number const statusNum = typeof s === 'string' ? parseInt(s) : s switch (statusNum){ case 200: console.log('ok') break case 404: console.log('not found') break case 500: console.log('internal server error') break default: console.log('internal server error') break //default实际上不需要，这里只是展示switch的使用方法 }} 循环语句跟C语言一样 for 12345let sum = 0for (let i = 0; i &lt; 100; i++){ sum += i}console.log(sum) while 1234567let sum = 0let i = 0while (i &lt; 100) { sum += i i++}console.log(sum) try-catchthrow抛出错误，注意throw后面的字符串包含${}取值所以不能使用引号，要使用 ` 抛出错误后程序依然会继续执行，sum输出结果为4950 1234567891011121314151617181920let sum = 0for (let i = 0; i &lt; 100; i++){ try { sum += i if (i % 17 === 0) { throw `bad number ${i}` } } catch (err) { console.error(err) }}console.log(sum)// 输出：// [ERR]: &quot;bad number 0&quot; // [ERR]: &quot;bad number 17&quot; // [ERR]: &quot;bad number 34&quot; // [ERR]: &quot;bad number 51&quot; // [ERR]: &quot;bad number 68&quot; // [ERR]: &quot;bad number 85&quot; // [LOG]: 4950 若不使用try-catch，在抛出错误后程序会直接终止 1234567891011let sum = 0for (let i = 0; i &lt; 100; i++){ sum += i if (i % 17 === 0) { throw `bad number ${i}` }}console.log(sum)// 输出:// [ERR]: &quot;执行 JavaScript 失败:&quot; // [ERR]: &quot;bad number 0&quot; 枚举类型typescript特有，JavaScript没有枚举类型如果不对枚举类型赋值的话就从0开始递增赋值HTTPStatus[s]可以直接打印出s，而不是其对应的枚举值 123456789101112131415161718192021enum HTTPStatus{ OK = 200, NOT_FOUND = 404 , INTERNAL_SERVER_ERROR = 500,}function processHTTPStatus(s:HTTPStatus){ if (s === HTTPStatus.OK){ console.log('good response') } else { console.log('bad response') } console.log(s) // 打印出s对应的值 console.log(HTTPStatus[s])}processHTTPStatus(HTTPStatus.INTERNAL_SERVER_ERROR)// 输出:// [LOG]: &quot;bad response&quot; // [LOG]: 500 // [LOG]: &quot;INTERNAL_SERVER_ERROR&quot; 数组 定义以下两种方法都可以，第二个是泛型类型let a : number[] = [1,2,3]let b : Array = [1,2,3] 123456789let a = [1,2,3]let a : number[] = [1,2,3]let a = [1,2,3,'a']let a : (string|number)[] = [1,2,3,'a']let b : Array&lt;number&gt; = [1,2,3] 获取数组长度及元素，数组越界不会报错会获得undefinedPs：空数组判断 ： a.length===0，不能直接写if(a) 123456789let a : number[] = [1,2,3,4]let b : string[] = ['a','b','c']console.log(a.length,b.length)console.log(a[3],b[1])console.log(a[4],b[-1])// 输出// [LOG]: 4, 3 // [LOG]: 4, &quot;b&quot; // [LOG]: undefined, undefined 增删元素 push/pop 从数组右边增加/删除元素 unshift/shift 从数组左边增加/删除元素 这里的数组可以用const定义，const表示a始终指向这个数组，数组的内容可以发生变化123456789const a : number[] = []a.push(1) // [1] a.push(2) // [1, 2] a.push(3) // [1, 2, 3] a.pop() // [1, 2] a.push(4) // [1, 2, 4] a.shift() // [2, 4]a.unshift(1)// [1, 2, 4]// a = [1, 2, 3] 报错 ， a为const不能指向其他数组 slice函数a.slice(start,end)：截取子数组a[start,end)，前闭后开越界不会报错，到边界就会结束a.slice(start)：从start取到数组结尾 123const a = [0, 1, 2, 3, 4, 5, 6, 7]console.log(a.slice(2, 5), a.slice(5, 10)) // [2, 3, 4], [5, 6, 7] splice函数a.splice(start, datacount, …items)：从start开始删除datacount个元素，并在start后插入items（items是可选的） 123const a = [0, 1, 2, 3, 4, 5, 6, 7]console.log(a.splice(3, 2, 10, 11, 12, 13)) // [3, 4] console.log(a) // [0, 1, 2, 10, 11, 12, 13, 5, 6, 7] indexOf函数a.indexOf(searchElement, fromIndex)：从下标fromIndex开始查找，返回searchElement第一次出现的位置，（fromIndex可选）a.lastIndexOf()：从后往前找 1234567const a = [0, 1, 2, 3, 4, 5, 6, 7, 11]console.log(a.splice(3, 2, 10, 11, 12, 13)) // [3, 4] console.log(a) // [0, 1, 2, 10, 11, 12, 13, 5, 6, 7, 11] console.log(a.indexOf(11)) // 4console.log(a.indexOf(11, 5)) // 10console.log(a.lastIndexOf(11)) // 10 sort函数排序，注意sort的排序是按照字典序排的，实际上对我们排序数字没有用，更多的是考虑排序一些单词，排序数字需要给sort传递一个compareFn参数。 123456const a = [0, 1, 2, 3, 4, 5, 6, 7, 11]console.log(a.splice(3, 2, 10, 11, 12, 13)) // [3, 4] console.log(a) // [0, 1, 2, 10, 11, 12, 13, 5, 6, 7, 11] a.sort()console.log(a) // [0, 1, 10, 11, 11, 12, 13, 2, 5, 6, 7] 元组 没有特别的元组语法，数组就可以当元组使用 1234// 元组 tupleconst a = [1, 2, 3]const [a1, a2, a3, a4] = aconsole.log(a1, a2, a3, a4) // 1, 2, 3, undefined split/joinsplit()：使用指定的分隔符将字符串拆分为子字符串，并将它们作为数组返回。join()：将数组的所有元素添加到字符串中，以指定的分隔符字符串分隔。 123// split/joinconsole.log('a,b,c,1,2,3'.split(',')) // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;] console.log([1,2,3,4].join(',')) // &quot;1,2,3,4&quot; forEach遍历数组，也可以使用传统for循环遍历整个数组，推荐使用forEach 1234const a = [1,2,3,4]a.forEach(v =&gt; { console.log(v)}) 对象类型不需要有类就可以直接声明 定义 123456789101112131415161718192021222324252627const emp1 = { name: { first: '三', last: '张' }, gender: 'male' as 'male' | 'female' | 'other' | 'unknown', //规定gender的类型 salary: 8000, bonus: undefined as number|undefined, performance: 3.5, badges: ['优秀员工', '迟到王'],}console.log(emp1)// 输出:// [LOG]: {// &quot;name&quot;: {// &quot;first&quot;: &quot;三&quot;,// &quot;last&quot;: &quot;张&quot;// },// &quot;gender&quot;: &quot;male&quot;,// &quot;salary&quot;: 8000,// &quot;bonus&quot;: undefined,// &quot;performance&quot;: 3.5,// &quot;badges&quot;: [// &quot;优秀员工&quot;,// &quot;迟到王&quot;// ]// } 输出结果为JSON对象 （JSON：JavaScript Object Notation） JSON 可以直接将输出结果赋值给新对象（字段名用不用引号效果是一样的）这里的新对象的类型就只有从结果中读出的类型，没有emp1中额外加的类型 1234567891011121314const emp2 = { &quot;name&quot;: { &quot;first&quot;: &quot;三&quot;, &quot;last&quot;: &quot;张&quot; }, &quot;gender&quot;: &quot;male&quot;, &quot;salary&quot;: 8000, &quot;bonus&quot;: undefined, &quot;performance&quot;: 3.5, &quot;badges&quot;: [ &quot;优秀员工&quot;, &quot;迟到王&quot; ]} JSON对象转为JSON字符串JSON.stringify(） 123const s : string = JSON.stringify(emp1)console.log(s)// [LOG]: &quot;{&quot;name&quot;:{&quot;first&quot;:&quot;三&quot;,&quot;last&quot;:&quot;张&quot;},&quot;gender&quot;:&quot;male&quot;,&quot;salary&quot;:8000,&quot;bonus&quot;:28000,&quot;performance&quot;:3.5,&quot;badges&quot;:[&quot;优秀员工&quot;,&quot;迟到王&quot;]}&quot; JSON字符串转为JSON对象JSON.parse()，这里JSON.parse()的返回值为any类型与直接输出emp1得到的结果相同（any类型不能直接通过.获取它的内在元素） 1234567891011121314151617const s : string = JSON.stringify(emp1)const emp2 = JSON.parse(s)console.log(emp2)// [LOG]: {// &quot;name&quot;: {// &quot;first&quot;: &quot;三&quot;,// &quot;last&quot;: &quot;张&quot;// },// &quot;gender&quot;: &quot;male&quot;,// &quot;salary&quot;: 8000,// &quot;bonus&quot;: 28000,// &quot;performance&quot;: 3.5,// &quot;badges&quot;: [// &quot;优秀员工&quot;,// &quot;迟到王&quot;// ]// } 对象类型不能直接比较 emp1 === emp2 返回值为false 函数 定义返回值可写可不写，不写的话可以函数的返回值类型由return语句决定，没有return语句的话返回值为void123function add(a: number,b: number): number{ return a+b} 可选参数?表示可选参数，如果没有输入的话，值为undefinedc||0：表示若c不为undefined的话返回值为c，否则返回值为01234function add(a: number, b: number, c?: number): number{ return c ? a + b + c : a + b // return a + b + (c||0)} 参数默认值可选参数后的参数必须是可选参数或者带有默认值123function add(a: number, b: number, c?: number, d: number=0): number{ return a + b + (c||0) + d} 可变参数列表…表示可变参数列表：可以传入任意多个参数，当做数组使用若想将数组传入函数，可以在数组前加…，将数组展开传入函数123456789101112131415function add( a: number, b: number, c?: number, d: number=0, ...e: number[]): number{ let sum = a + b + (c||0) + d for (let i = 0; i &lt; e.length; i++){ sum += e[i] } return sum}console.log(add(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))const numbers = [5, 6, 7, 8, 9, 10]console.log(add(1, 2, 3, 4, ...numbers)) 重载不建议使用函数重载函数重载通过声明函数实现 123456789101112131415161718function add(a: number, b: number): numberfunction add( a: number, b: number, ...e: number[]): numberfunction add( a: number, b: number, c?: number, d: number=0, ...e: number[]): number{ let sum = a + b + (c||0) + d for (let i = 0; i &lt; e.length; i++){ sum += e[i] } return sum} 对象类型参数参数列表过多或者具有boolean类型的参数时，可以定义对象类型的参数，这样函数调用者可以清楚的理解每个参数的具体作用（如果不使用对象类型直接传入一堆参数很难理解每个参数的意义，使用对象类型在调用的时候会表明对应的参数名便于理解）12345678910111213141516171819202122function sendRequest(params:{ url: string, method: 'GET'|'POST'|'PUT', header: object, data?: string, requireAuth: boolean, retry: boolean, retryTimeout?: number,}){}sendRequest({ url: 'https://www.test.com', method: 'GET', header: { contentType: 'application/json', }, data: '{}', requireAuth: false, retry: true, retryTimeout: 30000,}) 为对象定义方法不需要加function，其他的与普通的函数定义相同函数中的变量会从全局搜索，可以使用this引用自身的字段和方法123456789101112const emp1 = { name: 'john', salary: 8000, bonus: undefined as number|undefined, performance: 3.5, updateBonus() { if (!this.bonus) { this.bonus = this.salary * this.performance } },}emp1.updateBonus()","link":"/2022/12/16/%E3%80%90TypeScript%E3%80%91TypeScript%E5%9F%BA%E7%A1%80/"},{"title":"【Python】基础内容","text":"​点击阅读更多查看文章内容 简介 面向对象，解释型的编程语言 使用缩进作为逻辑层次 运行效率较低 单行注释：以#开头：#注释内容 多行注释：以一对三个双引号引起来的内容： “””注释内容””” 数据类型type(被查看类型的数据)：查看数据类型 数字（Number）整数（int）Python可以处理任意大小的整数 二进制整数使用前缀0b表示，例如：0b110，0b1100 十六进制整数使用前缀0x表示，例如：0x12ef，0xde2431af 浮点数（float）浮点数可以用正常写法：1.23，3.14，-9.01也可以使用科学计数法表示：1.23e9（1.23*10^9）注意：浮点数的运算可能会有误差 复数（complex）以j结尾表示复数，如4+3j 布尔值（bool）布尔值只有True，False两种值，可以使用and，or，not进行运算True本质上是一个数字记作1，False记作0 字符串（String） 描述文本的一种数据类型 字符串可以用’’或””括起来表示如果字符串本身包含单引号，这时可以用双引号括起来表示，如果包含双引号，就可以用单引号括起来表示，如果字符串既包含单引号也包括双引号，那么需要使用\\进行转义。 常用的转义字符还有：\\n表示换行\\t 表示一个制表符\\\\表示 \\ 字符本身 raw字符串如果一个字符串包含很多需要转义的字符，对每一个字符都进行转义会很麻烦，我们可以在字符串前面加个r，表示这是一个raw字符串，里面的字符就不需要转义了。 12345print(r&quot;c:\\newfile\\test.py&quot;)#c:\\newfile\\test.pyprint(&quot;c:\\newfile\\test.py&quot;)#c:#ewfile est.py raw'...'，不能表示多行字符串，也不能表示包含’和”的字符串（不能转义） 多行字符串使用'''...'''表示多行字符串 123print('''Line 1Line 2Line 3''') 也可以在多行字符串前面添加r，把这个多行字符串也变成raw字符串 字符串切片 前闭后开区间 12345s = 'ABCDEFG's1 = s[0:2]print(s1) # ABs2 = s[2:4]print(s2) # CD 以’’或””括起来的任意文本 字符串拼接 通过+可以将两个字符串拼接在一起 12name = &quot;world&quot;print(&quot;hello&quot; + name) # helloworld 字符串格式化%占位% 表示：我要占位s 表示：将变量变成字符串放入占位的地方综合起来：我先占个位置，等一会有个变量过来，我把它变成字符串放到占位的位置（%d：将内容转换成整数，放入占位位置；%f：将内容转换成浮点数，放入占位位置） 12345name = &quot;David&quot;tel = 1234567message = &quot;姓名：%s，电话：%d&quot; % (name, tel)print(message) # 姓名：David，电话：1234567print(&quot;%f&quot; % tel) # 1234567.000000 精度控制可以使用符号m.n来控制数据的宽度和精度m控制宽度，要求是数字，设置的宽度小于数字自身，不生效.n控制小数点精度，要求是数字，会进行小数的四舍五入 123print(&quot;%5d&quot; % 11) # [空格][空格][空格]11，用三个空格补齐宽度print(&quot;%7.2f&quot; % 11.345) # [空格][空格]11.35，小数部分限制两位四舍五入为.35，用两个空格补齐宽度print(&quot;%.2f&quot; % 11.345) # 11.35，不限制宽度，只设置小数点精度为2 f”内容{变量}” 不理会类型 不做精度控制1234name = &quot;David&quot;sex = &quot;male&quot;age = 20print(f&quot;我是{name}，我的性别是{sex}，我的年龄是{age}&quot;) format 1234567print('{} {}'.format(&quot;hello&quot;, &quot;world&quot;)) # hello worldprint('{0} {1}'.format(&quot;hello&quot;, &quot;world&quot;)) # hello worldprint('{1} {0}'.format(&quot;hello&quot;, &quot;world&quot;)) # world helloprint(&quot;hello:{country}, hello:{city}&quot;.format(country=&quot;china&quot;, city=&quot;beijing&quot;)) # hello:china, hello:beijinga = 3b = 4print('{} + {} = {}'.format(a, b, a+b)) # 3 + 4 = 7 列表（List） 有序的可变序列 元组（Tuple） 有序的不可变序列 集合（Set） 无序不重复集合 字典（Dictionary） 无序Key-Value集合 空值（None） 空值空值用None表示 函数无返回值 if判断：None等同于False 声明无内容变量 数据类型转换 int(x)：将x转换为一个整数 float(x)：将x转换为一个浮点数 str(x)：将对象x转换为字符串 浮点数转换为整数会丢掉小数部分，字符串必须为纯数字才能转换为数字 标识符的命名规则 大小写敏感 标识符由大小写英文字母、数字、中文和下划线组成（不推荐使用中文） 标识符不能由数字开头 标识符不能与Python关键字重合（比如：and、or、not） 标识符命名规范 英文字母全小写 多个单词之间用下划线分隔 定义变量变量没有类型，字符串变量表示变量存储了字符串而不是表示变量就是字符串 变量名 = 数据 一个变量可以先后存储多种不同类型的数据 1234a = 1 # 这个时候a存储的是整数类型print(a)a = 'ABC' # 这个时候a存储的是字符串类型print(a) 运算符算数运算符加减乘除 整数与浮点数运算的结果是浮点数除法的运算结果是浮点数 1234567891011121314# 加法num1 = 10num2 = 0.5result = num1 + num2print(result) # ==&gt; 10.5# 减法result = num1 - num2print(result) # ==&gt; 9.5# 乘法result = num1 * num2print(result) # ==&gt; 5.0# 除法result = num1 / num2print(result) # ==&gt;20.0 取模 123print(3 % 2) # ==&gt; 1print(33 % 10) # ==&gt; 3print(99 % 30) # ==&gt; 9 地板除 与普通除法相比，会忽略结果的纯小数部分，使用//进行都为整型则结果也为整型，只要有一个float，则返回float 123print(10//4) # ==&gt; 2print(10//2.5) # ==&gt; 4.0print(10//3) # ==&gt; 3 保留小数点位数round()，第一个参数是需要保留小数点位数的数值，第二个参数是保留的位数 12&gt;print(round(3.344, 2)) # ==&gt; 3.34&gt;print(round(3.345, 2)) # ==&gt; 3.35 指数 a**b：为a的b次方 1print(5**2) # ==&gt; 25 赋值运算符 =：赋值运算符，把 = 右边的结果赋给左边的变量 +=：c+=a等效于c=c+a -= *= /= %= **= //= 输入输出数据输出：print() print默认换行输出，在print后加上end=’’，即可实现输出不换行print(&quot;hello&quot;, end=&quot;&quot;) 数据输入：input() 使用input()语句可以从键盘获取输入 使用一个变量接受input语句获取的键盘输入数据即可 在input()的括号中输入语句，会在输入前输出这段提示语句 输入的数据都看作是字符串 判断语句布尔类型与运算两个布尔值都为True时，结果为True 1234True and True # ==&gt; TrueTrue and False # ==&gt; FalseFalse and True # ==&gt; FalseFalse and False # ==&gt; False 或运算只要有一个值为True，结果就为True 1234True or True # ==&gt; TrueTrue or False # ==&gt; TrueFalse or True # ==&gt; TrueFalse or False # ==&gt; False 非运算True变为False，False变为True 12not True # ==&gt; Falsenot False # ==&gt; True 布尔类型也可以与其他类型做运算Python把0、空字符串和None看成False，其他数值和非空字符串都看成True 1print(True and 0 or 99) # ==&gt; 99 要解释以上结果需要涉及到短路计算 在计算a and b时，如果 a 是 False，则根据与运算法则，整个结果必定为 False，因此返回 a；如果 a 是 True，则整个计算结果必定取决与 b，因此返回 b。 在计算a or b时，如果 a 是 True，则根据或运算法则，整个计算结果必定为 True，因此返回 a；如果 a 是 False，则整个计算结果必定取决于 b，因此返回 b True and 0 or 99：首先计算True and 0，根据短路计算返回0，然后计算0 or 99，根据短路计算返回99 比较运算符==、!=、&gt;、&lt;、&gt;=、&lt;= if-else 通过缩进表示这行代码是if/else判断的一个子分支（表示这行代码属于哪个语句） 在if/else后有一个:，表示接下来是分支代码块12345score = 59if score &lt; 60: print('抱歉，考试不及格')else: print('恭喜你，考试及格') elif 相当于 else if ， 可以简化逻辑 1234567891011score = 59if score &lt; 60: print('抱歉，考试不及格')else: if score &gt;= 90: print('恭喜你，拿到卓越的成绩') else: if score &gt;= 80: print('恭喜你，拿到优秀的成绩') else: print('恭喜你，考试及格') 123456789score = 59if score &lt; 60: print('抱歉，考试不及格')elif score &gt;= 90: print('恭喜你，拿到卓越的成绩')elif score &gt;= 80: print('恭喜你，拿到优秀的成绩')else: print('恭喜你，考试及格') 特别注意: 这一系列条件判断会从上到下依次判断，如果某个判断为 True，执行完对应的代码块，后面的条件判断就直接忽略，不再执行了。 循环语句while循环输出0～99 1234i = 0while i &lt; 100: print(f&quot;i = {i}&quot;) i += 1 for循环12for 临时变量 in 待处理数据集: 循环满足条件时执行的代码 将待处理数据集中的数据挨个取出，每一次循环就将当前数据赋予这个临时变量，在循环体中使用 12345678910str = &quot;Hello&quot;for x in str: print(x)&quot;&quot;&quot;Hello&quot;&quot;&quot; 无法定义循环条件 只能从待处理的数据集中，依次取出内容进行处理 理论上讲Python的for循环无法构建无限循环（被处理的数据集不可能无限大） 待处理数据集，严格来说称之为：序列类型 序列类型指：其内容可以一个个依次取出的一种类型，包括： 字符串 列表 元组 等 range语句 生成数字序列 range(num)：获取一个从0开始，到num结束的数字序列（不含num本身）如：range(5)取得的数据是：[0,1,2,3,4] range(num1, num2)：获取一个从num1开始，到num2结束的数字序列（不含num2本身）如：range(5, 10)取得的数据是：[5,6,7,8,9] range(num1, num2, step)：获取一个从num1开始，到num2结束的数字序列（不含num2本身），数字之间的步长为step（step默认为1）如：range(5, 10, 2)取得的数据是：[5,7,9] 在for循环外部可以访问临时变量，但在编程规范上是不允许这样做的 1234&gt;for x in range(10): print(f&quot;{x} &quot;,end=&quot;&quot;)&gt;print(x)&gt;# 0 1 2 3 4 5 6 7 8 9 9 如果想访问for循环内部变量，则应该在for循环外部预先定义 12345&gt;x = 0&gt;for x in range(10): print(f&quot;{x} &quot;,end=&quot;&quot;)&gt;print(x)&gt;# 0 1 2 3 4 5 6 7 8 9 9 for循环相当于对x进行了10次内容覆盖 continue和break continue：中断本次循环，直接进入下一次循环 break：直接结束循环 在嵌套循环中，只能作用在所在的循环上，无法对上层循环起作用 函数定义 123def 函数名(传入参数): 函数体 return 返回值 必须先定义后使用、参数不需要可省略、返回值不需要可省略 传入参数功能：在函数进行计算的时候，接受外部（调用时）提供的数据 1234def add(x, y): result = x + y print(f&quot;{x} + {y}的计算结果是：{result}&quot;)add(1,2) 函数定义中提供的x和y，称之为形式参数，参数之间使用逗号分隔 函数调用中提供的1和2，称之为实际参数，按顺序传入，使用逗号分隔 返回值 1234567def add(a, b): result = a + b return resultr = add(1, 2)print(r) 多个返回值返回Tuple 无返回值返回None 说明文档在函数体之前通过多行注释的形式，对函数进行说明解释 pycharm在函数名之后输入”””回车会自动补全注释 123456789def add(x, y): &quot;&quot;&quot; :param x: :param y: :return: &quot;&quot;&quot; result = x + y return result 123456789def add(x, y): &quot;&quot;&quot; add函数可以接收2个参数，进行2数相加的功能（整体说明） :param x:形参x表示相加的其中一个数字（参数说明） :param y:形参y表示相加的另一个数字 :return:返回值是2数相加的结果（返回值说明） &quot;&quot;&quot; result = x + y return result 鼠标悬停可以查看文档 变量作用域 局部变量：在函数体内定义的变量，只能在函数体内使用全局变量：在函数体外定义的变量，函数体内外都能使用 以下示例中，test函数内部相当于重新定义了一个num变量赋值为500，此时函数外部的num变量并没有被修改 123456789101112num = 100def test(): num = 500 print(num)test()print(num)# 500# 100 要想在函数内部修改全局变量需要使用global关键字 global：在函数内部声明变量为全局变量此时test()中的num和函数外的num就是同一个变量了 12345678910111213num = 100def test(): global num num = 500 print(num)test()print(num)# 500# 500 数据容器 一种可以容纳多份数据的数据类型，容纳的每一份数据称之为一个元素，每一个元素可以是任意类型的数据，如字符串、数字、布尔等。 列表（list） 可以容纳多个元素（上限为2**63-1）可以容纳不同类型的元素数据有序存储（有下标序号）允许重复数据存在可以修改、增加或删除元素 基本语法 以[]作为标识，列表内每一个元素之间用逗号隔开 元素可以为不同的数据类型，支持嵌套 123456# 定义列表list1 = [1, 2, True, &quot;hello&quot;]# 定义空列表list2 = []list3 = list() 下标索引从前向后：从0开始，依次递增从后向前：从-1开始，依次递减 1234list1 = [1, 2, True, &quot;hello&quot;, [1, 2, 3]]print(list1[0]) # 1print(list1[-1][1]) # 2 列表.index(元素)：查找某元素在list中第一次出现的位置 列表[下标]=值：修改特定索引的元素值 列表.insert(下标,元素)：在指定的下标位置，插入指定的元素 列表.append(元素)：将指定元素追加到列表的尾部 列表.extend(其它数据容器)：将其它数据容器的内容取出，依次追加到列表尾部 del 列表[下标]：删除指定位置元素 列表.pop(下标)：删除指定位置元素并返回 列表.remove(元素)：删除某元素在列表中的第一个匹配项 列表.clear()：清空列表内容 列表.count(元素)：统计某元素在列表内的数量 len(列表)：统计列表内有多少元素 元组（tuple） 元组与列表类似，最大的不同点在于：元组一旦定义完成，就不可修改 基本语法使用小括号定义，元素之间使用逗号分隔，数据可以是不同的数据类型 12345# 定义元组tuple1 = (1, 2, &quot;hello&quot;, [1, 2], (3, 4))# 定义空元组tuple2 = ()tuple3 = tuple() 注意：如果元组只有一个数据，这个数据后面要添加逗号，否则不是元组类型 1234tuple1 = (1)print(type(tuple1)) # inttuple2 = (1,)print(type(tuple2)) # tuple 元组的操作方法和列表相同，但是不能增加/删除/修改元素注意：元组的内容不能修改，但是可以修改元组中嵌套的list的内容 123tuple1 = (1, [1, 2, 3])tuple1[1][1] = 1print(tuple1) # (1, [1, 1, 3]) 字符串（string） 一个字符串可以存放任意数量的字符 下标索引从前向后，下标从0开始从后向前，下标从-1开始 注意：同元组一样，字符串是一个无法修改的容器，如果想要修改/删除/追加字符只能通过建一个新的字符串。 字符串.index(字符串)：查找特定字符串的下标索引值 字符串.replace(字符串1,字符串2)：将字符串内的全部字符串1替换为字符串2，这里不是修改字符串本身，而是得到一个新的字符串 字符串.split(分隔符字符串)：按照指定的分隔符字符串，将字符串划分为多个字符串，并存入列表对象中，字符串本身不变，而是得到了一个列表对象 字符串.strip()：去掉前后空格 字符串.strip(字符串)：去除前后指定字符串，这里不是严格按照字符串来去除的，而是把其划分为小字符串，如传入“12”，则字符串前后的“12”和“21”都会被去除 字符串.count(字符串)：统计字符串内某字符串出现的次数 len(字符串)：统计字符串的字符个数 序列的切片操作序列：内容连续、有序，可使用下标索引的一类数据容器（列表、元组、字符串）切片：从一个序列中，取出一个子序列语法：序列[起始下标:结束下标:步长] 起始下标表示从何处开始，留空视作从头开始 结束下标表示何处结束（不含），留空视作截取到结尾 步长：依次取元素的间隔，步长为负数表示反向取（起始下标和结束下标也要反向标记），省略步长为1 此操作不会影响序列本身，而是会得到一个新的序列 [::-1]：表示将序列反转 集合（set） 不支持重复元素且内容无序 基本语法 使用{}定义空集合使用set()定义，不能使用{}，{}是字典 1234# 定义集合变量set1 = {1, 2, &quot;hello&quot;}# 定义空集合set2 = set() 不能使用下标取元素，但是集合和列表一样可以修改 集合.add(元素)：将指定元素添加到集合内，集合本身被修改 集合.remove(元素)：将指定元素从集合内移除 集合.pop()：从集合中随机取出一个元素，返回一个元素，同时元素被移除 集合.clear()：清空集合 集合1.difference(集合2)：取集合1和集合2的差集（集合1有而集合2没有），得到一个新的集合，集合1和集合2不变 集合1.union(集合2)：将集合1和集合2合成新集合 len(集合)：统计集合元素数量 集合不支持下标索引，不能用while循环遍历，可以用for循环 123set1 = {1, 2, &quot;hello&quot;}for i in set1: print(i) 字典（dict）基本语法使用{}定义，不过存储的元素是一个个的：键值对 12345# 定义字典变量dict1 = {&quot;zhangsan&quot;: 30, &quot;lisi&quot;: 40, &quot;wangwu&quot;: 50}# 定义空字典dict2 = {}dict3 = dict() 字典不允许key重复，重复添加会把前面的覆盖掉 123# 定义字典变量dict1 = {&quot;zhangsan&quot;: 30, &quot;zhangsan&quot;: 40, &quot;wangwu&quot;: 50}print(dict1[&quot;zhangsan&quot;]) # 40 不可以通过下标索引，可以通过key值来取得对应的value key和value可以是任意数据类型（key不可为字典） 字典[key] = value：key不存在新增元素，key存在更新元素 字典.pop(key)：获取指定key的value，同时key的数据被删除 字典.clear()：清空字典 字典.keys()：得到字典中的全部key，可以用来遍历字典 遍历字典：可以首先通过keys获取字典中的全部key进行遍历，也可以for循环遍历每次取得的就是字典的key 总结 是否支持下标索引 支持：列表、元组、字符串 - 序列类型 不支持：集合、字典 - 非序列类型 是否支持重复元素： 支持：列表、元组、字符串 - 序列类型 不支持：集合、字典 - 非序列类型 是否可以修改 支持：列表、集合、字典 不支持：元组、字符串 通用操作 遍历 五类数据容器都支持for循环遍历 列表、元组、字符串支持while循环，集合、字典不支持（无法下标索引） 函数进阶多返回值多个返回值之间用逗号隔开 支持不同类型的数据return 可以使用1个变量接受多返回值，返回类型为tuple 可以使用多个变量分别接受各个返回值，接受变量必须与返回值一一对应 1234567def test_return(): return 1, 2t = test_return()print(type(t)) # &lt;class 'tuple'&gt;print(t) # (1, 2)x, y = test_return()print(x, y) # 1 2 传参方式位置参数 调用函数时根据函数定义的参数位置来传递参数 123def user_info(name, age, gender): print(f'您的名字是{name}, 年龄是{age}, 性别是{gender}')user_info('TOM', 20, '男') 关键字参数 函数调用时通过“键=值”的形式传递参数 123def user_info(name, age, gender): print(f'您的名字是{name}, 年龄是{age}, 性别是{gender}')user_info(gender='女', name='Alice', age=25) 可以不固定顺序可以和位置参数混用，位置参数必须在前，且匹配参数顺序 123def user_info(name, age, gender): print(f'您的名字是{name}, 年龄是{age}, 性别是{gender}')user_info('Alice', gender='女', age=25)","link":"/2023/06/14/%E3%80%90Python%E3%80%91%E5%9F%BA%E7%A1%80%E5%86%85%E5%AE%B9/"},{"title":"【TypeScript】TypeScript进阶","text":"​点击阅读更多查看文章内容 函数式编程函数作为“一等公民” 变量类型可以是函数，值（literal）可以是函数以下代码推荐写成lambda表达式的形式（在JavaScript/TypeScript中也被称为箭头函数）const compareNumber = (a: number, b: number) =&gt; a-b箭头函数：用箭头指向函数的结果，也可以用箭头指向{函数体} 1234567// lambda 表达式， JavaScript/TypeScript：箭头函数//const compareNumber = (a: number, b: number) =&gt; a-bconst compareNumber = function (a:number,b:number) { return a-b }let a = [5,2,1,6,8,10,5,25,16,23,11]a.sort(compareNumber) 对象的字段可以是函数 1234567const emp1 = { name: 'john', salary: 8000, increaseSalary: function (p: number) { this.salary *= p }} 函数的参数可以是函数 12345function compareNumber(a:number,b:number) { return a-b }let a = [5,2,1,6,8,10,5,25,16,23,11]a.sort(compareNumber) 函数的返回值可以是函数这里的createComparer函数中具有boolean类型的参数，如果直接传入false的话不知道false具体有什么作用，所以这里使用了对象类型参数在调用函数时可以很清晰的看出false的变量为smallerFirst 123456789function createComparer(p: {smallerFirst: boolean}){ if (p.smallerFirst) { return (a: number, b: number) =&gt; a-b } else { return (a: number, b: number) =&gt; b-a }}let a = [5,2,1,6,8,10,5,25,16,23,11]a.sort(createComparer({smallerFirst: false})) 高阶函数 函数的参数可以是函数函数的返回值可以是函数以上两种都属于高阶函数 loggingComparer()：函数的参数和返回值都是函数 1234567891011121314151617function loggingComparer(comp: (a: number, b: number) =&gt; number){ return (a: number, b: number) =&gt; { console.log('comparing', a, b) return comp(a, b) }}function createComparer(p: {smallerFirst: boolean}){ if (p.smallerFirst) { return (a: number, b: number) =&gt; a-b } else { return (a: number, b: number) =&gt; b-a }}let a = [5,2,1,6,8,10,5,25,16,23,11]const comp = createComparer({smallerFirst: true})a.sort(loggingComparer(comp)) 闭包使局部变量的生命周期延长 1234567891011121314151617181920212223242526272829303132function loggingComparer( logger: (a: number, b: number) =&gt; void, comp: (a: number, b: number) =&gt; number) { return (a: number, b: number) =&gt; { logger(a,b) return comp(a, b) }}function createComparer(p: {smallerFirst: boolean}){ if (p.smallerFirst) { return (a: number, b: number) =&gt; a-b } else { return (a: number, b: number) =&gt; b-a }}function processArray(a: number[] ){ let compCount = 0 // logger：闭包 const logger = (a: number, b: number) =&gt; { console.log('comparing', a, b) compCount++ //自由变量 } const comp = createComparer({smallerFirst: true}) a.sort(loggingComparer(logger, comp)) return compCount}let a = [5,2,1,6,8,10,5,25,16,23,11]const compCount = processArray(a)console.log(a,compCount) 部分应用函数 下例中isGoodNumber有两个参数，我们希望先用一个已知的goodFactor，使用这个goodFactor去判断我们收到的每个v 即我们现在只有一个参数goodFactor，我们想先将goodFactor传入函数，这样isGoodNumber就只有一个参数，此时只有一个参数的isGoodNumber就可以作为filterArray的参数f传入filterArray 解决方法：使用闭包将goodFactor放入函数体中 方法一（推荐使用）： 1234567891011function isGoodNumber(goodFactor: number, v: number){ return v % goodFactor === 0}function filterArray(a: number[], f: (v: number) =&gt; boolean) { return a.filter(f)}const GOOD_FACTOR = 2const a = [1, 2, 3, 4, 5, 6, 7, 8, 9]console.log(filterArray(a, (v) =&gt; isGoodNumber(GOOD_FACTOR, v))) 方法二（加深印象）： 1234567891011121314151617function isGoodNumber(goodFactor: number, v: number){ return v % goodFactor === 0}function filterArray(a: number[], f: (v: number) =&gt; boolean) { return a.filter(f)}function partiallyApply( f: (a: number, b: number) =&gt; boolean, a: number) { return (b: number) =&gt; f(a, b) }const GOOD_FACTOR = 2const a = [1, 2, 3, 4, 5, 6, 7, 8, 9]console.log(filterArray(a, partiallyApply(isGoodNumber, GOOD_FACTOR))) Promise回调函数会引起 “callback hell” 问题，如下例只能通过嵌套的方法计算2+3+4，会导致多层嵌套 123456789101112function add (a: number, b: number, callback: (res: number) =&gt; void): void{ setTimeout(()=&gt;{ callback(a+b) },2000)}add(2,3,res =&gt; { console.log('2+3',res) add(res,4,res2=&gt;{ console.log('2+3+4',res2) })}) 改写为promise，代码更加清晰new Promise是Promise的构造函数，它的参数(resolve,reject)=&gt;{ setTimeout(()=&gt;{ resolve(a+b) },2000) } 也是函数，这个函数的参数resolve和reject也是函数，如果运行成功就调resolve，如果失败就调reject resolve 1234567891011121314151617function add (a: number, b: number): Promise&lt;number&gt;{ return new Promise((resolve,reject)=&gt;{ setTimeout(()=&gt;{ resolve(a+b) },2000) })}add(2,3).then(res =&gt; { console.log('2+3',res) return add(res,4)}).then(res =&gt; { console.log('2+3+4',res) return add(res,6)}).then(res =&gt;{ console.log('2+3+4+6',res)}) reject 123456789101112131415161718function add (a: number, b: number): Promise&lt;number&gt;{ return new Promise((resolve,reject)=&gt;{ if (b % 17 === 0){ reject(`bad number: ${b}`) } setTimeout(()=&gt;{ resolve(a+b) },2000) })}add(2,17).then(res =&gt; { console.log('2+17',res) return add(res,4)}).catch(err =&gt; { console.log('caught error',err)})// caught error bad number: 17 同时等待多个PromisePromise.all等待任意一个PromisePromise.race 12345678910111213141516171819202122232425262728293031function add (a: number, b: number): Promise&lt;number&gt;{ return new Promise((resolve,reject)=&gt;{ if (b % 17 === 0){ reject(`bad number: ${b}`) } setTimeout(()=&gt;{ resolve(a+b) },2000) })}function mul(a: number,b: number): Promise&lt;number&gt;{ return new Promise((resolve,reject) =&gt; { setTimeout(() =&gt; { resolve(a*b) }, 3000) })}// (2+3)*(4+5)Promise.all([add(2,3), add(4,5)]).then(res =&gt; { const [a,b] = res return mul(a,b)}).then(res =&gt; { console.log(res)})Promise.race([add(2,3), add(4,5)]).then(res =&gt; { console.log(res)}) Promise通过串联就可以解决callback hell async-await 语法糖promise可以写成async-await的形式await是异步等待，只能在async function中调用以下calc函数返回类型为Promise&lt;number&gt; 12345678910async function calc() { const a = await add(2, 3) const b = await add(4, 5) const c = await mul(a, b) return c }calc().then(res =&gt; { console.log(res)}) 接口 作用：描述一个类型 1234567891011121314151617interface Employee { name: string salary: number bonus?: number}const emp1: Employee = { name: 'john', salary: 8000,}const emp2: Employee = { name: '张三', salary: 10000, bonus: 20000,} 可选字段串联e.name?.first?.startsWith('AAA')如果e.name为undefined则整个表达式都为undefined（如果不加? 则由于name可能为空编译器会报错） 12345678910111213interface Employee { name?: { first?: string last: string } salary: number bonus?: number}function hasBadName(e: Employee){ // 如果e.name为undefined则整个表达式都为undefined return e.name?.first?.startsWith('AAA')} 非空断言e.name!.first!.startsWith('AAA')断言e.name e.name.first不为undefined，此时编译器不会报错（如果不加! 则由于name可能为空编译器会报错），若其值为undefined则后果自负（程序运行出错） 123function hasBadName(e: Employee){ return e.name!.first!.startsWith('AAA')} 接口扩展extends：将已有接口拼成一个更大的接口 12345678910interface Employee extends HasName{ salary: number bonus?: number}interface HasName { name?: { first?: string last: string }} 接口的并集 e: WxButton|WxImage e只能调用他们共有的属性visible 12345678910111213141516interface WxButton { visible: boolean enabled: boolean onClick(): void}interface WxImage { visible: boolean src: string width: number height: number}function processElement(e: WxButton|WxImage) { e.visible} 类型断言e as WxButton，得到的类型为WxButton判断e是Button还是Image，由于ts在转为js时没有interface，所以要根据Button和Image的属性来判断，具有onClick方法的就是Button 12345678910function processElement(e: WxButton|WxImage) { // 判断e是Button还是Image if ((e as any).onClick) { const btn = e as WxButton btn.onClick() } else { const img = e as WxImage console.log(img.src) }} 类型判断(e as WxButton).onClick !== undefined：要想调用其他属性需要首先判断e的类型，这里不能使用typeof判断，因为在js中看不到自己定义的接口，需要通过判断e是否具有某个属性来判断它的类型。返回值为e is WxButton，编译器可以判断传入的e为WxButton 1234567891011function processElement(e: WxButton|WxImage) { if (isButton(e)) { e.onClick() } else { console.log(e.src) }}function isButton(e: WxButton|WxImage): e is WxButton { return (e as WxButton).onClick !== undefined} 类 类在定义时必须初始化可以通过构造函数/赋初值的方式不加private默认为public 123456789class Employee { name: string salary: number private bonus: number = 0 constructor(name: string, salary: number){ this.name = name this.salary = salary }} 可以在构造函数的参数前添加public/private，相当于定义属性可选参数不用初始化 123456789101112class Employee { private bonus?: number constructor(public name: string, public salary: number){ this.name = name this.salary = salary } updateBonus() { if (!this.bonus){ this.bonus = 20000 } }} getter/setter（allocatedBonus是private不能直接修改）调用时看不出是一个方法，相当于一个属性进行调用 12345678910111213141516171819202122232425class Employee { private allocatedBonus?: number constructor(public name: string,public salary: number){ this.name = name this.salary = salary } // getter/setter set bonus(v: number){ this.allocatedBonus = v } get bonus(){ return this.allocatedBonus || 0 }}const emp1 = new Employee('john',8000)emp1.bonus = 20000console.log(emp1.bonus) // 20000 console.log(emp1)// Employee: {// &quot;name&quot;: &quot;john&quot;,// &quot;salary&quot;: 8000,// &quot;allocatedBonus&quot;: 20000// } 类的继承extends通过super调用基类的构造函数（不加构造函数的话会默认使用基类的构造函数） 1234567891011121314151617181920212223242526class Employee { private allocatedBonus?: number constructor(public name: string,public salary: number){ this.name = name this.salary = salary } // getter/setter set bonus(v: number){ this.allocatedBonus = v } get bonus(){ return this.allocatedBonus || 0 }}class Manager extends Employee { private reporters: Employee[] constructor(name: string, salary: number) { super(name, salary) this.reporters = [] } addReporter(e: Employee){ this.reporters.push(e) }} 类实现接口隐式实现：不用implements实现，在定义类的时候不会检查属性，在将类赋值给接口时，会挨个比较属性，如果属性不全则会报错显示实现：使用implements，类在定义的时候需要定义接口的全部属性 123456789101112131415161718192021222324252627282930313233interface Employee { name: string salary: number bonus?: number}class EmplImpl implements Employee{ private allocatedBonus?: number constructor(public name: string,public salary: number){ this.name = name this.salary = salary } // getter/setter set bonus(v: number){ this.allocatedBonus = v } get bonus(){ return this.allocatedBonus || 0 }}class Manager extends EmplImpl { private reporters: EmplImpl[] = [] addReporter(e: EmplImpl){ this.reporters.push(e) }}const empImpl = new EmplImpl('john', 8000)const emp1: Employee = empImpl 定义方法选择 显示定义定义者=实现者（不推荐）在使用的时候会有很多多余的方法1234567891011121314151617181920212223242526272829303132333435// 定义接口interface Service { login(): void getTrips(): string getLic(): string startTrip(): void updateLic(lic: string): void}// 实现接口class RPCService implements Service { login(): void { throw new Error(&quot;Method not implemented.&quot;) } getTrips(): string { throw new Error(&quot;Method not implemented.&quot;) } getLic(): string { throw new Error(&quot;Method not implemented.&quot;) } startTrip(): void { throw new Error(&quot;Method not implemented.&quot;) } updateLic(lic: string): void { throw new Error(&quot;Method not implemented.&quot;) }}const page = { service: new RPCService() as Service, onLoginButtonClicked() { //使用接口 this.service.login() }} 定义方法选择 隐示定义定义者=使用者（推荐）由使用的人根据自己的需要定义接口，每个接口都很小比较好维护，实现解耦只能使用隐式实现，显示实现的话在实现时会implements很多不同的接口，每个使用者都有一个接口 12345678910111213141516171819202122232425262728293031// 实现接口class RPCService { login(): void { throw new Error(&quot;Method not implemented.&quot;) } getTrips(): string { throw new Error(&quot;Method not implemented.&quot;) } getLic(): string { throw new Error(&quot;Method not implemented.&quot;) } startTrip(): void { throw new Error(&quot;Method not implemented.&quot;) } updateLic(lic: string): void { throw new Error(&quot;Method not implemented.&quot;) }}// 定义接口interface LoginService { login(): void}const page = { service: new RPCService() as LoginService, onLoginButtonClicked() { //使用接口 this.service.login() }} 泛型用来约束参数类型const a: number[] = []等价于const a: Array&lt;number&gt; = [] 定义在定义类型时需要表明泛型类型在调用函数时可以不必表明类型，编译器可以根据参数自己判断类型 1234567891011121314151617181920class MyArray&lt;T&gt; { date: T[] = [] add(t: T) { this.date.push(t) } map&lt;U&gt;(f: (v: T) =&gt; U): U[] { return this.date.map(f) } print() { console.log(this.date) }}const a = new MyArray&lt;number&gt;()a.add(1)a.add(2000)a.add(30000)//(method) MyArray&lt;number&gt;.map&lt;string&gt;(f: (v: number) =&gt; string): string[]console.log(a.map(v =&gt; v.toExponential())) 使用接口约束泛型类型T 可以 . 出内容 12345678910111213141516171819202122232425262728interface HasWeight { weight: number}class MyArray&lt;T extends HasWeight&gt; { date: T[] = [] add(t: T) { this.date.push(t) } map&lt;U&gt;(f: (v: T) =&gt; U): U[] { return this.date.map(f) } print() { console.log(this.date) } sortByWeight() { this.date.sort((a, b) =&gt; a.weight - b.weight) }}class WeightedNumber { constructor(public weight: number) { }}const a = new MyArray&lt;WeightedNumber&gt;()a.add(new WeightedNumber(10000))a.add(new WeightedNumber(200))a.add(new WeightedNumber(30000))a.sortByWeight()console.log(a)","link":"/2022/12/26/%E3%80%90TypeScript%E3%80%91TypeScript%E8%BF%9B%E9%98%B6/"},{"title":"【数据结构1】数据结构的基本概念","text":"​点击阅读更多查看文章内容 数据结构的基本概念数据：数据是信息的载体，是描述客观事物属性的数、字符及所有能输入到计算机中并被计算机程序识别和处理的符号的集合。数据是计算机程序加工的原料。 数据元素、数据项：数据元素是数据的基本单位，通常作为一个整体进行考虑和处理。一个数据元素可由若干数据项组成，数据项是构成数据元素的不可分割的最小单位 要根据实际的业务需求来确定什么是数据元素、什么是数据项以微博账号为例 数据结构：数据结构是相互之间存在一种或多种特定关系的数据元素的集合数据对象：是具有相同性质的数据元素的集合，是数据的一个子集 以海底捞排队系统为例数据元素：数据结构：某个特定门店的排队顾客信息和它们之间的关系数据对象：全国所有门店的排队顾客信息 数据结构的三要素逻辑结构、物理结构（存储结构）、数据的运算 逻辑结构——数据元素之间的逻辑关系是什么 集合：各个元素同属一个集合，别无其他关系 线性结构：数据元素之间是一对一的关系，除了第一个元素，所有元素都有唯一前驱；除了最后一个元素，所有元素都有唯一后继 树形结构：数据元素之间是一对多的关系 图结构：数据元素之间是多对多的关系 物理结构（存储结构）——如何用计算机表示数据元素的逻辑关系 顺序存储：把逻辑上相邻的元素存储在物理位置上也相邻的存储单元中，元素之间的关系由存储单元的邻接关系来体现 链式存储：逻辑上相邻的元素在物理位置上可以不相邻，借助指向元素存储地址的指针来表示元素之间的逻辑关系 索引存储：在存储元素信息的同时，还建立附加的索引表。索引表中的每项称为索引项，索引项的一般形式是（关键字，地址） 散列存储： 根据元素的关键字直接计算出该元素的存储地址，又称哈希存储 数据的运算数据的运算——施加在数据上的运算包括运算的定义和实现。运算的定义是针对逻辑结构的，指出运算的功能；运算的实现是针对存储结构的，指出运算的具体操作步骤。 逻辑结构——线性结构（队列）结合现实需求定义队列这种逻辑结构的运算： 队头元素出队 新元素入队 输出队列长度 … 存储结构——顺序、链式顺序结构插入元素： 将新元素放到数据结构的末尾链式结构插入元素：将新元素放到任意位置，使用指针把新元素连接到数据结构末尾 数据类型、抽象数据类型数据类型：数据类型是一个值的集合和定义在此集合上的一组操作的总称。 原子类型。其值不可再分的数据类型。（int、bool） 结构类型。其值可以再分解为若干分量的数据类型（struct） 抽象数据类型（Abstract Data Type，ADT） 是抽象数据组织及与之相关的操作。ADT用数学化的语言定义数据的逻辑结构、定义运算。与具体的实现无关。只有当用计算机实际实现的时候才需要考虑使用哪种物理结构","link":"/2022/12/04/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%841%E3%80%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"},{"title":"二叉搜索树、B-树、B+树","text":"​​点击阅读更多查看文章内容 二叉搜索树二叉查找树，也称为二叉搜索树、有序二叉树或排序二叉树，是指一棵空树或者具有下列性质的二叉树： 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉搜索树； 如果二叉查找树是平衡的则查找、插入的时间复杂度为O(logn)。如果二叉查找树完全不平衡则时间复杂度为O(n)。 中序遍历二叉搜索树可以获得关键字的递增序列 二叉搜索树的查找算法在二叉查找树b中查找x的过程为： 若b是空树，则搜索失败，否则： 若x等于b的根节点的值，则查找成功；否则： 若x小于b的根节点的值，则搜索左子树；否则： 查找右子树。 二叉搜索树的节点插入算法向一个二叉搜索树b中插入一个节点s的算法，过程为： 若b是空树，则将s所指节点作为根节点插入，否则： 若s-&gt;data等于b的根节点的值，则返回，否则： 若s-&gt;data小于b的根节点的值，则把s所指节点插入到左子树中，否则： 把s所指节点插入到右子树中。（新插入节点总是叶子节点） 二叉搜索树的节点删除算法 若待删除节点*p为叶子节点则直接删除即可 若待删除节点*p只有左子树PL或右子树PR，则当*p是左子树（右子树）时直接令PL或PR成为其父节点*f的左子树（右子树） 若待删除节点*p的左子树或右子树均不为空， 其一是令*p的左子树为*f的左/右（依*p是*f的左子树还是右子树而定）子树，*s为*p左子树的最右下的结点，而*p的右子树为*s的右子树； 其二是令*p的直接前驱或直接后继替代*p，然后再从二叉查找树中删去它的直接前驱（或直接后继）。 AVL树 AVL树得名于它的发明者格奥尔吉·阿杰尔松-韦利斯基和叶夫根尼·兰迪斯，他们在1962年的论文《An algorithm for the organization of information》中公开了这一数据结构。 AVL树是一种自平衡二叉搜索树，在AVL树中任一节点对应的两棵子树的最大高度差为1，查找、插入和删除在平均和最坏情况下的时间复杂度都是O(log n)，增加和删除元素的操作则可能需要借由一次或多次树旋转，以实现树的重新平衡。 平衡因子：节点的平衡因子是它的左子树的高度减去它的右子树的高度（有时相反）。 旋转操作： 右旋 左旋 需要平衡的四种情况： B-树参考文章 B-树就是B树，中间的横线并不是减号 为什么数据库索引使用B-树而不是二叉搜索树？考虑磁盘IO的问题，数据库索引是存储在磁盘上的，当数据量比较大的时候，索引的大小可能有几个G甚至更多，当我们利用索引查询的时候只能逐一加载每一个磁盘页这里的磁盘页对应索引树的节点，最坏情况下磁盘IO次数等于索引树的高度，所以需要把原本“瘦高”的树结构变得“矮胖”，这就是B-树的特征之一。 B树是一种多路平衡查找树，每个节点最多可以包含k个孩子，k为B树的阶（k的选择取决于磁盘页大小） 一个m阶的B树具有如下几个特征： 若根节点不是叶子节点则至少有两个子节点 每个中间节点都包含 k-1 个元素和 k 个孩子，其中 ⌈m/2⌉ &lt;= k &lt;= m 每个叶子节点都包含 k-1个元素，其中⌈m/2⌉ &lt;= k &lt;= m 所有的叶子节点都位于同一层 每个节点中的元素从小到大排列，节点当中k-1个元素刚好是k个孩子包含的元素的值域分划。 B-树主要应用于文件系统以及部分数据库索引，比如著名的非关系型数据库MongoDB，大部分关系型数据库比如Mysql则使用B+树作为索引。 B树的插入操作参考博客插入操作是指插入一条记录，即（key, value）的键值对。如果B树中已存在需要插入的键值对，则用需要插入的value替换旧的value。若B树不存在这个key,则一定是在叶子结点中进行插入操作。 1）根据要插入的key的值，找到叶子结点并插入。 2）判断当前结点key的个数是否小于等于m-1，若满足则结束，否则进行第3步。 3）以结点中间的key为中心分裂成左右两部分，然后将这个中间的key插入到父结点中，这个key的左子树指向分裂后的左半部分，这个key的右子支指向分裂后的右半部分，然后将当前结点指向父结点，继续进行第3步。（ 当阶数m为偶数时，需要分裂时就不存在排序恰好在中间的key，那么我们选择中间位置的前一个key或中间位置的后一个key为中心进行分裂即可。 ） 以5阶B树为例，介绍B树的插入操作，在5阶B树中，结点最多有4个key，最少有2个key。 在空树中插入39此时根结点就一个key，此时根结点也是叶子结点 继续插入22、97、41根结点此时有4个key 继续插入53插入后超过了最大允许的关键字个数4，所以以key值为41为中心进行分裂，结果如下图所示，分裂后当前结点指针指向父结点，满足B树条件，插入操作结束。（当阶数m为偶数时，需要分裂时就不存在排序恰好在中间的key，那么我们选择中间位置的前一个key或中间位置的后一个key为中心进行分裂即可。） 依次插入13、21、40同样会造成分裂，结果如下图所示。 依次插入30、27、 33 ；36、35、34； 24、29 插入 30、27、 33 插入 36、35、34； 插入24、29 插入26当前结点需要以27为中心分裂，并向父结点进位27，然后当前结点指向父结点，结果如下图所示。进位后导致当前结点（即根结点）也需要分裂，分裂的结果如下图所示。分裂后当前结点指向新的根，此时无需调整。 最后再依次插入key为 17、28、31、32 的记录 B树的删除操作删除操作是指，根据key删除记录，如果B树中的记录中不存对应key的记录，则删除失败。 如果当前需要删除的key位于非叶子结点上，则用后继key（这里的后继key均指后继记录的意思）覆盖要删除的key，然后在后继key所在的子支中删除该后继key。此时后继key一定位于叶子结点上，这个过程和二叉搜索树删除结点的方式类似。删除这个记录后执行第2步 该结点key个数大于等于Math.ceil(m/2)-1，结束删除操作，否则执行第3步。 如果兄弟结点key个数大于Math.ceil(m/2)-1，则父结点中的key下移到该结点，兄弟结点中的一个key上移，删除操作结束。否则，将父结点中的key下移与当前结点及它的兄弟结点中的key合并，形成一个新的结点。原父结点中的key的两个孩子指针就变成了一个孩子指针，指向这个新结点。然后当前结点的指针指向父结点，重复上第2步。有些结点它可能即有左兄弟，又有右兄弟，那么我们任意选择一个兄弟结点进行操作即可。 以5阶B树为例，介绍B树的删除操作5阶B树中，结点最多有4个key,最少有2个key 原始状态 在上面的B树中删除21，删除后结点中的关键字个数仍然大于等2，所以删除结束 在上述情况下接着删除27。从上图可知27位于非叶子结点中，所以用27的后继替换它。从图中可以看出，27的后继为28，我们用28替换27，然后在28（原27）的右孩子结点中删除28。删除后的结果如下图所示。删除后发现，当前叶子结点的记录的个数小于2，而它的兄弟结点中有3个记录（当前结点还有一个右兄弟，选择右兄弟就会出现合并结点的情况，不论选哪一个都行，只是最后B树的形态会不一样而已），我们可以从兄弟结点中借取一个key。所以父结点中的28下移，兄弟结点中的26上移,删除结束。结果如下图所示。 在上述情况下接着删除32，结果如下图。当删除后，当前结点中只有一个key，而兄弟结点中也仅有2个key。所以只能让父结点中的30下移和这个两个孩子结点中的key合并，成为一个新的结点，当前结点的指针指向父结点。结果如下图所示。当前结点key的个数满足条件，故删除结束。 上述情况下，我们接着删除key为40的记录，删除后结果如下图所示。同理，当前结点的记录数小于2，兄弟结点中没有多余key，所以父结点中的key下移，和兄弟（这里我们选择左兄弟，选择右兄弟也可以）结点合并，合并后的指向当前结点的指针就指向了父结点。同理，对于当前结点而言只能继续合并了，最后结果如下所示。合并后结点当前结点满足条件，删除结束。 B+树参考文章B+树是B-树的一种变体，有着比B-树更高的查询性能一个m阶的B+树具有如下几个特征： 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）的元素 在B-树中无论是中间节点还是叶子节点都有卫星数据（牵引元素所指向的数据记录），而在B+树中只有叶子节点带有卫星数据，其余中间节点仅仅是索引，没有任何数据关联。 B+树的优点 单行查询在单元素查询的时候，B+树会自顶向下逐层查找节点，最终找到匹配的叶子节点。步骤与B-树类似，但是B+树的中间节点没有卫星数据，所以同样大小的磁盘页可以容纳更多的节点元素，在数据量相同的情况下B+树比B-树更加“矮胖”查询IO的次数也更少。其次，B+树的查询必须最终查找到叶子节点，而B-树只要找到匹配元素即可，无论匹配元素处于中间节点还是叶子节点，因此B-树的查找性能不稳定（最好情况是根节点，最坏情况是叶子节点），而B+树的每次查找都是稳定的。 范围查询B-树的范围查询只能依靠繁琐的中序遍历，B+树的范围查询只需要在链表上做遍历即可。 总结： 单一节点存储更多的元素，使得查询的IO次数更少。 所有查询都要查找到叶子节点，查询性能稳定。 所有叶子节点形成有序链表，便于范围查询。 红黑树","link":"/2024/03/14/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E3%80%81B-%E6%A0%91%E3%80%81B+%E6%A0%91/"},{"title":"【数据结构2】算法的基本概念","text":"​点击阅读更多查看文章内容 算法的基本概念 程序 = 数据结构 + 算法数据结构：如何把现实世界的问题信息化，将信息存进计算机。同时还要实现对数据结构的基本操作算法：如何处理这些信息，以解决实际问题 算法的特性 有穷性：一个算法必须总在执行有穷步之后结束，且每一步都可在有穷时间内完成。 确定性：算法中每条指令必须有确切的含义，对于相同的输入只能得出相同的输出 可行性：算法中描述的操作都可以通过已经实现的基本运算执行有限次来实现 输入：一个算法有零个或多个输入，这些输入取自于某个特定的对象的集合 输出：一个算法有一个或多个输出，这些输出是与输入有着某种特定关系的量 时间复杂度 算法时间开销T(n)与问题规模n的关系（T表示“time”） 简化（大O表示“同阶”，同等数量级。即：当n→无穷时，二者之比为常数）可以只考虑阶数高的部分 时间复杂度的大小关系： 空间复杂度空间开销（内存开销）S(n)与问题规模n之间的关系（S表示“Space”） 空间复杂度比较简单，主要分析递归函数的内存开销","link":"/2022/12/04/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%842%E3%80%91%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"},{"title":"什么是云计算？","text":"​​点击阅读更多查看文章内容 转载文章：云计算IaaS-Pssa-Saas（云计算的基本架构）、云计算服务类型都是什么？IaaS、PaaS、SaaS、BaaS、FaaS 云计算的定义美国国家标准与技术研究院（NIST）定义：云计算是一种模型，它可以实现随时随地、便捷地、随需应变地从可配置计算资源共享池中获取所需的资源（例如，网络、服务器、存储、应用、及服务），资源能够快速供应并释放，使管理资源的工作量和与服务提供商的交互减小到最低限度。 云计算的特点或优势 按需自助服务 广泛的网络接入：就是说我们要使用的资源可以使用任意一个网络连接到这个资源 资源池化：资源池化需要虚拟化来实现 快速弹性伸缩：也就是说我们可以按需的申请服务 可计量服务 计算技术的发展 串行计算传统上，一般的软件都是串行式计算，即将一个”problem”划分成一串离散的”Instructions”，每个”Instructions会在单个CPU上一个一个被执行，CPU在同一时间内只能处理一个”Instructions“ 并行计算将一个problem分解成多个可以被同时处理的part，再把每一个part划分成一串离散的instrutions,每个part把自己的instrutions交给各自的CPU进行处理，每个Cpu同时受理不同part的instrutions，再加入一个统一的控制机制对整个过程进行控制 分布式计算分布式计算属于研究分布式系统的计算机科学领域。分布式系统，是将自己的所有组件分散在属于不同网络的计算机上，这些计算机通过统一的消息机制来相互通讯和配合。分布在不同网络计算机上的组件互相协作，完成共同的目标。分布式计算与并行计算的区别：如果处理单元(处理单元也就是我们所说的CPU)共享内存，就称为并行计算，反之就是分布式计算。也有人认为分布式计算是并行计算的一种特例。其实分布式的任务包相互之间有独立性，上一个任务包的结果未返回或者处理结果错误，对下一个任务包的处理几乎没有什么影响。因此，分布式的实时性要求不高，而且允许存在计算错误(因为每个计算任务给好几个参与者计算，结果上传到服务器后要比较，然后对结果差异大的进行验证)。而并行程序并行处理的任务包相互之间有很大的联系，并且并行计算的每一个任务块都是必要的，没有浪费的分割的，就是每个任务包都要处理，而且计算结果相互影响，这就要求每个计算结果要绝对正确，而且在时间上要尽量做到同步，而分布式的很多任务块可以不用处理，比如大量的无用数据块，所以说分布式计算的速度尽管很快，但是真正的“效率”是低之又低的， 网格计算网格计算是利用广泛的零散的计算资源完成一个共同任务，它也是分布式计算的一种。根据IBM对“网格”的定义，它将本地网络或者互联网上零散的可用计算资源集合起来，使终端用户或者应用觉得他们在使用一台性能强悍的虚拟计算机。网格计算的愿景是创立一个虚拟动态的资源集合，使个人和组织机构能够安全协调的使用这些资源。网格计算通常使用集群的方式实现。 按运营模式对云计算分类 公有云由一个实力特别强大的厂商构建，因为公有云需要在全球部署数据中心结点，大型服务商将自己的资源提供给用户，例如：AWS是亚马逊提供的公有云业务 私有云也就是一个公司自己搭建的一个云，阿里，腾讯不提供私有云，华为提供私有云，当然还有一些其他公司提供私有云 混合云混合云是一种比较灵活的云计算模式，它可能包含了公有云、私有云或者后面要讲的行业云中的两种或两种以上的云，用户的业务可以根据需求在这几种云上切换。 行业云运输行业云，金融行业云，医药行业云等 按服务模式对云计算分类云计算服务主要有 3 种：基础架构即服务（IaaS）、平台即服务（PaaS）和软件即服务（SaaS） 对比传统服务器和VPS说到云，自然想到与传统服务器的对比。传统服务器需要自己从硬件采购做起，然后需要搭网线，处理各种基础设施，安装服务器操作系统，然后才是开发软件，安装软件。而人类社会的分工，自然是把专业的事情交给专业的人，然后专注自己所需要关心的事情。因此就出现了VPS，也可以理解为云服务的萌芽，Virtual Private Server，虚拟专用服务器。也就是有人管理了这个机房，然后把机器按性能虚拟成不同的主机，租用给别人使用，主要是个基础硬件层面的事情。VPS和云服务的对比可以看此文。 云服务将服务器需要做的事情做了更细的划分，并且提供了大量的多种多样的服务，可以按需使用。同时具有弹性扩容，数据备份恢复，分布式计算，服务器安全等特点。 IaaS（基础架构即服务）Infrastructure as a Service，基础设施即服务。基本上一图就可以看懂IaaS。IaaS就是由云服务提供商，提供底层/物理层基础设施资源（服务器，数据中心，环境控制，电源，服务器机房），客户自己部署和执行操作系统或应用程序等各种软件。最常见的形式，就是在阿里云、腾讯云、AWS上购买购买ECS云服务器等。 PaaS（平台即服务）Platform as a Service，平台即服务。PaaS处于中间层，服务商提供基础设施底层服务，提供操作系统（Windows，Linux）、数据库服务器、Web服务器、域控制器和其他中间件，以及服务模型中的备份服务等中件层服务，例如IIS，.NET，Apache，MySQL等。客户自己控制上层的应用程序部署与应用托管的环境。一些大的PaaS提供者有Google App Engine,Microsoft Azure，Force.com,Heroku，Engine Yard。最近兴起的公司有AppFog,Mendix和Standing Cloud. 为什么选择PaaS SaaS（软件即服务）SoftWare as a Service，软件即服务（SaaS）是一种软件许可模式，以订阅的方式提供对软件的访问，软件位于外部服务器上，而不是位于内部的服务器上。软件即服务 “通常通过网络浏览器访问，使用账号和密码登录系统。每个用户不必在他们的计算机上安装软件，就能够通过互联网访问该程序。软件即服务（SaaS）是一种软件许可模式，它允许使用外部服务器以订阅方式访问软件: SaaS允许每个用户通过互联网访问程序，不必在用户的电脑上安装软件。 SaaS方便实施、更新和调试，而且成本较低，因为用户在使用时支付SaaS的系统服务费，而不是为多台电脑购买多个软件许可证。 采用SaaS的缺点集中在数据安全、交付速度和缺乏控制方面。","link":"/2022/05/25/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%91%E8%AE%A1%E7%AE%97%EF%BC%9F/"},{"title":"函数调用时的堆栈变化（实例）","text":"​​点击阅读更多查看文章内容 函数调用时的堆栈变化关于函数调用是的堆栈变化，在网上找到的资料大都是一些配图文字等，理解起来尚有些困难，不过建议大家还是先了解一下基本的原理，下面我主要通过一个调用函数的实例来讲解一下函数调用时的堆栈变化（Ps：图片有点糊，大家最好自己跟着做一遍叭） 测试函数如下： 1234567891011121314#include &lt;iostream&gt;int add_1912080143(int x, int y){ int z = 0; z = x + y; return z;}void main(){ int n = 0; n = add_1912080143(1, 3); printf(&quot;%d\\n&quot;, n);} 1. 在VC++6.0中新建项目将函数代码复制上去 2.在函数调用处下断点，按F5进行调试 3.点击图示按钮查看程序的汇编代码 4.对汇编代码进行简单的分析 int n = 0 的汇编代码为 mov dword ptr [ebp-4],0 这里n为局部变量所以在栈中存储，ebp为基址支持寄存器存储的是栈帧的起始地址 F10单步执行程序push 3, push 1这里是将调用函数的两个参数从右到左依次入栈 继续F10单步执行，这里先不进入函数分析函数执行完之后的代码 add esp,8 这里是因为前面向栈中push了两个参数每个int占4字节，所以将esp（栈顶指针）加8个字节恢复到push参数之前的状态（注意：向栈中加数据是从高地址向低地址移动），mov dword ptr [ebp-4],eax将函数的返回值赋值给n，eax寄存器用来保存函数的返回值，[ebp-4]是n的值（这里的ebp是不变的因为在调用函数的时候会保存现场，具体过程可以看下面进入函数后的代码分析） 5.对进入函数后的汇编代码进行分析 在call指令处按F11进入函数，这里注意一下执行完函数后的下一条指令的地址00401098 按下F11后程序并没有立即跳转到代码区，我们查看查看一下栈中的内容，可以看到栈顶的数据为00401098（这里的存储方式采用小端存储注意顺序），而这正是执行完函数后的下一条指定的地址，由此我们判断这一步执行的操作时将程序执行完后的下一条指令地址入栈 F10继续执行来到代码区，首先将四个寄存器的值入栈保护现场，当函数执行完的时候再出栈，这也就是为什么4.3步中ebp的值不变的原因，然后mov ebp,esp sub esp,44h是为add函数开辟一段大小为44h的栈帧，ebp是栈帧的基址，esp为栈顶指针，这里add函数与main函数的栈帧是连续的，esp是main函数的栈顶指针所以可以将esp的值直接赋给ebp作为add函数栈帧的基址 接下来的四条语句为初始化栈帧的操作，ebp-44h为esp的值，ecx通常用来计数，下面还有一条rep循环指令，这四条语句最终的效果就是将add栈帧的值全都初始化为CCh 接下来分析程序执行时的三段语句第一段语句是局部变量的声明，ebp为add函数栈帧的基址，所以直接ebp-4的地址分给变量z第二段语句中[ebp+8]和[ebp+0ch]存储的都是最开始入栈的函数参数的值，这一步的结果存在eax中，然后将eax的值返回给[ebp-4]也就是变量z（ebp+和参数相关，ebp-和局部变量相关）第三段语句因为函数的返回值通常保存在eax寄存器中，而这个函数返回的是变量z，所以将变量z的值赋给eax 最后一部分为恢复现场，与函数最开始保护现场的部分一一对应，ebp的值赋给esp 附录lea指令的用法rep和stos指令的用法","link":"/2022/05/06/%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%97%B6%E7%9A%84%E5%A0%86%E6%A0%88%E5%8F%98%E5%8C%96%EF%BC%88%E5%AE%9E%E4%BE%8B%EF%BC%89/"},{"title":"区块链学习笔记10——BTC问答","text":"​​点击阅读更多查看文章内容 区块链学习笔记10——BTC问答 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 转账交易时候，如果接收者不在线(没有连在比特币网络上)怎么办？ 转账交易只需要在区块链上记录，将某账户比特币转到另一账户，而接收方是否在线并无影响。 假设某全节点收到某个转账交易，会不会有可能转账交易中收款人地址该全节点从未听过? 可能，比特币账户在创建的时候不需要通知其他人，在本地产生一个公私钥对就可以了，只有在它第一次收到钱的时候，其他节点才知道这个节点的存在 如果账户私钥丢失该怎么办？ 私钥丢失的话没有办法，里面的钱就永远取不出来了。 因为比特币是去中心化货币，没有第三方中心机构可以验证你的身份帮你重置密码，所以账户上的钱也就变成了死钱。 通过加密货币交易所(中心化机构)，一般需要提供身份证明，这种情况下把比特币保存在交易所里，那么私钥实际上是交易所保管的，如果忘记私钥可以找交易所申请追回私钥。但目前这类货币的交易所，尚且处于缺少监管的状态，并不一定具有可信力。而且，其本身仅起到“中介”作用，与该提问的回答“私钥丢失无法追回里面的比特币”并不冲突。 在历史上，有很多次交易所被黑客攻击偷走大量加密货币的事情，其中最著名的为Mt. GOX（中文译为：门头沟）事件。该交易所曾经为全球最大比特币交易所，交易量占到全球比特币交易量的70%左右，设于日本。后来由于被攻击丢失大量比特币，导致交易所破产，其CEO被判刑入狱。此外，也有交易所监守自盗，工作人员卷款跑路 私钥泄露怎么办？（如发现自己的账户上出现了可疑的交易） 尽快把账上的钱转到另一个安全账户上 产生账户的公私钥对无法更改，任何有私钥的人都可以把账户上的钱转走，是没有办法冻结的 转账填错地址怎么办？（地址是账户公钥的哈希）没有办法，只能自认倒霉，无法取消已经发布的交易。如果转入不存在地址，则该部分比特币便成为了死钱。当然，比特币系统中UTXO会永久保存该交易，记录该并不存在的地址。因此，对全节点来说，这是不友好的。 之前在BTC脚本中介绍了OP_RETURN指令，我们提到，这种方法为普通用户提供了一个向比特币网络中写入想要一直保存的内容。但OP_RETURN执行结果是无条件返回错误，而交易返回错误，区块又怎么会包含它？区块链又如何会接收这个区块？OP_RETURN是写在这个交易的输出脚本中，而验证这个交易是把这个交易的输入脚本和输入来源的输出脚本拼接在一起验证，也就是说验证这个交易的时候不会执行到这个语句，只有想花掉这笔钱的时候才会执行这个语句。 BTC系统挖矿，会不会有矿工“偷”答案？例如：某个矿工发现其他矿工发布了nonce，收到后验证该区块合法，将该nonce作为自己找到的nonce发布出去。实际上这是不可能的。发布的区块中包含铸币交易，其收款人地址为挖到矿的矿工地址，如果要偷答案，需要修改该收款地址，而地址改变，铸币交易内容也发生改变，从而引发Merkle Tree根哈希值改变。从而导致原本的nonce作废。也就是说，不可能会“偷”答案。每个矿工挖到的nonce是与他的地址绑定在一起的。 交易费是交易者为了自己交易可以上链而给出的“小费”，那么如何得知哪个矿工可以挖到矿？ 事先无需知道谁会挖到矿，交易中总输入和总输出差额就是交易费。哪个矿工挖到矿，在打包交易时，可以将这些交易费收集起来作为自己获得的交易费。 比特币的一些统计数据（均截止到2018年） 区块链的大小变化 因为区块链只能添加，不能删除。对于当前硬盘内容来说，保存其没有问题。 UTXO集合的大小交易增多，私钥丢失等都会导致UTXO增大。 矿池情况几个大的矿池占了比特币系统中很大一部分 BTC价格变化 市值变化与价格变化基本一致 交易量 交易数目 每个区块的交易数量每天产生区块数量基本差不多，所以交易数目变化基本和区块包含交易数目变化趋势一致。可以看到，理论上限为每个区块可包含4000个交易，而该图中并远未达到上限。所以很多人说到的1MB区块太小，另一方面真实的区块链上很多区块没有装满。","link":"/2022/01/14/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B010%E2%80%94%E2%80%94BTC%E9%97%AE%E7%AD%94/"},{"title":"区块链学习笔记11——BTC匿名性+零知识证明","text":"​​点击阅读更多查看文章内容 区块链学习笔记11——BTC匿名性 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 一般来说,匿名性多与隐私保护相关。但实际上，比特币中的匿名并非真正的匿名，而是假的匿名。实际上，比特币与纸币相比，纸币的匿名性更好，因为其并没有对个人信息的标记。也正是因为其匿名性，很多非法交易采用现金交易。但现金存在保管、运输等各个方面的不便。实际上，比特币中的数据是完全公开的，任何人都可以下载区块链上的完整交易，而网上的交易是要与实体世界进行交易的（例如用比特币在现实世界中买东西），所以大大破坏了其匿名性。假如银行允许用假名(以前的存折时代)，由于银行数据并非公开，所以银行系统的匿名性是要比比特币更好的。 BTC系统中什么情况会破坏其匿名性？ 用户可以生成多个账户，但这些账户可能被关联起来表面上看，每次交易可以更换公私钥对，从而每次都是新的账户，具有很强的匿名性。但实际上，这些账户在一定情况下，是可以被关联起来的。 例如下图，针对这样一个交易：如图，该交易有两个输入和两个输出，这两个输入很可能就是同一个人的账户，因为一个账户中的钱不够，而在两个输出中，有一个可能是找零的输出，即花掉之后剩余的钱，又转给自己的另一个账户如上图，针对该交易，账户上面数字表示BTC，可以看出addr4明显是找零的地址（如果addr4是交易地址的话不需要两个输入） 地址账户与个人在真实社会中的身份也可能会产生关联。任何使得BTC和实体世界中关联的操作都有可能泄露用户真实身份，其中最明显的就是资金的转入转出。要得到BTC，如果用钱买，就会与实体世界进行交互。想要将BTC转为现实中的货币，也同样需要与实体世界交互。 BTC支付的时候例如某些商家接受用BTC进行支付，例如可以用BTC购买咖啡、蛋糕等。(用BTC交易延迟高（等六个确认要一个小时），交易费贵，并非一个好的idea)在进行支付时候，便和个人账户建立了联系，从而会泄露掉个人信息。 假如有人知道你在某个时间用BTC进行了支付，他可以去区块链上查这个时间的所有交易，如此重复多次，他就可以定位到哪些账户是你的 匿名性保持最好的人：中本聪，因为他从来没有花过自己的比特币，如果他要花自己的比特币就要将其换为法定货币（如：日元），这就会暴露他的真实身份 如何提高匿名性？ 匿名的本质是不想要暴露身份。而对于普通人来说，BTC的现有机制已经足够保持个人隐私了。但如果涉及违法，行政机关想要获得真实身份，其实很容易。 应用层：把不同的人的币混在一起（coin mixing），让其他人分不清楚币是从哪来的。网络层：采用多路径转发的方法，不是直接发送出去，而是经过很多跳，中间的每个结点只知道上一个结点，不知道最初的结点是谁（洋葱路由） 保护匿名性的难度很大，本质上是因为区块链是公开的，而且是不可篡改的，一旦你某个交易把身份暴露出去了，这个交易会永久的写在区块链中 零知识证明 零知识证明是指一方（证明者）向另一方（验证者）证明一个陈述是正确的，而无需透露陈述是正确的外的任何信息。 例如：A想要向B证明某一账户属于A，这说明A知道该账户的私钥。但不可能通过A公布私钥的方法来证明，该账户确实属于A。因此，A可以产生一个账户签名，B通过公钥对签名进行验证。(实际上该证明是否属于零知识证明存在争议，因为泄露了用私钥产生的签名) 同态隐藏 不会产生碰撞，如果E(X)=E(y)，则必然有x=y 加密函数不可逆 最为重要，称为同态运算。说明对加密后的函数值进行某些代数运算，等价于对输入直接进行代数运算再加密。 例子： 盲签盲签名是一种特殊的数字签名技术。盲签名因签名的人看不到所签署文件的具体内容而闻名，它有两个显著的特点：一是签名者对消息的内容是不可见的 ;二是签名被公开后，签名者不能追踪签名。银行把货币给A的时候，编号是A自己产生的，且没有告诉银行，银行只知道给了A一个币，是哪个编号的币不知道，A把这个币转给B，B给银行验证的时候（防范double spending，这个序号的币是不是被花过），银行也不知道这个币是从哪来的 零币和零钞零币存在一种基础币（比如说比特币）和零币，用的时候证明你本来是有基础币的，然后把基础币变得不能花了，换取一个零币。零币在花费的时候，只需要用零知识证明来证明所花掉的币是系统中存在的某一个合法的币，但不用透露具体花掉的是系统中哪一个币。这样就破坏了关联性。当然，这类货币并非主流加密货币，因为其为了设计匿名性，付出了一定代价，而且，需要强匿名性的用户并不多。从数学上看，零币和零钞是安全的。但其并不是百分之百的匿名，其并未解决与系统外部实体发生交互时对匿名性的破坏。","link":"/2022/01/14/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B011%E2%80%94%E2%80%94BTC%E5%8C%BF%E5%90%8D%E6%80%A7+%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/"},{"title":"区块链学习笔记12——BTC思考","text":"​​点击阅读更多查看文章内容 区块链学习笔记12——BTC思考 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 哈希指针BTC系统中很多地方用到了哈希指针，比如区块的块头就包含指向前一个区块的哈希指针。指针保存的是本地内存的地址，只在本地的计算机上有意义，发送给其他计算机就没意义了。那么在发布区块的时候，哈希指针是如何通过网络进行传播？ 所谓的哈希指针，只是系统中一种形象化的方法。实际应用的时候，只有哈希而没有指针。回顾一下之前提到的Block header的数据结构：图示位置即为前一个区块的哈希因此可见，在block header中只有hash值，没有指针。那么如何查找到前一个区块的内容？全节点一般将区块存储于一个key-value数据库中，key为哈希，value为区块内容。常用的key-value数据库为levelDB，所谓的链式结构实际上就是在levelDB中通过哈希值串连起来的，只要掌握了最后一个区块的哈希值，就可以根据levelDB把最后一个区块的内容取出来，然后这个区块的块头中又有指向前一个区块的哈希值，以此类推，最终就能把整个区块链都找出来。有些节点只保存最近的区块链的部分信息，如果需要用到前面的区块，可以问其他的全节点要。哈希指针性质保证了整个区块链内容是不可篡改的。 区块“恋”有情侣一起买BTC，将私钥从中截断，每人保留其中一部分。如果未来两人依旧感情很好，就可以将钱取出；如果分手，这部分钱就会永久锁死，谁也无法取出，通过区块链的不可篡改性作为两人的爱情见证。这样做有什么问题？ 如此下来，N个人怎么办？如果按照这种方法，将私钥分为N份。但这样会有一系列问题。一. 如果N个人中任意一个人忘记私钥，则无法将钱取出。二.截断私钥长度，会降低安全性，因为私钥长度会直接影响破解难度(假如一共四个人，其中三个人串通起来，他们只需要尝试2^64^种可能就可以破解)，对于多个人的共享账户不要用截断私钥的方式，用多重签名。三.如果分手，该钱变成死钱，一直保存在UTXO集合中，对矿工不友好。 分布式共识为什么比特币系统能够绕过分布式共识中的那些不可能结论？严格地说比特币并没有达成真正意义下的共识，因为取得的共识随时都有可能被推翻。比如：分叉攻击，本来你以为已经达成了某个共识，分叉攻击后系统会回滚到前一个状态。理论上甚至可能一直回滚到创世区块按照分布式共识理论的要求，共识一旦达成后就不应该再改了，从这点来看，比特币并没有绕过分布式共识中那些不可能的结论。 发明比特币的中本聪应该不是学术界出身，否则他不会设计出像比特币这样的系统搞科研是很有意义的，但是不要被学术界的思维限制头脑，不要被程序员的思维限制想象力 比特币的稀缺性为什么要挖矿？因为有收益，且收益大于开销。早期BTC难度低且出块奖励高，从而吸引矿工。之前有提到，BTC总量固定，有人认为其是一个精妙的设计。但实际上，总量固定的东西并不适合作为货币，这也就决定了BTC并不能在未来完全颠覆现有货币体系。以太坊中便没有BTC中出块奖励定期减半的做法，此外，某些新型货币会自带通货膨胀的功能。对个人来说，通货膨胀并非好事，因为钱不值钱了。但人类每年创造的价值在增多，如果用总量固定的东西作为货币，则其只会越来越值钱，而这会导致拥有者不断看着其升值，其他没有的人无论如何奋斗都赶不上（房市也是如此，炒房使一部分人靠房租便可大赚特赚，个人奋斗却很难买房。这也是我国目前存在的较大的问题，社会财富的分配不公，最终引发各种社会矛盾，需要政府解决）。 量子计算比特币这种建立在密码学上的加密货币，在量子计算出来后会不会变得不安全。 量子计算距离使用仍然有很长距离（在BTC的有生之年，不一定会产生实质性的威胁） 量子计算若真正强大到破坏现有加密体系的话，首先冲击的是传统金融业。 比特币使用非对称加密体系，通过私钥是可以推导出公钥的，公钥推不出私钥。假如量子计算发达之后，能够从公钥推出私钥的话，比特币又加了一层保护，实际中使用的并非公钥，而是用公钥的哈希。所以如果有人想偷你账户里的钱的话首先要通过地址推导出你的公钥。相当于把公钥的哈希进行逆运算推导出公钥的本身，这一点即使是量子计算机也没法完成。（在取哈希的时候本身就会有信息的丢失，BTC中用的SHA-256，无论输入多大，最终结果都为256位，必然会导致信息丢失，无法反推原本数据。） 收钱只需要提供公钥的哈希，取钱才需要公钥和私钥产生的签名，如果有人监听到你取钱的交易，知道你的公钥是什么，他要偷你的钱，他需要实时的从你的公钥推导出你的私钥，然后产生一个和你竞争的交易，你要把钱转到你的账户，他要把钱转到他的账户，即使是量子计算机，也很难在几分钟之内把你的私钥破解了，而且他发布的交易还要抢在你之前，因为一旦你把钱转走了，他的交易就没用了，属于double spending。所以从安全性的角度来看，地址一旦用过之后就不要再用了。每次取钱最好一次性都取走。除了支付给别人的钱，剩下的钱可以转给自己的另一个账户，这样不但提高了安全性，也提高了隐私保护的程度","link":"/2022/01/15/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B012%E2%80%94%E2%80%94BTC%E6%80%9D%E8%80%83/"},{"title":"区块链学习笔记13——ETH以太坊概述","text":"​​点击阅读更多查看文章内容 区块链学习笔记13——ETH以太坊概述 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 比特币和以太坊是两种最主要的加密货币，比特币被称为区块链1.0，以太坊被称为区块链2.0，以太坊在设计上针对比特币进行了改进比如：出块时间降低到了十几秒，而且为了适应这种新的出块时间还设计了一套基于Ghost协议的共识机制；mining puzzle也有不同，比特币的mining puzzle是计算密集型的，比拼的是计算哈希值的算力，这样会使得挖矿设备专业化（asic芯片矿机，与去中心化理念不符合），所以以太坊设计的mining puzzle对内存的要求时很高的，一定程度上限制了ASIC芯片的使用；未来，以太坊还会用权益证明替代工作量证明，用类似于股份投票的方法决定下一个区块的产生以太坊还增加了一个重要的功能——对智能合约的支持 为什么要开发智能合约（smart contract）比特币是一种去中心化的货币，那么还有什么是可以去中心化的呢？以太坊的一个特性就是增加了对去中心化的合约的支持。 BTC和ETH，以太坊的货币叫做以太或以太币；BTC最小的计量单位为聪（Satoshi）ETH中最小的计量单位为“Wei” 去中心化的合约首先，讨论去中心化货币。货币本身由政府发行，货币的价值建立在政府公信力的基础上，政府通过司法手段维护货币体系的正常运行，BTC的出现，通过技术手段取代了政府的职能。去中心化的合约也是类似的意思现实生活中，合约的有效性也是需要政府进行维护的，如果合同产生纠纷可以通过打官司，法院判决等手段来维护合同的有效性。ETH的设计目的就是，通过技术手段来取代政府对于合约的职能。如果合同的内容可以通过代码实现，我们可以把这个代码放到区块链上，通过区块链的不可篡改性来保证代码的正确运行。但是，不是所有的合同内容都是可以通过编程语言实现的，也不是所以的合同条款都是可以量化的。只有内容比较简单，逻辑比较清晰的才可以写成智能合约的形式。 去中心化的合同有什么好处去中心化的货币：跨国转账智能合约：合同的签署方来自世界各地，没有统一的司法管辖，用司法手段维护合法性就比较困难（如：众筹，可能互相都不认识。实际上，就算大家都认识，解决合同纠纷仍然是一件费时费力的事情）。智能合约的好处就在于，代码一旦发布到区块链上，任何人都无法修改这个代码，所有人只能按照代码的规则执行，这样就不会有违约的发生。","link":"/2022/01/16/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B013%E2%80%94%E2%80%94ETH%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%A6%82%E8%BF%B0/"},{"title":"区块链学习笔记15——ETH状态树","text":"​​点击阅读更多查看文章内容 区块链学习笔记15——ETH状态树 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 在以太坊中，有三棵树的说法，分别是状态树、收据树和交易树。了解了这三棵树，就弄清楚了以太坊的基础数据结构设计。 引入要实现的功能：地址到状态的映射ETH的账户地址是160位的，一般表示成40个十六进制数状态就是外部账户和合约账户的状态，包括余额、交易次数，合约账户还有代码和存储。 数据结构的组织形式 直观上地址到状态的映射用哈希表存储比较简单，为什么不用哈希表存储呢？用哈希表如何提供Merkle Proof？将哈希表内容组织为一颗Merkle tree像比特币一样提供Merkle Proof，但是当新区块发布时，哈希表内容会改变，我们需要再次将其组织为新的Merkle Tree，这样的话，每当产生新区块(ETH中新区块产生时间为10s左右)，都要重新组织Merkle Tree，这样的代价是很大的，实际上发生变化的账户只有新交易所关联的那一部分。需要注意的是，比特币系统中没有账户概念，交易由区块管理，而区块包含上限为4000个交易左右，每次发布一个区块对应一棵新的Merkle tree，一旦发布是不会改变的，所以Merkle Tree不是无限增大的。而ETH中，Merkle Tree用来组织账户信息，是要把所有的以太坊账户一起构建一个Merkle tree，这个数目比BTC中的Merkle tree会大好几个数量级。实际中，发生变化的仅仅为很少一部分数据，我们每次重新构建Merkle Tree代价很大 能不能不用哈希表，直接用Merkle tree，改的时候直接在Merkle tree里改？Merkle tree没有提供一个高效的查找和更新的方法。为了保证所有节点的一致性和查找速度，必须进行排序。如果以太坊不排序的话，每个全节点维护的账户顺序不一样那么计算的Merkle tree的根哈希也是不一样的，比特币系统中虽然没有进行排序，但是交易的顺序是由发布区块的结点确定的，顺序是唯一的。如果以太坊要想实现的话必须把所有账户的状态也发布到区块上，数量级很大是不可行的。 如果用排序的Merkle tree会有什么问题？插入账户的话代价很大 综上所述，以上两种简单的数据结构均是不可行的，实际中以太坊采取的数据结构是MPT。 简单的数据结构——trie trie：字典树，边代表字母，从根结点到树上某一结点的路径就代表了一个字符串 特点： 每个结点的分支数目取决于Key值中每个元素的取值范围图例中的分支数目为27（最多26个小写的英文字母+一个结束标志位）；以太坊中的地址为40个十六进制数，所以分支数目为17（16个十六进制数+一个结束标志符） 查找效率取决于key值的长度，以太坊中所有的键值是相同长度，都是40位16进制数Ps：比特币和以太坊的地址是不通用的，格式长度均不同，以太坊的地址是公钥取哈希从前面截取一段（160bit）得来的 哈希表存储理论上是会出现哈希碰撞的，trie是不会出现碰撞的 给定一组输入构成的trie是相同的，与顺序无关 更新的局部性比较好，只需要更改元素所属的分支即可 缺点： 存储浪费，很多中间节点都只有一个子节点，如果能将其合并，可以减少存储的开销，同时提高了查找的效率。因此，为了解决这一问题，我们引入Patricia tree/Patricia trie。 Patricia tree 经过了路径压缩的前缀树 需要注意的是，如果新插入单词，原本压缩的路径可能需要扩展开来。路径压缩在什么情况下效果比较好：键值分布比较稀疏 Trie:Patricia tree: 以太坊的地址是160bit的，共有2^160^种，是非常稀疏的，这样可以避免产生碰撞，这是去中心化系统防止产生碰撞的唯一办法。 MPT——Merkle Patricia treeMerkle tree与binary tree的区别：把普通指针转为哈希指针 Merkle Patricia tree：所有账户组织成一棵Patricia tree，用路径压缩提高效率，然后把普通指针换成哈希指针，这样就可以计算出一个根哈希值。（比特币的block header中只有一个根哈希值，就是区块中包含的交易组成的Merkle tree的根哈希值；以太坊中有三个） 这个根哈希值的作用： 防篡改 Merkle proof，证明账户余额 证明账户不存在，如果存在的话应该存在哪个分支上，将这个分支作为Merkle proof发送，可证明其不存在 实际用到的MPT——Modified MPT每次发布新区块，状态树中部分节点状态会改变。但改变并非在原地修改，而是新建一些分支，保留原本状态。如下图中，仅仅有新发生改变的节点才需要修改，其他未修改节点直接指向前一个区块中的对应节点。合约账户的存储也是MPT形式保存，也是用一棵MPT，以太坊的结构是一棵大的MPT包含很多小的MPT，每一个合约账户的存储都是一个小的MPT所以，系统中全节点并非维护一棵MPT，而是每次发布新区块都要新建MPT。只不过大部分节点共享。 为什么要保留历史状态？系统中有时会出现分叉，出块时间降到十几秒，临时性的分叉是很普遍的。保留历史状态为了便于回滚。如下图1中产生分叉，而后上面节点胜出，变为2中状态。那么下面节点中状态的修改便需要进行回滚，将这个结点的状态取消掉，退回到上一个区块，然后沿着上一个链向后推进。因此，需要维护这些历史记录。比特币中的交易可以通过简单的反向交易退回到之前的状态，但是以太坊中有智能合约的存在，一旦执行完后就无法推算出之前的状态，所以要想回滚必须保存历史状态。 以太坊中代码的数据结构区块头的结构：区块的结构：区块在网上真正发布时的信息： value的存储 状态树中保存的是（key,value）key就是地址，value是经过RLP(Recursive Length Prefix)编码做序列化之后再存储RLP的特点：简单，只支持一种类型——nested array of bytes","link":"/2022/01/18/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B015%E2%80%94%E2%80%94ETH%E7%8A%B6%E6%80%81%E6%A0%91/"},{"title":"区块链学习笔记14——ETH账户","text":"​​点击阅读更多查看文章内容 区块链学习笔记14——ETH账户 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 基于交易的账本BTC系统是基于交易的账本，系统中并没有显式的记录账户有多少钱，要根据UTXO的信息推算，这种模式的好处是隐私保护比较好，但使用上是比较别扭的，跟日常体验不太一样。如A要转给B十个比特币，A要说明这十个币的来源是哪个交易。通过银行的交易是存钱的时候说明钱是哪来的，花钱的时候不需要说明。另外，在前面交易中收到的币在花的时候必须一次性全花出去，不能只花一部分。 如下图这样的话，七个比特币会以手续费的形式交给矿工。所以必须要把剩下的七个比特币转给自己的另一个账户。 基于账户的账本以太坊系统采用的是基于账户的模型，系统会显式的记录每个账户上有几个以太币A要转给B十个以太币，只需要查看A是否有足够的余额就可以了，不需要说明币的来源。同时也不需要一次性全部转账。这种模式对double spending attack有天然的防范，因为它不用管币的来源，每花一次钱就扣一次。这种模式也存在缺点，就是重放攻击，A向B转账，过一段时间，B将A的交易重新发布，从而导致A账户被扣钱两次。在比特币中这是显然的double spending。以太坊中通过为交易添加计数器来解决，记录这个账户一共发布过多少交易，转账的时候这个计数器作为交易内容的一部分一起包含进去，都受到发布交易者签名的保护。系统中的结点维护A的状态，不光维护A的余额，还要维护计数器的值（初始为0，每次收到一个交易就加1），如果有人重放这个交易，发现交易的计数器的值和当前维护的值相等（正常应该是维护的值加一）就不会再执行这个交易了。 以太坊的账户类型以太坊中存在两类账户，一类是外部账户，一类是合约账户外部账户：类似于比特币的账户，本地产生公私钥对，谁有私钥谁就有账户的控制权。外部账户的状态：balance（账户余额），nonce（交易计数器）合约账户：一个合约可以调用另外一个合约，同样需要nonce记录调用的次数，但是，合约账户不能主动发起交易，所有的交易只能通过外部账户发起，外部账户可以发起交易调用一个合约账户，这个合约账户可以调用另外一个合约账户。合约账户状态：除了balance和nonce之外还有code(代码)、storage(存储) 合约账户的调用：创建合约的时候会返回一个地址，知道这个地址就可以调用这个合约 为什么要设计以太坊这种新的模型，而不是沿袭BTC系统？比特币基于交易的模型隐私保护比较好，但是以太坊要支持智能合约，要求参与者有比较稳定的身份，","link":"/2022/01/17/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B014%E2%80%94%E2%80%94ETH%E8%B4%A6%E6%88%B7/"},{"title":"区块链学习笔记16——ETH交易树和收据树","text":"​​点击阅读更多查看文章内容 区块链学习笔记16——ETH交易树和收据树 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 交易树和收据树每次发布区块，区块中的交易会组织成一棵交易树，也是一棵Merkle tree与比特币类似每个交易执行完之后会产生一个收据，记录交易的相关信息，交易树和收据树的结点是一一对应的。由于以太坊智能合约执行较为复杂，通过增加收据树，便于快速查询执行结果。 数据结构交易树和收据树都是MPT，而BTC中都采用普通的MT，MPT的好处是支持查找操作，通过键值沿着树进行查找即可。对于状态树，查找键值为账户地址；对于交易树和收据树，查找键值为交易在发布的区块中的序号，序号由发布区块的结点决定。交易树和收据树只把当前发布区块的交易组织起来，而状态树是把系统中所有账户的状态包含进去，无论这些账户是否与当前区块中交易有关系。多个区块状态树共享节点，只会为更改了状态的结点新建一个分支，而交易树和收据树依照区块独立。 交易树和收据树的作用 提供Merkle proof 更加复杂的查找操作(例如：查找过去十天与某个智能合约有关的交易；过去十天的众筹事件等) Bloom filter支持较为高效地查找某个元素是否在某个比较大的集合中最笨：元素遍历，复杂度为O(n)，且轻节点没有存储交易列表不能使用Bloom filter的思想：给一个大的集合，计算出一个非常紧凑的“摘要” 例：如下图，给定一个数据集，其中含有元素a、b、c，通过一个哈希函数H()对其进行计算，将其映射到一个初始全为0的向量的某个位置，将该位置置为1。将所有元素处理完，就可以得到一个向量，则称该向量为原集合的“摘要”。可见该“摘要”比原集合是要小很多的。假定想要查询一个元素d是否在集合中，假设H(d)映射到向量中的位置处值为0，说明d一定不在集合中；假设H(d)映射到向量中的位置处为1，有可能集合中确实有d，也有可能因为哈希碰撞产生误报。Bloom filter特点：有可能出现误报，但不会出现漏报。Bloom filter变种：采用一组哈希函数进行向量映射，有效避免哈希碰撞Bloom filter不支持删除操作，有产生碰撞的可能 ETH中的Bloom filter每个交易完成后会产生一个收据，收据中会包含一个Bloom filter，记录这个交易的类型、地址等其他信息，在发布的区块的block header中也包含一个总的Bloom filter，其为该区块中所有交易的Bloom filter的一个并集。 要查找过去十天发生的与智能合约相关的所有交易查找时候先查找哪个块头中的Bloom filter有要查找的交易类型，如果块头中没有，则这个区块就不是我们要找的，如果块头有的话，我们继续查找这个区块所包含的交易的收据树中的Bloom filter，如果存在，再查看交易进行确认；如果不存在，则说明发生了“碰撞”。 好处：通过Bloom filter这样一个结构，快速大量过滤掉大量无关区块，从而提高了查找效率。 补充以太坊的运行过程，可以视为交易驱动的状态机，状态机的状态是状态树的内容，交易是每次发布的区块所包含的交易，通过执行当前区块中包含的交易，驱动系统从当前状态转移到下一状态。BTC我们也可以视为交易驱动的状态机，其状态为UTXO。 问题1：A转账到B，有没有可能收款账户不包含再状态树中？可能。因为以太坊中账户可以节点自己产生，不需要通知其他人，只有在产生交易时才会被系统知道，此时在状态树中会新插入一个结点。问题2：可否将每个区块中状态树更改为只包含和区块中交易相关的账户状态？(大幅削减状态树大小，且和交易树、收据树保持一致)不能。首先，这样设计要查找账户状态很不方便，因为不存在某个区块包含所有状态，在转账的时候因为要查找相关账户的状态信息，需要从区块依次往前查找这个账户的信息，如果这个账户很久没有参与交易的话会需要往前查找很多区块，其次，如果要向一个新创建账户转账，因为需要知道收款账户的状态，才能给其添加金额，但由于其是新创建的账户，所以需要一直找到创世纪块发现根本不存在这个账户，才能知道该账户为新建账户，系统中并未存储。 代码中的具体数据结构创建交易树和收据树求根哈希值Trie的数据结构Receipt的数据结构区块头的数据结构生成Bloom filter查询Bloom filter中是否包含topic","link":"/2022/01/18/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B016%E2%80%94%E2%80%94ETH%E4%BA%A4%E6%98%93%E6%A0%91%E5%92%8C%E6%94%B6%E6%8D%AE%E6%A0%91/"},{"title":"区块链学习笔记19——ETH难度调整","text":"​​点击阅读更多查看文章内容 区块链学习笔记19——ETH难度调整 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 前面学过，比特币是每隔2016个区块调整一次挖矿难度，目的是维持出块时间在10分钟左右；以太坊是每个区块都有可能调整挖矿难度，调整的方法比较复杂而且改过好几个版本。网络上存在诸多不一致，这里遵循以代码为准的原则，从以太坊代码中查看以太坊难度调整算法。 难度炸弹以太坊在设计之初就计划要逐步从POW（工作量证明）转向POS（权益证明），而权益证明不需要挖矿，这就带来一个问题——已经在挖矿设备上投入大量资金的矿工会不会联合起来抵制这个转换，从POW转向POS需要通过硬分叉来实现，这样就可能导致社区分裂，以太坊可能分裂成两条平行的链。在以太坊早期时，区块号较小，难度炸弹计算所得值较小，难度调整级别基本上通过难度调整中的自适应难度调整部分决定，而随着越来越多区块被挖出，难度炸弹的威力开始显露出来，这也就使得挖矿变得越来越难，从而迫使矿工愿意转入POS。难度炸弹的调整因为开发者低估了POS的设计难度，导致其迟迟没有设计出来，但是难度炸弹的威力已经开始显现出来，系统的出块时间已经开始逐渐变长，但矿工还需要继续挖矿，因此我们可以看到，上图中第二项的fake block number，该数对当前区块编号减去了三百万，也就是相当于将区块编号回退了三百万个。从而降低了出块的难度。当然，为了保持公平，也将出块奖励从5个以太币减少到了3个以太币。下图显示了难度调整对难度炸弹难度影响的结果： 以太坊发展的四个阶段 具体的代码实现难度计算公式基础部分的计算 难度炸弹的计算 以太坊实际统计数据（截止2018年）挖矿难度变化曲线断崖式下跌是难度炸弹的调整出块时间实际区块例子最长合法链对于以太坊来说也叫作最难合法链","link":"/2022/01/20/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B019%E2%80%94%E2%80%94ETH%E9%9A%BE%E5%BA%A6%E8%B0%83%E6%95%B4/"},{"title":"区块链学习笔记17——ETH-GHOST协议","text":"​​点击阅读更多查看文章内容 区块链学习笔记17——ETH-GHOST协议 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 引入以太坊的出块时间降低到了十几秒，大幅降低出块时间也带来了问题——两个矿工同时挖到区块所产生的临时性的分叉成为常态，而且分叉的数目也会更多，(因为十几秒的时间很有可能别的结点还没来得及收到你发布的区块，还是沿着之前的区块往下挖，等到收到你的区块的时候可能自己已经挖出了一个区块。)这对于共识协议来说，就存在很大挑战。在BTC系统中，不在最长合法链上的节点的出块奖励最后都是作废的。而在ETH中区块链的分叉很多，则矿工挖到矿很大可能会被废弃，这会大大降低矿工挖矿积极性。而对于个人矿工（算力分散）来说，和大型矿池相比更是存在天然劣势。 因此，以太坊采用了一个基于GHOST协议的共识机制（GHOST协议并不是以太坊发明的，以太坊对其做了修改）。GHOST协议的核心思想：给挖到了矿但最后没有得到认可的矿工一些“安慰”。 GHOST协议最初版本如图，假定以太坊系统存在以下情况，A、B、C、D在四个分支上，最后，随着时间推移B所在链成为最长合法链，因此A、C、D区块都作废，但为了补偿这些区块所属矿工所作的工作，给这些区块一些“补偿”，并称其为”Uncle Block”（叔父区块）。规定E区块在发布时可以将A、C、D叔父区块包含进来，A、C、D叔父区块可以得到出块奖励的7/8，而为了激励E包含叔父区块，规定E每包含一个叔父区块可以额外得到1/32的出块奖励。为了防止E大量包含叔父区块，规定一个区块只能最多包含两个叔父区块，因此E在A、C、D中最多只能包含两个区块作为自己的出块奖励 协议存在的缺陷： 一个区块最多只能包含两个叔父区块，如果出现呢两个以上怎么办 矿工自私，故意不包含叔父区块，导致叔父区块7/8出块奖励没了，而自己仅仅损失1/32。如果甲、乙两个大型矿池存在竞争关系，那么他们可以采用故意不包含对方的叔父区块，因为这样对自己损失小而对对方损失大。 新版本如下图中1为对上面例子的补充，F为E后面一个新的区块。因为规定E最多只能包含两个叔父区块，所以假定E包含了C和D。此时，F也可以将A认为自己的的叔父区块(实际上并非叔父辈的，而是爷爷辈的)。如果继续往下挖，F后的新区块仍然可以包含B同辈的区块(假定E、F未包含完)。这样，就有效地解决了上面提到的最初Ghost协议版本存在的缺陷。这样设计还存在一些问题？ 所谓的“叔父”应该隔多少代呢？如果没有限制的话，可以在最初挖矿难度小的时候一直挖叔父区块，等待取得叔父区块的奖励。 如下图所示，M为该区块链上一个区块，F为其严格意义上的叔父，E为其严格意义上的“爷爷辈”。以太坊中规定，如果M包含F辈区块，则F获得7/8出块奖励；如果M包含E辈区块，则F获得6/8出块奖励，以此类推向前。直到包含A辈区块，A获得2/8出块奖励，再往前的“叔父区块”，对于M来说就不再认可其为M的”叔父”了。对于M来说，无论包含哪个辈分的“叔父”，得到的出块奖励都是1/32出块奖励。也就是说，叔父区块的定义是和当前区块在七代之内有共同祖先才可（合法的叔父只有6辈）。 如果不限制叔父的辈分，对全结点来说要维护的状态就太多了，它可能要记录隔着一百代之前的叔父区块 出块奖励递减，有利于鼓励出现分叉后尽早合并 这种协议只能合并临时性的分叉，不能合并硬分叉（互相不认可对方的链，各自沿着自己的链向下挖） 以太坊中的奖励BTC发布区块的奖励：block reward（静态奖励）+transaction fee（动态奖励）ETH发布区块的奖励：block reward（静态奖励）+gas fee（动态奖励，区块中包含智能合约，执行智能合约时得到的奖励）叔父区块只能得到blcok reward，不能得到gas fee，实际上影响不大，汽油费只占很少一部分 把叔父区块包含进来的时候，叔父区块的交易需不需要执行？不执行，因为叔父区块中的有些交易可能在执行完父区块的交易后就不合法了。在包含叔父区块时，只检查其挖矿难度是否符合要求即区块是否合法，但是不执行里面的交易，也不检查交易的合法性。如果分叉后的叔父区块之后还有区块怎么办？例如下图所示，A-&gt;F该链并非一个最长合法链，所以B-&gt;F这些区块怎么办？该给挖矿补偿吗？如果给下面的整条链都分一些奖励的话，会使得分叉攻击的风险大大降低（攻击不成功的话还是会得到一些奖励）因此，ETH系统中规定，只认可A区块为叔父区块，给予其补偿，而其后的区块全部作废。鼓励出现分叉后及时合并，如果继续沿着分叉挖的话就都白挖了 以太坊的一些真实情况Etherscan——查看以太坊的一些实时数据","link":"/2022/01/19/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B017%E2%80%94%E2%80%94ETH-GHOST%E5%8D%8F%E8%AE%AE/"},{"title":"区块链学习笔记18——ETH挖矿算法","text":"​​点击阅读更多查看文章内容 本文转载自：文章来源目前在国内基本访问不了google站点和android的站点，下载个gradle都要等很久。所以如果不翻墙很多工作都没办法正常做。所以在学习翻墙的同时也顺便了解了下目前限制网络访问的一些基本知识。 网络限制和监控应该说大家都有体会。比如很多公司都会限制一些网站的访问，比如网盘、视屏网站。有时也会对你访问的内容进行监控。还有一些公共WIFI，可能限制你只能访问80端口。在比如在国内无法访问google，facebook，android等网站。要想绕过这些限制，必须先知道他们是如何限制的。 本文主要是从技术角度来了解的网络限制方式和应对方式。并不做任何翻墙方式的推荐和指导。对于网络的知识，还是停留在上过网络课 的水平，文章内容也都是自己了解后总结的。可能会有错误和遗漏。会定期更新。 DNS污染和劫持以下解释来自百度百科：某些网络运营商为了某些目的，对DNS进行了某些操作，导致使用ISP的正常上网设置无法通过域名取得正确的IP地址。某些国家或地区出于某些目的为了防止某网站被访问，而且其又掌握部分国际DNS根目录服务器或镜像，也会利用此方法进行屏蔽。 目前我们访问网站主要都是通过域名进行访问，而真正访问这个网站前需要通过DNS服务器把域名解析为IP地址。而普通的DNS服务使用UDP协议，没有任何的认证机制。DNS劫持是指返回给你一个伪造页面的IP地址，DNS污染是返回给你一个不存在的页面的IP地址。 比如你使用电信、联通、移动的宽带，默认你是不需要设置任何DNS服务器的。这些DNS服务器由他们提供。一旦检测到你访问的网页是不允许的访问的，就会返回一个不存在的网页。而很多运营商也会使用DNS劫持来投放一些广告。 解决办法： 使用OpenDNS（208.67.222.222）或GoogleDNS（8.8.8.8）（现在不太好用，被封锁，速度慢） 使用一些第三方的DNS服务器 自己用VPS搭建DNS服务器 修改机器host文件，直接IP访问 封锁IP通过上面一些方式，可以绕过DNS污染，通过IP地址访问无法访问的网页。但是目前针对IP进行大范围的封锁。虽然google这种大公司有很多镜像IP地址，但是目前基本全部被封锁掉，有漏网的可能也坚持不了多久。而且很多小公司的服务是部署在一些第三方的主机上，所以封锁IP有时会误伤，封锁一个IP导致主机上本来可以使用的页面也无法访问了。 不过目前不可能把所有国外的IP全部封锁掉，所以我们采用机会从国内连接到国外的VPS，进行翻墙。 解决办法： 使用VPS搭建代理 使用IPV6 （IPV6地址巨大，采用封地址不现实，但是目前国内只有部分高校部署了IPV6） 封锁HTTP代理对于没有办法搭建VPS的人来说，最好的办法就是使用HTTP代理。客户端不在直接请求目标服务器，而是请求代理服务器，代理服务器在去请求目标服务器。然后返回结果。对于HTTP代理来说，封锁起来非常简单。因为HTTP协议是明文，Request Message中就带有要请求的URL或IP地址，这样很容易就被检测到。对于HTTPS来说，虽然通信是进行加密了，但是在建连之前会给代理服务器发送CONNECT方法，这里也会带上要访问的远端服务器地址。如果代理服务器在国外，在出去前就会被检测到。 如果代理服务器在国内，呵呵，你也出不去啊。 对于HTTP代理，因为是明文，所以很容易被服务器了解你的一些数据。所以不要随便使用第三方的HTTP代理访问HTTP网站，而HTTPS虽然不知道你的数据，但是可以知道你去了那里。 解决办法： 使用VPS搭建VPN 使用第三方VPN 封锁VPN虚拟专用网（英语：Virtual Private Network，简称VPN），是一种常用于连接中、大型企业或团体与团体间的私人网络的通讯方法。虚拟私人网络的讯息透过公用的网络架构（例如：互联网）来传送内联网的网络讯息。它利用已加密的通道协议（Tunneling Protocol）来达到保密、发送端认证、消息准确性等私人消息安全效果。正常网络通信时，所有网络请求都是通过我们的物理网卡直接发送出去。而VPN是客户端使用相应的VPN协议先与VPN服务器进行通信，成功连接后就在操作系统内建立一个虚拟网卡，一般来说默认PC上所有网络通信都从这虚拟网卡上进出，经过VPN服务器中转之后再到达目的地。通常VPN协议都会对数据流进行强加密处理，从而使得第三方无法知道数据内容，这样就实现了翻墙。翻墙时VPN服务器知道你干的所有事情（HTTP，对于HTTPS，它知道你去了哪)。 VPN有多种协议：OPENVPN、PPTP、L2TP/IPSec、SSLVPN、IKEv2 VPN，Cisco VPN等。其中的PPTP和L2TP是明文传输协议。只负责传输，不负责加密。分别利用了MPPE和IPSec进行加密。 对于VPN和其他一些加密的传输的协议来说，没有办法直接获取明文的请求信息，所以没有办法直接封锁，而是使用了监控的方式： 暴力破解对于一些使用弱加密方式的协议来说，直接使用暴力破解检查传输内容。比如PPTP使用MPPE加密，但是MPPE是基于RC4，对于强大的防火墙背后的超级计算机集群，破解就是几秒钟的事情。 破解后明文中一旦包含了违禁内容，请求就会被封。而对应的IP可能会进入重点关怀列表。 特征检测要想成功翻墙都必须与对应的远程服务器建立连接，然后再用对应的协议进行数据处理并传输。而问题就出在这里：翻墙工具和远程服务器建立连接时，如果表现的很独特，在一大堆流量里很显眼，就会轻易被GFW识别出从而直接阻断连接，而VPN（尤其是OPENVPN）和SSH这方面的问题尤其严重。 流量监控当一个VPN地址被大量人请求，并保持长时间连接时，就很容易引起关注。SSH接口有大量数据请求。一般会结合其他特征。 深度包检测深度数据包检测（英语：Deep packet inspection，缩写为 DPI），又称完全数据包探测（complete packet inspection）或信息萃取（Information eXtraction，IX），是一种电脑网络数据包过滤技术，用来检查通过检测点之数据包的数据部分（亦可能包含其标头），以搜索不匹配规范之协议、病毒、垃圾邮件、入侵，或以预定之准则来决定数据包是否可通过或需被路由至其他不同目的地，亦或是为了收集统计数据之目的。 比如我们用HTTPS来访问一个网站，TLS/SSL协议在建连过程如下：很明显的会发送“client hello”和“server hello” 这种特诊很明显的信息。（当然不会根据这个就封掉，否则https没法用了）。而后续会有服务端证书发送，验证，客户端密钥协商等过程。有明显的协议特征。 下面是网上找的两张图：提醒大家最好不要随便用不安全的VPN来访问不合适的网页，开开android没啥问题。 Socks代理Socks代理/SSH SocksSOCKS是一种网络传输协议，主要用于客户端与外网服务器之间通讯的中间传递。SOCKS是”SOCKetS”的缩写。当防火墙后的客户端要访问外部的服务器时，就跟SOCKS代理服务器连接。这个代理服务器控制客户端访问外网的资格，允许的话，就将客户端的请求发往外部的服务器。这个协议最初由David Koblas开发，而后由NEC的Ying-Da Lee将其扩展到版本4。最新协议是版本5，与前一版本相比，增加支持UDP、验证，以及IPv6。根据OSI模型，SOCKS是会话层的协议，位于表示层与传输层之间 与HTTP代理的对比SOCKS工作在比HTTP代理更低的层次：SOCKS使用握手协议来通知代理软件其客户端试图进行的连接SOCKS，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头（例如，使用另一种底层协议，例如FTP；然而，HTTP代理只是将HTTP请求转发到所需的HTTP服务器）。虽然HTTP代理有不同的使用模式，CONNECT方法允许转发TCP连接；然而，SOCKS代理还可以转发UDP流量和反向代理，而HTTP代理不能。HTTP代理通常更了解HTTP协议，执行更高层次的过滤（虽然通常只用于GET和POST方法，而不用于CONNECT方法） Socks代理本身协议是明文传输，虽然相对HTTP有一些优势，但是明文也导致Socks代理很容易被封。所以可以考虑对Socks进行加密。所以出现了SSH Socks，对于MAC和Linux来说，不需要Client就可以进行访问。详细可以看：SSH隧道技术简介：端口转发&amp;SOCKS代理 但是网上看有些地区好像会对一些VPS的SSH进行端口干扰。我在武汉好像SSH到我的VPS一会就会断。在上海一直没这问题。而且SSH一般是小流量数据，如果数据量特别大，也会被认为是翻墙，进入特别关怀列表。 Shadowsocks认准官网：https://shadowsocks.org/en/index.html （.com那个是卖账号的） 12A secure socks5 proxy,designed to protect your Internet traffic. Shadowsocks 目前不容易被封杀主要是因为： 建立在socks5协议之上，socks5是运用很广泛的协议，所以没办法直接封杀socks5协议 使用socks5协议建立连接，而没有使用VPN中的服务端身份验证和密钥协商过程。而是在服务端和客户端直接写死密钥和加密算法。所以防火墙很难找到明显的特征，因为这就是个普通的socks5协议。 Shadowsock搭建也比较简单，所以很多人自己架设VPS搭建，个人使用流量也很小，没法通过流量监控方式封杀。 自定义加密方式和密钥。因为加密主要主要是防止被检测，所以要选择安全系数高的加密方式。之前RC4会很容易被破解，而导致被封杀。所以现在推荐使用AES加密。而在客户端和服务端自定义密钥，泄露的风险相对较小。 所以如果是自己搭建的Shadosocks被封的概率很小，但是如果是第三方的Shadeowsocks，密码是server定的，你的数据很可能遭受到中间人攻击。顺便说一下，Shadowssocks是天朝的clowwindy大神写的。不过Shadowsocks项目源码已经从github上删除了并停止维护了，但是release中还有源码可以下载。https://github.com/shadowsocks/shadowsocks Shadowsocks-rss前面认为Shadowssocks特征并不是很明细，但是了解协议工作原理后会发现，SS协议本身还有有漏洞，可以被利用来检测特征，具体讨论看：ShadowSocks协议的弱点分析和改进。 里面中间那些撕逼就不用看了，我总结了下大致意思是：协议过于简单，并且格式固定，很容易被发起中间人攻击。先看看协议结构 12345+--------------+---------------------+------------------+----------+| Address Type | Destination Address | Destination Port | Data |+--------------+---------------------+------------------+----------+| 1 | Variable | 2 | Variable |+--------------+---------------------+------------------+----------+ Possible values of address type are 1 (IPv4), 4 (IPv6), 3 (hostname). For IPv4 address, it’s packed as a 32-bit (4-byte) big-endian integer. For IPv6 address, a compact representation (16-byte array) is used. For hostname, the first byte of destination address indicates the length, which limits the length of hostname to 255. The destination port is also a big-endian integer. The request is encrypted using the specified cipher with a random IV and the pre-shared key, it then becomes so-called payload. 结构很简单，上面解释也很清楚。Client每一个请求都是这种格式，然后进行加密。Server端解密然后解析。看起来没什么问题，没有密钥你无法模拟中间人攻击，也没什么明显特征。但是看看Server处理逻辑会发现存在一些问题： Client数据在加密目前用的最多的是AES系列，加密后在协议数据前会有16位的IV。而Server段解析后，首先判断请求是否有效，而这个判断很简单： 判断的依据就是Address Type的那个字节，看它是不是在那三个可能取值，如果不是，立即断开连接，如果是，就尝试解析后面的地址和端口进行连接。 如果能发起中间人攻击，模拟Client请求，这个就是一个很明显的特征，如果把Address Type穷举各种情况，其中只有3种情况会连接成功。那么很可能就是一个Shadowsocks 服务器。 所以只需要先劫持一条socks5的请求，因为AES加密后Address Type位置是固定的（第17位），篡改这一位，穷举256种情况（AES-256），然后发送给服务器。如果服务器在3种情况没有关闭连接，就说明这个很可能是Shadowsock服务。你这个IP很快就进入关怀列表了。 这里的关键就是AES加密明文和密文对应关系。密码学不是太懂，贴帖子里面一个回复： 1234567891011121314151617举个例子，现在有一个协议包，共7个字节0x01, 0x08, 0x08, 0x08, 0x08, 0x00, 0x50对照socks5协议，很明显这是一个IPv4包(第一个字节是0x01)，目的地是8.8.8.8的80端口被shadowsocks加密了以后（密码abc，加密方式aes-256-cfb），数据包就变成了这样0xbb, 0x59, 0x1c, 0x4a, 0xb9, 0x0a, 0x91, 0xdc, 0x07, 0xef, 0x72, 0x05, 0x90, 0x42, 0xca, 0x0d, 0x4c, 0x3b, 0x87, 0x8e, 0xca, 0xab, 0x32前16个字节，从0xbb到0x0d，都是iv，根据issue中提到的弱点和之前的总结，只需要修改0x4c，即真正密文中的第一个字节，就可要起到修改明文中的第一个字节的效果。那就把0x4c修改成0x4d吧，解密以后的结果是0x00, 0x08, 0x08, 0x08, 0x08, 0x00, 0x50的确只有第一个字节被改掉了，根据breakwa11的理论，不难推出其他情况，其中合法的是0x4e =&gt; 0x03 (Domain Name)0x49 =&gt; 0x04 (IPv6) 所以目前Shadowsocks应该是比较容易被检测出来。但是为什么没有被封掉，呵呵，就不知道了。所以这个项目目的就是在SS基础上进行一些混淆。因为原有实现确实有漏洞。 不过目前这个项目好像也停止更新了。并且木有开源。 当然如果是自己用完全可以自己修改一个私有协议，这样就没法被检测到了。但是需要同时修改Server段，MAC Client，Windows Client， Android Client。 – -！ GoAgent和GoProxyGoogle App Engine是一个开发、托管网络应用程序的平台，使用Google管理的数据中心 GoAgent的运行原理与其他代理工具基本相同，使用特定的中转服务器完成数据传输。它使用Google App Engine的服务器作为中传，将数据包后发送至Google服务器，再由Google服务器转发至目的服务器，接收数据时方法也类似。由于服务器端软件基本相同，该中转服务器既可以是用户自行架设的服务器，也可以是由其他人架设的开放服务器。 GoAgent其实也是利用GAE作为代理，但是因为他是连接到google的服务器，因为在国内现在google大量被封，所以GoAgent也基本很难使用。目前github上源码也已经删除。 但是GoAgent本身不依赖于GAE，而且使用Python编写，完全可以部署到VPS上进行代理。GoProxy是GoAgent的后续项目 https://github.com/phuslu/goproxy还有一个XX-NET：https://github.com/XX-net/XX-Net 有兴趣都可以去了解下。 TorTor（The Onion Router，洋葱路由器）是实现匿名通信的自由软件。Tor是第二代洋葱路由的一种实现，用户通过Tor可以在因特网上进行匿名交流。 Tor:Overview The Tor network is a group of volunteer-operated servers that allows people to improve their privacy and security on the Internet. Tor’s users employ this network by connecting through a series of virtual tunnels rather than making a direct connection, thus allowing both organizations and individuals to share information over public networks without compromising their privacy. Along the same line, Tor is an effective censorship circumvention tool, allowing its users to reach otherwise blocked destinations or content. Tor can also be used as a building block for software developers to create new communication tools with built-in privacy features. 而关于Tor的漏洞和检测看这里：Tor真的十分安全么其原理以及漏洞详解目前有结合Tor+Shadowsocks前置代理使用的。","link":"/2022/01/19/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B018%E2%80%94%E2%80%94ETH%E6%8C%96%E7%9F%BF%E7%AE%97%E6%B3%95/"},{"title":"区块链学习笔记20——权益证明","text":"​​点击阅读更多查看文章内容 区块链学习笔记20——ETH权益证明 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 权益证明（POS——Proof of stake） POW能耗 数据来源：https://digiconomist.net/ 目前比特币和以太坊都是基于工作量证明的共识机制，这种共识机制对电力的浪费非常严重 比特币能耗下图为比特币系统电力消耗随着时间变化的情况。y轴的单位为Twh，1Twh = 10^9 Kwh,1Kwh就是我们平时生活中常说的“一度电”。可以看到比特币系统的能耗是相当大的，每个交易的平均能耗是1000度电，但是尽管成本很高，却仍然存在利润空间。 以太坊能耗以太坊能耗也是随时间增长的，中间有一点波动以太坊的出块时间短，所以每个交易的平均能耗少 比特币和以太坊的能耗相加当做一个国家来看 思考挖矿消耗的这些能源是必须的吗？矿工为什么要挖矿？矿工挖矿是为了取得出块奖励，获取收益。而系统给予出块奖励的目的是激励矿工参与区块链系统维护，进行记账，而挖矿本质上是看矿工投入资金来决定的(投入资金买设备-&gt;设备决定算力-&gt;算力比例决定收益)。那么，为什么不直接拼“钱”呢？现状是用钱购买矿机进行挖矿比拼算力，那么为什么不直接将钱投入到系统开发和维护中，而根据投入钱的多少来进行收益分配呢？这就是权益证明的基本思想。 权益证明采用权益证明的货币，一般在正式发行之前会先预留一些货币给开发者，而开发者也会出售一些货币换取开发所需要的资金，在系统进入稳定状态后，每个人都按照持有货币的数量进行投票。 优点 省去了挖矿的过程，减少了能耗 POW中维护其安全的资源没有形成闭环，它需要通过显示中的货币去购买矿机，这也就导致只要有人想要攻击，只需要外部聚集足够资金就可以成功。而对于POS，要想发动攻击的话需要得到这个币种发行量一半以上的份额才行，发动攻击的资源只能从这个加密货币的内部才可以得到（闭环）。 POS与POW并不是互斥的，有的加密货币采用一种混合模型，即仍然需要挖矿，但挖矿难度跟你持有的币的数量有关，持有的币越多，挖矿越简单。当然这也是有问题的，即持有币数量最多的人每次挖矿都是最容易的。所以，有的加密货币要求投入的币会被锁定一段时间不能重复使用，比如：挖当前区块投入一定数量的币用于降低挖矿难度，等这个区块发布后，这些币会被锁定一段时间，下次再挖的时候这些币就不能再用了，要过多少个区块之后才能再用。 权益证明的应用仍然存在很多挑战，其中一个就是“两边下注”的问题 如下图所示，区块链系统产生了分叉，存在两个区块A和B竞争主链时，如果是工作量证明的话，同时挖A、B两条链会因为算力分散导致挖到区块的概率降低，但是采用权益证明的话，在A和B同时进行了下注。最终A区块胜出，那么他能够获得A区块相应收益，而在B区块进行投票放入的“筹码”只记录在下面的分叉上并不影响你在上面分叉上的使用，这也就导致其每次都能获得收益。由于一个人可以拥有多个账户，所以我们无法强迫一个人一次只能投向一个区块。而越有钱的人，通过“双边下注”得到的收益也就越多。 以太坊准备采用的权益证明协议以太坊中，准备采用的权益证明协议为Casper the Friendly Finality Gadget(FFG)，该协议在过渡阶段是要和POW结合使用的。为工作量证明提供Finality。 Finality是一种最终的状态，包含在Finality中的交易不会被取消 单纯基于挖矿的交易是有可能被回滚的，比特币中规定要等六个区块来防止被回滚，但这只是说明回滚的概率比较小，但是只要攻击者的算力足够强（占到50%以上）仍然可能回滚该交易。所以单纯基于挖矿的区块链是缺乏这种Finality的。 Casper协议引入一个概念：Validator(验证者)，一个用户想要成为Validator，需要上交一笔“保证金”，这笔保证金会被系统锁定。Validator的职责是推动系统达成共识，投票决定哪一条链成为最长合法链，投票权重取决于保证金数目。挖矿的时候每挖出一百个区块就作为一个epoch，然后通过投票决定其能不能成为一个Finality。 投票时采用two-phase commit，第一轮投票是Prepare Message，第二轮投票时Commit Message，Casper规定每一轮投票都要得到2/3以上的验证者才能通过（按照保证金的金额大小计算）实际系统中不再区分这两个Message，而且把epoch从100个区块减到50个区块，且只需要一轮投票（对于上一个epoch是Commit Message，对下一个epoch是Prepare Message），要连续两轮投票都得到2/3以上的多数才算有效。 原始版本：优化后： 矿工挖矿会获得出块奖励，而验证者也会得到相应奖励。当然，为了防止验证者的不良行为，规定其被发现时要受到处罚。例如某个验证者“行政不作为”，不参与投票导致系统迟迟无法达成共识，这时会扣掉部分保证金；如果某个验证者“乱作为”，给两个有冲突的分叉都进行投票（两边下注），被发现后没收全部保证金。没收的保证金被销毁，从而减少系统中货币总量。验证者存在“任期”，在任期结束后，进入“等待期”，在此期间等待其他节点检举揭发是否存在不良行为进行惩处，若通过等待期，则可以取回保证金和应得的奖励。 Q：通过验证者达成的Finality有没有可能被推翻？A：如果发动攻击的组织仅仅作为矿工的话是无法推翻的，必须在系统中，存在大量“验证者”对前后两个有冲突的Finality都下注。也就是说，至少1/3（该协议规定超过2/3才有效）的验证者两侧都投票。而这一旦被发现，这1/3验证者的保证金将会被没收。 以太坊系统设想，随着时间推移，挖矿奖励逐渐减少而权益证明奖励逐渐增多，从而实现POW到POS的过渡，最终实现完全放弃挖矿。 为什么以太坊不从一开始就用权益证明呢？因为权益证明还不是很成熟，工作量证明是很成熟的，经过了时间的检验（bug bounty）。EOS加密货币，即“柚子”，就是采用权益证明的共识机制，其采用的是DPOS：Delegated Proof of Stake。该协议核心思想是通过投票选21个超级节点，再由超级节点产生区块。但目前，权益证明仍然处于探索阶段。 其他观点前面的基本观点都是基于“挖矿消耗大量电能，而这是不好的”这一观点，但也有人持有相反观点。他们认为其所消耗的电能所占比值并不大，而且其对于环境的影响是有限的。挖矿提供了将电能转换为钱的手段，而电能本身难以传输和存储，一般来说，白天所发的电不足，晚上所发的电又多于实际需求，很多大型数据中心要建在电比较便宜的地方，就是因为传输数据比传输电要容易。因此，挖矿为将多余的电能转换为有价值的货币提供了很好的解决手段。也就是说挖矿消耗电能可以有效消耗过剩产能，带动当地经济发展。","link":"/2022/01/20/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B020%E2%80%94%E2%80%94%E6%9D%83%E7%9B%8A%E8%AF%81%E6%98%8E/"},{"title":"区块链学习笔记1——BTC密码学原理","text":"​​点击阅读更多查看文章内容 区块链学习笔记1——密码学原理 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 梦开始的地方（狗头） BTC的密码学原理主要包括两个方面——哈希、签名 一、哈希 哈希函数是把任意长度的输入（又叫做预映射pre-image）通过散列算法变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出。 比特币系统中哈希函数的三个重要性质 collision resistance：如果x!=y，那么H(x)!=H(y)，对一个给定的x很难找到y使得H(x)=H(y) hiding：已知H(x)很难推出x puzzle friendly：对H(x)的范围是不可预测的 通过collision resistance和hiding两条特性，我们可以实现digital commitment，以预测股票为例，一个人要想预测第二天的股票，但是他不能直接说出他预测的股票到底是哪一个，否则可能会导致人为因素对结果造成干扰，此时他可以给出他所预测的股票的hash值，这时根据hiding的性质，其他人不能得到他预测的股票到底是哪个，等到第二天结果出现时，他只需要公布他所预测的结果，其他人对他的结果计算hash值看是否与昨天公布的值一致即可，这时根据collision resistance的性质，不同的值对应的hash值也不同，所以不会出现他所公布的结果与昨天预测的结果不同的情况 比特币中所使用的的哈希函数是SHA-256 挖矿挖矿实际上就是一个不断测试区块头部中的随机数部分nonce使的整个区块头的哈希值满足某一target的过程H(block header)&lt;=target这里的target通常是前x位为0由于哈希函数的puzzle friendly的性质，即对某一x其H(x)的范围是不可预测的，所以我们只能不断的尝试nonce，谁先计算出对应的nonce谁就获得了记账权，这就是后面要说的共识算法中的POW（工作量证明）虽然计算nonce的过程很困难，但是验证nonce只需要一次计算即可 二、签名要加入比特币系统中，需要自己创建一个公私钥对。公钥和私钥的应用保证了“签名”的应用。当在比特币网络中进行转账时，通过“签名”可以明确是由哪个账户转出的，从而防止不良分子对其他账户比特币的盗取。在发布交易时，通过自己私钥签名，其他人可以根据公钥验证，从而保证该交易由自己发起。也就是说，只有拥有私钥，才能将该账户中的比特币转走。","link":"/2021/12/11/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%E2%80%94%E2%80%94BTC%E5%AF%86%E7%A0%81%E5%AD%A6%E5%8E%9F%E7%90%86/"},{"title":"区块链学习笔记21——ETH智能合约","text":"​​点击阅读更多查看文章内容 区块链学习笔记21——ETH智能合约 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 智能合约简介 智能合约是运行在区块链上的一段代码，代码的逻辑定义了合约的内容 智能合约的账户保存了合约当前的运行状态 balance：当前余额 nonce：交易次数 code：合约代码 storage：存储，数据结构是一棵MPT Solidty是智能合约最常用的语言，其语法上与JavaScript很接近 智能合约的代码结构 如何调用智能合约调用智能合约与转账是类似的，比如A发起一个交易转账给B，如果B是一个普通账户那么这就是一个普通的转账交易，如果B是一个合约账户的话，那么这个交易实际上是发起一次对B这个合约的调用，具体调用的是哪个函数是在DATA域中说明的 event的作用就是写一个log，对程序的运行逻辑没有影响一个交易只能外部账户发起，合约账户不能自己主动发起一个交易下面例子实际上需要一个外部账户先调用合约B中的callAFooDirectly函数，这个函数再调用合约A中的foo函数使用call()函数调用与直接调用的一个区别是错误处理的方式直接调用如果在a.foo()执行出错，那么外部callAFooDirectly也会出错，本次调用全部回滚使用call()函数调用，如果调用过程中被调用合约产生异常，会导致call()返回false，但发起调用的函数不会抛出异常，而是继续执行。 关于之前函数中的payable以太坊中规定，如果一个函数可以接收外部转账，则必须标记为payable。该例中背景为拍卖，bid()为出价，调用bid()函数的时候要把你的出价发送出去，存储到合约中锁定一直到拍卖结束。因此需要payable进行标记；withdraw()为其他未拍卖到的人将锁定在智能合约中的钱取出的函数，其不涉及转账，不需要把钱转给智能合约，而仅仅是把当初锁定的钱取回来，因此不需要payable进行标记。 fallback()函数该函数主要是防止A向B转账，但没有在data域中说明要调用哪个函数或说明的要调用函数不存在，此时调用fallback()函数。只有合约账户才有代码，因此这些只和合约账户有关。如果没有fallback()，在发生之前的情况后，就会直接抛出异常。另：转账金额和汽油费是不同的。汽油费是为了让矿工打包该交易，而转账金额是单纯为了转账，其可以为0，但汽油费必须给 智能合约的创建和运行 汽油费以太坊中功能很充足，提供图灵完备的编程模型，但这也导致一些问题，例如当一个全节点收到一个对智能合约的调用时怎么知晓执行其是否会导致死循环（比特币中根本不支持循环）。事实上，无法预知其是否会导致死循环，实际上，该问题是一个停机问题，而停机问题不可解。因此，以太坊引入汽油费机制将该问题扔给了发起交易的账户。汽油费实际上是对执行智能合约所消耗资源的补偿 当一个全节点收到一个对智能合约的调用，先按照最大汽油费收取，从发起调用的账户一次性扣除，再根据实际执行情况，多退少补(汽油费不够会引发回滚，而非简单的补齐)。 发布区块的汽油费这里面的GasUsed是区块中包含的所有交易所消耗的汽油费的总和但是GasLimit并不是区块中所有交易的GasLimit的总和发布区块需要消耗一定的资源，我们需要对消耗的资源进行限制，如果不限制的话，有的矿工可能把特别多的交易打包到一个区块中，这个区块在区块链上会消耗很多的资源。比特币中规定每个区块的大小不能超过1MB，比特币系统比较简单基本可以通过交易的字节数来衡量其消耗的资源；而以太坊中智能合约的逻辑很复杂，所以我们要根据交易的具体操作来收费，这里的区块头中的GasLimit是区块中所有交易能消耗汽油的一个上限，不是把区块中所有的GasLimit加在一起（这样的话就没有限制了，因为每个交易的GasLimit是发布交易的账户自己定的） 比特币直接通过限制区块大小为1MB是固定的，无法修改。而以太坊中，每个矿工都可以以前一个区块中GasLimit为基数，进行上调或下调1/1024，从而，通过矿工不断地上下调整，最终得到的GasLimit是所有矿工希望的平均值。 错误处理以太坊中交易具有原子性，要么全执行，要么全不执行，不会只执行一部分(包含智能合约)。所以如果在执行智能合约的过程中出现错误，会导致整个交易回滚，退回到之前的状态，就像这个交易从未执行。出现错误的情况：如果交易执行完后没有达到gas limit，那么多余的会退回；如果执行到一半gas limit都用完了，要退回到交易执行前的状态，而且已经消耗的汽油费是不会退回的，防止了恶意节点对全节点进行恶意调用。 嵌套调用嵌套调用是否发生连锁式回滚，取决于调用方式，直接调用方式会引发连锁回滚，使用call()函数的话只会使当前调用失败返回一个false一个合约向一个合约账户直接转账，因为fallback函数的存在，仍有可能会引发嵌套调用。 问答Q：假设全节点要打包一些交易到区块中，其中存在某些交易是对智能合约的调用。全节点应该先执行智能合约再挖矿，还是先挖矿获得记账权后执行智能合约？ 观点1：先挖矿后执行智能合约。因为如果先执行智能合约，后挖矿，可能导致同一智能合约被不同节点执行多次，因此可能会导致一个转账操作被执行多次，即转账了好多次。 实际上，一个在区块链上的区块中的智能合约，其必然在系统中所有节点中都得到了执行，因为这样才能保证系统中所有节点从一个状态转入另一个状态，从而保证系统的一致性。如果存在一个全节点没有执行该智能合约，那么该全节点的状态就和其他节点不一致，则该系统就没有保持状态一致。 观点2：先挖矿后执行智能合约。因为执行智能合约要收取汽油费，如果多个人都执行，会收取很多份汽油费。 汽油费是怎么扣除的？首先，之前在以太坊数据结构中介绍了以太坊中“三棵树”——状态树、交易树、收据树。这三棵树都位于全节点中，是全节点在本地维护的数据结构，记录了每个账户的状态等数据，所以该节点收到调用时，是在本地对该账户的余额减掉即可,如果余额不够就不执行，如果有剩下的再加回去即可。所以多个全节点每人扣一次，仅仅是每个全节点各自在本地扣一次。也就是说，智能合约在执行过程中，修改的都是本地的数据结构，只有在该智能合约执行完被发布到区块链上之后，这个本地修改才是外部可见的，才会成为区块链上的共识。 观点3：先执行智能合约后挖矿。 这个观点是正确的，在挖矿的时候要计算block header的哈希值，而block header中包含有三棵树的根哈希值。所以，只有执行完区块中的所有交易（包括智能合约交易）才能更新这三棵树，得到这三个根哈希值，这样block header的内容才能确定，然后才能尝试nonce进行挖矿。 Q：矿工先消耗了很多资源执行了这个智能合约，但是最后没有挖到矿怎么办？能得到什么补偿？ 没有任何补偿，汽油费只给获得记账权发布区块的那个矿工，不仅如此，他还需要把别人发布的区块中的交易在本地执行一遍，验证它的正确性，每个全结点都要独立验证。 Q：会不会有的矿工因为没有汽油费而不去验证别人的区块（验证别人的区块还会消耗自己的资源）？ 如果出现这种情况最直接的后果会危害区块链的安全（区块链安全的保证：所有的全结点独立验证发布区块的合法性，这样少数恶意结点才无法篡改区块链的内容），如果矿工跳过验证，那么他就无法更新本地的三棵树，以后再发布区块时别人也不会通过他所发布的区块 Q：发布到区块链上交易都是成功执行的吗？如果智能合约的执行出现错误，要不要也发布到区块上去？ 要发布，要扣掉汽油费，只在本地扣掉的汽油费是没有用的，只有发布到区块上形成共识，才会成为你账户上的钱。 Q：智能合约支持多线程吗？ 不支持，solidty根本就没有支持多线程的语句。因为以太坊本质为一个交易驱动的状态机，给定一个智能合约，面对同一组输入，必须转移到一个确定的状态。因为所有全结点都要执行同一组操作，到达同一个状态进行验证，如果状态不确定的话三个树的根哈希值根本对不上。但对于多线程来说，如果多个核对内存访问顺序不同的话，最终的结果可能不一致。除了多线程外，其他可能造成结果不一致的操作也都不支持，如产生随机数。所以以太坊的智能合约没法产生真正意义下的随机数，都是伪随机数。同时也不能获得执行环境的信息。 Receipt数据结构 智能合约可以获得的信息下图中A调用合约C1中f1函数，C1中f1函数调用C2合约的f2函数对f2来说，C1是msg.sender；A是tx.origin 地址类型 转账方法transfer和send专门用来转账：transfer会导致连锁式回滚；send不会导致连锁式回滚call也可用来转账，不会导致连锁式回滚区别在于transfer和send转账金额是很少的，call是把当前调用剩下的所有汽油全部发送过去 例子拍卖规则：在拍卖的时候每个人都可以出价竞拍，同时要把出价的以太币发到智能合约中锁定，直到拍卖结束。拍卖结束后，出价最高的人会把他投出去的钱给受益人，受益人也应该把拍卖物品想办法给最高出价人。其他没竞拍成功的人可以把投进去的钱才取回来。竞拍可以多次出价，比如第一次出100个以太币，第二次出120个以太币，这时只需要补差价20个以太币即可，出价要想有效必须比当前的最高出价要高。拍卖用到的两个函数 收款地址未定义fallback函数的问题：竞拍合约退款时，用的是transfer方式，没有调用任何函数，这时会调用fallback函数，而该合约没有定义，所以竞拍合约的退款会抛出异常，引起连锁式回滚，中间执行过程更改的数据结构也会全部还原，所以整个auction函数执行失败，所有人都收不到转账。解决方案：设计由投标者自己取回出价的方式，首先判断拍卖是否截止，检查取回的地址是否为最高出价人，然后判断余额是否大于0，然后将账户余额转给调用合约的人，然后在合约中给对应出价人清0，如下所示 code is law智能合约的规则由代码逻辑决定，由于区块链的不可篡改，发布到区块链上的所有合约都将无法修改，好处是没有人可以篡改规则，坏处是如果存在漏洞也无法修改，智能合约如果设计不好，有可能会造成以太币锁在里面，永远无法取出来。所以智能合约必须经过严格的测试，可以在testnet上用假的以太币测试，确认完全没有问题再发布。能否在智能合约中留一个后门，用来修改bug？比如给合约的创建者超级用户的权利，这样做的前提是所有人都要信任这个超级用户，与去中心化的理念背道而驰。 重入攻击的问题合约账户收到ETH时，通过addr.send()、addr.transfer()、addr.call.value()()三种方式都会触发addr里的fallback函数。fallback()函数由用户自己编写，内部又调用一次withdraw函数，造成退款的递归调用，不停的从竞拍合约中取钱，直到余额不足、汽油费不足以及栈溢出。如下所示：解决方案改为先将收款人清0，再转账，再次调用将没有金额用于转账；另外还可将转账方式改为send或transfer，汽油费只有2300，不足以让接受的合约再发起一个新的调用，只够写一个log，如下所示： 对于可能和其他合约发生交互的经典的编程模式： 判断条件 改变条件 与其他合约交互","link":"/2022/01/21/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B021%E2%80%94%E2%80%94ETH%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"title":"区块链学习笔记22——ETH-TheDAO","text":"​​点击阅读更多查看文章内容 区块链学习笔记22——ETH-TheDAO 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 DAO：Decentralized Autonomous Organization（去中心化的自治组织） 建立在代码上，规章制度写在代码中，通过共识协议来维护规章制度的正常运行。DAC：Decentralized Autonomous Corporation（去中心化的自治公司） 出于营利目的，DAO可以是出于非营利目的。 在2016年5月出现了一个致力于众筹投资的DAO——TheDAO：本质是一个智能合约，你可以把以太币发给智能合约，然后换回TheDAO的代币，决定投资哪个项目时是投票决定的，投票权重由TheDAO的代币决定，收益也是按照智能合约的规章制度进行分配。TheDAO是一次伟大的尝试，很快吸引了大量的资金，但是很快就失败了 splitDAO函数如果有人的投资理念与大部分人不同，可以通过splitDAO拆成出一个子基金，之前的代币会被收回，换成相应数量的以太币打到子基金里，然后投资自己想投的项目，这也是取回钱的唯一方式。拆分前有7天的辩论期，拆分后有28天的锁定期 黑客通过重入攻击转走了5000w美元的以太币，差不多总资金的1/3以太坊社区讨论解决方法分成两派一派是回滚交易：有28天的锁定期，黑客暂时还无法把钱取走，通过回滚交易保证投资者的利益。另一派认为不需要补救：因为黑客的行为并没有违法，code is law，代码中的漏洞也是规则的一部分以太坊开发团队支持采取补救措施 补救措施从发生黑客攻击的前一个区块开始分叉，上面的链不挖了，挖下面的链使下面的链更长。但这样会使得后面许多合法的交易也被回滚，要想回滚必须精确定位，只回滚黑客盗取以太币的交易，这是采取补救措施的原则 开发团队制定了“两步走”方案： 软分叉方案：锁定黑客账户，开发团队发布了一个软件升级，增加一条规则——凡是跟TheDAO这个基金相关的账户不允许做任何交易。这是一个软分叉。但是发布之后有一个bug——与汽油费有关，与The DAO的账户相关的交易不予执行，这时要不要收取汽油费？这条新规则没有收取汽油费，这时可能会有一些恶意的攻击者不断发送这种非法的交易浪费矿工的资源，这就导致本来已经升级的大多数矿工纷纷回滚软件升级，改回了之前的版本，于是这种软分叉的方案就失败了。这时28天的锁定期剩下的已经不多了。 硬分叉方案：通过软件升级把TheDAO账户上的所有资金强行转到另一个智能合约上，这个智能合约只有一个退钱功能。升级的软件中规定了强制执行的具体日期，到192W个区块自动执行转账交易，不需要合法的签名，在软件中写死的规则，所以旧的矿工是不会认可的，所以属于硬分叉。 最后通过投票决定大部分矿工支持硬分叉，升级了硬分叉的版本，于是大家就等待着挖出192W个区块的时刻，这次没有出现意外，硬分叉成功了 但是，当初反对硬分叉的人并没有因为投票结果改变立场，所以旧的链并没有消亡，还有矿工在挖矿，只不过算力大幅下降了，但是挖矿难度也大幅下降了，所以还是有矿工愿意在旧链上挖的。 旧链上的以太币：ETC新链上的以太币：ETH但是分裂出两条链给管理上带来了混乱，比如重放攻击，新链的交易放到旧链是合法的，旧链的交易放到新链也是合法的，后来给这两条链加了chainID区分开来 Q：为什么当初硬分叉和软分叉的操作是针对所有The DAO的账户，而不是只针对黑客的账户？智能合约一旦发布，不能修改，这个bug不能修复，这次黑客用了，下次其他的账户也可以用，任何人都能成为黑客，这个合约就作废了。","link":"/2022/01/24/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B022%E2%80%94%E2%80%94ETH-TheDAO/"},{"title":"区块链学习笔记23——ETH反思","text":"​​点击阅读更多查看文章内容 区块链学习笔记23——ETH反思 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 智能合约真的智能吗？ 智能合约并没有用到人工智能的技术，有人认为应该叫做“自动合约”，按照事先写好的代码自动执行某些操作。现实世界中自动执行某些操作的例子如ATM取款机，物理世界的自动合约，插入银行卡输入密码，就会自动把钱给你。智能合约其实并不智能，反而有些“笨”，因为一旦写好之后就无法修改，实际上是一种代码合同。 不可篡改性是一把双刃剑 一方面来说不可篡改性增加了合同的公信力，大家都只能按照合约中的规定去做，没有人能篡改。另一方面不可篡改性也意味着如果规则中有漏洞，想要修补这个漏洞，想软件升级，都是很困难的。在区块链的世界里，软件更新需要硬分叉来实现，无论是比特币还是以太坊，硬分叉都不是随便搞得，以太坊的硬分叉，最后就造成了两条平行的链。而且硬分叉要说明理由，否则矿工不会升级软件，但是一旦说明理由就容易把漏洞的信息泄露出去，有恶意的攻击者可能会在没来得及升级软件之前抢先发动攻击。另外，即使我们已经发现了系统漏洞，已经有人进行恶意攻击了，想要冻结账户终止交易都是很困难的。要想冻结账户，要进行软发叉，发布一个软件的更新凡是跟这个账户相关的交易都是不合法的，这才能够冻结，但是明显不可能因为个人原因发布一个软分叉，只能把账户剩下的钱尽快转到安全的账户。与之类似，智能合约一旦发布到区块链上，没有办法阻止对它的调用。比如The DAO事件，1/3的钱被黑客盗走了，剩下的2/3的钱也非常危险，但是没有办法阻止别人调用智能合约，唯一的办法是用黑客的方法把钱转到另一个安全的合约。 没有什么是真的不可篡改的 一个篡改的例子就是分叉攻击，以太坊团队通过软件升级的方法强行改变某些账户的状态。一般情况下区块链上的内容想要篡改是很难的，但是遇到重大事件真的想改还是能改得了的。 Solidity语言设计上的问题 solidity的语言特性是反自然的，一般的理解，我给你转账，你是一个被动的接受者，你不可能反过来调用我，但是solidity的语言特性是说我给你转账的操作等于隐性地调用了你的fallback函数，结果你就可以再来调用我。这个和生活常识不同所以安全漏洞容易被忽略。有人提出应该用函数式的编程语言，函数式语言(例如：ocaml)比较安全不容易出现这种漏洞 编写智能合约的语言应该有什么样的表达能力？ solidity 语言是图灵完备的，但是会有漏洞，比特币脚本语言比较简单，目前没有发现任何漏洞。能不能找到一个比比特币语言复杂又比solidity简单的语言？不容易出现安全漏洞。很难找到，因为在设计语言的时候不可能预知到其所有的使用场景解决方法：可以向常用的智能合约提供一些模板，也有可能会出现专门编写智能合约的机构就像律师事务所一样。 开源的好处 去中心化的系统像如区块链都是开源的，也就是透明的，因为必须要让所有的节点都执行同样的内容才能达成共识。开源的一个好处就是增加合约的公信力，接受群众的监督。有些人认为开源的另外一个好处是安全，因为全世界的人都在看着这些代码，那么为什么开源软件还会出现漏洞呢？这种现象叫做many eyeball fallacy错误认知的意思，相当于misbelief。但实际上真正有时间看代码的人少之又少，看的人不是很多，也不一定能看得懂。 关于去中心化 以太坊的硬分叉真的就是以太坊的开发团队说了算的吗？不是，这个硬分叉能成功，也是90%的绝大多数的矿工升级了软件用行动支持了硬分叉，剩下的一小部分虽然没有支持，但是也依然在旧链上继续挖矿，以太坊团队也没有办法强制所有人都升级软件。去中心化并不是不能修改已经制定的规则，而是修改规则要用去中心化的方式进行。硬分叉的成功是因为大多数的矿工认为以太坊团队的措施是符合公众利益的。而分叉正好是去中心化系统的体现，因为只有去中心化系统，用户才可以选择分叉，中心化系统只能选择继续或者放弃。存在分叉的现象恰恰是民主的体现，比如系统私自增多以太币供给量，使得以太币贬值，矿工就可以选择分叉继续维护原来的以太币 去中心化与分布式不是等价的 一个去中心化的系统必然是分布式的，如果这个系统只运行在一台计算机上，显然不能叫去中心化；但是分布式系统不一定是去中心化的，即使这个系统运行在成千上万的计算机上，如果计算机都是由同一个组织管辖的，那也不是去中心化，比如谷歌的search engine；在一个分布式的平台上可以运行一个中心化的应用，也可以运行一个去中心化的应用。比特币和以太坊都是交易驱动的状态机，state machine的特点是让系统中几千台机器重复做同一组操作，付出很大的代价来维护状态的一致性，这个并不是分布式系统常用的工作模式，大多数的分布式是让每台机器做不同的事情，然后再把各台机器的工作结果汇总起来，目的是比单机速度快。状态机的目的不是为了比一台计算机的处理速度快，而是为了容错。状态机最早的应用场景：mission critical application.特点是应用程序必须无间断的对外提供服务，哪怕宕机一分钟都会造成很大的损失，所以他才有好几组计算机重复同一组操作，这样即使有一台计算机故障，剩下的计算机也可以对外提供服务。 eg: airtraffic control; stock exchange; space shuttle.这样付出的代价是效率很低，几台机器合在一起比一台机器慢，因为需要同步状态，而且集群里的数目越多速度越慢，所以传统利用状态机的应用场景，机器的数目都是比较少的，可能就是个位数字。像比特币和以太坊这样上千台机器重复同一组操作，之前是没有出现过的。 智能合约是编写控制逻辑的，只有那些互不信任的实体之间建立共识的操作才需要写在智能合约里。大规模存储和计算不适用，又慢又贵，因为还要消耗汽油费，使用云服务平台更好。","link":"/2022/01/24/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B023%E2%80%94%E2%80%94ETH%E5%8F%8D%E6%80%9D/"},{"title":"区块链学习笔记24——ETH美链","text":"​​点击阅读更多查看文章内容 区块链学习笔记24——ETH美链 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 ICO：Initial Coin Offering 首次代币发行IPO：Initial Public Offering 首次公开募股 背景介绍 这些发行的代币没有自己的区块链，而是以智能合约的形式运行在以太坊的EVM平台上，发行代币的智能合约对应的是以太坊状态树中的一个节点，这个节点有他自己的账户余额，就相当于这个智能合约一共有多少个以太币，就是这个发行代币的智能合约他的总资产是多少个以太币，然后在合约里每个账户有多少代币是作为存储树中的变量，存储在智能合约的账户里，代币的发行，转账，销毁都是通过调用智能合约中的函数来实现的，每个代币都可以制定自己的转换规则，比如1个以太币=100个代币，比如外部账户给这个智能合约转一个以太币，智能合约就会给你在合约里的代币账户发送100个代币，每个账户的余额都是维护在发行代币的智能合约的存储树里面。美链的代币叫BEC，比如我有很多BEC，给十个不同的账户发送代币，调用这个batchTransfer 函数，每个人发送100个代币，那么这个batchTransfer函数先从我的账户上扣掉1000个代币，然后给十个账户分别增加100个代币。 batchTransfer函数 攻击细节一堆数字是函数调用的参数，函数有两个参数，分别对应那串数字的前两行，第一个参数是地址，第一行给出的实际上是第一个参数出现的具体位置，这里是16进制的，40也就是64，也就是说第一个参数出现在第64个字节的位置，每一行是32个字节，所以实际上是从第2号开始出现的。第二行是这个value的值，这是个很大的数，前面是8，后面都是0，第三行是这个数组的具体内容，数组的长度，是2，接下来两行是两个接收的地址。 参数的特征：第二行amount是8，再乘以2，算出来的amount恰好溢出为0，add(value)的时候还是加原来特别大的那一串数目。红框中是接收地址接收的代币，每个地址都接收到了很大一部分代币， 被攻击之后暂停提币的功能，防止黑客携款逃走。两天之后回滚交易，事件影响没有The DAO影响深远。攻击发生后这个代币的价格暴跌代币上市的交易所在发生攻击后暂停提币的功能 反思在进行数学运算的时候一定要考虑溢出的可能性。solidity有一个safeMath库，里面提供的操作运算都会自动检测有没有出现溢出。 C语言里，两个数相乘会有一定的精度损失，再除以一个数，不一定会得到和另外一个数一模一样的数。但是在solidity里面是不存在的，因为两个数都是256位的整数，整数先进行乘法，再进行除法。 batchTransfer的加法和减法都用的safeMath库，只有乘法不小心没有使用，结果酿成了悲剧。","link":"/2022/01/24/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B024%E2%80%94%E2%80%94ETH%E7%BE%8E%E9%93%BE/"},{"title":"区块链学习笔记25——总结","text":"​​点击阅读更多查看文章内容 区块链学习笔记25——总结 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 区块链错误应用场景1：用BTC转账加速保险理赔 保险理赔慢，并不是因为转账慢，而是需要人工进行实际的评判，这是区块链无法解决的 区块链错误应用场景2：防伪追溯，如将有机蔬菜的生产运输全过程上链 首先可能写入区块链的过程本身就是假的，而且在实际运输中蔬菜也有可能被掉包 区块链的共识机制目的是在互不信任的实体间建立共识，有人认为这是一个伪命题，因为互不信任的实体间是无法进行交易的。 比如说网上购物，假设有个电商网站是去中心化的，你将比特币付给商家，对方不给你发货或有质量问题怎么办？在一个中心化的世界里可以通过各种机构来解决。但在去中心化的世界里是无法做到的。中心化和去中心化的界限不是黑白分明的，在一个成功的商业模式里，既可以有中心化成分也可以有去中心化成分，比特币只是一种支付方式，并不是说采用比特币作为支付方式的商业模式也要是去中心化的 BTC不应该和已有的支付手段竞争 它应该发挥自己的特长，用在已有的支付方式解决的不是很好的地方，比如跨境支付。现在的金融体系缺乏一种可以在全球流通的数字货币，而且这种货币的支付方式可以和信息传播的方式融合在一起。有人说下一代互联网是价值交换网络，我们现在的互联网是信息传播网络。现在的问题在于信息的传播和交互比较方便，但是价值交换是不方便的。未来的发展趋势就是支付渠道和信息渠道相互融合，使得价值获得和信息获得一样方便。 与支付效率相关的质疑 有人认为加密货币的支付效率是非常低效的，而且能耗是很大的，好像现有的支付方式好很多。 加密货币本身就不是用于跟已有的货币做竞争的，在一些用普通货币更方便的地方，没有必要用加密货币； 随着区块链的发展以及共识协议的改进，一些新的加密货币已经在支付效率上已经是大大提高了； 评价支付的效率要放在当时的历史背景之下比较。 与智能合约相关的质疑 智能合约出现漏洞之后有些人觉得还是自然语言的法律合同更好，普通人还能看得懂。对于这种观点，首先要意识到程序化是个大趋势，ATM机可以看作是物理世界中的智能合约，按照事先设定好的规则进行操作。ATM机现在也会出现故障，我们并没有因为它出现故障而不使用它，所以智能合约的故障是无关紧要的，技术的革新会不断完善。 完结撒花！","link":"/2022/01/24/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B025%E2%80%94%E2%80%94%E6%80%BB%E7%BB%93/"},{"title":"区块链学习笔记2——BTC中的数据结构","text":"​​点击阅读更多查看文章内容 区块链学习笔记2——BTC中的数据结构 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 本文主要介绍四种数据结构：Hash pointers、Block chain、Merkle tree、Block Hash pointers（哈希指针） 哈希指针与普通指针类似，它除了保存地址之外还保存哈希值 Block chain（区块链）区块链中区块与区块之间通过哈希指针相连，这里哈希指针中的哈希值是对前一个区块的整体取哈希，包括前一个区块的哈希指针，因此区块链如果有一个区块被修改，那么他之后的所有区块都会改变，我们只需要记住最后一个区块的哈希值，就可以判断整个区块链有没有被修改。用户一般不需要保存区块链中的全部区块，在使用的时候向其他区块要即可，通过哈希值可判断对方给的区块有没有被修改。 Merkle tree Merkle Tree与二叉树类似，主要是将二叉树中的指针换成了哈希指针 在Merkle tree中，我们只需要记住根节点的哈希值，就可以检测出整棵树的内容有没有被修改。每个区块所包含的交易都组织成Merkle tree的形式，就是上图中的Data Blocks。 Block（区块）block包括block header和block body两部分block header：root hash（Merkle tree的根哈希值）等信息block body：交易列表 Merkle proofMarkle Tree可以用于提供Markle Proof。关于Markle proof，需要先了解比特币系统中节点。比特币中节点分为轻节点和全节点。全节点保存整个区块的所有内容，而轻节点仅仅保存区块的块头信息。当需要向轻节点验证它的交易是否被写到区块中时需要用到Merkle proof。 以上图为例，要验证黄色的交易是否被写到区块中，我们首先要请求第三层的红色的哈希值，然后根据黄色的交易求出第三层的绿色哈希值，然后通过这两个已知的哈希值求出第二层的绿色哈希值，再请求第二层的红色哈希值，以此类推最终求得根哈希值，然后与存储在自身结点中的根哈希值比较，若相同则证明交易已经写入到了区块中。 上面的验证是proof of membership 时间复杂度为O(logn)关于proof of non-membership验证，如果交易是无序的，我们只能证明每个结点都是对的，说明没有该节点，时间复杂度为O(n)如果交易是按hash值从小到大排序，我们对要检验的交易取hash，判断它应处的位置，然后计算他前后的两个结点的hash，若这两个结点确实相邻（merkle proof），则证明我们要找的结点不存在（若存在则会在这两个结点之间，这两个结点不会相邻），时间复杂度为O(logn) 注意无环的情况下都可以使用hash pointer代替point有环时会因为每一个hash point都与它前一个的hash值有关，所以会产生循环依赖，每个hash都定不下来。","link":"/2021/12/11/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%E2%80%94%E2%80%94BTC%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"区块链学习笔记4——BTC实现","text":"​​点击阅读更多查看文章内容 区块链学习笔记4——BTC实现 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 UTXO区块链是一个去中心化的账本，比特币采用了基于交易的账本模式 。然而，系统中并没有记录账户所包含的比特币数，需要通过交易记录进行推算。在比特币系统中，全节点需要维护一个名为 UTXO(Unspent Transaction Output 还没有被花掉的交易输出) 的数据结构。 A转给B五个BTC，转给C三个BTC，B将5个BTC花掉，则该交易记录不保存在UTXO中，C没有花掉，则该交易记录保存在UTXO中 UTXO中的每个元素包括产生这个输出的交易的哈希值以及它在这个交易里是第几个输出就可以定位到这个输出 作用检测交易是否合法，要花的币必须在UTXO中，便于快速检测double spending 每个交易会消耗输出，也会产生新的输出如图，A转给B五个BTC，之后B将其转给D，则UTXO中会删掉A-&gt;B这一交易记录，同时会添加B-&gt;D这一交易记录。如果一个人的比特币一直都不花，那他就会永久的保存在utxo中。 Transaction fee交易可以有多个输入也可以有多个输出，但输入之和要等于输出之和（total inputs = total outputs）。 有一些交易的total inputs会略大于total outputs，这个差额就是transaction fee，给了获得记账权的结点。 之前有提到过会不会存在节点只想发布区块获得出块奖励而不想打包交易？因此，BTC系统设计了Tranction fee（交易费），对于获得记账权节点来说，除了出块奖励之外，还可以得到打包交易的交易费。但目前来说，交易费远远小于出块奖励。等到未来出块奖励变少，可能区块链的维护便主要依赖于交易费了。 平均每隔十分钟产生一个新区块，每21万个区块，出块奖励减半，大约每隔四年出块奖励就会减半。 基于账户的模式比特币是基于交易的模式，与之对应，还有一种基于账户的模式（如：以太坊）。基于账户的模式要求，系统中显示记录账户余额。也就是说，可以直接查询当前账户余额是多少货币。可以看到，比特币这种模式，隐私性较好，但其也付出一定代价。在进行交易时，因为没有账户这一概念，无法知道账户剩余多少BTC,所以必须说明币的来源（防止双花攻击）。而基于账户的模式，则天然地避免了这种缺陷，转账交易就是对一个（多个）账户余额的数字减和另一个（多个）账户余额的数字加 铸币交易（coinbase交易）区块头中的nonce是一个32位无符号整数，在挖矿时候是通过不断调整nonce进行的，但可以看到，nonce的取值最多为2^32^种。但并非将这些nonce全部遍历一遍，就一定能找到符合要求的nonce。由于近年来，挖矿人员越来越多，挖矿难度已经调整的比较大了，而2^32这一搜索空间太小，所以仅调整nonce很大可能找不到正确的结果。那么，还能修改哪些值呢？从上图可以看出，只有Merkle Tree的根哈希值可以进行修改，对根哈希值的修改主要是通过修改coinbase实现的。每个发布区块者可以得到出块奖励，也就是可以在区块中发布一个 铸币交易(coinbase交易) ,这也是BTC系统中产生新比特币的唯一方式。下为一个铸币交易的内容：可以看到，有一个CoinBase域，其中可以写入任何内容，在这里写什么都没有影响。所以可以在这里添加一些任意信息，便可以实现无法篡改（也无法删除）。（例如：提前写入股票预测结果的哈希值）所以，只要我们改变了写入内容，便可以改变Merkle Tree 的根哈希值。下图为一个小型的区块链，假定左下角交易为coinbase交易，可以看到，该交易发生改变会逐级向上传递，最终导致Merkle Tree根哈希值发生改变。在实际的挖矿中，包括两层循环，外层循环调整coinbase域（可以规定只将其中前x个字节作为另一个nonce），算出block header中根哈希值后，内层循环再调整nonce。 普通转账交易如果将输入脚本和输出脚本拼接起来可以顺利执行不出现错误，则说明交易合法。 挖矿过程的概率分析 挖矿本质上是不断尝试各种nonce，来求解这样一个puzzle。每次尝试nonce，可以视为一次伯努利试验。最典型的伯努利试验就是投掷硬币，正面和反面朝上概率为p和1-p。在挖矿过程中，一次伯努利试验，成功的概率极小，失败的概率极大。挖矿便是多次进行伯努利试验，且每次随机。这些伯努利试验便构成了a sequence of independent Bernoulli trials(一系列独立的伯努利试验)。根据概率论相关知识知道，伯努利试验本身具有无记忆性。也就是说，无论之前做多少大量试验，对后续继续试验没有任何影响 对于挖矿来说，便是多次伯努利试验尝试nonce，最终找到一个符合要求的nonce。在这种情况下，可以采用泊松分布进行近似，由此通过概率论可以推断出，系统出块时间服从指数分布。(需要注意的是，出块时间指的是整个系统出块时间，并非挖矿的个人) 指数分布本身也具有无记忆性。也就是说，对整个系统而言，已经过去10min，仍然没有人挖到区块，那么平均仍然还需要等10min（很不符合人的直觉）。也就是说，将来要挖多久和已经挖多久无关。 比特币总数计算：Geometric series21万×50+21万×25+21万×12.5+…=21万×50×（1+1/2+1/4+…）=21万×50×1/（1-1/2）=2100万 -&gt; 比特币总数 BitCoin is secured by mining1.可否将其他账户上比特币转给自己？ 答案：不能。因为转账交易需要签名，恶意节点无法伪造他人签名。如果恶意结点强行把一个非法的交易加到区块链中，其他的诚实结点检测到这个区块含有非法交易就不会接到这个区块链之后，并且另外形成一条最长合法链，这样恶意结点所添加的区块不在最长合法链上，恶意节点不仅无法偷币，而且无法获得出块奖励。2.可否将已经话过的币再花一遍？如下图1，若M已经将钱转给B，现在想再转给自己，假设其获得记账权，若按照图1方式，很明显为一个非法区块，不会被其他节点承认。所以，M只能选择图2方式，将M转账给B的记录回滚掉。这样就有了两条等长合法链，取决于哪一个会胜出。（如果上面交易产生不可逆的外部效果，下面交易回滚便又拿回钱，从而不当获益）如果在M-&gt;B这个交易之后还延续有几个区块，如下图所示，则大多数诚实节点不会承认下面的链。所以，便变成了恶意节点挖下面的链，其他节点挖上面的链的算力比拼。由于区块链中大多数节点为善意节点，则最终上面链会胜出，而恶意节点的链会不被认可，从而导致投入成本白费。一种简单防范防范便是多等几个确认区块。比特币协议中，缺省需要等6个确认区块，此时才认为该记录是不可篡改的。平均出块时间10min，六个确认区块便需要1小时。 Selfish mining如图所示，假使挖到2号时候先不发布，则其他人仍然需要挖1号区块，若其算力足够强，能保证别人挖出1之后可以挖出3.可以此时将2和3一起发布，从而将1区块所在链最长合法链挤掉（减少了别人和自己竞争挖3号区块）。但这样存在风险，如果别人已经挖出1，自己还没挖出3，则需要尽快发布2和别人竞争最长合法链地位。","link":"/2021/12/19/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04%E2%80%94%E2%80%94BTC%E5%AE%9E%E7%8E%B0/"},{"title":"区块链学习笔记3——BTC协议","text":"​​点击阅读更多查看文章内容 区块链学习笔记3——BTC协议 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 数字货币所面临的主要挑战Double spending attack（双花攻击，同一张数字货币可以复制的使用）防范：通过一个可信第三方（如央行）维护一个很大的数据库存储每张货币的所有人，对每张货币添加一个唯一编号，当一个人花掉这张货币的时候，这张货币的所有人也会相应的发生变化， 去中心化 所谓去中心化即没有可信第三方的参与，那么就需要解决数字货币的发行由谁执行？如何发行？发行多少？什么时候发行？ 在传统中心化货币体系中，这些问题我们可以交给第三方机构（如央行）。当引入去中心化思想后，系统中节点平等，交易不通过第三方，那么货币发行权的分配必然是一个需要解决的问题。比特币通过挖矿来决定货币的发行权，发行量 去中心化如何防范双花攻击，恶意用户等 该问题的解决，依赖于系统中维护的一个数据结构，记录货币的使用情况（是否被花过？被谁花过？）。该数据结构由系统中全体用户共同维护，保证了交易的有效性。该数据结构，便是区块链。 简单的区块链交易模型在该模型中，A获得了铸币权，发行了十个币，在第一个交易中，A转给了B五个币，转给了C五个币，A对该交易签名，同时，通过一个指针指出了这十个币的来源，后面的两个交易类似。 在进行交易时，需要付款人的签名和收款人的地址，在比特币系统中，该地址即为收款人的公钥的哈希。可以将其视为银行账户，根据此进行转账交易。（虽然公钥可以公开，但实际中更多公开的是公钥的哈希）在交易中，收款方需要知道付款方的公钥，从而验证A签名是否有效。即A需要提供自己的公钥（实际上其他节点都需要知道付款方公钥，验证交易合法性）实际中A转账时候提供的公钥需要和铸币交易中公钥对的上，这样就防止了恶意节点伪造A的公钥来“偷”走A的比特币。在比特币系统中，通过执行脚本实现上述验证过程。将当前交易输入脚本与前一个交易输出脚本（说明币的来源的交易）拼接执行，如果可以正确执行，说明交易合法。在该图中，一个区块仅含有一个交易，实际中一个区块中包含多个交易，交易通过Markle Tree组织起来，在区块中存储。 区块信息 Block header 区块头 Version 比特币的协议版本 Hash of previous block header 区块链中指向前一个区块的指针 Merkle root hash 整课Merkle tree的根哈希值 Target 难度目标阈值（比特币有关） nonce 随机数（比特币有关） Merkle root hash保证了block body内容不被篡改，所以只需要计算block header即可保证整个区块内容不会被篡改 Block body 区块体 Transaction list 交易列表 Full node：保存区块链的所有信息，验证每一个交易Light node：只保存block header，不参与区块链的构造维护 Distributed consensus（分布式共识）FLP impossibility result系统网络传输是异步的，网络时延没有上限，哪怕系统中有一个成员是faulty的，那就无法达成共识。CAP TheoremC:consistency 一致性A:Availability 可靠性P:Partition tolerance 容错性任何一个分布式系统中这三个性质最多只能满足两个。 Consensus in BitCoin（比特币中的共识协议）存在的问题：系统中存在恶意结点1.直接投票某个结点发布交易到区块链中，其他结点检查该区块，通过投票决定是否将其加入到区块链中，如果赞成票数超过一半，则加入区块链。问题1——恶意结点不断打包不合法区块，导致一直无法达成共识，时间全浪费在投票上问题2——无激励机制，有些节点不会投票问题3——网络延迟为止，投票等待时间不确定，效率上会产生问题女巫攻击——比特币系统允许任何人加入，只需要本地创建公私钥对即可创建账户。这样，恶意用户只需不断产生新的节点，当节点数达到一半以上时就会有区块链的控制权，操纵投票结果。2.算力投票算力投票是比特币使用的共识协议，即通常所说的“挖矿”，每个结点都可以自行组装区块，尝试各种nonce值，当找到某个符合条件的nonce时便获得了记账权，从而将区块发布到系统中，其中节点收到区块后可以验证其合法性，如果系统中大多数结点验证通过，则接受该区块。forking attack（分叉攻击）如上图所示，A对同时给两个用户转账。在两条链上，发现交易都合法，这是典型的双花攻击。A先给B转账后，通过分叉攻击将交易回滚，把钱又转回来，这在验证上是可以通过的。但在实际的比特币系统中，这种情况很难发生，因为大多数矿工认可的是最长的合法链，会沿着上面的链继续挖下去，如果A想回退这个记录，就必须使得下面的链比上面的还要长，理论上需要达到51%的算力才能攻击成功，实际中这是很困难的。 如上图所示，在区块链正常的工作中，也可能会发生分叉，当连个节点同时获得记账权时，会有两个区块同时上链，此时会有两个等长的合法链。在缺省情况下，节点接受最先听到的区块，该节点会沿着该区块继续延续，但随着时间延续，必然有一个链胜出，由此保证了区块链的一致性。 Block reward（出块奖励）出块奖励是比特币中的激励机制，获得记账权的结点在发布的区块中可以加一个特殊的交易（铸币交易），这是发布比特币的唯一方法，不需要指明币的来源。最开始每个区块可以发布50个比特币，每过21万个区块比特币会减半，现在只有12.5个比特币。","link":"/2021/12/11/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03%E2%80%94%E2%80%94BTC%E5%8D%8F%E8%AE%AE/"},{"title":"区块链学习笔记5——BTC网络","text":"​​点击阅读更多查看文章内容 区块链学习笔记5——BTC网络 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 比特币系统的工作过程用户将交易发布到比特币网络上，节点收到交易后打包到区块中，然后将区块发布到比特币网络上，那么新发布的交易和区块在比特币网络上是如何传播的呢？ 比特币网络的工作原理比特币工作于应用层，其底层（网络层）运行的是一个P2P Overlay Network，比特币的P2P网络非常简单，所有节点都是对等的。 比特币要加入网络首先要知道一个种子节点，然后与种子节点联系，它会告诉你它所知道的网络中的其他节点。 结点之间通过tcp通信，这样有利于穿透防火墙。 离开网络时不需要做其他操作，直接退出应用程序即可，其他节点没有听到你的消息，过一段时间后就会把你删掉。 比特币的设计原则：简单、鲁棒，而不是高效 每个结点会维护一个邻居节点的集合，消息传播采取flooding的方法，节点第一次听到某个消息时，会把它传播给其他所有的邻居节点，同时记录这个消息已经收到过了，下次再收到时就不会再传播给其他邻居节点了。邻居节点的选择是随机的，没有考虑底层的拓扑结构（一个在加利福尼亚的结点的邻居节点可能在阿根廷），这样增强了鲁棒性，但牺牲了效率。 每个结点还要维护一个等待上链的交易的集合，第一次听到交易，若是合法交易，则将其加入该交易集合并转发给邻居节点，以后再收到该交易就不再转发（避免网络上交易无限传输）。假如网络中存在两个冲突交易，如交易1：A-&gt;B,交易2：A-&gt;C（假设花费的同一笔钱）。具体接收哪个取决于节点先接收到哪个交易，之后收到另一个交易会将其放弃，结点位置不同，收到的交易也不同。如果交易被写到区块链上，就删掉这个交易。如果节点收到交易1，但又听到交易2被写到区块链上，那么交易1为非法交易，也会被删掉 新发布区块在网络中传播方式与新发布交易传播方式类似，每个节点除检查该区块内容是否合法，还要检查是否位于最长合法链上。区块越大，则网络上传输越慢。BTC协议对于区块大小限制为不大于1M大小。（比特币网络所采取的传输方式是非常耗带宽的，按照1M的大小来算，一个新发布的区块有可能需要几十秒才能传播到网络上的绝大多数结点） 比特币网络传播属于 Best effort（尽力而为） ，不能保证一定传输成功。以一个交易发布到网络上，未必所有节点都能收到，也未必所有节点收到交易顺序都一致。","link":"/2021/12/26/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B05%E2%80%94%E2%80%94BTC%E7%BD%91%E7%BB%9C/"},{"title":"区块链学习笔记6——BTC挖矿难度","text":"​​点击阅读更多查看文章内容 区块链学习笔记6——BTC挖矿难度 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 为什么要调整挖矿难度挖矿：不断尝试nonce使整个block header的哈希值小于等于目标阈值 H(block header)&lt;= target （target越小，挖矿难度越大）调整挖矿难度就是调整目标空间在整个输出空间中所占的比例 比特币用的哈希方法是 SHA-256，产生的哈希值是256位，整个的输出空间是2^256^,调整目标空间所占比例，简单的说需要目标值前需要多少个0。 这里是引用挖矿难度与目标阈值成反比difficulty_1_target是挖矿难度等于1时所对应的目标阈值挖矿难度最小为1，此时对应的target是一个很大的数 如果不调整挖矿难度会怎么样？如果挖矿难度不变，那么随着算力增强，出块速度会变快，出块时间越来越短。 出块时间越来越短是好事吗？如果出块时间缩短，那么交易可以很快便被写入区块链，并且提高了系统响应时间，增加了区块链系统效率。但是，出块时间并不是越短越好。出块时间太短，也会造成一定的问题。首先，区块在网络上传播具有时延，假如出块时间为1秒，但网络传播需要10秒，则会使得系统中节点经常性处于不一致的状态，增加了系统不稳定性，且系统经常性位于分叉状态（不仅二分叉，乃至多分叉）。分叉过多，则不利于系统达成共识，且会造成算力分散，使得黑客攻击成本大大降低(不再需要整个系统51%的算力)。 10min的出块间隔是最优吗？ 当然不是，以太坊中平均出块时间仅为15秒左右，出块速度是比特币的四十倍，出块时间大幅减少后以太坊设计了新的共识协议Ghost，在此协议中，分叉产生的区块是orphan block，不会简单丢弃掉，而是给予一些奖励（uncle reward）。以太坊中同样需要调整挖矿难度，使出块时间稳定，不能无限的减小下去。 怎样调整挖矿难度比特币协议中规定，每隔2016个区块要重新调整目标阈值，大概每两周调整一次。这里上调下调都是有限的，如果actual time非常长，超过了八个星期，也按照八个星期来计算，即target一次性最多只会增大四倍。如果actual time非常短，不到半个星期，也按照半个星期来算，即target一次性最小只会减小四倍。 怎样让所有矿工同时调整目标阈值？计算target的方法是写在比特币系统的代码里，每挖到2016个区块会自动调整，如果有某个有恶意的结点故意不调整，其他诚实结点会验证这个区块的nBits域（对目标阈值的一个压缩编码，target有32个字节，nBits只有4个字节）不合法，这个区块不会被接受 算力、挖矿难度、难度调整、出块时间的变化曲线算力变化情况：最近一年（2017年）呈指数增长，不是严格递增的，中间也有很多波动，需要注意的是，之前一段并非直线，而是之后增长太猛导致之前增长趋势看上去太低。 挖矿难度变化情况：和系统算力变化基本同步难度调整曲线：每隔两个星期，难度上一台阶，反映出人们对比特币的热情越来越高出块时间：总的来说稳定在10分钟上下震动，难度调整达到了预期目的","link":"/2022/01/12/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B06%E2%80%94%E2%80%94BTC%E6%8C%96%E7%9F%BF%E9%9A%BE%E5%BA%A6/"},{"title":"区块链学习笔记7——BTC挖矿","text":"​​点击阅读更多查看文章内容 区块链学习笔记7——BTC挖矿 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 结点全结点： 一直在线 在本地硬盘上维护完整的区块链信息 在内存里维护UTXO集合，以便快速检验交易的正确性 监听比特币网络上的交易信息，验证每个交易的合法性 决定哪些交易会被打包到区块里 监听别的矿工挖出来的区块，验证其合法性 挖矿 决定沿着哪条链挖下去？(缺省：最长合法链) 当出现等长的分叉的时候，选择哪一个分叉？(缺省：最先监听到的) 轻节点： 不是一直在线 不能保存整个区块链，只要保存每个区块的块头 不用保存全部交易，只保存与自己相关的交易 无法检验大多数交易的合法性，只能检验与自己相关的那些交易的合法性 合法检测网上发布的区块的正确性 可以验证挖矿的难度 只能检测哪个是最长链，不知道哪个是最长合法链 挖矿设备 刚开始用CPU、通用计算机挖矿会导致内存等其他资源有很多闲置，性价比太低后转入第二代GPU计算，用于通用并行计算，但其中还有许多部件是闲置的(如用于浮点数计算的部件)ASIC芯片专门为挖矿设计，一种芯片只能挖一种货币，除非使用相同的mining puzzle，性价比最高 CPU(通用计算)-&gt;GPU(通用并行计算)-&gt;ASIC(挖矿专用) 大型矿池的出现 挖矿另一个趋势便是大型矿池的出现。对于单个矿工来说，即使使用了ASIC矿机，其算力在整个系统中仍然只占据很少一部分，即使从平均收益看有利可图，但收入很不稳定。此外，单个矿工除挖矿还要承担全节点其他责任，造成了算力的消耗。 一个全结点驱动很多矿机。矿工只需要不停计算哈希值，而全节点其他职责由矿主来承担。ASIC芯片只能计算哈希值，不能实现全节点其他功能。此外，矿池出现解决了单个矿工收益不稳定的问题。当获得收益后，所有矿工对收益进行分配，从而保证了收益的稳定性。矿池一般具有两种组织形式。1.类似大型数据中心（同一机构），集中成千上万矿机进行哈希计算。2.分布式。矿工与矿主不认识(不同机构)，矿工按照矿池规定的通讯协议与矿主联系，矿主分配任务，矿工进行计算并将结果返回给矿主，获得收益后整个矿池中所有矿工进行利益分配。 矿池利益分配 平均分配，平分出块奖励，会使得有些矿工不工作，偷懒 按照工作量分配 之前说到的挖矿收益不稳定是因为挖矿难度太高假设要前70位为0，可能要一两年才能挖到，现在可以降低挖矿的难度，只需要前60位为0，这样挖矿会更容易挖到。当然，这个哈希是不会被区块链所承认的，我们将其称为一个share，或almost valid share。矿工每挖到一个share，将其提交给矿主，矿主对其进行记录，作为矿工工作量的证明。等到某个矿工真正挖到符合要求的的区块后，根据所有矿工提交的share数量进行分配。 因为每个矿工尝试的nonce越多，挖到矿的可能性越大，所能得到的share也会越多，所以这种方案作为工作量证明方案是可行的。 思考一：有没有可能，某个矿工平时正常提交share，但真正挖到区块后不提交给矿主而是自己偷偷发布出去，从而避免他人分走挖矿所得到的出块奖励？事实上，这种情况是不可能的。因为每个矿工挖矿任务是矿主分配的。矿主组装区块，交给矿工计算，而区块中铸币交易的收款人地址是矿主，区块发布出去的收益也是矿主的，如果矿工修改该地址，算出的Merkle tree是不同的，矿主不会承认share。思考二：有没有可能矿工自己刚开始就自己偷偷组装一个区块，自己挖矿？这样就类似于其脱离了该矿池。因为其自己所组织的区块交易列表已经被改过了，算出的Merkle tree的根哈希值是不同的，不会被矿主所认可，其提交的share也不会被认可，也就得不到分配的收益。思考三：有没有可能矿工捣乱？平时提交share，等挖到后扔掉区块，不提交？这种可能是有的，如果矿工本身仅仅想捣乱，是可以这么做的。但扔掉区块后，对其本身来说，也没有相应的奖励获得，看似是损人不利己的情况。但是，矿池之间存在竞争关系。有可能为了打击竞争对手，会派出矿机加入竞争对手矿池挖矿，从而起到搞破坏的作用。即只参与其他矿工挖矿分红，自己挖到的区块却丢掉不给他人分。 关于矿池的一些统计数据矿池在各个国家分布比例图（2018年） 这个时间，存在一个矿池(GHash.IO)算力比例占据全部算力一半以上，当时引起了恐慌(一个矿池就可以发动51%攻击)。之后，该矿池主动降低了矿池算力（化整为零，实际上仍然存在发动51攻击能力），避免动摇人们对比特币信心。 表面看上去是安全的，但实际实上某个机构如果有超过50%算力，其必然不会将其放入一个矿池中。而是将其分散隐藏，真正需要发动攻击时候再集中起来发动51攻击（注意：矿工转换矿池是很容易的）。 由这些数据可以得知，矿池本身对BTC系统带来了较大威胁。某个恶意用户如果想发动攻击，以前需要自己达到51%算力，现在自己只需要作为矿主，只需要很少一部分算力就可以了。只要能够吸引到足够多的不明真相的矿工，便可以用较低成本实现51%攻击。当然，矿主经验管理矿池，也需要收取一定比例(出块奖励、交易费)作为管理费用。如果恶意者想要攻击系统，会将管理费降低甚至赔本吸引足够多矿工加入。这便使得发动51%攻击变得容易了起来。 51%算力矿池可以发动的攻击 分叉攻击 即使某个区块已经经过6次确认，矿池依旧可以进行分叉攻击，因为原则上51%算力的矿池扩展区块链的速度更快，可以将交易记录回滚， 封锁交易（Boycott） 之前说过，如果某个矿工发布的区块故意不包含A的交易，但其他诚实的矿工还是会包含A的交易。假设某个拥有51%算力的矿池要封锁A的交易，每次发布一个包含A的交易，就立刻发动分叉攻击，使得这个区块无法获得收益，这样就使得其他的诚实矿工也不敢发布包含A的交易，实现了对A的交易封锁。 盗币（将他人账户BTC转走）这个是不可能的，因为其并没有他人账户私钥。如果依仗算力强，强行将没有签名的转账发布到区块链，正常节点不会认为其合法，这样，即使这条链再长，其他人也不会认为其是最长合法链。 矿池出现的优劣优点：解决了矿工收入不稳定的问题，减轻了矿工的负担。缺点：威胁到了区块链系统的安全，使得51%攻击变得容易起来","link":"/2022/01/12/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B07%E2%80%94%E2%80%94BTC%E6%8C%96%E7%9F%BF/"},{"title":"区块链学习笔记8——BTC比特币脚本","text":"​​点击阅读更多查看文章内容 区块链学习笔记8——BTC比特币脚本 学习视频：北京大学肖臻老师《区块链技术与应用》笔记参考：北京大学肖臻老师《区块链技术与应用》公开课系列笔记——目录导航页 交易实例比特币系统中使用的脚本语言非常简单，唯一可以访问的内存空间只有栈，所以也被称为“基于栈的语言”如果存在 一个交易有多个输入，那么每个输入都要说明币的来源并给出签名（BTC中一个交易可能需要多个签名） 输入输出脚本的执行如图所示，为脚本执行流程。在早期，直接将两个脚本按照如图顺序(input script在前，output script在后) 拼接后执行，后来考虑到安全性问题，两个脚本改为分别执行：先执行input script，若无出错，再执行output script。如果脚本可以顺利执行，最终栈顶结果为非零值即true，则验证通过，交易合法；如果执行过程中出现任何错误，则交易非法。如果一个交易有多个输入脚本，则每个输入脚本都要和对应的输出脚本匹配执行，全部验证通过才能说明该交易合法。 输入输出脚本的几种形式P2PK（Pay to Public Key）最简单的方式输出脚本直接给出收款人的公钥，CHECKSIG是检查签名的操作输入脚本直接给出签名，这个签名是用私钥对整个输入脚本所在交易的签名实际执行情况：实例： P2PKH（Pay to public key hash）输出脚本没有直接给出收款人的公钥，而是给出公钥的哈希，是最常用的形式 实际执行情况 说明：1.图中第5步，两个公钥哈希是不同的。上面一个是输出脚本提供的收款人的哈希，下面一个是要花钱时候输入脚本要给出的公钥通过HASH160操作得到的。2…图中第6步，该操作的目的是为了防止冒名顶替(公钥)。假设比较正确，则两个元素消失（不往栈中压入TRUE或FALSE）。 实例： P2SH（Pay to script hash）输出脚本给出的不是收款人公钥的哈希，而是收款人提供的一个脚本的哈希。该脚本称为redeemScript,即赎回脚本。等未来花钱的时候，输入脚本要给出redeemScript的具体内容以及可以使之正确运行需要的签名。验证过程：1.验证序列化的redeemScript是否与output script中哈希值匹配。2.反序列化并执行redeemScript，验证iutput script中给出签名是否正确。（将赎回脚本内容当作操作指令执行一遍）实例：用P2SH实现P2PK第一阶段执行拼接后的输入和输出脚本。第二阶段执行反序列化后的赎回脚本（反序列化操作并未展现，因为其是每个节点需要自己执行的） 针对以上例子使用赎回脚本可能会有些复杂，但实际上，该功能的一个主要的应用场景是多重签名。即一个输出需要多个签名才能取出钱来，例如一个公司账户，需要五个合伙人中的任意三个的签名才能取走钱，这样便为私钥泄露和丢失提供了一定程度的保护。 多重签名这个功能是通过CHECKMULTISIG来实现的，输出脚本给定N个公钥，同时指定一个阈值M，输出脚本只要给定这个N个公钥中M个合法签名即可通过验证，给出的M个签名顺序要和N个公钥中相对顺序一致 输出脚本最前面有一个红色的X，是因为比特币中CHECKMULTISIG的实现存在一个bug，执行时会从堆栈上多弹出一个元素。这个bug现在已经无法修改(去中心化系统中软件升级代价极大，需要硬分叉修改)。所以，实际中采用的方案是往栈中多压入一个无用元素。执行实例：如图为一个N=3，M=2的多重签名脚本执行过程。其中前三行为输入脚本内容，后续为输出脚本内容。 这个过程当中并没有用到P2SH，只是用原生的CHECKMULTISIG实现的早期的实际应用中，多重签名就是这样写的。但是，在应用中体现出了一些问题。例如，在网上购物时候，某个电商使用多重签名，要求5个合伙人中任意3个人才能将钱取出。这就要求用户在生成，转账交易时候，要给出五个合伙人的转账公钥以及N和M的值。而对于用户来说，需要购物网站公布出来才能知道这些信息。不同电商对于数量要求不一致，会为用户转账交易带来不便之处(因为这些复杂性全暴露给了用户)。为了解决这一问题，就需要用到P2SH P2SH实现多重签名 使用P2SH本质上是将复杂度从输出脚本转移到赎回脚本，输出脚本只需要给出赎回脚本的哈希值即可，该赎回脚本在输入脚本提供，即收款人提供。这样做，类似之前提到的电商，收款人只需要公布赎回脚本哈希值即可，用户只要在输出脚本中包含该哈希值，用户无需知道收款人的相关规则(对用户更加友好)。如果电商改变了多重签名的规则，只要改变输入脚本和赎回脚本的内容，然后把新的哈希值公布出去就行了 执行过程 第一阶段验证（输入输出脚本）：第二阶段验证（赎回脚本）： 使用P2SH做多重签名的实例 输入脚本push的最后一个数据就是序列化的赎回脚本，反序列化得到的就是三个里面取两个的多重签名脚本现在的多重签名，大多都采用P2SH的形式 一个特殊的脚本 以RETURN开始，后面可以跟任何内容。RETURN操作，无条件返回错误，所以该脚本永远不可能通过验证。执行到RETURN，后续操作不会再执行。该脚本是销毁比特币的一种方法。 Q：为什么要销毁比特币？？？现在比特币价值极高，销毁是不是很可惜？1.部分小币种(AltCoin)要求销毁部分比特币才能得到该种小币种。例如，销毁一个BTC可以得到1000个小币。即，使用这种方法证明付出了一定代价，才能得到小币种。2.往区块链中写入内容。我们经常说，区块链是不可篡改的账本，有人便利用该特性往其中添加想要永久保存的内容。例如：股票预测情况的哈希、知识产权保护——取知识产权的哈希值放在return的后面，反正return之后的都不会执行，放什么都没关系，而且放置的是一个哈希值不会占太大的空间，也没有泄露知识产权的具体内容，将来如果产生了纠纷，就把这个具体内容公布出去，证明在某个时间点已经知道某个知识了 有没有觉得第二个应用场景有些熟悉？实际上，之前谈到BTC发行的唯一方法，便是通过铸币交易凭空产生（数据结构篇中）。在铸币交易中，有一个CoinBase域，其中便可以写入任何内容。那么为什么不使用这种方法呢，而且这种方法不需要销毁BTC，可以直接写入。因为这种方法只有获得记账权的节点才可以写入内容。而上面的方法，可以保证任何一个BTC系统中节点乃至于单纯的用户，都可以向区块链上写入想写入的内容。【发布交易不需要有记账权，发布区块需要有记账权】任何用户都可以使用这种方法，通过销毁很小一部分比特币，换取向区块链中写入数据的机会。 实际上，很多交易根本没有销毁比特币，只是支付了交易费 下图是一个铸币交易，其中包含两个交易，第二个交易的输出脚本就是开头为return，只是仅仅想要往其中写入内容。下图是一个转账交易，输出脚本也是以return开头的，输入是0.05BTC，输出是0，说明输入金额全部用来支付交易费，这个交易并没有销毁任何比特币，只是将输入的费用作为交易费转给挖到矿的矿工了这种交易永远不会兑现，所以矿工不会将其保存在UTXO中，对全节点比较友好。 实际中的脚本，都需要加上OP前缀，如：CHECKSIG应该为OP_CHECKSIG,这里仅仅为了学习友好，就删去了该前缀 总结BTC系统中使用的脚本语言非常简单，简单到没有一个专门的名称，我们就称其为”比特币脚本语言“。而在后文的以太坊的智能合约中，则比此复杂得多。实际上，该脚本语言甚至连一般语言中的循环都不支持，但设计简单却也有其用意。如果不支持循环，也就永远不会出现死循环，也就不用担心停机问题。而在以太坊中，由于其语言图灵完备，所以要依赖于汽油费机制来防止其陷入死循环。此外，该脚本语言虽然在某些方面功能很有限，但另外一些方面功能却很强大(密码学相关功能很强大)例如，前文提到的CHECKMULTISIG用一条语句便实现了检查多重签名的功能。这一点与很多通用编程语言相比，是很强大的。","link":"/2022/01/12/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B08%E2%80%94%E2%80%94BTC%E6%AF%94%E7%89%B9%E5%B8%81%E8%84%9A%E6%9C%AC/"},{"title":"区块链学习笔记9——BTC分叉","text":"​​点击阅读更多查看文章内容 区块链学习笔记9——BTC分叉state fork：由于对区块链当前状态有意见分歧而导致的分叉，几乎同时产生两个区块插入到链中forking attack: 属于state fork，这个意见分歧是故意造成的 Protocol fork：对比特币协议产生分歧，用不同版本的协议造成的分叉根据协议修改内容的不同可以分为hard fork和soft fork hard fork（硬分叉） 什么情况会出现硬分叉？对比特币协议增加新协议，扩展新功能，未升级软件的旧节点会不认可这些修改，会认为这些特性是非法的。这也就是对比特币协议内容产生分歧，从而导致分叉。硬分叉的一个典型例子，就是对比特币区块大小的修改（之前有提到过，BTC区块大小限制1MB，但是否合适存在争议）。 在BTC系统中，区块大小最大为1MB，可以包含的交易最大数量为4000笔左右。而一个区块产生大概需要10min左右，也就是说，整个比特币系统，平均每10分钟最多只能处理4000笔交易(平均每秒7笔交易)，相比目前银行等金融机构每秒数十万数百万的交易量来说，根本不在一个数量级上，严重影响吞吐率和交易处理(即上链)时间(因为交易太多，无法写入只能等待下一个区块，一等平均就是十分钟)。 所以，有人便认为可以增大区块大小，使得一个区块中可以包含的交易数量增多，在此，我们假设将区块大小从1MB增大至4MB。 假设大多数结点都更新到了4MB，少数结点没更新，（这里的大多数是根据算力来看的不是根据账户的数量）。即：新节点认为区块大小最大4MB，旧节点认为区块大小最大1MB，且新节点占据大多数。 假设1为当前区块链，此时软件更新，有一个新节点挖出了一个区块如2。但对于旧节点来说，该区块为一个非法区块，旧节点不会对其认可，从而，旧节点仍然从其前一个区块开始挖矿，如3.需要注意的是，**旧节点挖出的区块，新节点是认可的(并未超过4MB限制)**，所以对旧节点来说，3中下面的链才是合法链，而对新节点来说，这两条链都是合法的链。因为新节点算力强，所以出现4中情况可能性大。对于新节点来说，上面的为最长合法链，新节点便都会沿着上面的链继续挖；对于旧节点来说，上面的链无论多么长，都是一条非法链，不会认可该链，所以旧节点就会沿着下面的链继续挖矿。 此时，就出现了新节点永远沿着上面的链挖矿，旧节点永远沿着下面的链挖矿，由于新节点算力足够强，所以形成两条永远都在延伸且平行的链。当然，上面的链，也有可能会挖出大小在1MB内的小区块，但对旧节点来说，该链上存在非法区块，不会认可该链。可见，这种分叉是永久性的。只要这部分旧节点永远不更新软件，下面的链便永远不会消失。 1.BTC社区中有些人很保守，不愿意加大区块大小 2.区块大小并非越大越好，在网络篇中提到，比特币网络传输为flooding的方式，对带宽的消耗是很大的，带宽是瓶颈。 3.单纯增加区块大小，对交易数量的增加远不能达到数量级的提升。 出现hard fork后，便变成了两条平行的链，也就造成了社区分裂。社区中有一部分人，会认为下面的链才是”正统“(根正苗红)，各个链上的货币独立。 实际上，这个事情真正出现过。后续会介绍以太坊，以太坊历史上的一件大事就是硬分叉事件。以太坊称为ETH，但目前看到的ETH已经不是最初的ETH了，以太坊在历史上发生过硬分叉，另一个链称为ETC（和过高速公路那个ETC可半毛钱关系都没有呀）。实际上，ETC才是以太坊设计原本的协议，而ETH是黑客攻击ETH上一个智能合约THE DAO后进行回滚的协议链(将黑客攻击偷取的以太币采用硬分叉方式回滚回到另一智能合约，然后退还给真正拥有者)。但是这次硬分叉的后果，由于有人不愿意这么做，造成了以太坊社区的分裂。实际上，虽然ETC不如ETH又名，但实际它也是目前一种主流货币。分叉之初，由于两个链分叉造成了互相影响，产生了很多麻烦。比如：在ETH链上有一笔转账B-&gt;C，有人便在ETC链上回放，将ETC链上的货币页转给了C(C收到两笔钱)。后来，对两条链各添加了一个chainID，将两个链区分开，才使得这两条链真正分开。 soft fork（软分叉）如果对BTC协议添加限制，使得原本合法交易在新交易中不合法，便会形成软分叉。 假设有人发布一个软件更新将区块大小把1MB转为0.5MB（实际中不会这么做，1MB已经足够小了） 此时还是把节点分为新节点和旧节点，新节点认为是0.5MB，旧节点认为是1MB 假设1为初始的区块链，新节点开始挖小的区块如2，这个区块旧节点也是认可的，也会沿着这个小区块挖矿，如3。但是新节点会认为该旧节点挖出区块超过0.5MB限制，为一个非法区块，不会认可该区块，会从其前一个小区块开始挖矿。如4所示此时旧节点因为也认可新节点，所以它又会按照最长合法链向下挖，最终会造成5中的效果(绿色大节点为旧节点)，旧节点挖出的区块一直被抛弃，无法得到出块奖励(不在最长合法链上)。这就倒逼旧节点升级软件，最终会实现区块链上的所有矿工共同认可新协议，实现软件协议的升级。 实际中可能出现软分叉的情况给某些目前协议中没有规定的域赋予新的含义或规则。 coinbase域有人便提出将其作为UTXO集合的根哈希值。目前UTXO是全节点自己在本地为了方便查询自行维护的，但UTXO内容并未写入区块链（还记得Merkle proof吗？Merkle proof用于验证某个交易是否在区块中，Merkle proof的交易信息是写入区块链的。）如果账户要查询余额，可以查找账户在UTXO里输出一共收到多少个币，如果是全结点的话可以算出来，但是很多比特币钱包不可能在手机上维护一个完整的区块链，实际上是一个轻节点，如果查询某账户余额，轻节点便需要询问全节点，全节点根据UTXO中信息可以计算得到账户余额，但如何确保全节点给的数据可信？有人提议把UTXO集合中的内容也组织成一棵Merkle tree，将其根哈希值写在coinbase域中，（如果改block header的话动静太大，coinbase域正好没人用），改这个域的内容，最后会改到block header中的根哈希值，这样就可以通过Merkle proof证明出来了。可以看到，旧节点认可新节点的区块，因为旧节点不管你写的内容，但新节点对于旧节点CoinBase域检查时候，发行并没有这个UTXO的根哈希值，不会认可其发布的区块，所以这是软分叉。 P2SH这个功能在最初是没有的，是后来通过软分叉加进去的对于旧节点只会做第一阶段的验证，新节点才会做第二阶段的验证，所以旧节点认为合法的交易新节点可能认为是非法的，新节点认为合法的交易，旧节点一定认为是合法的 总结 soft fork：只要系统中拥有半数算力以上的结点更新了软件，系统就不会出现永久的分叉 hard fork：必须所有节点都更新了软件，系统才不会出现永久性的分叉，如果有小部分结点不愿意更新，系统就分成了两条链","link":"/2022/01/13/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B09%E2%80%94%E2%80%94BTC%E5%88%86%E5%8F%89/"},{"title":"区块链跨链技术","text":"​​点击阅读更多查看文章内容 区块链跨链技术背景近年来，随着区块链技术的不断发展，区块链的应用场景逐渐从最初的加密货币领域扩展到金融、物流、医疗、公共服务等各个领域。随着区块链的应用场景不断增多，区块链的“数据孤岛”问题日益突出，不同场景下的区块链之间相互隔绝，无法实现信息交互，极大地阻碍了区块链技术的进一步发展。为了解决区块链之间的扩展性问题，区块链跨链技术应运而生。 关键技术问题 保证跨链交易的原子性和最终确定性 保证跨链双方可以验证另一条链上的交易状态 保证两条链上的资产总量不变 保证跨链系统安全运行 多链协议适配 主要跨链技术 哈希锁定 公证人机制 侧链/中继 分布式私钥控制 其中采用中继链的跨链方法扩展性最好但是实现相对复杂，是目前最主要的研究方向 哈希锁定哈希锁定最初起源于闪电网络。从原理上看，哈希锁定是基于哈希函数的单向性来保证资产的安全交换，它包括哈希锁和时间锁，哈希锁是指用户只有知道哈希原像才可以解锁资产，时间锁是指用户如果超过时间仍未解锁资产，则资产会退回原账户。 该模式的实现流程如下图所示，（用户A与用户B进行跨链资产交换） 用户A生成一个随机数x并计算其哈希值H(x)发送给用户B。 用户A使用H(x)和时间t1在链A上锁定资产a，若超过时间t1仍未解锁，则将资产退回给A。 用户B使用H(x)和时间t2（t2&lt;t1）在链B上锁定资产b，若超过时间t2仍未解锁，则将资产退回B。 用户A将随机数x发送给用户B解锁得到用户B锁定的资产，此时用户B也获得了随机数x。 用户B再用随机数x解锁用户A锁定的资产，由此实现了资产的跨链交换。 这里时间锁t1和t2是为了防止用户A在解锁获得B的资产后退回自己锁定的资产导致用户B的资产损失。因为用户A必须要在t2之前解锁用户B的资产，而用户A的锁定时间t1大于t2，所以用户A在解锁B的资产时自己的资产一定是锁定状态的，可以保证用户B在拿到随机数x后有充足的时间解锁用户A的资产。 公证人机制公证人机制是一种中心化的跨链方式，该方式通过引入一方或多方可信实体对跨链交易进行信用背书来保证跨链系统的可靠运行。在公证人机制中，公证人是跨链交易的核心角色。它们通常是一组专门的节点，用于协调不同区块链之间的交易。当交易发生时，公证人将执行一系列操作来验证交易的有效性，例如检查交易的签名，检查转移资产的数量是否正确等。这种方式的实现较为简单，代表方案有ripple提出的Interledger。 侧链/中继技术侧链的概念于2014年首次提出。侧链通过双向锚定技术将一种加密货币资产锁定在一个区块链上，然后在另一个区块链上创建一个代表该资产的代币，从而实现在两个不同的区块链之间传输资产的功能。通过这种方式可以将主链的货币发送到侧链上，在侧链上分担主链的交易，从而减轻主链的压力，扩展主链性能。双向锚定技术的实现方式包括单一托管模式、联合锚定模式、SPV模式和驱动链模式，其中SPV模式是侧链白皮书中对去中心化双向锚定技术的最初设想，该模式的工作流程如下图所示。 用户在主链上将资产发送到一个特殊的地址进行锁定，在等待一段时间确保交易不会被回滚之后，主链会为用户生成一个SPV证明，证明用户已经在主链上锁定了部分资产。 用户可以将该SPV证明发送到侧链上，侧链在接收并验证SPV证明之后会等待一段竞争期确保用户的资产成功锁定，然后就在侧链上为用户释放相应数量的资产，由此实现用户资产的跨链转移。 中继可以看作是侧链和公证人机制的融合扩展，通过在相互通信的两个区块链之间添加一条中继链对跨链的请求进行验证和转发。中继技术弥补了公证人机制中存在的中心化问题，具有较高的安全性和可扩展性，可以适应大部分的应用场景。但是基于中继链的跨链系统实现起来比较复杂，需要较高的技术成本。 分布式密钥控制分布式密钥控制是基于密码学中的多方计算和门限密钥的一种技术，在分布式密钥控制中会将控制资产的私钥分成多份并分别由多个用户持有，在进行资产转移时需要多个用户共同参与，即使其中某些用户被攻击或私钥被窃取，攻击者也无法获取完整的私钥，保证了资产的安全性。以分布式密钥控制的代表项目Fusion为例，跨链资产转移流程如下图所示。 用户A发起跨链请求，首先在分布式网络中会生成一对公私钥，公钥是一个新用户B的地址，私钥分成多份由网络中的多个用户持有。 用户A将资产转移到新地址B中锁定。 目标链上的用户C使用相同的方法将资产转移到一个新地址D中锁定。 在两个用户都锁定资产后，分布式节点再使用私钥分别解锁B和D锁定的资产，将D的私钥发放给A，将B的私钥发放给C，从而实现跨链的资产交换。","link":"/2023/10/11/%E5%8C%BA%E5%9D%97%E9%93%BE%E8%B7%A8%E9%93%BE%E6%8A%80%E6%9C%AF/"},{"title":"同态加密详解","text":"​​点击阅读更多查看文章内容 什么是同态加密同态加密（Homomorphic Encryption）是指将原始数据经过同态加密后，对得到的密文进行特定的运算，然后将计算结果再进行同态解密后得到的明文等价于原始明文数据直接进行相同计算所得到的数据结果。同态加密与一般加密方案的关注点不同，一般的加密方案关注的是数据存储安全，即我要给其他人发送信息或者存储信息，我需要对数据进行加密之后再发送和存储，这里我们只需要保证在数据传送和存储的过程中不被其他人窃听到即可，在这个过程中用户时不能对加密的结果做任何操作的，否则可能会导致解密失败通态加密的关注点则是数据处理安全，同态加密提供了一种对加密数据进行处理的功能。也就是说其他人可以对加密后的数据进行处理，在这个过程中不会泄露任何原始的内容，在数据处理完成之后再进行解密，得到的正是对原始数据进行相同处理后的结果。 举个例子（内容来自知乎）有个叫Alice的用户买到了一大块金子，她想让工人把这块金子打造成一个项链。但是工人在打造的过程中有可能会偷金子啊，毕竟就是一克金子也值很多钱的说… 因此能不能有一种方法，让工人可以对金块进行加工（delegate processing of your data），但是不能得到任何金子（without giving away access to it）？当然有办法啦。Alice可以这么做： Alice将金子锁在一个密闭的盒子里面，这个盒子安装了一个手套。工人可以带着这个手套，对盒子内部的金子进行处理。但是盒子是锁着的，所以工人不仅拿不到金块，连处理过程中掉下的任何金子都拿不到。加工完成后。Alice拿回这个盒子，把锁打开，就得到了金子。这个盒子的样子大概是这样的：这里面的对应关系是： 盒子：加密算法 盒子上的锁：用户密钥 将金块放在盒子里面并且用锁锁上：将数据用同态加密方案进行加密 加工：应用同态特性，在无法取得数据的条件下直接对加密结果进行处理 开锁：对结果进行解密，直接得到处理后的结果 加密步骤本部分内容参考链接 （本地）生成一对公私钥，公钥pub和密钥priv，公钥用于加密，密钥用于解密； （本地）使用公钥pub分别加密m1和m2，得到Epub(m1)和Epub(m2)； （第三方）使用Addpub函数处理Epub(m1)和Epub(m2)，即Addpub(Epub(m1),Epub(m2))； （本地）使用密钥priv解密Addpub(Epub(m1),Epub(m2))，即Dpriv(Addpub(Epub(m1),Epub(m2)))； Dpriv(Addpub(Epub(m1),Epub(m2)))就等于m1+m2。第三方通过上述步骤3实现了m1和m2在加密状态下做加法的操作。 同态加密的类型部分同态加密（partially homomorphic）部分同态加密算法允许某一操作被执行无限次。例如，一个特定的算法可能是加法同态的，这意味着将两个密文相加会产生与加密两个明文之和相同的结果。 加法同态：该加密方案支持的同态函数族为所有可以仅由加法实现的函数。目前使用比较广泛的是paillier加法同态。 乘法同态：该加密方案支持的同态函数族为所有可以仅由乘法实现的函数。比如经典的RSA加密方案。 稍微同态加密（somewhat homomorphic）有点同态加密算法可以对密文进行有限次数的任意操作，例如，某种程度的同态加密算法可以支持最多五种加法或乘法的任意组合。但是，任何一种类型的第六次操作都将产生无效的结果。 某种同态加密算法是实现完全同态加密的重要垫脚石。设计一个同时支持加法和乘法的算法（即使是支持一组数量的操作）的算法比创建一个允许无限加法或乘法密文的算法要困难的多。 全同态加密（fully homomorphic）可以对密文进行无限次数的任意同态操作，也就是说它可以同态计算任意的函数 应用场景 参考链接一；参考链接二 云计算在云计算或外包计算中，用户为了节约自身的软硬件成本，可将计算和存储需求外包给云服务提供商，利用云服务提供商强大的算力资源实现数据的托管存储和处理。但是，将明文数据直接交给云服务器具有一定的安全风险，而传统的加密存储方式则无法实现对密文数据的直接计算，因此如何同时实现数据的机密性和可计算性成为了一个难题，同态加密的出现为这一场景的实现提供了可能性。在传统的云存储与计算解决方案中，用户需要信任云服务器提供商不会窃取甚至用户数据，而基于同态加密的云计算模型可在根本上解决这一矛盾。首先，用户使用同态加密算法和加密密钥对数据进行加密，并将密文发送给云服务器；云服务器在无法获知明文数据的情况下按照用户给定的程序对密文进行计算，并将密文计算结果返回给用户；用户使用同态加密算法和解密密钥对密文计算结果进行解密，所得结果与直接对明文进行相同计算的结果等价。 具体过程图解： Alice对数据进行加密。并把加密后的数据发送给Cloud； Alice向Cloud提交数据的处理方法，这里用函数f来表示； Cloud在函数f下对数据进行处理，并且将处理后的结果发送给Alice； Alice对数据进行解密，得到结果。 不足目前，全同态加密算法的现有方案均存在计算和存储开销大等问题，距离高效的工程应用还有着不小的差距，同时还面临国际与国内相关标准的缺失，因此在半同态加密算法满足需求的情况下要优先使用半同态加密算法。","link":"/2022/05/05/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E8%AF%A6%E8%A7%A3/"},{"title":"博客搭建（hexo+github）","text":"​​点击阅读更多查看文章内容 简介搭建完成网站的如下所示https://polarday.top/ 使用github托管博客，完全免费不需要购买服务器博客框架：hexohexo主题：ICARUS图床：github+PicGo编辑：vscode 为什么使用hexo框架？因为hexo是静态框架，我们使用github托管博客的页面只能使用静态的框架，不支持像wordpress等需要请求数据库的动态框架，这类框架必须具有自己的服务器 搭建步骤 搭建hexo框架发布到github 更换ICARUS主题 配置vscode的markdown环境 连接图床 搭建hexo框架发布到github先安装node.js和git参考教程hexo官方文档 1.github创建个人仓库点击GitHub中的New repository创建新仓库，仓库名应该为：用户名.github.io这个用户名使用你的GitHub帐号名称代替，这是固定写法，比如我的仓库名为: 2.安装hexoHexo就是我们的个人博客网站的框架， 这里需要自己在电脑常里创建一个文件夹,可以命名为Blog,进入文件夹中,使用npm命令安装Hexo，输入：npm install -g hexo-cli安装完成后，初始化我们的博客，输入：hexo init blog初始化完成后进入blog目录，输入以下三条命令检测网站是否安装成功： 生成一篇文章hexo new test_my_site 生成静态文件hexo g 启动服务器，默认情况下，访问网址为： http://localhost:4000/hexo s 3.本地静态文件推送到github上面只是在本地预览，接下来要做的就是就是推送网站，可以通过github的域名访问blog目录下的_config.yml是网站的配置信息，包括网站标题等自定义内容可以参考hexo官方文档设置，在本地都调试完成后将其推送到github，在_config.yml的最后有deploy的配置，修改为如下配置，其中repo是你之前创建的仓库的路径 1234deploy: type: git repo: https://github.com/shnpd/shnpd.github.io.git branch: main 执行命令，就可以一键部署，具体命令细节可以参考hexo官方文档hexo cleanhexo ghexo d 然后访问shnpd.github.io就可以看到我们的博客了组成我们网站的文件是blog目录下的public目录，执行clean命令会清楚public目录，执行generate命令会生成public目录，部署命令也是将public目录部署到github上 4.域名绑定（可选）绑定域名是可选的，我们使用shnpd.github.io本身就可以访问博客了，如果有同学想绑定自己的域名可以参考本节 首先需要购买自己的域名，购买的途径有很多，像腾讯云、阿里云都可以，我使用的是腾讯云 在腾讯云控制台域名解析中添加两条记录 登录github之前创建的仓库，settings-pages-custom domain填入自己的域名，点击save保存 进入blog的source目录下新建txt，输入你的域名。如果带有www，那么以后访问的时候必须带有www完整的域名才可以访问，但如果不带有www，以后访问的时候带不带www都可以访问。所以建议不要带有www。保存命名为CNAME，无后缀名。 域名绑定完成，这里因为是基于github搭建的所以不需要对域名进行备案 更换hexo主题hexo的主题有很多，我们这里使用的是icarushexo-theme-icarus官方文档 1.主题安装在blog目录下执行如下命令：npm install -S hexo-theme-icarus hexo-renderer-inferno 在网站配置_config.yml文件中启用icarus主题：theme: icarus或使用hexo命令修改主题为Icarushexo config theme icarus 启动本次服务器测试是否成功：hexo server 2.主题配置icarus的具体主题配置都可以参考官方文档，细节配置可以参考文档自行定义，下面主要介绍几个关键的地方 图片我们在设置网站的logo或其他配置时可能会用到图片，这里图片的路径为/img/xxx.jpg，这是相对路径，相对blog目录的路径为：/node_modules/hexo-theme-icarus/source/img/xxx.jpg About页面about页面在初始化的时候是没有的，需要我们自己创建，创建命令为：hexo new page about 需要执行以下命令重新生成静态文件 12hexo cleanhexo g 创建其他页面时也按照这个步骤，新建的页面在source目录下 写文章新建文章使用hexo new &quot;第一篇文章&quot;命令，就可以在source/_posts目录下创建文章的markdown文件直接编辑即可文章分类和标签的设置参考hexo官方文档Front-matter文章在首页默认会显示全部内容，需要在文章中添加&lt;!– more –&gt;标签。 标签前面的文章内容会被标记为摘要，而其后的内容不会显示在文章列表上。 配置vscode markdown环境（可选 推荐）这里因为我们需要编辑markdown来写文章，这里我们推荐使用vscode，通过vscode打开blog目录，可以方便的查看目录结构，同时也可以直接在vscode中开启终端执行相关命令，使用vscode编写markdown非常方便，具体配置教程有很多，这里主要就是安装几个插件 Markdown All in One （基本语法） Markdown Preview Enhanced（预览） markdownlint（语法检查） 安装完成后就可以直接编写markdown了 配置图床（可选 推荐）我们文章中会存在大量的图片，直接将图片保存在网站的文件中会相当的臃肿，所以我们推荐使用图床将图片保存在其他位置并生成外链，在我们的文章中通过外链来引用图片即可。 可以用来充当图床的服务有很多，包括七牛云、阿里云OSS、腾讯云COS、GitHub等，其中七牛云需要备案域名、阿里云和腾讯云不是完全免费的，我们这里使用的是GitHub，但是GitHub本身存在访问较慢的问题，还是推荐大家使用七牛云、阿里云等费用不是很贵。 1.新建github仓库新建github仓库作为图床用来保存我们的图片，仓库名字可以随便起我的名字是blog-pic，仓库需要设置为public 2.下载PicGoPicGo官方文档PicGo是一个用于快速上传图片并获取图片URL链接的工具，如果使用vscode的话可以直接安装PicGo的扩展，安装完成后配置github图床 配置名：随意起仓库名：新建仓库的名称分支名：设置为main即可Token：需要在github中申请；settings——Developer Settings——Personal access tokens——tokens——Generate new token vscode的扩展也是相同的配置方法，这里主要说一下vscode中的使用 复制自动生成链接通过使用Upload image from clipboard就可以从粘贴板上传图片，这里的快捷键我们设置为ctrl+alt+e比较方便，当我们复制了一张图片后，使用该快捷键就可以自动将图片上传并生成链接插入到对应的位置 自定义图片的输出格式这里定义了前一步插入的格式，考虑到通用性我们设置为html的格式，同时添加了width=”50%”默认对每张图片缩放50%","link":"/2024/04/05/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%88hexo+github%EF%BC%89/"},{"title":"在ensp安装过程中遇到的错误（40 41错误，usg6000v导入时配置文件格式错误）","text":"​​点击阅读更多查看文章内容 这个ensp安装配置我前前后后捣鼓了好几天，好不容易整好了，在这里稍微记录一下，希望能帮助大家少走弯路。 40 41错误1.首先，可以把virtualbox卸载了重装一遍，版本我用的是5.2.30，太新的话会不兼容。如果重装一遍还不行的话就要直接把这个方法pass掉吧，不要再傻乎乎的去官网下载各种不同的版本，浪费时间且无用！！！2.然后可以参考官方的帮助文档，这里我是网卡的问题，查看一下自己电脑的网络适配器有没有VirtualBox Host-Only Ethernet Adapter，如果没有可参照以下博客安装：https://blog.csdn.net/zlt995768025/article/details/79986744注意！ 这里安装之前最好先清理一遍注册表，否则可能会安装失败，清理的方法有很多，我是用CCleaner清理的3.VirtualBox Host-Only Ethernet Adapter安装完成后要注意后面有没有类似“#2”，有些人可能之前安装过这些东西，再安装的时候后面会有一些数字，正是因为这些数字会导致你的ensp运行出错，解决方法参考如下博客：https://blog.csdn.net/qq_43288686/article/details/106556585 配置文件格式错误我遇到这个错误的原因是重复导入，其实你之前已经导入过了，我是重装了一遍后发现的这个原因，你可以重转一遍试一下，第一次导入的时候会成功导入，再次导入就会遇到这个错误。 以上就是我遇到的错误，如果大家还遇到有别的错误可以在评论区一起交流。","link":"/2021/09/10/%E5%9C%A8ensp%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%94%99%E8%AF%AF%EF%BC%8840%2041%E9%94%99%E8%AF%AF%EF%BC%8Cusg6000v%E5%AF%BC%E5%85%A5%E6%97%B6%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E9%94%99%E8%AF%AF%EF%BC%89/"},{"title":"字典树（介绍+实现+例题）","text":"​​点击阅读更多查看文章内容 字典树介绍字典树也叫前缀树、Trie树等字典树是一颗非典型的多叉树模型字典树的结点包含有一个长度为26的指针数组，分别对应26个字母，指向当前字母对应的下一个字母。字典树充分利用了字符串的公共前缀包含三个单词 “sea”,”sells”,”she” 的字典树如下所示：图片来源 代码实现定义 123456struct Trie { vector&lt;Trie *&gt; children; string word; Trie() : children(26), word(&quot;&quot;) {} }; 插入 123456789101112void insert(Trie *root, string word) { Trie *node = root; for (char c : word) { c -= 'a'; if (node-&gt;children[c] == nullptr) node-&gt;children[c] = new Trie(); node = node-&gt;children[c]; } node-&gt;word = word; } 查找 123456789101112131415bool search(Trie *root, string word) { Trie *node = root; for (char c : word) { c -= 'a'; if (node-&gt;letter[c] == nullptr) return false; node=node-&gt;letter[c]; } if (node-&gt;word != &quot;&quot;) return true; else return false; } 前缀查找 123456789101112bool startsWith(Trie *root,string prefix) { Trie *node = root; for (char c : prefix) { c -= 'a'; if (node-&gt;letter[c] == nullptr) return false; node=node-&gt;letter[c]; } return true; } 例题 LeetCode 208Trie（发音类似 “try”）或者说 前缀树 是一种树形数据结构，用于高效地存储和检索字符串数据集中的键。这一数据结构有相当多的应用情景，例如自动补完和拼写检查。请你实现 Trie 类：Trie() 初始化前缀树对象。void insert(String word) 向前缀树中插入字符串 word 。boolean search(String word) 如果字符串 word 在前缀树中，返回 true（即，在检索之前已经插入）；否则，返回 false 。boolean startsWith(String prefix) 如果之前已经插入的字符串 word 的前缀之一为 prefix ，返回 true ；否则，返回 false 。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Trie{private: vector&lt;Trie*&gt; letter; bool isend = false;public: Trie():letter(26), isend(false) { } void insert(string word) { Trie *node = this; for (char c : word) { c -= 'a'; if (node-&gt;letter[c] == nullptr) node-&gt;letter[c] = new Trie(); node = node-&gt;letter[c]; } node-&gt;isend = true; } bool search(string word) { Trie *node = this; for (char c : word) { c -= 'a'; if (node-&gt;letter[c] == nullptr) return false; node=node-&gt;letter[c]; } if (node-&gt;isend) return true; else return false; } bool startsWith(string prefix) { Trie *node = this; for (char c : prefix) { c -= 'a'; if (node-&gt;letter[c] == nullptr) return false; node=node-&gt;letter[c]; } return true; }}; LeetCode 212给定一个 m x n 二维字符网格 board 和一个单词（字符串）列表 words，找出所有同时在二维网格和字典中出现的单词。单词必须按照字母顺序，通过 相邻的单元格 内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母在一个单词中不允许被重复使用。示例：输入：board = [[“o”,”a”,”a”,”n”],[“e”,”t”,”a”,”e”],[“i”,”h”,”k”,”r”],[“i”,”f”,”l”,”v”]], words = [“oath”,”pea”,”eat”,”rain”]输出：[“eat”,”oath”] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Solution{public: int dirs[4][2] = {{1, 0}, {-1, 0}, {0, 1}, {0, -1}}; vector&lt;string&gt; ret; struct Trie { vector&lt;Trie *&gt; children; string word; Trie() : children(26), word(&quot;&quot;) {} }; void insert(Trie *root, string word) { Trie *node = root; for (char c : word) { int i = c - 'a'; if (node-&gt;children[i] == nullptr) node-&gt;children[i] = new Trie(); node = node-&gt;children[i]; } node-&gt;word = word; } void dfs(int x, int y, Trie *node, vector&lt;vector&lt;char&gt;&gt; &amp;board) { char c = board[x][y]; if (node-&gt;children[c - 'a'] == nullptr) return; board[x][y] = '#'; node = node-&gt;children[c - 'a']; if (node-&gt;word != &quot;&quot;) { ret.push_back(node-&gt;word); node-&gt;word=&quot;&quot;; } for (int i = 0; i &lt; 4; i++) { int newx = x + dirs[i][0]; int newy = y + dirs[i][1]; if (newx &gt;= 0 &amp;&amp; newx &lt; board.size() &amp;&amp; newy &gt;= 0 &amp;&amp; newy &lt; board[0].size()) { if (board[newx][newy] != '#') { dfs(newx, newy, node, board); } } } board[x][y] = c; } vector&lt;string&gt; findWords(vector&lt;vector&lt;char&gt;&gt; &amp;board, vector&lt;string&gt; &amp;words) { Trie *root = new Trie(); for (string s : words) insert(root, s); for (int i = 0; i &lt; board.size(); i++) { for (int j = 0; j &lt; board[0].size(); j++) { dfs(i, j, root, board); } } return ret; }};","link":"/2021/09/16/%E5%AD%97%E5%85%B8%E6%A0%91%EF%BC%88%E4%BB%8B%E7%BB%8D+%E5%AE%9E%E7%8E%B0+%E4%BE%8B%E9%A2%98%EF%BC%89/"},{"title":"对BP神经网络的理解及5.13公式推导","text":"​​点击阅读更多查看文章内容 BP神经网络概述误差逆传播(errorBackPropagation,简称BP)算法是迄今最成功的神经网络学习算法.现实任务中使用神经网络时,大多是在使用BP算法进行训练.值得指出的是,BP算法不仅可用于多层前馈神经网络,还可用于其他类型的神经网络,例如训练递归神经网络[Pineda,1987].但通常说“BP网络”时，一般是指用BP算法训练的多层前馈神经网络. 算法一、简要思想BP算法的全称是误差逆传播算法，顾名思义。BP算法就是根据当前数据产生的误差进行逆向传播修改参数，从而不断获得更合适的参数的过程。整个算法分为数据前传获得结果以及误差逆传修改参数两部分。二、参数解释给定训练集D = {(x1, y1),(x2, y2),.. . , (xm,ym)},xi∈ Rd, yi∈Rl,即输入示例由d个属性描述,输出l维实值向量.下图给出了一个拥有d个输入神经元、l个输出神经元、q个隐层神经元的多层前馈网络结构,θj——输出层第j个神经元的阈值γh——隐层第h个神经元的阈值vih——输入层第i个神经元与隐层第h个神经元之间的连接权whj——隐层第h个神经元与输出层第j个神经元之间的连接权αh——隐层第h个神经元接收到的输入βj——输出层第j个神经元接收到的输入bh——隐层第h个神经元的输出三、误差逆传播过程1.根据训练例求出对应的均方误差Ek2.基于梯度下降策略根据Ek以及给定的学习率η求出对应的Δwhj、Δθj、Δvih、Δγh3.更新whj、θj、vih、γh 累积BP我们上面介绍的“标准BP算法”每次仅针对一个训练样例更新连接权和阈值，也就是说，算法的更新规则是基于单个的Ek推导而得.如果类似地推导出基于累积误差最小化的更新规则,就得到了累积误差逆传播(accumulated error backpropagation)算法.累积BP算法与标准BP算法都很常用.一般来说,标准BP算法每次更新只针对单个样例,参数更新得非常频繁,而且对不同样例进行更新的效果可能出现“抵消”现象.因此,为了达到同样的累积误差极小点,标准BP算法往往需进行更多次数的迭代.累积BP算法直接针对累积误差最小化,它在读取整个训练集D一遍后才对参数进行更新，其参数更新的频率低得多.但在很多任务中，累积误差下降到一定程度之后,进一步下降会非常缓慢,这时标准BP往往会更快获得较好的解，尤其是在训练集D非常大时更明显. 过拟合由于其强大的表示能力，BP神经网络经常遭遇过拟合,其训练误差持续降低,但测试误差却可能上升.有两种策略常用来缓解BP网络的过拟合.第一种策略是“早停”(early stopping):将数据分成训练集和验证集,训练集用来计算梯度、更新连接权和阈值,验证集用来估计误差,若训练集误差降低但验证集误差升高,则停止训练,同时返回具有最小验证集误差的连接权和阈值.第二种策略是“正则化”(regularization) 其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和.仍令Ek表示第k个训练样例上的误差，w表示连接权和阈值,则误差目标函数改变为其中λ∈ (0,1)用于对经验误差与网络复杂度这两项进行折中,常通过交叉验证法来估计. 5.13公式推导","link":"/2021/07/22/%E5%AF%B9BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%90%86%E8%A7%A3%E5%8F%8A5.13%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/"},{"title":"常用Git命令（简洁版）","text":"​​点击阅读更多查看文章内容 一、添加SSH 本地生成密钥，存储在用户目录(~)下的.ssh目录中，.ssh是隐藏文件要使用ls -a查看ssh-keygen -t rsa -C &quot;your_email@example.com&quot; id_rsa是私匙，id_rsa.pub是公匙，在github上添加公钥cat /root/.ssh/id_rsa.pub：查看公钥内容 二、拉取项目在github页面找到要拉取项目的url，使用git clone命令拉取到当前目录下git clone https://github.com/shn-1/HyperledgerFabric_Learning.git 三、上传项目上传项目主要用到三个命令git addgit commitgit push 把当前目录变成 Git 可以管理的仓库git init 执行将目录下的所有文件加入到暂存区git add * 将暂存区的内容提交到版本库git commit -m &quot;注释&quot; 至此，在本地仓库的操作已经完成，下面是远程仓库的操作 remote 及 push 命令详解 与远程仓库建立连接，其中origin可以视为远程仓库在本地的别名git remote add origin https://github.com/shn-1/HyperledgerFabric_Learning.git 将本地分支推送到远程仓库的分支即可，其中origin为远程仓库，master为本地分支（默认）git push origin master 这里可能需要输入用户名和密码，注意这里的密码不是登录密码而是Personal Access token如果token忘记了或是过期了，点击对应的token直接重新生成即可 四、分支操作 查看本地所有分支，前面带*的是当前所处的分支git branch 查看远程所有分支git branch -r 创建分支git branch [name] 切换分支git checkout [name] 合并分支git merge [name] 五、部分命令的详细用法关于git push命令的用法参考文章 git push &lt;远程仓库名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;：将本地分支推送到远程仓库的远程分支。（注意：这里的远程仓库名依然是在本地仓库中对远程仓库起的别名）&lt;远程仓库名&gt;：在本地仓库中对远程仓库起的别名，如上面命令解析2(1)中设置的origin。&lt;本地分支名&gt;：本地分支的名称，比如我们在项目开发，一般主分支(也是默认分支)叫做master，一些新功能开发的分支叫做develop或feature。这些我们在我们自己电脑本地用git branch创建的分支就是本地分支。&lt;远程分支名&gt;：在远程仓库的普通分支，比如远程仓库上的master，自己在远程仓库创建的分支，以及自己推送到远程仓库上去的在远程仓库上的分支。（注意：&lt;远程分支名&gt;与 &lt;远程仓库名&gt;的情况不同：(i)&lt;远程分支名&gt;的取名由git push中的远程分支名决定，一般Git使用者会省略&lt;远程分支名&gt;这个参数，所以Git会默认把&lt;本地分支名&gt;设置为&lt;远程分支名&gt;;(ii)&lt;本地分支名&gt;无论在远程仓库还是本地仓库就只有一个名字，不像&lt;远程分支名&gt;有一个绝对URL地址名字和一个在本地仓库中的别名。）","link":"/2022/05/13/%E5%B8%B8%E7%94%A8Git%E5%91%BD%E4%BB%A4%EF%BC%88%E7%AE%80%E6%B4%81%E7%89%88%EF%BC%89/"},{"title":"微信小程序运行机制分析","text":"​​点击阅读更多查看文章内容 setData渲染机制Native就是微信客户端，逻辑层JsCore（js文件）通过setdata把数据送到渲染层Webview（小程序页面，wxml文件），渲染层接收到数据后就会改变对应的元素值。用户在小程序页面进行操作可以触发event，event传给Native再重新路由到逻辑层JsCore 生命周期小程序的生命周期： onLaunch：启动 onShow：显示 onHide：隐藏 页面生命周期： 页面路由框架以栈的形式维护了当前的所有页面。 当发生路由切换的时候，页面栈的表现如下： 路由方式 页面栈表现 初始化 新页面入栈 打开新页面 新页面入栈 页面重定向 当前页面出栈，新页面入栈 页面返回 页面不断出栈，直到目标返回页 Tab 切换 页面全部出栈，只留下新的 Tab 页面 重加载 页面全部出栈，只留下新的页面","link":"/2023/12/29/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"title":"并查集（模板+例题）","text":"​​点击阅读更多查看文章内容 并查集概念并查集是一种树型的数据结构，用于处理一些不相交集合的合并及查询问题（即所谓的并、查）。比如说，我们可以用并查集来判断一个森林中有几棵树、某个节点是否属于某棵树等。 实现属性：pre[]：记录每个结点的先驱结点size[]：记录当前结点所属集合的大小count：记录连通分量的个数方法：查找代表元（find）：查找当前结点所属集合的代表元，树形结构，我们可以通过pre逐层向上查找，一直找到根节点即为当前集合的代表元。（这里的代表元就是一个集合中的代表元素，如果两个元素的代表元相同，则这两个元素属于同一集合） 123456int find(int x) { if (pre[x] == x) return x; return pre[x] = find(pre[x]); } 合并（connect）：合并两个结点，我们通过pre[y]=x，将y结点连接到x上，这里我们为了减少find函数的迭代次数，我们总是把小的集合连接到大的集合上。 12345678910111213bool connect(int x, int y) { x = find(x); y = find(y); if (x == y) return false; if (size[x] &lt; size[y]) swap(x, y); pre[y] = x; size[x] += size[y]; count--; return true; } 查询（isconnect）：判断两个结点是否属于同一集合 1234bool isconnect(int x, int y) { return find(x) == find(y); } 断开连接（disconnect）：将当前结点断开与其上层节点的连接 1234void disconnect(int x) { pre[x] = x; } 模板1234567891011121314151617181920212223242526272829303132333435363738394041424344class UnionFind{public: vector&lt;int&gt; pre; vector&lt;int&gt; size; int count; UnionFind(int n) { count = n; pre.resize(n); size.resize(n, 1); for (int i = 0; i &lt; n; i++) { pre[i] = i; } } int find(int x) { if (pre[x] == x) return x; return pre[x] = find(pre[x]); } bool isconnect(int x, int y) { return find(x) == find(y); } bool connect(int x, int y) { x = find(x); y = find(y); if (x == y) return false; if (size[x] &lt; size[y]) swap(x, y); pre[y] = x; size[x] += size[y]; count--; return true; } void disconnect(int x) { pre[x] = x; }}; 例题LeetCode5941 给你一个整数 n ，表示有 n 个专家从 0 到 n - 1 编号。另外给你一个下标从 0 开始的二维整数数组 meetings ，其中 meetings[i] = [xi, yi, timei] 表示专家 xi 和专家 yi 在时间 timei 要开一场会。一个专家可以同时参加 多场会议 。最后，给你一个整数 firstPerson 。专家 0 有一个 秘密 ，最初，他在时间 0 将这个秘密分享给了专家 firstPerson 。接着，这个秘密会在每次有知晓这个秘密的专家参加会议时进行传播。更正式的表达是，每次会议，如果专家 xi 在时间 timei 时知晓这个秘密，那么他将会与专家 yi 分享这个秘密，反之亦然。秘密共享是 瞬时发生 的。也就是说，在同一时间，一个专家不光可以接收到秘密，还能在其他会议上与其他专家分享。在所有会议都结束之后，返回所有知晓这个秘密的专家列表。你可以按 任何顺序 返回答案。 解析看到题目第一眼肯定不难想到先按照时间排个序，然后从前往后遍历如果当前会议有知道秘密的专家参与，那么另一个专家也会知道秘密。这里的主要问题就是，时间相同的会议怎么处理？在这里，我们就可以使用并查集，把相同时间举行的会议中参与的专家分别连接起来，然后判断当前会议的专家是否与专家0是连通的，如果连通则该专家会知晓秘密，如果不连通，则当前会议的专家仍不知晓秘密，断开刚刚建立的连接，继续判断下一场会议。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889class UnionFind{public: vector&lt;int&gt; pre; vector&lt;int&gt; size; int count; UnionFind(int n) { count = n; pre.resize(n); size.resize(n, 1); for (int i = 0; i &lt; n; i++) { pre[i] = i; } } int find(int x) { if (pre[x] == x) return x; return pre[x] = find(pre[x]); } bool isconnect(int x, int y) { return find(x) == find(y); } bool connect(int x, int y) { x = find(x); y = find(y); if (x == y) return false; if (size[x] &lt; size[y]) swap(x, y); pre[y] = x; size[x] += size[y]; count--; return true; } void disconnect(int x) { pre[x] = x; }};class Solution{public: static bool cmp(vector&lt;int&gt; &amp;a, vector&lt;int&gt; &amp;b) { return a[2] &lt; b[2]; } vector&lt;int&gt; findAllPeople(int n, vector&lt;vector&lt;int&gt;&gt; &amp;meetings, int firstPerson) { sort(meetings.begin(), meetings.end(), cmp); UnionFind uf(n); int m = meetings.size(); uf.connect(0, firstPerson); for (int i = 0; i &lt; m; i++) { int j = i + 1; for (; j &lt; m; j++) { if (meetings[i][2] != meetings[j][2]) break; } for (int k = i; k &lt; j; k++) { uf.connect(meetings[k][0], meetings[k][1]); } for (int k = i; k &lt; j; k++) { if (!uf.isconnect(meetings[k][0], 0)) { uf.disconnect(meetings[k][0]); uf.disconnect(meetings[k][1]); } } i = j - 1; } vector&lt;int&gt; ret; for (int i = 0; i &lt; n; i++) { if (uf.isconnect(i, 0)) ret.push_back(i); } return ret; }};","link":"/2021/11/28/%E5%B9%B6%E6%9F%A5%E9%9B%86%EF%BC%88%E6%A8%A1%E6%9D%BF+%E4%BE%8B%E9%A2%98%EF%BC%89/"},{"title":"微隔离（MSG）","text":"​​点击阅读更多查看文章内容 微隔离（MSG）参考文章：用”微隔离”实现零信任、什么是微隔离？当下哪家微隔离最靠谱?参考视频：不仅是防火墙！用微隔离实现零信任 定义微隔离（Micro Segmentation），微隔离是一种网络安全技术，其核心的能力要求是聚焦在东西向流量的隔离上。微隔离的实现方式是将数据中心内部所有的业务按照特定的原则划分为数个微小的网络节点，根据动态策略分析对这些节点执行访问控制，在逻辑上将这些节点隔离开，限制用户横向移动，这就是微隔离。在微隔离的架构中，不再存在内、外网的概念，而是将数据中心网络隔离成了很多微小的计算单元，这里我们简称节点。每个节点要访问其他节点的资源，都需要经过微隔离客户端的认证，如果节点身份认证不通过，或不具备访问权限，会被客户端拦截。 节点可以是门户网站，可以是数据库、审计设备，甚至一个文件服务器，只要具备一定的数据处理能力的单元，都可以成为一个节点。他们不再因处于内网而被认为是“可信的”，所有节点都被逻辑隔离，节点之间的访问都是受控的。节点划分越细致，控制中心对整个数据中心网络的流量可视化就越清晰。 数据流向南北向流量：指通过网关进出数据中心的流量，一般来说防火墙部署在数据中心的出口处，来做南北向流量的保护东西向流量：指由数据中心内部服务器彼此相互访问所造成的内部流量，据统计，当代数据中心75%以上的流量为东西向流量 组成有别于传统防火墙单点边界上的隔离（控制平台和隔离策略执行单元都是耦合在一台设备系统中），微隔离系统的控制中心平台和策略执行单元是分离的，具备分布式和自适应特点： 策略控制中心：主要包括管理引擎和策略管理两个控制块。管理引擎接收客户端发送的流量数据，并根据这些信息建立业务模型，交由策略管理模块分析当前网络形势，进行多维度策略运算，动态生成安全策略，并下发给客户端执行，通过流量自学习实现策略自适应。 策略执行单元：通过代理或虚墙实现，主要包括流量信息收集和策略执行两个部分。向控制中心反馈当前网络中的业务流量信息，实时上报业务动态，接收控制中心下发的策略控制指令，执行安全策略动作， 实现方法 1、基于agent客户端实现微隔离 这种模式需要每个服务器的操作系统上装一个agent。Agent调用主机自身的防火墙或内核自定义防火墙来做服务器间的访问控制。图中右侧红方块是管理平台，负责制定策略，收集信息。优势：与底层无关，支持容器，支持多云。 缺点：必须在每个服务器上安装agent客户端。有人会担心资源占用问题，担心影响现有业务。 2、基于云原生能力实现微隔离 使用云平台基础架构中虚拟化设备自身的防火墙功能来做访问控制。优点：隔离功能与基础架构都是云提供的，所以两者兼容性更好，操作界面也类似。 缺点：无法跨越多个云环境进行统一管控。 3、基于第三方防火墙实现微隔离 利用现有的防火墙做访问控制。优势：网络人员很熟悉，有入侵检测、防病毒等功能。 缺点：防火墙本身跑在服务器上，缺少对底层的控制。 好处 如果黑客已经攻进了一个服务器，那么他就可以利用这个服务器做跳板，进一步攻击网络中的其他服务器。 微隔离可以阻止这种来自内部的横向攻击。微隔离通过服务器间的访问控制，阻断勒索病毒在内部网络中的蔓延，降低黑客的攻击面。 这正好符合了零信任的原则：（1）假设已经被攻破（2）持续验证，永不信任（3）只授予必须的最小权限 实施步骤 定义资产：资产（服务、业务等）分组；按逻辑分组 梳理业务模型：服务安全域识别；网络流量自学习、自发现、自描绘服务安全域 设计微隔离分组：安全策略组、系统安全域、租户安全域、业务安全域 实施保护：根据策略执行阻断、放行；新增负载自动加域 持续监控：快速发现内部渗透、横移、扫描、勒索病毒传播等行为；阻断日志、异常行为告警","link":"/2022/06/11/%E5%BE%AE%E9%9A%94%E7%A6%BB%EF%BC%88MSG%EF%BC%89/"},{"title":"扩展欧几里得求逆元实例","text":"​​点击阅读更多查看文章内容 扩展欧几里得求逆元实例 首先说一下逆元的定义存在一个数a使得ax对y进行取余运算，得到的值是1，则称a是x的逆元。在数学中记做：a * x = 1(mod p)例如x = 4，y = 11，3x = 1(mod y)，3 × 4 = 12，12 mod 11 = 1 , 3就是x的逆元。 对于求逆元这一操作在计算机领域主要用于非对称加密，如我们常见的RSA加密算法等。 那应该求得这个逆元呢，我们知道，再求两个数的最大公约数的时候可以用欧几里得算法。在欧几里得算法中，通过辗转相除，当余数为0的时候最后的除数就是两个数的最大公约数。 而在其扩展算法中，我们已知两个数的最大公约数，我们已知 ax = 1(mod p),展开就是 ax mod p = 1，首先我们先求 p = x1 * a + p1，然后 p = a，a = p1，迭代下去直到pi = 1（i表示出了i次）为止然后就可以得出 1 = p - xi * a，此时的a和p已经不是我们初始的a和p了，我们需要往前推，推到 1= xa + yp 为止，此时得出的x就是a的逆元，当然如果逆元x为负数，或者比p大，要对其就行取余操作。 举个例子 11 = 1(mod 20)求11的逆元 20 = 1 × 11 + 9 //注释：此时x1 = 1， a = 11，p = 20，p1 = 9，执行p = a，a = p111 = 1 × 9 + 2 //注释：x2 = 1，a = 9，p2 = 2。9 = 4 × 2 + 1 //注释：p3 = 1 此时得到：1 = 9 - 2 × 4，开始往前推直到推出 1= xa + yp从上述式子中可以得知 9 = 20-111 = 20 - 11 - 2 × 4同时 2 = 11 -91 = 20 -11 -4 × (11-9)已知 9 = 20 - 111 = 20 -11 -4 × (11-(20-11))1 = 20 -11 -4 × (11-20+11)合并同类项得1 = 5 × 20 - 9 × 111 = y × 20 + x × 11 x为a的逆元 -9-9对p取余为11综上11模20的逆元为11 验证 11 × 11 = 121，121 mod 20 = 6 — 1到此 计算结束 关于更具体的讲解可以阅读下面的文章扩展欧几里得求逆元","link":"/2022/08/01/%E6%89%A9%E5%B1%95%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E6%B1%82%E9%80%86%E5%85%83%E5%AE%9E%E4%BE%8B/"},{"title":"操作系统笔记整理 ——目录索引页","text":"​​点击阅读更多查看文章内容 操作系统笔记整理 ——目录索引页 笔记整理参考书籍：《计算机操作系统》第四版 汤小丹等编著 以下笔记整理主要包含了前八章的内容，具体包含的内容会在下面详细说明 笔记尚有许多不足之处，如果大家发现错误还请私信我修改，感谢！ 目录即链接，点击目录即可跳转到对应笔记页面 @[toc] 一、操作系统引论 操作系统的特征、功能 批处理系统 微内核操作系统 二、进程的描述与控制(1) 前趋图 进程概念(定义、特征、状态、PCB、层次结构) 进程控制(创建、终止、阻塞与唤醒、挂起与激活) 三、进程的描述与控制(2) 线程概念(状态、多进程中的线程) 线程实现(内核支持线程、用户级线程) 进程的同步与互斥(信号量机制、管程机制) 进程通信 四、处理机调度与死锁(1) 处理机调度的层次 作业调度算法(先来先服务、短作业优先、优先级调度、高响应比优先) 进程调度(最短剩余时间、时间片轮转、优先级调度、多级队列调度) 实时调度(限制条件、最早截止时间优先、最低松弛度优先) 五、处理机调度与死锁(2) 死锁概述(产生死锁的原因、必要条件、处理死锁的方法) 预防死锁(破坏四个条件) 避免死锁(银行家算法) 死锁的检测和解除(资源分配图) 六、存储器管理(1) 存储器的层次结构 程序的装入和链接 可重定位装入方式 连续分配存储管理(单一连续分配、固定分区分配、动态分区分配) 基于顺序搜索的动态分区分配算法(首次适应、循环首次适应、最佳适应、最坏适应) 基于索引搜索的动态分区分配算法(快速适应、伙伴系统、哈希算法) 系统中的碎片 动态可重定位分区分配 七、存储器管理(2) 离散分配方式 分页存储管理方式 分段存储管理方式 分页与分段的区别 段页式存储管理方式 八、虚拟存储器 虚拟存储器概述 请求分页存储管理方式(请求页表机制、地址变换、物理块的分配策略) 页面置换算法(抖动现象、最佳置换、先进先出、最近最久未使用、最近最少使用、CLock置换、页面缓冲、访问内存的有效时间) 抖动与工作集 请求分段 九、输入输出系统（1） I/O系统的功能、模型和接口 I/O设备和设备控制器(内存映像、通道) 中断机构和中断处理程序 设备驱动程序(设备处理、对I/O设备的控制方式、DMA) 与设备无关的I/O软件 十、输入输出系统（2） 用户层I/O软件(系统调用、库函数、Spooling系统) 缓冲区管理(单缓冲、双缓冲、环形缓冲区、缓冲池) 磁盘存储器的性能和调度(磁盘访问时间、磁盘调度算法) 十一、文件和文件系统 数据项、记录和文件 文件系统 文件的逻辑结构(顺序、索引、索引顺序) 文件目录(索引结点) 文件共享 文件保护(访问矩阵) 十二、磁盘存储器的管理 外存的组织方式(连续组织方式、链接组织方式、FAT、NTFS、索引组织方式) 文件存储空间的管理(空闲表法和空闲链法、位示图、成组链接) 提高磁盘I/O速度的途径","link":"/2022/01/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%20%E2%80%94%E2%80%94%E7%9B%AE%E5%BD%95%E7%B4%A2%E5%BC%95%E9%A1%B5/"},{"title":"操作系统中的作业、程序、进程","text":"​​点击阅读更多查看文章内容 作业作业是用户向计算机提交任务的任务实体，是要求计算机系统所做工作的集合，在用户向计算机提交作业后，系统将它放入外存中的作业等待队列中等待执行。它包括程序，数据及其作业说明书。 程序程序是为解决一个信息处理任务而预先编制的工作执行方案，是由一串CPU能够执行的基本指令组成的序列，每一条指令规定了计算机应进行什么操作（如加、减、乘、判断等）及操作需要的有关数据。 进程进程是程序的一次执行实例，是一个程序及其数据在处理机上顺序执行时所发生的活动，是系统进行资源分配和调度的一个独立单位","link":"/2022/02/17/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E4%BD%9C%E4%B8%9A%E3%80%81%E7%A8%8B%E5%BA%8F%E3%80%81%E8%BF%9B%E7%A8%8B/"},{"title":"操作系统笔记整理10——输入输出系统（2）","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 用户层I/O软件用户层软件必须通过一组系统调用来取得操作系统服务。通过调用对应的库函数使用系统调用I/O软件还包括运行在内核之外的守护进程（后台）等 系统调用操作系统内核提供的一组功能强大的函数，在核心态下运行系统调用是用户程序取得OS服务的唯一途径当OS捕获到应用程序中的系统调用后，便将CPU的状态从用户态转换到核心态，然后转向操作系统中相应进程，由该过程完成所需的I/O操作，执行完成后，系统又将CPU状态从核心态转换到用户态，返回到应用程序继续执行。 库函数库函数是系统调用的一种封装和扩展，工作在用户态用户层 I/O 软件提供了一些读/写设备和控制/检查设备的库函数，以方便 用户取得 OS 的服务。 假脱机（Spooling）系统脱机输入输出技术为了缓和 CPU 的高速性与 I/O 设备的低速性间矛盾而引入，该技术在外 围控制机的控制下，先将低速I/O设备上的数据传送到高速磁盘上，或者相反，这样当处理机需要输入数据时，便可以直接从磁盘中读取数据，极大地提高了输入速度。反之，在输出数据时，也可以快速地把数据先输出到磁盘上，处理机便可去做其他的事情。假脱机技术当系统中引入了多道程序技术后，完全可以利用其中的一道程序，来模拟脱机输入时的外围控制机功能，把低速I/O设备上的数据传送到高速磁盘上，再用另一道程序模拟脱机输出时外围控制机的功能，把数据从磁盘传送到低速输出设备上 SPOOLing的组成 输入井和输出井（外存中）在磁盘上开辟出来的两个内存区域。输入井模拟脱机输入时的磁盘，用于收容I/O设备输入的数据。输出井模拟脱机输出时的磁盘，用于收容用户程序的输出数据 输入缓冲区和输出缓冲区（内存中）在内存中开辟的两个缓冲区，用于缓和 CPU、磁盘、I/O 设备之间速度不匹配的矛盾。输入缓冲区用于暂存由输入设备传送的数据，之后再传送到输入井。输出缓冲区用于暂存从输出井传送的数据，之后再传送到输出设备。 输入进程和输出进程输入进程用于模拟脱机输入时的外围控制机，将用户要求的数据从输入设备传送到输入缓冲区，再存放到输入井，当CPU需要输入设备时，直接从输入井读入内存。输出进程也用于模拟脱机输出时的外围控制机，把用户要求输出的数据从内存传送到输出井，待输出设备空闲时，再将输出井中的数据经过输出缓冲区输出至输出设备上。 井管理程序用于控制作业与磁盘井之间信息的交换磁盘井 ⇔ 进程 buf ⇔ 用户进程 SPOOLing系统的特点 提高了I/O速度把对低速设备操作变为对输入/输出井的操作。 将独占设备改造为共享设备。实际上并没有为任何进程分配设备，分配设备的实质是分配输入/输出井，并为进程分配一个存储区和建立一 张 I/O 请求表 实现了虚拟设备功能。 缓冲区管理缓冲的引入 缓解 CPU 与 I/O 设备间速度不匹配的矛盾。 减少中断 CPU 的次数。buffer 越大，“buffer 满”发生频率越低。 解决数据粒度（即基本数据单元大小）不匹配的问题。 提高 CPU 与 I/O 设备的并行性。 中断一次需要的时间（缓冲区满所用的时间，即中断一次所需的时间）中断响应时间：CPU必须在下一数据写入缓冲区之前，对当前缓冲区中数据进行响应处理，否则缓冲区中的数据将会被覆盖掉。 单缓冲区和双缓冲区单缓冲区单缓冲区方式是在设备和处理机之间设置一个缓冲区。设备与处理机交换数据时，先把交换的数据写入缓冲区，然后需要数据 的设备/处理机再从缓冲区中取走数据。单缓冲区方式可以缓解 CPU 与 I/O 设备间速度不匹配的矛盾。由于缓冲区属于临界资源，不允许多个进程同时对一个缓冲区操作，因 此在某一段时间内，缓冲区只能存放输入数据或输出数据（单向传输）。 无缓冲区时：处理一块数据的时间为:T+C有缓冲区时：C和T是可以并行的，因此，处理一块数据的时间为:Max(C,T)+M 双缓冲区 由于缓冲区是共享资源，生产者与消费者在使用缓冲区时必须互斥。如果消费者尚未取走缓冲区中的数据，即使生产者生产出新的数据，也无法将它送入缓冲区，生产者需等待。由此，引入双缓冲区，便能解决这一问题。 双缓冲区方式是在设备和处理机之间设置两个缓冲区。 在设备输入时，先将数据送入第一缓冲区，装满后便转向第二缓冲区。此时操作系统可以从第一缓冲区中移出数据，并送入用户进程。 M与T可以并行，C与T也可以并行，因此处理一块数据的时间为：Max(C+M,T)，通常 M≪T，因此处理一块数据的时间可以粗略地估计为Max(C,T)。如果C&lt;T,可使块设备连续输入如果C&gt;T,可使CPU不必等待设备输入 环形缓冲区 当输入输出的速度基本相等时，采用双缓冲能获得较好的效果，可使生产者和消费者基本上能并行操作。但若两者的速度相差甚远，双缓冲的效果则不够理想，不过可以随着缓冲区和数量的增加，使情况有所改善。因此，又引入了多缓冲机制，可将多个缓冲区组织成环形缓冲区形式。 环形缓冲区的组成多个缓冲区：在设备和处理机之间设置多个大小相等的缓冲区，这些缓冲区构成环形。作为输入的多缓冲区可分为三种类型：用于装输入数据的空缓冲区R、已装满数据的缓冲区G以及计算进程正在使用的现行工作缓冲区C多个指针：Nexti：指示下次可用的空缓冲区的指针Nextg：指示下次可用的数据缓冲区的指针Current：指示正在使用的缓冲区的指针 环形缓冲区的使用Getbuf过程：计算进程：调用Getbuf过程，取Nextg对应缓冲区使用，须把它改为现行工作缓冲区，并令Current指针指向该缓冲区的第一个单元，同时将Nextg对应的缓冲区置为空，Nextg=（Nextg+1）Mod N输入进程：调用Getbuf过程，取Nexti对应缓冲区使用，将Nexti对应的缓冲区置为满，Nexti=（Nexti+1）Mod NReleasebuf过程输入进程：把C装满后，调用Releasebuf过程释放缓冲区，改为G计算进程：把C的数据提取完毕后，调用Releasebuf过程释放缓冲区，改为R 进程之间的同步问题指针 Nexti 和指针 Nextg 将不断地沿着顺时针方向移动。Nexti 追上 Nextg：表示输入速度 &gt; 输出速度，全部 buf 满，再无空 buf 可用，这时输入进程阻塞。这种情况被称为系统受计算限制。Nextg 追上 Nexti：输入速度 &lt; 输出速度，全部 buf 空，这时输出进程阻塞。这种情况被称为系统受 I/O 限制。 缓冲池 上述三种缓冲区的组织形式仅适用于某种特定的 I/O 进程和计算进程，属于专用缓冲。当系统中的设备很多时，将会有许多这样的循环缓冲区，消耗大量的内存空间，而且其利用率也不高。为了提高缓冲区的利用率，可以采用公共缓冲池技术，在池中设置了多个可供若干个进程共享的缓冲区。缓冲池与缓冲区的区别在于：缓冲区仅仅是一组内存块的链表，而缓冲池则是包含了一个管理的数据结构及一组操作函数的管理机制，用于管理多个缓冲区。 缓冲池的组成 空白缓冲队列emq：由空缓冲区所链成的队列。其队首指针F(emq)和队尾指针L(emq)分别指向该队列的首缓冲区和尾缓冲区 输入队列inq：由装满输入数据的缓冲区所链成的队列，队首指针F(inq),队尾指针L(inq) 输出队列outq：由装满输出数据的缓冲区所链成的队列，队首指针F(outq),队尾指针L(outq) 收容输入缓冲区hin 提取输入缓冲区sin 收容输出缓冲区hout 提取输出缓冲区sout getbuf过程和putbuf过程Addbuf(type,number) 过程：用于将参数 number 所指示缓冲区挂在 type队列上。Takebuf(type) 过程：用于从 type 所指示的队列的队首摘下一个缓冲区。MS(type)：互斥信号量，使诸进程互斥地访问缓冲池队列RS(type)：资源信号量（如缓冲队列中缓冲区的数量），保证诸进程同步地使用缓冲区 缓冲池的工作方式 收容输入：输入进程调用Getbuf(emq)过程，从空缓冲队列emq的队首摘下一空缓冲区，把它作为收容输入工作区hin。然后，把数据输入其中，装满后再调用Putbuf(inq,hin)，将它挂在输入队列inq的末尾。 提取输入：计算进程调用Getbuf(inq)过程，从输入队列inq队首取得一缓冲区，作为提取输入工作缓冲区sin，计算进程用完该数据后，再调用Putbuf(emq,sin)过程，将它挂到空缓冲队列emq末尾 收容输出：计算进程调用Getbuf(emq)，从空缓冲队列emq的队首取得一空缓冲作为输出工作缓冲区hout，当其中装满输出数据后，又调用Putbuf(outq,hout)过程，将它挂在outq末尾 提取输出：输出进程调用Getbuf(outq)过程，从输出队列的队首取得一装满输出数据的缓冲区，作为提取输出工作缓冲区sout。在数据提取完后，再调用Putbuf(emq,sout)，将它挂在emq末尾 磁盘存储器的性能和调度磁盘结构 磁道：磁盘在格式化时被划分成许多同心圆，这些同心圆轨迹叫做磁道，磁盘的 0 磁道在最外圈 柱面：不同盘片相同半径的磁道所组成的圆柱称为柱面 扇区：磁道被划分成一段段的圆弧，每段圆弧叫做一个扇区。扇区是磁盘最小的物理存储单元 簇：簇是操作系统使用的逻辑概念(分配的最小单位)，相邻的扇区组合在一起，形成一个簇 数据的组织磁盘结构：盘面、磁道、扇区磁盘物理块的地址：磁头号、柱面号、扇区号存储容量=磁头(盘面)数 × 磁道(柱面)数 × 每道扇区数 × 每扇区字节数 磁盘类型：固定头磁盘：每条磁道上都有一个磁头移动头磁盘：每个盘面上都有一个磁头 磁盘格式化：低级格式化：物理级的格式化，主要是用于划分硬盘的磁柱面、建立扇区数和选择扇区间隔比。高级格式化：清除硬盘上的数据、生成引导区信息、初始化FAT表、标注逻辑坏道等。 温彻斯特盘低级格式化每个扇区容量为 600 个字节，其中 512 个字节存放数据，其余用于存放 控制信息。每扇区包括两个字段：标识符字段：其中一个 SYNCH 字节（同步字节）用于标识一个扇区，CRC 字段用于段校验（循环冗余码校验）。 数据字段：其中可存放 512 个字节的数据。为了简化和方便磁头的辨识，在一个盘面的不同磁道、一个磁道的不同扇区、一个扇区的不同字段之间都设置了一个到若干个不同长度的间距(Gap) 磁盘访问时间**寻道时间Ts**：磁头定位到磁道所需时间Ts = m × n + ss 为启动磁臂的时间，n 为移动的磁道数，m 为常数与磁盘驱动器的速度有关。 **旋转延迟时间Tr**：扇区移动到磁头下面所经历的时间Tr ＝ 1/2r（均值）r为磁盘每秒钟的转数 **传输时间Tt**：数据从磁盘读出或向磁盘写入数据所经历的时间Tt= b/rNr为磁盘每秒钟的转数，N为一条磁道上的字节数，b为每次读/写的字节数 访问时间Ta = m × n + s + 1/2r + b/rN 例1：考虑一个磁盘系统。平均寻道时间是 4ms，转速是 7500rpm，忽略控制器的开销。每个磁道有 500 个扇区，每个扇区 512 字节。假设读取一个包括2500 个扇区的文件（文件大小为 1.28MB），试估计传送需要的总时间。1.假设文件尽可能紧凑地保存在磁盘上，占据 5 个相邻磁道的所有扇区（5×500）。读取第一条磁道的时间：读取第一条磁道的时间为 16ms。 读取整个文件的时间：后面的 4 个磁道不再需要寻道时间，每个磁道可以在 4+8=12ms 内读入。总时间 = 16 + (4 × 12) = 64ms = 0.064s2.假设文件随机地分布在磁盘上。读取整个文件的时间： 例2 磁盘调度算法先来先服务算法(FCFS)只考虑申请者申请的先后次序完成磁盘访问操作磁头臂来回反复移动，增长了等待时间，对机械结构不利。 最短寻道时间优先算法(SSTF)选择要求访问的磁道与当前磁头所在磁道距离最近的访问，以使每次的寻道时间最短，但不能保证平均寻道时间最短 缺点：磁臂粘着：在最短寻道时间优先调度算法中，可能出现磁臂停留在某处的 情况，即反复请求某一磁道，从而垄断了整个磁盘设备，这种现象称为磁臂粘着。磁道歧视：假设某一时刻外磁道请求不断，则内磁道请求可能长时间得不 到满足，这种现象称为“磁道歧视”。因此 SSTF 算法缺乏公平性，存在饥饿和饿死的问题。磁盘的0磁道在最外圈 扫描算法(Scan) 扫描算法一直移动到最内柱面，LOOK算法（电梯算法）一旦内柱面没有访问请求就改变移动方向，不扫描到头。这里不做区分，统一按照LOOK算法解决 无访问请求时，磁头引臂停止不动；当有访问请求时，起始时磁头由外柱面向内柱面移动，并为途经的请求服务。一旦内柱面没有访问请求， 则改变移动方向（如外柱面有请求）或停止移动（外柱面也无请求）。对于 SCAN(LOOK) 算法来说，位于不同磁道（柱面）的 I/O 请求与获取 服务所需的等待时间是不同的。对于靠近边缘的柱面，最坏情况的移动量为2N-1（N 为柱面数）；对于 靠近中部的柱面，最坏情况为N-1。平均情况分别约为 N 和 N/2。 循环扫描算法(CSCAN)循环扫描算法是为了消除边缘柱面与中部柱面等待时间差异而进行的改进。磁头只在单方向移动过程中才为途经的请求服务，一旦达到边缘，则立 即快速移动至另一边缘，在此移动过程中并不处理访问请求，然后重新 开始新一轮扫描。 NStepSCAN算法将磁盘请求队列分成若干个长度为 N 的子队 列，磁盘调度将按 FCFS 算法依次处理这些子队列，而每一子队列按SCAN 算法处理。N=1 ⇒ FCFS 算法N 很大 ⇒ SCAN 算法 FSCAN算法FSCAN 算法实质上是 N 步 SCAN 算法的简化。FSCAN 只将磁盘请求 队列分成两个子队列。一个是由当前所有请求磁盘 I/O 的进程形成的队列，由磁盘调度按 SCAN 算法进行处理。另一个是在扫描期间，将新出现的所有请求磁盘 I/O 的进程放入另一个等待处理的请求队列。这样所有的新请求都将被推迟到下一次扫描时处理。","link":"/2022/01/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%8610%E2%80%94%E2%80%94%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F%EF%BC%882%EF%BC%89/"},{"title":"操作系统笔记整理11——文件和文件系统","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 所有的计算机应用程序都需要存储和检索信息。 长期存储信息有三个基本要求：能够存储大量信息.使用信息的进程终止时，信息仍旧存在。必须能使多个进程并发存取有关信息。解决所有这些问题的通常做法是把信息以文件的形式，存储在磁盘或其他外部介质上。存储在文件中的信息必须是永久性的，不会因为创建和终止进程而受到影响。只有在文件的所有者显式地删除文件时，文件才会消失。 数据项、记录和文件数据项基本数据项：用于描述一个对象的某种属性的字符集，是数据组织中可 以命名的最小逻辑数据单位即原子数据，又称为数据元素或字段。如描述一个学生的基本数据项有学号、姓名等。组合数据项：由若干个基本数据项组成的，简称组项。如工资是组合数据项，包括基本工资，奖金等。数据项的名字和类型两者共同定义了一个数据项的“型”（Type）。而表征一个实体在数据项上的数据则称为“值”（Value）。如：学生是一个实体，“成绩”是实体的“型”描述，具体的分数是实体的“值”。 记录记录是一组相关数据项的集合，用于描述一个对象在某方面的属性。 一个记录应包含哪些数据项，取决于需要描述对象的哪个方面。为了描述对象的不同属性，一个记录可以选取不同的数据项。例如一个人当把他作为一个学生：可选取学号、姓名、成绩等数据项。当把他作为一个病人：可选取病历号、姓名、病史等数据项。关键字：能唯一地标识出记录的一个或几个基本/组合数据项。 文件文件是由创建者所定义的、具有符号名的相关信息集合。文件可分为有结构文件和无结构文件两种。有结构文件是由若干个相关记录组成，无结构文件被看成一个字符流。文件是文件系统中最大的一个数据单位，它描述了一个对象集。例如，可将一个班的学生记录作为一个文件 文件属性包括：1.文件类型：如源文件、目标文件、可执行文件等2.文件长度3.文件的物理位置4.文件的建立时间：指最后一次修改的时间文件类型： 文件系统文件系统模型 对象及其属性 文件 目录：为了方便用户对文件的存取和检索，在文件系统中必须配置目录，在目录的每个目录项中，必须含有文件名、对文件属性的说明，以及该文件所在的物理地址。 磁盘存储空间：文件和目录必定占用存储空间，对这部分空间的有效管理，不仅能提高外存的利用率，而且能提高对文件的存取速度 对对象操纵和管理的软件集合文件系统的功能大多在这一层实现，其中包括 对文件存储空间的管理 对文件目录的管理 用于将文件的逻辑地址转换为物理地址的机制 对文件读和写的管理 对文件的共享与保护等功能 为实现这些功能，OS通常都采取了层次组织结构，即在每一层都包含了一定的功能，处于某个层次的软件，只能调用同层或更低层次中的功能模块 一般地，把与文件系统有关的软件分为四个层次： I/O控制层：由设备驱动程序和中断处理程序组成，启动I/O操作及处理设备发来的中断信号 基本文件系统层：处理内存与磁盘间的数据块交换 基本I/O管理程序：用于完成与磁盘I/O有关的事务，如将文件逻辑块号转换为物理块号 逻辑文件系统：处理与记录和文件有关的操作，如允许用户和应用程序使用符号文件名访问文件及记录 文件的逻辑结构文件的逻辑结构：从用户观点出发所观察到的文件组织形式，是用户可以直接处理的数据及其结构，它独立于物理特性。文件的物理结构：是指文件在外存上的存储组织形式，用户是看不见的，文件的物理结构 不但与存储介质的存储性能有关，而且还与所采取的外存分配方式有关。 逻辑结构的类型： 按是否有结构分类 有结构文件（记录式文件），如数据库文件定长记录：文件中所有记录的长度都是相同的变长记录：文件中各记录的长度不相同，产生变长记录的原因可能是由于一个记录中所包含的数据项数目不同，也可能是数据项本身的长度不定 无结构文件（流文件），如程序、文本文件 按文件的组织方式分类 顺序文件一系列记录按某种顺序排列所形成的文件，其中的记录可以是定长记录或可变长记录 索引文件指为可变长记录文件建立一张索引表，为每个记录设置一个表项，以加速对记录的检索速度 顺序索引文件在为每个文件建立一张索引表时，并不是为每一个记录建立一个索引表项，而是为一组记录中的第一个记录建立一个索引表项 顺序文件顺序文件的排序 串结构：记录顺序与关键字无关，按存入时间的先后排列 顺序结构：记录顺序按用户指定的关键字排列 顺序文件的优缺点优点：顺序存取速度快，批处理时效率是所有逻辑文件中最高的。缺点：建立文件前需要能预先确定文件长度，以便分配存储空间。交互应用时“效率低”（如要查找单个记录），尤其是对变长记录的顺序文件。增加、删除记录涉及到排序问题，开销大。解决方法：为顺序文件配置一个事务文件 (log），把试图增加、删除或修改的信息记录于其中，规定每隔一定时间(如4小时)，将运行记录文件与原来的主文件合并，产生一个按关键字排序的新文件。 对顺序文件的续写操作定长记录：读写完一个记录（定长 L）后：读指针 Rptr:= Rptr + L；写指针 Wptr:= Wptr + L第 i 个记录相对于第一个记录首址的地址：Ai=i× L变长记录：读写完一个记录后：Rptr:=Rptr+Li+1；Wptr:=Wptr+Li+1。Li 是刚读完或写完记录的长度。变长记录中每个记录前用一个字节指明该记录的长度。 第 i 个记录的首址：须顺序地查找每个记录，获得记录长度 Li，然后才能 计算出第 i 个记录的首址：Ai=${ \\sum_{i=0}^{i-1} (Li+1)}$ 索引文件 定长记录的文件可以通过简单的计算，很容易地实现随机查找，但变长记录文件查找一个记录必须从第一个记录查起，耗时很长。 索引文件为变长记录文件建立一张索引表，每个记录在索引表中占一个表项，记录指向记录的指针(即记录在逻辑地址空间的首址)以及记录的长度L，索引表按关键字排序，其本身也是一个定长记录的顺序文件，这样就把对变长记录顺序文件的顺序检索转变为对定长记录索引文件的随机检索，从而加快对记录检索的速度 索引文件可以有多个索引表，即为每一种可能成为检索条件的域(属性或关键字)都配置一张索引表，如学号索引表、姓名索引表 优点：通过索引表可方便地实现直接存取，具有较快的检索速度。（索引表本身就 是一个定长记录的顺序文件）易于进行文件的增删。缺点索引表的使用增加了存储费用。 索引顺序文件顺序文件+索引文件在顺序文件的基础上(记录是按关键字的顺序组织)，另外建立了文件索引表(实现对索引顺序文件的随机访问)和溢出文件(记录新增加的、删除的和修改的记录) 一级索引顺序文件首先将变长记录顺序文件中的所有记录分为若干个组，如50个记录一组，然后为顺序文件建立一张索引表，并为每组中的第一个记录在索引表中建立一个索引项，其中含有该记录的关键字和指向该记录的指针在检索时首先利用关键字检索索引表，找到该记录所在组的第一个记录的地址，然后再用顺序查找法去查找主文件 两级索引顺序文件为索引文件在建立一张索引表，从而形成两级索引表 例 1：10000 个记录 (N)顺序文件：5000 次查找。（平均 N/2 次）索引顺序文件：设 100 个记录一组，索引表查找方法设为顺序法的情况 下，则查找次数为 50+50=100。例 2：1000000 个纪录索引顺序文件：采用多级索引表低级索引：（100 个纪录一组）：10000。高级索引：100查找次数：50+50+50=150 直接文件和哈希文件直接文件传统转换：记录键值 → 线性表或链表 → 物理地址直接文件：根据给定的记录键值，直接获得指定记录的物理地址。即记录键值本身就决定了记录的物理地址。键值转换（Key to address transformation）：由记录键值直接到记录物理 地址的转换。 哈希文件K 为记录键值，A 为通过 Hash 函数转换所形成的该记录在目录表中对应表目的位置，则：A=H(k)。该表目的内容指向相应记录的物理块。 文件目录 用于检索文件的目录称为文件目录，它是由目录项所构成的有序序列。 对文件目录的管理要求实现“按名存取”提高对目录的检索速度文件共享（多个用户共享一个文件，只需要在外存保留一个文件）允许文件重名（不同文件使用同一个名字） 文件控制块文件控制块是操作系统为管理文件而设置的数据结构，存放了文件的有关 说明信息，是文件存在的标志。文件控制块中，通常应含有三类信息，即基本信息、存取控制信息及使用信息 基本信息文件名文件物理位置文件逻辑结构(指示文件时流式文件还是记录式文件、记录数，文件是定长记录还是变长记录)文件物理结构(指示文件是顺序文件还是链接式文件或索引文件) 存取控制信息文件的存取权限等 使用信息类包括文件的建立日期和时间、文件上一次修改的日期和时间，以及当前使用信息等 存取文件的过程：文件控制块 FCB→ 块链文件控制块 FCB→FAT/MFT→ 块链 FCB保存在外存空间中，当访问一个文件时，应当能够根据文件名字找到它所对应的 FCB。那么 FCB 是如何保存于外存的呢？它是作为目录项存储于目录文件中的。FCB 也被称作目录项。 文件目录：文件目录是一种数据结构，用于标识系统中的文件及其物理地址，将文件名映射到外存物理位置，供检索使用。目录项：构成文件目录的项目（目录项就是 FCB）目录文件：为了实现对文件目录的管理，通常将文件目录以文件的形式保存在外存，这个文件就叫目录文件。 文件目录和目录文件是同一事物的两种称谓。从用途角度来看称其为文件目录，从实现角度来看称其为目录文件。 索引结点 文件目录通常是存放在磁盘上的，当文件很多时，文件目录可能要占用大量的盘块。在查找目录的过程中，先将存放目录文件的第一个盘块中的目录调入内存，然后把用户所给定的文件名与目录项中的文件名逐一比较。若未找 到指定文件，便再将下一个盘块中的目录项调入内存。设目录文件所占用的盘块数为 N，按此方法查找，则查找一个目录项平均需要调入盘块 (N+1)/2 次。检索目录文件的过程中，只用到了文件名，仅当文件名与指定要查找的文件名相匹配时，才需从该目录项中读出该文件的物理地址，而其它信息在检索目录时不需调入内存。为此，便可以采用文件名与文件描述分开的办法，使文件描述单独形成一个称为索引结点的数据结构，简称i结点，在文件目录的每个目录项仅由文件名和指向该文件所对应的i结点的指针组成，这样在有限的盘块空间内可以存放更多的目录项，减少了调入盘块的次数，大大节省了系统开销 索引结点分为磁盘索引结点和内存索引结点 磁盘索引结点：存放在磁盘上的索引结点，主要包括以下内容 文件主标识符，即拥有该文件的个人或小组的标识符 文件类型，包括正规文件、目录文件或特别文件 文件存取权限，指各类用户对该文件的存取权限 文件物理地址，每一个索引结点中含有13个地址项，给出数据文件所在盘块的编号 文件长度，指出以字节为单位的文件长度 文件连接计数，表明在本文件系统中所有指向该文件名的指针计数 文件存取时间，指出本文件最近被进程存取的时间，最近被修改的时间及索引结点最近被修改的时间 内存索引结点：存放在内存中的结点。当文件被打开时，要将磁盘索引结点拷贝到内存的索引结点中，便于以后使用，并增加以下内容 索引结点编号，用于标识内存索引结点 状态，指示i结点是否上所或被修改 访问计数，每当有一进程要访问此i结点时，将该访问计数加1，访问完再减1 文件所属文件系统的逻辑设备号 链接指针，设置有分别指向空闲链表和散列队列的指针 例：在某个文件系统中，每个盘块为 512 字节，文件控制块占 64 个字节，其中文件名占 8 个字节。如果索引结点编号占 2 个字节，对一个存放在磁盘上的 256 个目录项的目录，试比较引入索引结点前后，为找到其中一个文件的FCB，平均启动磁盘的次数。解：引入索引节点前，每个目录项中存放的是对应文件的 FCB，故 256 个目 录项的目录总共需要占用 256×64/512=32 个盘块。故在该目录中检索到一个 文件平均启动磁盘次数为 (1+32)/2=16.5。引入索引节点后，每个目录项中只需存放文件名和索引节点的编号，因 此 256 个目录项的目录总共需要占用 256×(8+2)/512=5 个盘块。因此，找到 匹配的目录项平均需要启动 3 次磁盘；而得到索引结点编号后还需启动磁盘将对应文件的索引结点读入内存，故平均需要启动磁盘 4 次。 目录的结构单级文件目录在整个系统中只建立一张目录表，每个文件占一个目录项，为表明每个目录项是否空闲，还设置有一个状态位。 每当建立一个新文件时，必须先检索所有的目录项，以保证新文件名在目录中是唯一的，然后再从目录表中找出一个空白目录项，填入新文件，并置状态位为1。删除文件时，先从目录中找到该目录项，回收该文件所占用的存储空间，然后再清除该目录项。 优点：单级文件目录管理比较简单，易于实现按名存取。缺点：限制了用户对文件的命名（不允许重名）。文件平均检索时间长 (平均 N/2)。不便于实现文件共享，通常每个用户都有自己的名字空间，因此，应当允许不同用户使用不同的文件名来访问同一个文件。 两级文件目录为每个用户建立一个单独的用户文件目录（UFD）。系统中为所有用户建立一个主文件目录（MFD），每个用户目录文件都占有一个目录项。优点：两级文件目录提高了检索目录的速度。例如：如果有 n 个用户，每用户最 多 m 个文件，则最多检索 n+m 个目录项而非单级目录结构的 n×m 项。不同用户目录中可重名。不同用户可用不同文件名来访问系统中一共享文件。缺点对文件的共享不方便（用户隔离）。增加了系统开销，缺乏灵活性，无法反映真实世界复杂的文件结构形式。 树型结构目录树型结构目录只有一个根目录，而且除根目录外，其余每个目录或者文 件都有唯一的一个上级目录。每一级目录可以包含文件，也可以包含下一级目录。操作系统为每个目录建立一个目录文件，其内容就是该目录下包含的文件的 FCB 集合。优点：层次结构清晰，便于管理和保护。解决重名问题。查找速度加快，因为每个目录下的文件数目较少。缺点：查找一个文件，需要按路径名逐级访问中间节点，增加了磁盘访问次数。 路径名：在树形目录结构中，从根目录到任何数据文件，都只有一条唯一的通路。 这一系列目录名和最后达到的文件名自身依次地用“/”连接起来组成了该文件的路径名。多个文件可以同名，只要保证它们的路径名唯一即可。当前目录：为了提高文件检索速度，文件系统向用户提供了一个当前正在使用的目录，称为当前目录（工作目录）。当前目录一般存放在内存。绝对路径名：绝对路径名是从根目录开始到达所要查找文件的路径名，以“/”打头。/root/usr/m1/prog/f1.c相对路径名：相对路径名从当前目录（工作目录）的下级开始书写。例如：当前目录是/usr/m1，则有相对于当前目录的相对路径名：prog/f1.c. 当前目录：./prog/f1.c.. 上级目录：../ml/prog/f2.c创建目录：用户可以为自己建立用户文件目录（UFD），并创建子目录。创建一个新文件时，只需查看 UFD 及其子目录中有无与新建文件相同的文件名。若无，便可在 UFD 或其某个子目录中增加一个新目录项。删除目录：不删除非空目录。必须先删除所有文件，变成空目录后才能删除。 可删除非空目录。移动目录：文件或子目录移动后（剪切、复制），文件的路径名将随之改 变。链接操作：对于树型结构目录，每个文件或子目录只允许一个父目录。 但是可以通过链接操作让指定文件有多个父目录，从而方便共享。（网状 结构）目录查询：操作系统支持多种目录查找方式。 目录查询技术文件名 → 目录项（FCB）或索引结点 → 盘块号 → 驱动程序 → 启动磁盘 → 读数据文件至内存 目录查询方式：线性检索法(顺序检索法)、Hash方法 线性检索法顺序查找（线性查找）查找过程：从表的一端开始查找，顺序用各记录的关键字进行比较，若找 到与其值相等的元素，则查找成功；若直到最后一个记录仍未找到，则查 找失败。线性表可以是顺序存储结构或链式存储结构，可以是有序表或无序表。 二分查找（折半查找）线性表必须是顺序存储结构，并且是有序表。 Hash方法Hash 表（散列表）的查找采用计算寻址的方式进行查找，查找效率与比较次数无关或关系较小，所以查找的效率较高。 Hash 方法目录查询 构造 Hash 表：以文件名 k 为自变量，通过一个确定的函数关系 f 计算出Hash 函数值 f(k)，把这个值（Hash 地址）存储为一个线性表，称为散列表或哈希表。 查找 Hash 表：根据给定值 k（文件名），计算 Hash 函数值 f(k)，若系统 中存在文件名与 k 相等的记录，则必定存储在哈希表中 f(k) 的位置上。因此不需比较便可直接在哈希表中取得所查目录项。然后在目录项中得文件的物理地址。 文件共享文件共享：一个文件被多个用户或程序使用共享的方法：基于索引结点的共享方式、利用符号链实现文件共享 基于索引结点的共享方式 有向无循环图目录结构（带链接的树形目录）。它允许目录含有共享子目录和文件，但不构成环路同一个文件可以有多个路径名。有向无循环图目录结构不再是一颗树，而成为网状结构。在有向无循环图目录结构中，如果有用户要共享一个文件或子目录，必须把共享文件或子目录拷贝或链接到用户的目录中。存在的问题：新增内容不能被共享。 文件目录：由文件名和指向索引结点的指针组成索引结点(i结点)：存放除文件名以外的文件属性。包括文件的结构信息、物理块号、存取控制、管理信息等。 基于索引结点的共享方式：共享索引结点 在索引结点中增加链接计数 count，表示共享的用户数。删除文件时必须 count=0 方可。当 count&gt;1 时，文件主也不能删除文件，否则指针悬空。 当用户C创建一个文件时，他便是该文件的所有者，此时将count置1。当有用户B要共享此文件时，在用户B的目录中增加一目录项，并设置一指针指向该文件的索引结点，此时主文件仍然是C，count=2。如果用户C不再需要文件，它也不能删除该文件，若删除了该文件，也必然删除了该文件的索引结点，这样便会使B的指针悬空，而B则可能正在此文件上执行写操作，此时将因此半途而废，但如果C不删除，则C必须为B使用此文件而付账，直至B不再需要 要解决基于索引结点的共享方式可能发生的指针悬空问题，可以利用符号链接实现文件共享。 利用符号链接实现文件共享利用符号链接实现文件共享：允许一个文件或子目录有多个父目录，但其中仅有一个作为主父目录，其它的几个父目录都是通过符号链接方式与之相链接的(简称链接父目录)。为使链接父目录能共享文件，可以由系统创建一个LINK类型的新文件，并将之写入链接父目录中，该文件仅包含被链接/共享文件的路径名，当用户通过链接父目录访问共享文件时，此要求会被OS截获，OS根据新文件中的路径名去找到共享文件，然后对它进行读写。 符号链方式中，只有文件主才拥有指向其索引结点的指针，其它共享的 用户只有该文件的路径名，不拥有指向其索引结点的指针。 文件主可对原文件删除。其他用户试图通过符号链去访问一个已被删除的共享文件时，会因系统找不到该文件而使访问失败，于是将符号链删除，而不会发生指针悬空现象。 Windows 中的快捷方式就是符号链文件 优点：当文件主删除一个共享文件时，其它共享文件的用户不会留下一个悬空指针。利用符号链实现共享时，可以通过网络链接到分布在世界各地的计算机系统中的文件 缺点：基于索引结点的共享方式可以直接从索引节点得到文件的物理地址，而利用符号链实现文件共享则需要根据给定的文件路径名去查找目录，启动磁盘的频率较高，使访问文件的开销增加。符号链本身也是一个文件，虽然很简单，但也需要配索引结点，耗费磁盘空间。 文件保护影响文件安全性的主要因素 人为因素 系统因素 自然因素，随着时间的推移，存放在磁盘上的数据会逐渐消失 确保文件系统安全性的措施 存取控制机制 ——人为因素 系统容错技术 ——系统因素 后备系统 ——自然因素 访问控制技术：现代操作系统中，几乎都配置了对系统资源进行保护的机制，引入了保护域和访问权的感念。 访问权：一个进程能对某对象 (Object) 执行操作的权力称为访问权(Access Right)。每个访问权可以用一个有序对（对象名，权集）来表示。例如，某进程有对文件 F1 执行读和写操作的权力，这时可将该进程的访问 权表示成 (F1，[R/W])。 保护域：保护域是进程对一组对象的访问权的集合。进程仅在保护域内执行操作，保护域规定了进程所能访问的对象和能执行的操作。 进程与域之间的联系： 静态联系：进程和域之间一一对应，即一个进程只联系着一个域，这意味着，在进程的整个生命期中，其可用资源是固定的，这种域称为“静态域”，这将会使赋予进程的访问权超过实际需要。 动态联系：动态联系是指进程的可用资源集在进程的整个生命中是变化的。进程和域是一对多的关系，即一个进程可联系着多个域。可将进程的运行分为若干个阶段，其每个阶段联系着一个域，这样便可根据运行的实际需要，来规定在进程运行的每个阶段中所能访问的对象。 访问矩阵基本的访问矩阵访问矩阵：用以描述系统存取控制的矩阵。访问矩阵中的行代表同一域，列代表同一对象，矩阵中每一项由一组访问权组成。R 读 W 写 E 执行访问权 access(i,j) 定义了在域Di中执行的进程能对对象j施加的操作集。 访问权通常由资源的拥有者或管理者所决定。 具有域切换权的访问矩阵为了实现在进程和域之间的动态联系，应能够将进程从一个保护域切换到另一个保护域。为了能对进程进行控制，同样应将切换作为一种权利，仅当进程有切换权时，才能进行这种切换。切换权 switch∈access(i,j) 时，表示允许进程从域 i切换到域 j。 如下图，由于域D1和域D2所对应的项目中有一个S即Switch，故而允许在域D1中的进程切换到域D2中 访问矩阵的修改拷贝权拷贝权指进程在某个域中对某对象拥有的访问权可通过拷贝将访问权扩展到同一列（即同一对象）的其它域中。亦即，为进程在其它的域中也赋予同一对象的访问权。访问权access(i,j) 上加*者表示在域i运行的进程可以把对对象j的访问权复制到同一对象的任何域中。限制拷贝：拷贝后的访问权不带*号，不能再将其拷贝 所有权除了可以利用拷贝权把访问权进行有控制的扩散以外，系统还需要能增加或删除某些控制权，我们可以利用所有权实现这些操作。如果在访问权access(i,j)中包含所有权(o)，则在域Di上运行的进程，可以增加或删除其在j列上任何项中的访问权。换言之，进程可以增加或删除在任何其它域中运行的进程对对象j 的访问权。 控制权拷贝权和所有权都是用于改变矩阵内同一列的访问权。控制权则可用于改变矩阵内同一行 (域)中的访问权，即用于改变在某个域中运行进程对不同对象的访问权。如果在访问权access(i,j) 中包含了控制权 Control，则在域Di中运行的进程 可以删除在域Dj中运行进程对各对象的任何访问权。 访问矩阵的实现 在较大的系统中，访问矩阵将变得非常巨大，而且矩阵中的许多格可能 都为空（稀疏矩阵），造成很大的存储空间浪费，因此在实际应用中访问 控制很少利用访问矩阵的方式实现。目前使用的访问控制实现技术不是保存整个访问矩阵，而是基于访问矩阵的列或者行来保存信息，分别形成访问控制表和访问权限表。 访问控制表(Access Control List)把访问矩阵按列（对象）划分，为每一列建立一张访问控制表ACL。在该表中，已把矩阵中属于该列的所有空项删除，此时的访问控制表是由一有序对（域，权集）所组成的当对象为文件时，常把访问控制表 ACL 存放于该文件的 FCB 或索引结点中，作为存取控制信息。 域是一个抽象的概念，可用各种方式实现。最常见的一种情况是每一个用户就是一个域，而对象则是文件。此时，用户能够访问的文件集和访问权限取决于用户的身份。另一种情况是每个进程是一个域，此时，能够访问的对象集中的各访问权取决于进程的身份。 访问权限表(Capabilities List)把访问矩阵按行（域）划分，每行形成一张访问权限表。表中的每一项为该域对某对象的访问权限。访问权限表不允许直接被用户 (进程) 所访问。访问权限表被存储到专用系统区内，只允许专用于进行访问合法性检查的程序访问，以实现对访问权限表的保护。大多数系统都同时采用访问控制表和访问权限表。系统中为每个对象配置一张访问控制表。当一个进程第一次试图去访问一个对象时，必须先检查访问控制表，检查进程是否具有对该对象的访问权。若有权访问，根据访问权限表为该进程建立一个访问权限，以后该进程便可直接利用这一返回的权限去访问该对象。利用访问控制表和访问权限表可以快速地验证访问的合法性。当进程不再需要对该对象进行访问时，便可撤消该访问权限。","link":"/2022/01/02/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%8611%E2%80%94%E2%80%94%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"title":"操作系统笔记整理1——操作系统引论","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 操作系统的作用 作为用户与计算机硬件系统之间的接口 作为计算机系统资源的管理者 实现了对计算机资源的抽象 单道批处理系统作业逐个送入内存运行特征：自动型、顺序性、单道性优点：减少了人工操作的时间，缓解了一定程度的人机速度矛盾，资源利用率有所提升。缺点：内存中仅能有一道程序运行，只有该程序运行结束之后才能调入下一道程序，CPU有大量的时间是在空闲等待I/O完成。资源利用率依然很低。 多道批处理系统解决单道批处理系统中内存仅存放一道作业，导致资源利用率和吞吐量低下的问题多个作业先在外存“后备队列”中排队，经作业调度选择若干个调入内存，使它们共享CPU和系统中的各种资源。特征：调度性、无序性、多道性优点：资源的利用率高、系统吞吐量大缺点：平均周转周期长、无交互能力 例题：A、B 两个程序，程序 A 按顺序使用 CPU 10s，设备甲 5s，CPU 5s， 设备乙 10s，CPU 10s，程序 B按顺序使用设备甲 10s，CPU 10s，设备乙 5s，CPU 5s，设备乙 10s。问：1、在顺序环境下执行程序 A 和 B，CPU利用率多少？ 2、在多道环境下呢？答：1、A 和 B 顺序执行时，A 执行完毕 B 才开始，总共耗时 80s，占用 CPU40s，故利用率为 40/80=50%。2、多道时，两程序共耗时 45s, 占用 CPU 40s, 故利用率 40/45=88.89%。 批处理操作系统的特征： 脱机：是指用户脱机使用计算机，即用户提交作业之后直到获得结果之前几乎不再和计算机打交道。 多道：是指多道程序运行，即按多道程序设计的调度原则，从一批后备作业中选取多道作业调入内存并组织它们运行； 成批处理：是指操作员把用户提交的作业组织成一批，由操作系统负责每批作业间的自动调度。 分时操作系统的特征： 多路性：系统按分时原则为多个终端用户提供服务，允许多个用户共享一台计算机。 独立性：每个用户在各自的终端上进行操作，彼此之间互不干扰 及时性：用户的请求能在很短的时间内获得相应 交互性：用户可以通过终端与系统进行广泛的人机对话 实时操作系统的特征： 多路性：系统周期性地对多路现场信息进行采集，以及对多个对象或多个执行机构进行控制 独立性：对信息的采集和对对象的控制彼此互不干扰 及时性：是指系统能及时响应外部事件的请求，并在规定时间内完成对该事件的处理 交互性：仅限于用户发送某些特定的命令，如开始、停止、快进等，由系统立即响应。 可靠性：是指系统本身要安全可靠，因为像生产过程的实时控制、航空订票等实时事务系统，信息处理的延误或丢失往往会带来不堪设想的后果。 操作系统的特征 并发性（最重要特征）： 在一段时间内同时存在多道运行的程序（进程） 宏观上：多道程序同时执行 微观上：在单处理机系统中，任何时刻只有一道程序在执行，即微观上多道程序在CPU上交替执行。并行：多道程序在同一时刻执行 共享性：指系统中的资源不再为某道程序所独占，而是供多道程序共同使用。 并发性和共享性是操作系统的两个最基本的特征 虚拟性：指把一个物理实体映射为若干个对应的逻辑实体。 时分复用：即分时使用方式。如：虚拟处理机、虚拟设备。 空分复用：用于提高存储空间的利用率。如：虚拟磁盘、虚拟存储器。 异步性：异步性也称不确定性，指进程在执行中，其执行时间、顺序、向前推进的速度和时间等都是不可预知的。 操作系统的功能 处理机管理 进程控制：状态转换 进程同步：协调运行进程 进程通信：合作进程信息交换 调度 ：作业调度+进程调度 存储器管理 内存分配：为每道程序分配内存空间内存保护：确保用户程序在自己的内存空间运行，互不干扰，不允许其访问操作系统的程序和数据，也不允许其转移到非共享的其他用户程序中执行地址映射：逻辑地址-&gt;物理地址内存扩充：虚拟存储技术 设备管理 缓冲管理：单缓冲、双缓冲、缓冲池设备分配：根据用户请求和系统现有资源分配其所需设备设备处理：设备处理程序又称为设备驱动程序，实现CPU和设备控制器之间的通信虚拟设备 文件管理 文件存储空间的管理目录管理文件的读/写管理和保护 用户接口 用户接口：联机用户接口、脱机用户接口、图形用户接口程序接口：为用户程序访问系统资源而设置的，是其获得操作系统服务的唯一途径 微内核操作系统当前比较流行的操作系统几乎全部采用微内核结构 为了提高灵活性和可扩充性，OS分为：微内核、用于提供各种服务的一组服务器 微内核：能实现现代OS核心功能的小型内核，运行在核心态下，开机后常驻内存，不会因内存紧张而换出。 1.实现与硬件紧密相关的处理 2.实现一些较基本的功能（如地址变换） 3.负责客户和服务器之间的通信 微内核OS技术的主要思想：在内核中留下一些最基本的功能，而将其他服务分离出去，由工作在用户态下的进程来实现，形成所谓“客户/服务器”模式。客户进程可通过内核向服务器进程发送请求，以取得OS的服务。 微内核的结构 足够小的内核微内核并非是一个完整的OS，而只是将OS中最基本的部分放入微内核，通常包含有：①.与硬件处理紧密相关的部分；②.一些较基本的功能；③.客户和服务器之间的通信 基于客户/服务器模式将操作系统中最基本的部分放入内核中，而把操作系统的绝大部分功能都放在内核外面的一组服务器（进程）中实现，如用于提供对进程(线程)进行管理的服务器等，它们都是被作为进程来实现的，运行在用户态。客户和服务器之间是借助微内核提供的消息传递机制来实现信息交互的 应用“机制与策略分离”原理机制：指实现某一功能的具体执行机构策略：在机制的基础上，借助于某些参数和算法来实现该功能的方法。简单理解：软件是策略，硬件是机制。命令是策略，实施是机制微内核操作系统：只把机制放在OS的微内核中，把策略从内核中分离出去，可以把内核做得很小。 采用面向对象技术 微内核的基本功能 进程(线程)管理采用“机制与策略分离”的原理。例如：为实现进程调度，须在内存中设置一个或多个进程优先级队列，将制定进程从队列中调出，并投入执行。这一部分属于调度功能的机制部分，将其放入微内核中。而对于进程如何分类，以及优先级的确认方式或原则，都属于策略问题。放入微内核外的进程管理服务器中 低级存储器管理在微内核中，通常只配置最基本的低级存储器管理机制，如用于实现逻辑地址到物理地址的变换的页表机制和地址变换机制，这一部分依赖于硬件，放入微内核。而实现虚拟存储器管理的策略，则包含页面置换算法以及内存分配与回收策略的选择等，这部分应放在微内核外的存储器管理服务器中去实现。 中断和陷入处理大多数微内核操作系统都是将与硬件紧密相关的一小部分放入微内核中处理，此时微内核的主要功能就是捕获所发生的中断和陷入事件，并进行相应的前期处理，如现场保护，识别中断类型，将有关信息转化成消息后，再把它发送给相关服务器，由服务器进行后期处理 处理机状态：处理机至少需要两种独立的操作模式：核心态和用户态核心态：又称系统态或管态，是操作系统运行时所处的状态。处理机处于核心态时可以执行硬件所提供的全部指令，包括特权指令和非特权指令。用户态：又称为目态，是一般用户程序运行时所处的状态。处理机处于用户态时只能执行非特权指令。用户态下程序不能将其运行状态改为核心态，这样就可以防止用户有意或无意的侵入系统，从而起到系统保护的作用。 微内核操作系统的优缺点优点： 提高了系统的可扩展性 增强了系统的可靠性 可移植性强 提供了对分布式系统的支持 融入了面向对象技术 缺点： 运行效率有所降低，在完成一次客户对操作系统提出的服务请求时，需要进行四次上下文切换：1.客户发送消息给内核；2.内核把消息发给服务器；3.服务器把相应消息发给内核；4.内核将响应消息发给客户；这在早期的OS中，一般只需要两次切换：1.执行系统调用后由用户态转向系统态；2.在系统完成用户请求的服务后，由系统态返回用户态。","link":"/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%861%E2%80%94%E2%80%94%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%BC%95%E8%AE%BA/"},{"title":"操作系统笔记整理3——进程的描述与控制（2）","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 线程的概念基本属性：资源的拥有者，独立调度单位引入线程的目的：减少并发执行时的时空开销。因为进程的创建、撤销、切换交费时间。 线程是系统独立调度和分派的基本单位，基本上不拥有系统资源，只需要少量的资源（指令指针IP，寄存器，栈（地址、实参、局部变量，每个线程都有自己的stack）），但可以共享其所属进程所拥有的全部资源。 进程与线程的比较1.调度单位 引入线程后，线程是处理机调度的基本单位，进程是资源分配的基本单位，而不再是一个可执行的实体。 在同一进程中线程的切换不会引起进程的切换，但从一个进程中的线程切换到另一个进程中的线程时，将会引起进程的切换。 2.并发性 引入线程后，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间也可以并发执行 多个线程会争夺处理机，在不同的状态之间转换。线程也是一个动态的概念，也有一个从创建到消亡的生命过程，具有动态性。3.资源分配 进程是资源分配的单位，一般线程自己不拥有系统资源，但可以访问其隶属进程的资源， 同一进程中的所有线程都具有相同的地址空间（进程的地址空间）4.独立性 同进程的不同线程间的独立性要比不同进程间的独立性低得多 多个线程共享进程的内存地址空间和资源5.系统开销 线程开销小6.支持多处理机系统 同进程的不同线程可分配到多个处理机上执行，加快了进程的完成。 线程的运行状态执行：线程正获得处理机而运行就绪：具备了除CPU外的所有资源阻塞：线程处于暂停执行时的状态 线程有挂起状态吗？挂起是进程级的概念，一个进程被挂起，它的所有线程也必被挂起，一个进程被激活，它的所有线程也都被激活。 线程控制块TCB:标志线程存在的数据结构，其中包含对线程管理所需要的全部信息 多线程中的进程拥有系统资源的基本单位可包括多个线程不再是一个可执行的实体。所谓进程处于执行状态，实际上是指该进程中的某线程正在执行。 线程的实现对于通常的进程，都是利用系统调用而进入OS内核不论是系统进程还是用户进程，不论是进程还是线程，都必须直接或间接得到OS内核的支持 系统调用是内核提供的一组函数，是应用程序和操作系统内核之间的功能接口 内核支持线程KST内核支持线程由操作系统直接支持，在内核空间中执行线程的创建、调度和管理优点：当有多个处理机时，一个进程的多个线程可以同时执行。实现：直接利用系统调用进行线程控制 用户级线程ULT用户级线程指不需要内核支持而在用户空间中实现的线程内核并不知道用户级的线程对于用户级线程其调度仍是以进程为单位优点：同一进程内的线程切换不需要转换到内核空间，控制简单，调度算法是进程专用的，与操作平台无关。缺点：当线程执行一个系统调用时，不仅该线程被阻塞，进程内的其他线程也会被阻塞。实现：不能直接利用系统调用（导致进程中的全部线程阻塞），为了取得内核服务，需借助中间系统 运行时系统:运行时系统是用于管理和控制线程的函数（过程）的集合，其中包括用于 创建和撤消线程的函数、线程同步和通信的函数以及实现线程调度的函数 等。运行时系统使用户级线程与内核无关运行时系统中的所有函数都驻留在用户空间，并作为用户级线程与内核之 间的接口。当线程需要系统资源时，将该要求传送给运行时系统，由后者通过相应的 系统调用 来获得系统资源 进程同步与互斥直接制约关系（进程同步）：协调各进程间的工作而相互等待、相互交换信息而产生的制约关系间接制约关系（进程互斥）：进程共享独占型资源而必须互斥执行的间接制约关系 同步与互斥的比较 临界资源：一次只允许一个进程使用的资源，如打印机、绘图机、变量、数据等，进程之间采取互斥方式实现对临界资源的共享，访问临界资源的那一段代码称为临界区。临界区：进入区：检查欲访问的临界资源此刻是否被访问临界区：进程访问临界资源的那段代码退出区：将临界资源的访问标志恢复为未被访问剩余区：其余代码同步机制应遵循的规则1.空闲让进：临界资源空闲，允许进入2.忙则等待：临界资源正被访问，其它试图进入临界区的资源必须等待3.有限等待：对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区，以免陷入死等状态（循环请求）4.让权等待：当进程不能进入临界区时，应立即释放处理机，以免进程陷入 忙等 没有进入临界区的正在等待的某进程根本无法获得临界资源而进入进程，这种等待是无结果的，是死等状态没有进入临界区的正在等待的某进程不断的在测试循环代码段中的变量的值，占着处理机而不释放，这是一种忙等状态。例如：while S≤0 do no−opS: = S−1;只要 S≤0，wait 操作就不断地测试（忙等），因而未做到“让权等待” 信号量机制 信号量是用于表示资源数目或请求使用某一资源的进程个数的整型量。信号量只能通过初始化和两个标准的原语（P，V 操作）来访问。信号量机制也称为P、V操作，P 操作也称为 wait 操作，V 操作也称为 signal 操作。 整型信号量：用于表示资源数目的非负整数记录型信号量：引入阻塞队列，信号量可以取负值组成：整型变量value:代表资源数量；链表指针L:用于连接所有等待的进程执行一次P(s)操作：进程请求一个单位的资源，s&lt;0表明资源已分配完，若有请求则阻塞，绝对值表示因申请该资源而被阻塞的进程的数目执行一次V(s)操作：进程释放一个单位的资源，s&lt;0表明由进程被阻塞，需要唤醒AND型信号量：一次性分配（释放）所有临界资源P原语 Swait(S1,S2,…,Sn)；V原语 Ssignal(S1,S2,…,Sn)信号量集：对需要多种资源、每种占用的数目不同、且可分配资源还存在一个临界值时的信号量处理。进程对信号量Si的测试值为ti（信号量的判断条件，当资源数小于ti时，不予分配），占用值为di（资源的申请量，即Si=Si-di和Si=si+di）P原语 Swait(S1,t1,d1;…;Sn,tn,dn);V原语 Ssignal(S1,d1;…;Sn,dn); 释放时不必考虑tiSwait(S，1，0)：可作为一个可控开关(S≥1 时，允许多个进程进入某特定 区；S=0 时禁止任何进程进入)。 例题设系统有 n（n&gt;2）个进程，且当前不在执行进程调度程序，试考虑下述4种情况，不可能发生的是（A）。A、没有运行进程，有 2 个就绪进程，n-2 个进程阻塞B、有 1 个运行进程，没有就绪进程，n-1 个进程阻塞C、有 1 个运行进程，有 1 个就绪进程，n-2 个进程阻塞D、有 1 个运行进程，n-1 个就绪进程，没有进程阻塞解析：没有运行进程且就绪队列非空，处理机不应空闲，而应该调度一个进程来运行，因此A错误 对于两个并发进程，设互斥信号量为 mutex。当 mutex=0 时，则（B）。A、表示没有进程进入临界区B、表示有一个进程进入临界区C、表示有一个进程进入临界区，另一个进程等待进入D、表示有两个进程进入临界区解析：A:mutex=1 B:mutex=0 C:mutex=-1 D: 错误 wait、signal操作小结 wait、signal 操作必须成对出现，有一个 wait 操作就一定有一个 signal操作。 当为互斥操作时，它们同处于同一进程。 当为同步操作时，则不在同一进程中出现。 如果两个 wait 操作相邻，那么它们的顺序至关重要，而两个相邻的signal 操作的顺序无关紧要。 一个同步 wait 操作与一个互斥 wait 操作在一起时，同步 wait 操作在互 斥 wait 操作前。 优点：简单，而且表达能力强（用 wait、signal 操作可解决任何同步互 斥问题）。 缺点：不够安全，P、V 操作使用不当会出现死锁。 经典进程同步问题 生产者-消费者问题 “哲学家进餐”问题 读者-写者问题 管程机制基本思想：把访问某种临界资源的所有进程的同步操作都集中起来，构成一个所谓的“秘书”进程（管程），凡是访问临界资源的进程，都需要报告“秘书”，由秘书来实现诸进程的同步管程的定义：一个数据结构和在该数据结构上能被并发进程所执行的一组操作，这组操作能使进程同步和改变管程中的数据。 进程通信进程通信：进程间的信息交换低级通信：信号量机制，效率低，对用户不透明高级通信：效率高，对用户透明高级通信机制：共享存储器系统、消息传递系统（直接通信方式：消息缓冲通信；间接通信方式：又称为信箱通信方式）、管道通信系统、客户机-服务器系统 套接字：套接字（Socket）是对网络中进程之间进行双向通信的端点的抽象。一个套接字就是网络中进程通信的一端。套接字是一个通信标识类型的数据结构，包含许多选项，由操作系统内核管理。","link":"/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%863%E2%80%94%E2%80%94%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%8E%A7%E5%88%B6%EF%BC%882%EF%BC%89/"},{"title":"操作系统笔记整理12——磁盘存储器的管理","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 外存的组织方式外存的组织方式有 连续组织方式：为每个文件分配一片连续的磁盘空间，由此所形成的文件物理结构将是顺序式的文件结构 链接组织方式：可以为每个文件分配不连续的磁盘空间，通过链接指针将一个文件的所有盘块链接在一起，由此所形成的是链接式的文件结构 索引组织方式：索引式文件结构 连续组织方式为每一个文件分配一片连续的磁盘块。例如，第一个盘块的地址为b，则第二个盘块的地址为b+1，第三个盘块的地址为b+2。通常它们都位于一条磁道上，在进行读/写时不必移动磁头，仅当访问到磁道的最后一个盘块后才需要移到下一条磁道。这样所形成的文件结构称为顺序文件结构，此时的物理文件称为顺序文件。文件目录项中只需要保存文件的起始块号和长度（连续的块数）。连续组织方式会形成外部碎片。可以通过紧凑 (compact) 技术把外存空闲空间合并成连续的区域。但对外存空间的一次紧凑所花费的时间远比内存紧凑一次的时间多。 优点： 顺序访问容易 访问速度快，磁头移动距离少（换磁道时才移动）。 保证了逻辑文件中的记录顺序与存储器中文件占用盘块的顺序的一致性。 从逻辑地址映射到物理地址较简单。 缺点： 要求有连续的存储空间。 存在外部碎片 必须事先知道文件的长度。有时需要估计（预留空间问题）。 不能灵活地插入删除 链接组织方式将文件装到多个离散的盘块中，通过每个盘块上的链接指针，将同属于一个文件的多个盘块链接成一个链表，由此所形成的的物理文件称为链接文件。 链接分配分为隐式链接和显式链接两种。 隐式链接采用隐式链接分配方式时，在文件目录的每个目录项中，保存指向链接文件第一个盘块和最后一个盘块的指针。缺点： 只适合于顺序访问，对随机访问极其低效。如果要访问文件所在的第 i 个盘块，则必须先读出文件的第一个盘块，· · · ，顺序地查找直至第 i 块（访问第 i 盘块，需要启动 i 次磁盘）。 可靠性差，任何一个指针出现问题，都会导致整个链的断开。 指针占存储空间。如果指针占用 4 个字节，对于盘块大小为 512 字节的磁盘，则每个盘块中只有 508 个字节可供用户使用。 显示链接把用于链接的指针显式地存放在内存的一张表中，查找在内存中进行。 文件分配表 FAT (File Allocation Table) 文件分配表在整个逻辑磁盘分区仅设置一张。 表序号为整个磁盘的物理块号。 表项中存放链接指针，即下一个块号。 文件的首块号存入相应文件的 FCB 中。 特点：FAT 表在内存中，查找记录的过程是在内存中进行的，不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。缺点： FAT表需占用较大的内存空间 FAT(File Allocation Table)技术在FAT中引入了“卷”的概念，支持将一个物理磁盘分成四个逻辑磁盘，每个逻辑磁盘就是一个卷(也称为分区)，每个卷都是一个能被单独格式化和使用的逻辑单元，供文件系统分配空间时使用。 一个卷中包含了文件系统信息，一组文件以及空闲空间。每个卷都有专门区域存放自己的目录和FAT表，以及自己的逻辑驱动器字母。(通常对仅有一个硬盘的计算机，最多将其硬盘划分为”C:”、”D:”、”E:”、”F:”四个卷)。在现代OS中，一个物理磁盘可以划分成多个卷，一个卷也可以由多个物理磁盘组成。 FAT 文件系统共三个版本：FAT12，FAT16 和 FAT32。 簇的概念 若干个连续的扇区 (sector) 或盘块称为一簇，簇的大小一般是 2^n^ 个扇区或盘块。比如，一个簇可包含4个盘块，在进行盘块分配时，是以簇为单位进行的。在链接文件中的每个元素也是以簇为单位的。FAT文件系统把簇作为一个虚拟扇区。文件的存储空间通常由多个簇组成。 如何选择簇的大小两个极端：大到能容纳整个文件，小到一个扇区。如果簇较大：可提高 I/O 访问性能，减少访问时间，但簇内碎片浪费问题 较严重。如果簇较小：簇内的碎片浪费较小，但可能存在簇编号空间不够的问题（如 FAT12、16）。 FAT12文件系统每个 FAT 表的表项数占 12 位，即 FAT 表最多允许4096(2^12^)个表项。如果采用盘块作为基本分配单位，每个盘块（扇区）的大小一般是 512 字节，则每个磁盘分区的容量为 2MB（4096×512 B）。一个物理磁盘最多支持 4 个逻辑磁盘分区，所以可管理的磁盘最大容量为 8MB。如果采用簇（cluster）作为基本分配单位，当一个簇包含 8 个扇区时， 磁盘容量可以达到 64MB。 磁盘分区容量与簇大小的关系 如果磁盘分区容量增加，而簇的总数保持不变即簇编号所需位数保持不变，则簇就变大。缺点是簇内碎片浪费增加。 如果磁盘分区容量增加，而簇的大小不变，则簇的总数就会增加，相应地簇的编号所需要的位数增加。 以簇作为基本分配单位的优点： 可以管理较大容量磁盘。 在相同的磁盘容量条件下，可以减少 FAT 表的表项数，使 FAT 表占用更少的存储空间，减少了访问 FAT 表的存取开销，提高了文件系统的效率。 FAT16文件系统每个 FAT 表的表项数占 16 位，即 FAT 表最多允许65536(2^16^)个表项。一个磁盘分区可以管理 65536 个簇。在 FAT16 的每个簇中可以有的盘块数为 4、8、16、32、64。如果每个簇中最大的盘块或扇区数为 64，FAT16可以管理的最大分区空间为 65536× 64×512 = 2048 MB。（不引入簇为 32MB） 优点：可以管理更大的容量磁盘。缺点：当磁盘容量迅速增加时，FAT16 文件系统簇内碎片所造成的浪费 比较严重。 FAT32文件系统每个 FAT 表的表项数占 32 位，即 FAT 表最多允许 2^32^=4,294,967,296 个表项。FAT32 可以管理更多的簇，这样就允许采用较小的簇（较少簇内碎片），通常FAT32 的每个簇都固定为 4 KB（如果盘块大小为 512B，则每簇包括 8 个扇区）。 缺点 FAT表很大，运行速度慢 有最小管理空间的限制，FAT32卷至少要有65537个簇，不支持容量小于512MB的分区 NTFS(New Technology File System)文件系统NTFS是目前的主流文件系统 NTFS 具有很多新特征： NTFS 文件系统使用了 64 位磁盘地址，理论上可以支持 2^64^ 字节的磁盘分区（实际支持最大分区容量为 2TB）。 支持长文件名，单个文件名限制在 255 个字符以内，全路径名为 32767 个 字符。 具有系统容错功能。 提供了数据的一致性功能（日志文件和检查点）。 提供了文件加密、文件压缩等功能。 磁盘的组织NTFS 也是以簇作为磁盘空间分配和回收的基本单位。一个文件占用若 干个簇，一个簇只属于一个文件。 NTFS 通过簇来间接管理磁盘，不需要知道盘块的大小，使 NTFS 具有了与磁盘物理盘块大小无关的独立性，很容易支持盘块大小不是 512 字节的非标准磁盘。 在 NTFS 文件系统中，把卷上簇的大小称为“卷因子”，一个簇包含 2^n^(n为整数) 个盘块。 簇的大小可由格式化命令按磁盘容量和应用需求来确定，可以为 512B、1KB、…，最大可达64KB。为了在传输效率和簇内碎片之间进行折中，NTFS 在大多数情况下簇的大小 4KB。 NTFS 使用逻辑簇号（LCN）和虚拟簇号（VCN）来进行簇的定位。 LCN是以卷为单位，把整个卷中所有的簇从头到尾进行简单的编号。NTFS 在进行地址映射时，可以通过卷因子与 LCN 的乘积，便可算出卷上的物理字节偏移量，从而得到文件数据所在的物理磁盘地址。 VCN是以文件为单位，把某个文件的簇按顺序编号。只要知道了文件开始的簇地址，就可以把 VCN 映射到 LCN。 文件的组织在 NTFS 中，以卷为单位，把一个卷中的所有文件信息都以文件记录的方式记录在一张主控文件表 MFT (Master File Table) 中。 MFT 为每一个文件保存着一组称为“属性”的记录，在 MFT 中占有一行。每行大小固定为 1 KB，每行称为所对应文件的元数据 (metadata)，也称为文件控制字。 当文件较小时，可以把文件的所有属性直接记录在元数据中。当文件较大时，元数据仅记录该文件的一部分属性，文件的 data 属性（文件内容）等记录到卷中的其它簇中，并将这些簇按其所记录文件的属性进行分类，分别链接成多个队列，并将指向这些队列的指针保存在元数据中。 索引组织方式 链接分配方式解决了连续分配方式存在的问题（要求连续空间、外部碎 片等），但又出现了另外两个问题：不能支持高效的直接存取。隐式链接分配方式查找某一个块必须从第一块开始沿指针进行。显式链接分配方式要对一个较大的文件进行直接存取， 必须首先在 FAT 中顺序地查找许多盘块号。FAT 需占用较大的内存空间。由于一个文件所占用盘块的盘块号是随机地分布在 FAT 表中的，因而只有将整个 FAT 表调入内存，才能保证在 FAT 表中找到一个文件的所有盘块号。当磁盘容量较大时，FAT 表可能要占用数兆字节的内存空间，这是令人难以接受的。 事实上在打开某个文件时，只需把该文件占用的盘块编号调入内存即可， 没有必要把整个 FAT 表调入内存。 改进：把每个文件所对应的盘块号集中地放在一起，在访问到某个文件时，将该文件所对应的盘块号一起调入内存。 索引分配：为每一个文件分配一个索引块（表），再把分配给该文件的所有块号，都记录在该索引块中。索引块就是一个含有许多块号地址的数组。 单级索引分配单级索引分配为每个文件分配一个索引块 (表)，把分配给该文件的所有盘块号都记录在该索引块中。在建立一个文件时，只需在该文件的目录项中填上指向索引块的指针 多级索引分配多级索引分配为这些索引块再建立一级索引，即系统再分配一个（目录）索引块，作为第一级索引的索引块（两级索引）。 如果每个盘块的大小为 1 KB，每个盘块号占 4 个字节，则在一个索引块 中可存放 256 个盘块号。在两级索引时，最多可存放的盘块号总数 N = 256×256 = 64 K 个，即所允许的文件最大长度为 64 MB。如果每个盘块的大小为 4 KB，每个盘块号占 4 个字节，单级索引时所允 许的文件最大长度为 1024×4 KB =4MB如果采用两级级索引时最大文件长度为 1024×1024×4 KB =4GB 优点：大大加快了对文件的查找速度缺点：启动磁盘的次数随着索引级数的增加而增多 增量式索引组织方式在采用混合索引分配方式的文件系统中，索引结点中设置了 13 个地址项，前10 个是直接地址项，后 3 个是间接地址项。 直接地址：在索引结点中设置 10 个直接地址项，用来存放直接地址。假如每个 盘块的大小为 4KB，当文件不大于 40KB 时，便可直接从索引结点中读出该文件的全部盘块号。 一次间接地址：利用索引结点中的一次间接地址项来提供一次间址。一次间址块中可存放 1K 个盘块号，允许文件长达 4MB。事实上就是一级索引分配方式多次间接地址：利用二次间接地址项提供二次间接地址。在采用二次间址方式 时，文件最大长度可达 4GB。同理在采用三次间地方式时，所允许的文件最大长度可达 4TB。实质上就是二级索引分配方式。 文件存储空间的管理 文件存储空间的管理可采用连续分配和离散分配方式。内存分配基本不采用连续分配方式。外存管理中，小文件经常采用连续分配方式，大文件采用离散分配方式。 存储空间的常用管理方法 空闲表法和空闲链法 位示图法 成组链接法 空闲表法和空闲链法空闲表法空闲表也叫空闲文件目录，是将文件存储器上一个个连续的未分配区域（称作空闲文件）按第一个空闲块号，连续空闲的块数，具体的位置信息（物理块号）等信息记在空闲表中。这种方法适合于建立连续文件，适合少量的空闲区。如果存取空间中有着大量的小的空白区，则空闲表变得很大，因而效率大为降低。当请求分配存储空间时，系统依次扫描空闲文件目录的表目，直到找到一个合适的空闲文件为止（首次适应算法），分配给用户进程，修改空闲表。 当用户撤消一个文件时，系统回收该文件所占用的空间。扫描空闲表目录，寻找一个空表目，并将释放空间的第一个物理块号及它所占的物理 块数填到这个表目中。考虑回收区是否与空闲表中插入点的前区和后区相邻接，对相邻接者应予以合并。 空闲链法空闲盘块链：把所有“空闲块”（即未分配使用的物理块，也称“自由块”）链接起来。当创建一个文件需要存储块时，就从链头上依次取下若干块来，而撤销文件时则将回收空间又依次链接到链尾上。 空闲盘区链：把磁盘上的所有空闲盘区（每个盘区可包含若干个盘块） 拉成一条链。在每个盘区上除含有用于指示下一个空闲盘区的指针外， 还有指明本盘区大小（盘块数）的信息。 优点：分配和回收的过程非常简单。缺点：为一个文件分配盘块时，可能要多次重复操作。 位示图法位示图（二维）：利用二进制的一位（bit）来表示磁盘中一个盘块的使用情况。 每个字节的每一位都对应了一个物理块的状态。当该位取 1 时，表示对应的物理块已分配；取 0 时表示该物理块未分配。 特点：占空间少，可放入内存，易于访问。 盘块的分配： 顺序扫描，找一个或一组值为 0 的块。 把找到的二进制位转换成与之相应的盘块号。假定找到的“0”的二进制位在, 第 i 行、第 j 列， 每行位数为 n，则相应的盘块号：b=n(i-1)+j。(根据实际题目的起始编号计算) 修改位示图：map[i,j]=1。 盘块的回收： 由盘块号 b 得行列号 (i,j)i = (b-1) div n +1j = (b-1) mod n +1div 取整 mod 取余 修改位示图：map[i,j]=0 成组链接法成组链接法是结合了空闲表和空闲链优点的一种空闲盘块管理方法，并克服了空闲表过大或空闲链过长的缺点。 空闲盘块号栈：存放一组空闲盘块的盘块号（最多 100 个），以及栈中尚有的空闲盘块号数 N（兼作栈顶指针，当N=100时，它指向S.free(99)）。s.free(0) 是栈底，栈满时的栈顶为S.free(99)。 所有空闲盘块被分成若干组（每组 100 个）。 把每组的盘块数 N 和该组所有的盘块号记入其前一组盘块的第一个盘块。 把第一组的盘块数和所有盘块号记入空闲盘块号栈中，作为当前可供分配的空闲盘块号。 最末一组只有99个可用盘块，其盘块号分别记入前一组的S.free(1)~S.free(99)中，而在S.free(0)中则存放“0”作为空闲盘块链的结束标志。(注:最后一组的盘块数仍为100，但实际可供使用的空闲盘块数却是99，对应的编号为(1~99),0号盘中放空闲盘块链的结束标志，而不再是空闲盘块号) 空闲盘块的分配与回收分配：从栈顶取出一空闲盘块号，将与之对应的盘块分配给用户，然后 将栈顶指针下移一格。到s.free(0)时，所分配的磁盘块号是栈中最后一个可用盘块号，由于该块内容为下一组的所有盘块号，因此要先将该块的内容读入栈中，然后才能将该块分配出去。回收：将回收盘块的盘块号压入空闲盘块号栈的顶部，并执行空闲盘块数 N加1 操作。到栈满时，将现有栈中的 100 个盘块弹出栈，组成新的一组空闲盘块组。它们的盘块号被记入新回收的盘块中，再将其盘块号作为新栈底（记录了前一组的 100 个盘块号）。 提高磁盘I/O速度的途径 提高文件的访问速度可从三方面着手：1 改进文件的目录结构以及检索目录的方法以减少对目录的查找时间。2 选用好的文件存储结构3 提高磁盘 I/O 速度 设置磁盘高速缓存（Disk Cache） 其它方法（提前读、延迟写、虚拟盘） 采用高度可靠、快速的磁盘系统：独立磁盘冗余阵列（RAID） 磁盘高速缓存磁盘高速缓存是指内存中的一部分存储空间，用来暂存从磁盘读出的一系列盘块中的信息，所以它是一组在逻辑上属于磁盘，而物理上是驻留在内存中的盘块。当出现一个访问磁盘的请求时，由核心先去查看磁盘高速缓冲器，若请求的盘块内容已在缓存中，便可从高速缓存中直接读取，省去了启动磁盘的时间，如果不在，才需要启动磁盘将所需要的盘块内容读入，并把盘块内容送给磁盘高速缓存。 数据交付方式数据交付是指将磁盘高速缓存中的数据传送给请求者进程。 步骤：请求访问磁盘时先查缓存、后查磁盘并更新缓存。 系统采取两种方式把数据交付给请求进程：数据交付：系统直接将磁盘高速缓存中的数据传送到请求者进程的内存工 作区。指针交付：只将指向磁盘高速缓存中该数据的指针，交付给请求者进程。后一种方式由于所传送的数据量少，节省了数据从磁盘高速缓存到进程的内存工作区的时间。 置换算法在将磁盘中的盘块读入到磁盘高速缓存中时，若因磁盘高速缓存已满，则采用常用的算法进行置换：最近最久未使用算法 LRU最近未使用算法 NRU最少使用算法 LFU 请求调页与磁盘 I/O 中的工作情况不同，在置换算法中所应考虑的问题 也有所差异。磁盘高速缓存置换时除上述算法外还应考虑的问题：访问频率：请求调页 &gt; 磁盘 I/O可预见性：请求调页 &lt; 磁盘 I/O数据的一致性：一旦系统发生故障，高速缓存中的数据将会丢失，如果未 拷回磁盘，会造成数据的不一致。 周期性地写回磁盘数据的一致性解决方法：将系统中所有盘块数据拉成一条 LRU（最近最 久未使用算法）链，需要一致性的块放在LRU 队列的头部，优先回写。 可能在不久之后再使用的盘块数据，挂在 LRU 链的尾部。 系统中所有盘块数据拉成一条 LRU 链，经常访问的数据被挂在链尾，一 直保留磁盘高速缓存中，可能长期不会被写回磁盘。若系统出故障，则存在磁盘高速缓存中的数据将丢失。 在UNIX系统中专门增设一个修改程序，使之在后台运行，该程序周期性地调用一个系统调动SYNC，其主要功能就是强制性地将所有在高速缓存中已修改的盘块数据写回磁盘。一般是把两次调用SYNC的时间间隔定位30s。这样，因系统故障所造成的工作损失不会超过30s的工作量 提高磁盘I/O速度的其他方法提前读由于用户对文件的访问常用顺序方式，所以可采用预先读方式，即在读当 前块的同时，连同将下一块提前读入缓冲。当访问下一块数据时，其已在 缓冲中，而不需去启动磁盘 I/O。 延迟写在缓存中的数据，本应立即写回磁盘，考虑不久可能再用，故不立即写回磁盘，挂在空闲缓冲区队列末尾。当该缓冲区仍在队列中时，任何访问该数据的进程，都可直接读出其中的数据而不必去访问磁盘。随着空闲缓冲区的使用，缓冲区也缓缓往前移动，直至移到空闲缓冲队列之首。当再有进程申请到该缓冲区时，才将该缓冲区的数据写入磁盘，而把该缓冲区作为空闲缓冲区分配出去。 优化物理块的分布使磁头移动的距离最小。多个连续的块组成一簇，以簇为单位进行分配。 虚拟盘虚拟盘是利用内存去仿真磁盘，又称为 RAM 盘。 虚拟盘对用户是透明的，仅是感觉略微快些而已。虚拟盘是易失性存储器（内存），关机或重新启动计算机时，虚拟盘上的信息将丢失，所以在关机或重新启动计算机前，一定要及时把在虚拟盘上的 重要的数据存放到真正的硬盘中。 虚拟盘与磁盘高速缓存的区别：RAM 盘中的内容由用户控制，而缓存中的 内容则由 OS 控制。 廉价磁盘冗余阵列(RAID)RAID是利用一台磁盘阵列控制器来统一管理和控制一组磁盘驱动器，组成一个高度可靠的、快速的大容量磁盘系统。并行交叉存取（条带化存取）、 冗余存取、校验存取 并行交叉存取在该系统中，有多台磁盘驱动器，系统将每一盘块中的数据分为若干个子盘块数据，再把每一个子盘块的数据分别存储到各个不同磁盘中的相同位置上。以后当要将一个盘块的数据传送到内存时，采取并行传输方式，将各个盘块中的子盘块数据同时向内存中传输，从而使传输时间大大减少 RAID的分级 RAID0：仅提供了并行交叉存取仅提供了并行交叉存取，没有数据冗余；无容错功能，不增强可靠性。 RAID1：具有磁盘镜像功能完全相同的数据重复存 于多个盘上。注意：数据读取时可选任一独立磁盘，但修改时必须对所 有镜像同时进行，以保证数据一致性。具有高可靠性，分布存放；镜像冗余，空间利用率 50%，代价很高，需 要 2n 个独立磁盘；不校验。 RAID2：Hamming Code ECC（汉明码错误检测与修正） RAID3：Parallel transfer with parity（并行传输及校验） RAID4：Independent Data disks with shared Parity disk（独立的数据硬盘与共享的校验硬盘） RAID5：Independent Data disks with distributed parity blocks（独立的数据磁盘 与分布式校验块） RAID6：Independent Data disks with two independent distributed parity schemes（独立的数据硬盘与两个独立分布式校验方案） RAID7：Optimized Asynchrony for High I/O Rates as well as High Data Transfer Rates（最优化的异步高 I/O 速率和高数据传输率） RAID10：此级别是 RAID 0 与 RAID 1 的结合（stripping+mirroring） 各级RAID的比较","link":"/2022/01/02/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%8612%E2%80%94%E2%80%94%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E7%AE%A1%E7%90%86/"},{"title":"操作系统笔记整理2——进程的描述与控制（1）","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 前趋图表示一个程序各部分间的依赖关系程序顺序执行时的特征： 顺序性：严格按照先后次序执行 封闭性：程序运行时独占全部系统资源 可再现性：若初始条件相同，那么重复执行时结果也相同程序并发执行时的特征： 间断性：互斥、同步 失去封闭性：共享资源-&gt;失去封闭性 不可再现性：失去封闭性-&gt;失去可再现性 进程 程序并发执行时的不可再现性是不被允许的，因此要引入进程对并发执行的程序加以描述和控制，保持程序的可再现性 定义 进程是程序的一次执行实例 进程是一个程序及其数据在处理机上顺序执行时所发生的活动 进程是程序在一个数据集合上的运行过程，它是系统进行资源分配和调度的一个独立单位 每个进程都配置一个进程控制块（PCB），每个进程都是由程序段、相关数据段及进程控制块组成。 进程实际上是指进程实体 创建、撤销进程实际上指创建、撤销进程实体的PCB PCB是进程存在的唯一标志 特征 动态性：进程的实质是程序在处理机上的一次执行过程，因此是动态。动态性是 进程的最基本的特征 。 并发性：指多个进程实体同时存在于内存中，能在一段时间内同时运行。 独立性：指进程是一个能独立运行的基本单位，也是系统进行资源分配和调度的独立单位 异步性：指进程以各自独立的、不可预知的速度向前推进。 状态三种基本状态：就绪、执行、阻塞 就绪：进程已获得除处理机以外的所有资源，等待分配处理机 执行：进程已获得必要资源并在处理机上执行 阻塞：正在执行的进程由于发生某事件而暂时无法执行下去 创建：申请PCB，分配资源，正在创建的状态 终止：进程执行完毕，释放所占资源的状态 挂起：程序在运行期间，由于某种需要，往往要将进程暂停执行，使其静止下来，以满足其需要。这种静止状态就称为进程的挂起状态。一般情况下，挂起状态的进程将从内存移到外存，正在执行的进程暂停执行、就绪的进程暂不接受调度、阻塞的进程即使阻塞事件释放也不能继续执行。 PCBPCB是操作系统为了管理和控制进程运行而为每一个进程定义的一个数据结构，它记录了系统管理进程所需的全部信息PCB常驻内存，存放在操作系统中专门开辟的PCB区内作用1.作为独立运行的标志 PCB是进程存在的唯一标志2.能实现间断性运行方式 利用 PCB 保存处理机状态信息，保护和恢复 CPU 现场。3.提供进程管理所需要的信息 根据 PCB 中的程序和数据的内存始址，找到程序和数据。系统根据 PCB 了解进程所需的全部资源。4.提供进程控制所需要的信息 OS 要调度某进程执行时，从 PCB 中查现行状态及优先级。5.实现与其他进程的同步和通信PCB中的信息1.进程标志符 内部标识符：由系统创建进程时分配给进程的唯一标识号，用于区分不同的进程（进程号） 外部标识符：用户访问该进程时使用（用户号）2.处理机状态（断点信息） 通用寄存器、指针计数器、PSW（程序状态字）、用户栈指针3.进程调度信息 进程状态、优先级、进程调度所需信息（等待时间、已执行时间等）、事件（状态转换的原因）4.进程控制信息 程序和数据的地址、同步和通信机制（消息队列指针、信号量等）、资源清单（除CPU外，所需资源及已分配资源的清单）、链接指针（下一个进程的PCB的首地址）PCB的组织方式链接方式：同一状态的PCB链接成一个队列，形成就绪队列、阻塞队列等索引方式：将同一状态的进程组织在一个索引表中，索引表的表项指向相应的PCB，不同状态对应不同的索引表 进程的层次结构子进程可继承父进程的所有资源子进程撤销时要把资源归还给父进程父进程撤销时也必须撤销所有子进程 进程控制进程控制是进程管理中最基本的功能，即对系统中所有的进程实施有效的管理，其功能包括进程的创建、撤销、阻塞与唤醒等，这些功能一般是由操作系统的内核中原语来完成 操作系统内核：内核是基于硬件的第一层软件扩充，它为系统控制和管理进程提供了良好的环境。在现代OS中，常把一些功能模块（与硬件紧密相关的及运行频率较高的）放在紧靠硬件的软件层中，加以特殊保护，使它们常驻内存，以提高OS的运行效率，这部分功能模块就称为OS的内核。 中断中断：CPU对系统中或系统外发生的某个事件作出的一种反应。如外部设备完成数据传输、实施设备出现异常等。引入中断的目的：中断机制是操作系统得以正常工作的最重要的手段操作系统是由中断驱动的原语原语：由若干条指令组成的，用于完成一定功能的一个过程。它与一般过程的区别在于：它们是“原子操作”。原子操作：指一个操作中的所有动作要么全做，要么全不做。换言之，它是一个不可分割的基本单位，因此，在执行过程中不允许被中断。原语在核心态下执行，常驻内存 进程创建导致进程创建的事件：1.用户登录：为该终端用户创建一个进程2.作业调度：为被调度的作业创建进程3.提供服务：如要打印时建立打印进程4.应用请求：由应用程序建立多个进程（并发） 使用进程创建原语Create创建进程 进程终止导致进程终止的事件：1.进程正常结束2.进程异常结束（越界、超时等）3.外界干预（操作员、OS、父进程）使用进程撤销原语Kill撤销进程 进程的阻塞与唤醒导致进程阻塞和唤醒的事件：1.向进程请求共享资源失败2.等待某种操作的完成3.新数据尚未到达4.无新工作可做阻塞原语：Block唤醒原语：Wakeup进程从执行态到阻塞态是主动的，进程发现需要等待某一事件，主动向系统申请进入阻塞态。进程从阻塞态到就绪态是被动的，当系统（或其它进程）发现阻塞进程阻塞的条件已释放，向系统申请将该进程置为就绪态。 进程的挂起与激活挂起原语：Suspend挂起是由进程自己或其父进程调用Suspend原语完成 激活原语：Active激活是由父进程或用户进程请求激活指定进程，系统利用Active原语将指定进程激活 练习题","link":"/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%862%E2%80%94%E2%80%94%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%8E%A7%E5%88%B6%EF%BC%881%EF%BC%89/"},{"title":"操作系统笔记整理4——处理机调度与死锁（1）","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 处理机调度的层次1.高级调度（作业调度）从外存后备队列中选择作业进入内存就绪队列2.中级调度（交换调度）在内存和外存对换区之间按照给定的策略选择进程对换3.低级调度（进程调度）从就绪队列中选择一个进程来执行并由分派程序分配处理机是OS中最基本的调度CPU的利用率=$\\frac{CPU有效工作时间}{CPU有效工作时间+CPU空闲等待时间}$周转时间=结束时间-到达时间带权周转时间=$\\frac{周转时间}{系统服务时间}$带权周转时间越小越好 作业调度作业：作业是把命令、程序和数据按照预先确定的次序结合在一起，并提交给系统的一个组织单位。作业控制块JCB是作业在系统中存在的唯一标志作业运行时首先被调度进入内存，并以进程的形式存在，其状态是执行状态，处于执行状态的作业可以有多个，处于执行状态的作业并不意味着一定在CPU上运行，是否运行依赖于进程控制。 先来先服务调度算法FCFS按进程（作业）进入就绪（后备）队列的先后次序来分配处理机（为期创建进程）特点：简单，但效率不高，有利于CPU繁忙型作业，不利于I/O繁忙型作业 短作业优先调度算法（SJF）用于作业调度，主要任务是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存类似地，用于进程的是短进程优先调度算法（SPF）能有效降低作业的平均等待时间和平均周转时间，提高了吞吐量，但是对长作业不利，没有考虑作业的紧迫程度，作业执行时间、剩余时间仅为估计。 优先级调度算法（PSA）PSA：Priority scheduling algorithm以作业的紧迫程度为优先级静态优先级：优先权在创建进程时确定，且在整个运行期间保持不变动态优先级：在进程的存在过程中不断发生变化 高响应比优先算法（HRRN）HRRN：Highest response ratio next高响应比优先算法既考虑了作业的等待时间，也考虑的作业的运行时间，是是一种动态优先级调度算法优先权=$\\frac{等待时间+要求服务时间}{要求服务时间}$ 例题 进程调度任务：保存处理机的现场信息、按某种算法选取进程、把处理机分配给进程 最短剩余时间调度算法（SRT (Shortest Remaining Time)）最短剩余时间调度算法是针对SPF(短进程优先)增加了抢占机制的一种调度算法它总是选择预期剩余时间最短的进程。只要新进程就绪，且有更短的剩余时间，调度进程就可能抢占当前正在运行的进程。 时间片轮转调度算法（RR）系统将所有就绪进程按FCFS的原则，排成一个队列依次调度，把CPU分配给队首进程，并令其执行一个时间片，通常为10-100ms,时间片用完后，系统的计时器发出时钟中断，该进程将被剥夺CPU并插入就绪队列末尾 进程切换时机：1.一个时间片尚未用完进程便已完成，立即在调度就绪队列中队首进程运行，并启动一个新的时间片2.如果在一个时间片用完时进程尚未运行完毕，则剥夺CPU，调度程序把它送完就绪队列的末尾。 响应时间T=时间片q*就绪队列进程数n 例：一个分时OS，10个终端，时间片100ms，每个用户的请求进程要300ms的时间处理，问终端用户提出二次请求的时间间隔最少是多少？响应时间=100ms*10=1s，每个用户的请求要3个时间片才能处理完，要轮转3次，所以终端用户的二次请求的时间间隔最少应为2.1s~3s 优先级调度算法非抢占抢占 多级队列调度算法将就绪队列划分成若干个独立的队列，每个作业固定地分属一个队列，不同的队列可以采用不同的调度算法 多级反馈队列调度算法FCFS+优先级+RR+抢占1.设置多个就绪队列，队列1的优先级最高，其余队列逐个降低2.每个队列中进程执行的时间片大小各不相同，进程所在队列的优先级越高，时间片就越短3.新进程进入系统，先放入队列1的末尾，按FCFS调度，若能完成则撤离系统，反之调入队列2，按FCFS调度，如此下去，最后进入队列n按RR算法调度4.仅当队列1为空时，才调度队列2中的进程运行。若一个队列中的进程正执行，此时有新进程进入高级队列，则新进程抢占运行，原进程移至本队队尾。 实时调度实时调度的基本条件：1.提供必要的调度信息2.系统处理能力强3.采用抢占式的调度机制4.具有快速切换机制 限制条件m：实时任务数；Ci：每次处理时间；Pi：周期时间单处理机：$\\sum_{i=1}^{m}\\frac{Ci}{Pi}$≤1多处理机：$\\sum_{i=1}^{m}\\frac{Ci}{Pi}$≤N（N：处理机数目） 最早截止时间优先算法（EDF）非抢占式用于非周期实时任务抢占式 最低松弛度优先算法低松弛=高紧急紧急度越高，优先级越高算法采用抢占调度方式松弛度=必须完成时间-本身剩余运行时间-当前时间 优先级倒置优先级倒置现象：高优先级进程（或线程）被低优先级进程（或线程）延迟或阻塞。 例如：有三个完全独立的进程 Task A、Task B 和 Task C，Task A 的优 先级最高，Task B 次之，Task C 最低。Task A 和 Task C 共享同一个临 界资源 X。根据优先级原则，高优先级进程优先执行。但此例中 Task A 和 Task C共享同一个临界资源，出现了不合理的现象。高优先级进程 Task A 因低优先进程 Task C 被阻塞，又因为低优先进程Task B的存在延长了被阻塞的时间。 解决方法： Priority Ceiling进程 Task C 在进入临界区后，Task C 所占用的处理机就不允许被抢占。 这种情况下，Task C 具有最高优先级（Priority Ceiling）。如果系统中的临界区都较短且不多，该方法是可行的。反之，如果 Task C 临界区非常长，则高优先级进程 Task A 仍会等待很长的时间，其效果无法 令人满意。 Priority Inheritance当高优先级进程 Task A 要进入临界区使用临界资源 X 时，如果已经有一个 低优先级进程 Task C 正在使用该资源，可以采用优先级继承（Priority Inheritance）的方法。此时一方面 Task A 被阻塞，另一方面由 Task C 继承 Task A 的优先级，并 一直保持到 Task C 退出临界区。","link":"/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%864%E2%80%94%E2%80%94%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6%E4%B8%8E%E6%AD%BB%E9%94%81%EF%BC%881%EF%BC%89/"},{"title":"操作系统笔记整理6——存储器管理（1）","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 存储器的层次结构 程序的装入和链接一个用户源程序要变为在内存中可执行的程序，通常要进行以下处理：编译：由编译程序将用户源程序编译成若干个目标模块链接：由链接程序将目标模块和相应的库函数链接成装入模块装入：由装入程序将装入模块装入内存 根据链接时间的不同，程序的链接可分为：静态链接、装入时动态链接和运行时动态链接 可重定位装入方式事先不知用户 程序在内存的驻留位置，装入程序在装入时根据内存的实际情况把相 对地址（逻辑地址）转换为绝对地址，装入到适当的位置。（在装入 时进行地址转换）静态重定位 当用户程序被装入内存时，一次性实现逻辑地址到物理地址的转换，以后 不再转换。 一般在装入内存时由软件完成。 动态重定位 在程序运行过程中要访问数据时再进行地址变换（即在逐条指令执行时完 成地址映射）。 一般为了提高效率，此工作由硬件地址映射机制来完成。 硬件（寄存器）支持，软硬件结合完成。 连续分配存储管理方式连续分配方式（分区技术）：指为一个用户程序分配一片连续的内存空间静态分区：作业装入时一次完成，分区大小和边界在运行时不能改变动态分区：根据作业大小动态地建立分区，分区的大小、数目可变。 单一连续分区分配（静态分区技术）：仅用于单用户单任务系统 固定分区分配（静态分区技术）：可用于多道系统 动态分区分配（动态分区技术） 动态可重定位分区分配（动态分区技术）：引入了动态重定位和内存紧凑技术 伙伴系统（动态分区技术） 单一连续分区分配内存管理方法：将内存分为系统区（内存低端，分配给OS用）和用户区（内存高端，分配给用户用）。采用静态分配方式，即作业一旦进入内存，就要等待它运行结束后才能释放内存只能用于单用户、单任务的OS中，内存中只装入一道作业运行 一个容量为256KB的内存，操作系统占用32KB，剩下224KB全部分配给用户作业，如果一个作业仅需64KB，那么就有160KB的存储空间被浪费。 固定分区分配方式最早使用的一种可运行多道程序的存储管理方法存储管理方法：将内存空间划分为若干个固定大小的分区，除OS占一区外，其余的一个分区装入一道程序。分区的大小可以相等，也可以不等，但事先必须确定，运行时不能改变。即分区的大小及边界在运行时不能改变系统需建立一张分区说明表，以记录分区号、分区大小、分区的起始地址及状态（已分配或未分配）当用户程序要装入内存时，通常将分区按大小进行排队，由内存分配程序检索分区说明表，找出一个满足要求的尚未分配的分区分配该程序 动态分区分配方式存储管理方法：内存不是预先划分好的，作业装入时，根据作业的需求和内存空间的使用情况来决定是否分配。若有足够的空间，则按需要分割一部分分区给该进程；否则令其等待内存空间 动态分区分配中的数据结构空闲分区表：用来登记系统中的空闲分区（分区号、分区起始地址、分区大小及状态）空闲分区链：前、后向链接指针用于把所有的空闲分区链接成一个双向链。当分区被分配出去以后， 前、后向指针无意义。状态位 0：未分配状态位 1：已分配 分区分配操作分配内存事先规定size是不再切割的剩余分区的大小设请求的分区大小为u.size，空闲分区的大小为m.size若m.size-u.size≤size说明多余部分太小，可不再切割，将整个分区分配给请求者否则，便从该分区中安请求的大小划分出一块内存空间分配出去，余下的部分仍留在空闲分区链（表）中。回收内存回收分区上邻接一个空闲分区，合并后首地址为空闲分区的首地址，大小为二者之和回收分区下邻接一个空闲分区，合并后首地址为回收分区的首地址，大小为二者之和回收分区上下邻接空闲分区，合并后首地址为上空闲分区的首地址，大小为三者之和回收分区不邻接空闲分区，这时在空闲分区表中新建一表项，并填写分区大小等信息 动态分区分配方法基于顺序搜索的动态分区分配算法按照一定的分配算法从空闲分区表（链）中选出一个满足作业需求的分区分割，一部分分配给作业，剩下的部分仍然留在空闲分区表（链）中，同时修改空闲分区表（链）中相应的信息。 首次适应算法空闲分区链按地址递增的次序排列在进行内存分配时，从空闲分区表/链首开始顺序查找，直到找到第一个满足其大小要求的空闲分区为止，然后再按照作业大小，从该分区中划出一块内存空间分配给请求者，余下的空闲分区仍留在空闲分区表中 例题系统中的空闲分区表如下表示，现有三个作业分配申请内存空间100K、30K及7K，给出按首次适应算法的内存分配情况及分配后空闲分区表。按首次适应算法，申请作业 100k，分配 3 号分区，剩下分区为 20k，起始地址 160K ；申请 作业 30k，分配 1 号分区，剩下分区为 2k，起始地址 50K ；申请作业 7k，分配 2 号分区， 剩下分区为 1k，起始地址 59K。 特点：优先利用内存低地址部分的空闲分区。但由于低地址部分不断被划分，留下许多难以利用的很小的空闲分区（碎片或零头），而每次查找又都是从低地址部分开始，增加了查找可用空闲分区的开销。 循环首次适应算法与首次适应算法类似，只不过不再每次从空闲分区表/链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找，直到找到第一个能满足其大小要求的空闲分区为止。 最佳适应算法空闲分区表/链按容量大小递增的次序排列。在进行内存分配时，从空闲分区表/链首开始顺序查找，直到找到第一个满足其大小要求的空闲分区为止。注意分配完后要按容量递增的顺序重新排列特点：最佳适应算法往往使剩下的空闲分区非常小，从而在存储器中留下许多难以利用的小空闲区（碎片） 最坏适应算法空闲分区表/链按容量大小递减的次序排列。在进行内存分配时，从空闲分区表/链首开始顺序查找，直到找到第一个满足其大小要求的空闲分区为止。特点：由于最大的空闲分区总是因首先分配而划分，当有大作业到来时，其存储空间的申请往往会得不到满足 基于索引搜索的动态分区分配算法基于顺序搜索的动态分区分配算法一般只适合于较小的系统，如果系统的分区很多，空闲分区表（链）可能很大（很长），检索速度会比较慢。为了提高搜索空闲分区的速度，大中型系统采用了基于索引搜索的动态分区分配算法 快速适应算法快速适应算法，又称为分类搜索法，把空闲分区按容量大小进行分类， 经常用到长度的空闲区设立单独的空闲区链表。系统为多个空闲链表设 立一张管理索引表。在查找时，仅需要根据进程的长度，寻找到能容纳它的最小空闲区链表，取下第一块进行分配即可该算法在分配时，不会对任何分区产生分割在分配空闲分区时是以进程为单位，一个分区只属于一个进程，存在一定的浪费。空间换时间。 伙伴系统伙伴系统是介于固定分区与可变分区之间的动态分区技术伙伴：在分配存储块时将一个大的存储块分裂成两个大小相等的小块，这两个小块就称为“伙伴”伙伴系统规定，无论已分配分区或空闲分区，其大小均为 2 的 k 次幂，k 为整数，n ≤ k ≤ m，其中：2^n^ 表示分配的最小分区的大小，2^m^ 表示分配的最大分区的大小，通常2^m^是整个可分配内存的大小。内存管理模块保持有多个空闲块链表，空闲块的大小可以为 2，4，8，…，2^m^ 字节。 对于 1M 的内存，空闲块的大小最多有20种不同的取值 内存分配 系统初启时，只有一个最大的空闲块（整个内存） 当一个长度为n的进程申请内存时，就分给它一个大于等于n的最小的2次幂的空闲块 如果2^i-1^&lt;n≤2^i^,则在空闲分区大小为2^i^的空闲分区链表中查找，如50KB的内存请求，会首先向上取整转化为一个64KB的请求 若找到2^i^的空闲分区，则将其分配给进程，否则，在分区大小为2^i+1^的空闲分区链表中寻找 若存在2^i+1^的空闲分区，则把该分区分为相等的两个分区，这两个分区称为一对伙伴，其中的一个分区用于分配，另一个加入2^i^的空闲分区链表中 若2^i+1^也不存在，则查找2^i+2^的空闲分区，若找到对其进行两次分割，若仍然找不到则继续查找2^i+3^的空闲分区，以此类推。 内存释放首先考虑将被释放块与其伙伴合并成一个大的空闲块，然后继续合并下去，直到不能合并为止如果有两个存储块大小相同，地址也相邻，但不是由同一个大块分裂出来（不是伙伴），则不会被合并起来。 哈希算法上述的分类搜索算法和伙伴系统算法中，都是将空闲分区根据分区大小进行分类，对于每一类具有相同大小的空闲分区，单独设立一个空闲分区链表。哈希算法：构造一张以空闲分区大小为关键字的哈希表，该表的每一个 表项记录了一个对应的空闲分区链表表头指针进行空闲分区分配时，根据所需空闲分区大小，通过哈希函数得到在哈 希表中的位置，从中得到相应的空闲分区链表的表头指针。 系统中的碎片内部碎片：指分配给作业的存储空间中未被利用的部分，如固定分区中存在的碎片外部碎片：指系统中无法利用的小的空闲分区。如分区与分区之间存在的碎片。这些不连续的区间就是外部碎片。 动态可重定位分区分配紧凑技术通过移动作业把多个分散的小分区拼接成一个大分区的方法目标：消除外部碎片，使本来分散的多个小空闲分区连成一个大的空闲区紧凑时机：找不到足够大的空闲分区且总空闲分区容量可以满足作业要求时 动态重定位作业在内存中的位置发生了变化，必须对其地址加以修改或变换动态可重定位分区分配算法在分区存储管理方式中，必须把作业装入到一片连续的内存空间。如果系统中有若干个小的分区，其总容量大于要装入的作业，但由于它们不相邻接，也将致使作业不能装入内存。动态可重定位分区分配相当于引入了动态重定位和内存紧凑技术的动态分区分配","link":"/2021/12/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%866%E2%80%94%E2%80%94%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86%EF%BC%881%EF%BC%89/"},{"title":"操作系统笔记整理7——存储器管理（2）","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 离散分配方式连续分配存储管理方式产生的问题：1.要求连续的存储区2.碎片问题 变连续分配为离散分配，允许将作业离散放到多个不相邻接的分区中 离散分配方式包括：1.分页式存储管理：离散分配的基本单位是页2.分段式存储管理：离散分配的基本单位是段3.段页式存储管理：离散分配的基本单位是段、页 分页存储管理方式页面和物理块空间划分：将一个用户进程的地址空间（逻辑空间）划分成若干个大小相等的区域，称为页或页面，各页从0开始编号。内存空间也分成若干个与页大小相同的区域，称为块，同样从0开始编号内存分配：在为进程分配内存时以块为单位，将进程中若干页装入到多个不相邻的块中，最后一页常装不满一块而出现页内碎片 地址结构逻辑地址：地址长为32位其中0-11位为页内地址，即每页的大小为2^12^=4KB；12-31位为页号，地址空间最多允许有2^20^=1M页。物理地址：地址长为22位其中0-11位为块内地址，即每块的大小为2^12^=4KB，与页相等12-21位为块号，内存地址空间最多允许有2^10^=1K块 页表分页系统为每个进程配置一张页表，放在PCB中，执行时装入页表寄存器（PTR），进程逻辑地址空间中的每一页，在页表中都对应有一个页表项页表存放在内存中，属于进程的现场信息用途：1.记录进程的内存分配情况 2.实现进程运行时的动态重定位访问一个数据需访问内存两次，页表一次，内存一次页表的基址及长度由页表寄存器给出关于页面大小的问题：若页面较小：减少了页内碎片，但使页表长度增加，占用内存较大，页面换进换出的速度将降低若页面较大：页表长度减少，占用内存较小，页面换进换出的速度将提高，但增加了页内碎片，不利于提高内存利用率 地址变换机构将用户地址空间中的逻辑地址变换为内存空间中的物理地址 基本的地址变换机构地址变换借助页表来完成，页表驻留内存1.逻辑地址: 把相对地址分为页号和页内地址两部分。2.越界中断: 页号与页表长度做比较，若页号大于等于页表长度，则产生地址越界中断3.页表项定位：页表始址 + 页号 × 页表项长度。4.查询页表：读出块号。5.物理地址：块号 + 块内地址。（块内地址 = 页内地址） 例题例：存储器的用户空间共有 32 个页面，每页 1KB，内存 16KB。假定某时刻系统为用户的第 0、1、2、3 页分别分配的物理块号为 5、10、4、7，试 将逻辑地址 0A5C 和 093C 变换为物理地址。解：逻辑地址为：共有32个页，页号5位（2^5^=32），每页1KB，页内位移10位；物理地址为：内存16KB，每块1KB，共有16块，物理块号4位（2^4^=16），每块1KB，块内位移10位。逻辑地址 0A5C 对应的二进制为：00010 1001011100，前五位00010为页号，后十位1001011100为页内偏移，第2页对应的块号为4故物理地址为0100 1001011100即125C同理可求 093C 的物理地址为 113C。 具有快表的地址变换机构基本的地址变换机构因为两次访问内存，所以地址变换速度低具有快表的地址变换机构：目的：提高地址变换速度快表：又称为联想寄存器快表是一种特殊的高速缓冲存储器（Cache），内容是页表中的一部分或全部内容CPU产生逻辑地址的页号，首先在快表中寻找，若命中就找出其对应的物理块；若未命中，再到页表中找其对应的物理块，并将之复制到快表。若快表中内容满，则按某种算法淘汰某些页。 访问内存的有效时间有效访问时间（Effective Access Time,EAT）是指从给定逻辑地址，经过地址变换，到在内存中找到对应物理地址单元并取出数据所用的总时间 基本地址变换机构设TM为内存的访问时间EAT=2TM 具有快表的地址变换机构设PTLB为快表的命中率，TTLB为快表的访问时间EAT=PTLB*（TTLB+TM）+（1-PTLB）*（TTLB+2TM） 多级页表若逻辑地址空间很大，则划分的页比较多，页表就很大，占用的存储空间大，实现较困难 两级页表将页表再进行分页，离散地将各个页表页面存放在不同的物理块中，同时也再建立一张外部页表用以记录页表页面对应的物理块号正在运行的进程，必须把外部页表调入内存，而动态调入内部页表。只将当前所需的一些内层页表装入内存，其余部分根据需要再陆续调入逻辑地址 地址变换 多级页表将外层页表再进行分页，也将各外层页表页面离散地存放在不同的物理块中逻辑地址 反置页表对于 64 位逻辑地址空间的分页系统，如果规定页面大小为 4 KB 即 2^12^B，则在每个进程页表就由高达 2^52^ 页组成。设表中每项为 8byte，则 需 8 ∗2^52^ =2^55^ =32768 TB 的内存空间。一般页表的页表项是按页号进行排序，页表项中的内容是物理块号反置页表是为每一个物理块设置一个页表项并按物理块号排序，其中的内容是页号P及隶属进程标志符pid 利用反置页表进行地址变换： 用进程标志符和页号去检索反置页表 如果检索完页表没有找到与之匹配的页表项，表明此页尚未调入内存 如果检索到，则表项的序号i表示该页的物理块号，将该块号与页内地址一起构成物理地址反置页表可以有效减少页表占用的内存，但反置页表中只包含已经调入内存的页面，因此必须为每个进程建立一个外部页表，发现页面不在内存时才访问外部页表。外部页表存放各页在外存中的物理位置。通过外部页表可将所需要的页面调入内存 页的共享与保护页的共享各进程把需要共享的数据/程序的相应页指向相同物理块页的保护地址越界保护在页表中设置保护位（定义操作权限：只读，读写，执行等）共享带来的问题若共享数据与不共享数据划在同一块中，则：有些不共享的数据也被共享，不易保密；计算共享数据的页内位移较困难 实现数据共享的最好方法：分段存储管理 分段存储管理方式引入分段存储管理是为了满足用户的要求 方便编程：通常一个作业是由多个程序段和数据段组成的，一般情况下，用户希望按逻辑关系对作业分段，并能根据名字来访问程序段和数据段 信息共享：共享是以信息的逻辑单位为基础的。页是存储信息的物理单位，段却是信息的逻辑单位；页式管理中地址空间是一维的，主程序，子程序都顺序排列，共享公用子程序比较困难，一个共享过程可能需要几十个页面 信息保护：页式管理中，一个页面中可能装有两个不同的子程序段的指令代码，不能通过页面共享实现共享一个逻辑上完整的子程序或数据块。段式管理中，可以以信息的逻辑单位进行保护 动态增长：实际应用中，某些段（数据段）会不断增长，前面的存储管理方法均难以实现。 动态链接：动态链接在程序运行时才把主程序和要用到的目标程序（程序段）链接起来。 空间划分将用户作业的逻辑地址空间划分成若干个大小不等的段。各段有段名，首地址为0 利用段表实现地址映射 段表记录了段与内存位置的对应关系 段表保存在内存中 段表的基址及长度由段表寄存器给出 访问一个字节的数据/指令需访问内存两次（段表一次，内存一次） 逻辑地址由段号和段内地址组成 地址变换机构系统将逻辑地址中的段号S与段表长度TL进行比较 若S&gt;TL，表示段号太大，产生越界中断信号 若未越界，则根据段表的始址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存的始址再检查段内地址d，是否超过该段的段长SL 若超过，同样发出越界中断信号 若未越界，则将该段的基址与段内地址d相加，即可得到要访问的内存物理地址 信息共享例：一个多用户系统，可同时接纳40个用户，都执行一个文本编辑程序(Text Editor)。如果文本编辑程序有160KB的代码和另外 40 KB 的数据区，如果不共享，则总共需有8MB的内存空间来支持40个用户。如果 160 KB 的代码是可重入的，则无论是在分页系统还是在分段系统中，该代码都能被共享。在内存中只需保留一份文本编辑程序的副本，此时所需的内存空间仅为1760 KB(40×40+160)，而不是 (160+40)×40= 8000KB 。分页系统的共享假定每个页面的大小为4KB，160KB的代码将占用40个页面，数据区占10个页面为实现代码的共享，应在每个进程的页表中都建立40个页表项，它们的物理块号是21~60。在每个进程的页表中，数据区页表项的物理块号是61~70、71~80 分段系统的共享在分段系统中，实现共享容易的多，只需在每个进程的段表中为文本编辑程序设置一个段表项 分页与分段的主要区别 页是信息的物理单位，分页仅仅是由于系统管理的需要，对用户透明的。段是信息的逻辑单位，分段的目的是为了能更好的满足用户的需要。 页的大小固定且由系统确定，把逻辑地址划分为页号和页内地址两部分。段的长度不固定，决定于用户所编写的程序 分页的作业地址空间是一维的，分段的作业地址空间是二维的 页和段都有存储保护机制。但存取权限不同：段有读、写和执行三种权限；而页只有读和写两种权限 段页式存储管理方式段页式存储管理是分段和分页原理的结合，即先将用户程序分成若干个段，并为每一个段赋一个段名，再把每个段分成若干个页其地址结构由段号、段内页号及页内位移三部分所组成系统中设段表和页表，均存放于内存中。读一字节的指令或数据须访问内存三次。每个进程一张段表，每个段一张页表段表含段号、页表始址和页表长度页表含页号和块号 段页式存储管理的地址变换 从PCB中取出段表始址和段表长度，装入段表寄存器 将段号与段表长度进行比较，若段号大于或等于段表长度，产生越界中断 利用段表始址与段号得到该段表项在段表中的位置。取出该段的页表始址和页表长度 将页号与页表长度进行比较，若页号大于等于页表长度，产生越界中断 利用页表始址与页号得到该页表项在页表中的位置 取出该页的物理块号，与页内地址拼接得到实际的物理地址","link":"/2021/12/30/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%867%E2%80%94%E2%80%94%E5%AD%98%E5%82%A8%E5%99%A8%E7%AE%A1%E7%90%86%EF%BC%882%EF%BC%89/"},{"title":"操作系统笔记整理5——处理机调度与死锁（2）","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 死锁概述死锁是多个进程在运行过程中因争夺资源而造成的一种僵局，若无外力作用，这些进程都将无法向前推进。 参与死锁的进程数至少为两个 参与死锁的所有进程均等待资源 参与死锁的进程至少有两个已经占有资源 死锁进程是系统中当前进程集合的一个子集 产生死锁的原因1.竞争不可抢占资源引起死锁2.竞争可消耗资源引起死锁3.进程间推进顺序不当引起死锁 产生死锁的四个必要条件1.互斥条件：进程对分配到的资源进行排他性使用2.请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程被阻塞，但对自己已经获得的资源保持不放3.不可剥夺条件：进程已获得的资源，在未使用之前不能被抢占，只能在进程使用完时自己释放4.环路等待条件：在发生死锁时，必然存在一个进程-资源的循环链，如P0等待一个P1占用的资源，P1等待P2占用的资源，P2等待P0占用的资源 处理死锁的方法1.鸵鸟方法：忽略死锁2.预防死锁：通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个3.避免死锁：在资源的动态分配过程中，用某种方法防止系统进入不安全状态4.检测死锁：允许系统在运行过程中发生死锁，但可设置检测机构及时检测死锁的发生，并可采取适当措施加以清除5.解除死锁：检测出死锁后，采取适当措施将进程从死锁中解脱出来 预防死锁预防死锁是要破坏四个必要条件中的一个或几个，下面逐个条件分析 破坏互斥条件要想破坏互斥条件，就要允许多个进程同时访问资源，但由于资源本身固有特性的性质，此方法不可行 破坏请求和保持条件 第一种协议：全分配，全释放：采用预先静态分配方法，即要求进程在运行之前一次性申请它所需要的全部资源，在它的资源未满足前，不把它投入运行。摒弃了请求条件：在整个运行期间不会再提出资源请求摒弃了保持条件：在该进程的等待期间，它并未占有任何资源 第二种协议：允许一个进程只获得运行初期所需的资源后，便开始运行。摒弃保持条件：进程运行过程中必须释放已分配且已用完的资源，然后才能申请新的资源。 破坏不可剥夺条件 实施方案1：进程在申请新的资源不能立即得到满足而变为等待状态之前，必须释放已占有的全部资源，若需要再重新申请 实施方案2：进程申请的资源被其它进程占用时，可通过操作系统抢占这一资源 破坏环路等待条件采用有序资源分配方法，即将系统中所有资源都按类型赋予一个编号，要求每个进程均按照资源序号递增的次序来请求资源，从而保证不出现环路。 例如：系统把所有资源按类型进行排队。如输入机 =1，打印机 =2，磁带 机 =3，磁盘机 =4。如果一个进程已经分配了序号为 i 资源，它接下来请求的资源只能是那些排在 i 之后的资源。当 i&lt;j 时，进程 A 获得 Ri，可以请求 Rj，而进程 B 获得 Rj 再请求 Ri不可能发生，因为资源 Ri 排在 Rj 前面。 避免死锁在系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统可能发生死锁，则不予分配，从而避免发生死锁。安全状态：在某一时刻，系统能按照某种资源顺序来为每个进程分配其资源，直到满足每个进程对资源的最大需求，若不存在这样一个安全序列，则称此时的状态为不安全状态如果一个系统处于安全状态，就不会死锁如果一个系统处于不安全状态，就有可能死锁避免死锁的实质：确保系统不进入不安全状态 安全状态实例例：假定系统中有三个进程 P1、P2 和 P3，共有 12 台打印机，三个进程对打印机的需求和占有情况如下表所示：T0时刻，存在一个安全序列（P2,P1,P3）首先分配P2两个资源，P2满足需求释放资源，此时有五个可用资源，再将这五个可用资源分配给P1，P1满足需求释放资源，此时有十个可用资源，再分配给P3七个，P3满足需求，至此，满足了每个进程的需求。安全序列可能不唯一如果将上例改为下图则进入不安全状态P2得到两个资源满足需求，释放资源后还有四个可用资源，此时这四个可用资源不能满足P1和P2的需求 银行家算法实质设法保证系统动态分配资源后不进入不安全状态 前提进程必须预先提出自己的最大资源请求数量，这一数量不能超过系统资源的数量，系统资源的总量是一定的 数据结构假定系统中有n个进程（P1,P2,…,Pn）,m类资源（R1,R2,…,Rm） 可利用资源向量：Available[j]=k，表示Rj类资源有k个可用 最大需求矩阵：Max[i,j]=k，进程Pi最大请求k个Rj类资源 分配矩阵：Allocation[i,j]=k，进程Pi已经分配到k个Rj类资源 需求矩阵：Need[i,j]=k，进程Pi还需要k个Rj类资源 Need[i,j]=Max[i,j]-Allocation[i,j] 算法描述资源分配算法假定进程Pi请求分配Rj类资源k个，设Request[i,j]=k，当进程Pi发出资源请求后，系统按如下步骤进行检查： 如果Request[i,j]≤Need[i,j]，转(2)；否则出错，因为进程申请资源量超过它声明的最大量 如果Request[i,j]≤Available[j]，转(3)；否则表示资源不够，需等待 系统试分配资源给进城Pi，并做如下修改1.Available[j]=Available[j]-Request[i,j]2.Allocation[i,j]=Allocation[i,j]+Request[i,j]3.Need[i,j]=Need[i,j]-Request[i,j] 系统执行安全性算法。若安全，则正式进行分配，否则恢复原状态让进程Pi等待 安全性算法为了进行安全检查，需要定义如下数据结构1.工作变量Work[m]：记录可用资源。开始时，Work=Available2.finish[n]：记录系统是否有足够的资源分配给进程，使之运行完成。开始时，finish[i]=false；当有足够资源分配给进程Pi时，令finish[i]=true 执行过程： Work:=Available;Finish[i]=false 寻找满足如下条件的进程PiFinish[i]=falseNeed[i,j]≤Wrok[j]，如果找到，转(3)，否则转(4) 当进程Pi获得资源后，可顺利执行完，并释放分配给它的资源，故执行：Work[j]:=Work[j]+Allocation[i,j];Finish[i]:=true,转(2) 若所有进程的Finish[i]=true，则表示系统处于安全状态，否则处于不安全状态 例题这里就以计算T0时刻的安全性为例这里提一下，建议大家做题的时候也像上图一样画一个表格，注意每一列所对应的内容，首先根据初始的Work也就是Available找到Need小于Work的进程，然后记录下出Work+Allocation的值，并将Finish改为true，再计算下一个的时候直接用刚刚计算的Work+Allocation代替Work继续寻找小于该值的Need，以此类推，这样做起来逻辑比较清楚，不容易出错。 死锁的检测和解除如果在一个系统中，既未采用死锁预防方法，也未采用死锁避免方法，而是直接为进程分配资源，则系统中便有可能发生死锁检测死锁的基本思想：在操作系统中保存资源的请求和分配信息，利用某种算法对这些信息加以检查，以判断是否存在死锁 资源分配图资源分配图又称进程-资源图，它是描述进程和资源间的申请和分配关系的一种有向图圆圈：进程节点P方框：资源节点R，方框中的小黑点数表示资源数请求边：Pi-&gt;Rj分配边：Rj-&gt;Pi 如果资源分配图中不存在环路，则系统中不存在死锁；反之，如果资源分配图中存在环路，则系统中可能存在死锁，也可能不存在死锁 资源分配图的化简方法 寻找一个既不阻塞也不孤立的进程节点Pi，若无则算法结束； 去除Pi的所有分配边和请求边，使Pi成为一个孤立结点 转步骤(1) 在进行一系列化简后，若能消去图中所有的边，使所有进程都成为孤立结点，则称该图是可完全简化的；反之，称该图是不可完全简化的孤立结点：没有请求边和分配边与之相连阻塞结点：有请求边但资源无法满足其要求死锁定理：出现死锁的充分条件是资源分配图不可完全简化 可以完全简化不可完全简化，三个进程结点均为阻塞结点资源分配图的化简结果与化简顺序无关，最终结果相同 死锁的解除常用的解除死锁方法有两种： 资源剥夺法: 当发现死锁后，从其它进程剥夺足够数量的资源给死锁进 程，以解除死锁状态。 撤消进程法: 采用强制手段从系统中撤消一个/一部分死锁进程，并剥夺这些进程的资源供其它死锁进程使用。 撤消全部死锁进程。 按照某种顺序逐个地撤消进程，直至有足够的资源可用，使死锁状态消除 为止。","link":"/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%865%E2%80%94%E2%80%94%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6%E4%B8%8E%E6%AD%BB%E9%94%81%EF%BC%882%EF%BC%89/"},{"title":"操作系统笔记整理8——虚拟存储器","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 虚拟存储器概述虚拟存储器：指具有调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统请求调入功能：在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页或段调入到内存，然后继续执行程序 置换功能：操作系统将内存中暂时不使用的页或段调出保存在外存上，从而腾出空间存放将要装入的程序以及将要调入的页或段 虚拟存储：具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统 速度和容量：虚拟存储量的扩大是以牺牲 CPU 工作时间以及内外存交换 时间为代价。虚拟存储器的容量取决于主存与辅存的容量，最大容量是由计算机的地 址结构决定。 请求分页存储管理方式请求页表机制状态位P：表示该页是否已调入内存，供程序访问时参考访问字段A：记录本页在一段时间内被访问的次数或最近未被访问的时间，供选择页面换出时参考修改位M：表示该页在调入内存后是否被修改过，若修改过，则置换该页时需重写该页至外存，供置换页面时参考外存地址：指出该页在外存上的地址，供调入该页时参考 地址变换 物理块的分配策略 固定分配局部置换固定分配：为每个进程分配固定数目n的物理块，在进程运行期间不再改变局部置换：如果进程在运行过程中发现缺页，则只能从分配给该进程的n个页面中选出一页换出，再调入一页，以保证分配给该进程的内存空间不变。 可变分配全局置换可变分配：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少全局置换：如果进程在运行中发现缺页，则将OS所保留的空闲物理块取出一块分配给该进程，或者以所有进程的全部物理块为标的，选择一块换出，然后将所缺之页调入 可变分配局部置换 例题 例：一个采用请求分页存储管理的计算机系统，其内存（实存）容量为256M 字节，虚拟内存容量（给用户的最大地址空间）为 4G 字节，页面大 小为 4K 字节，试问：实存物理地址应设为多少位？28 位实存中有多少物理块？64K实存中最大块号是多少？64K-1虚存地址应设多少位？32 位 虚拟地址空间最多可以有多少页？1M页内最大偏移量是多少？4095 何时调页 预调页策略预调页：将预计在不久之后便会被访问的页面预先调入内存。进程的页一般存放在外存的一个连续区域中。一次调入若干个相邻的页会 比一次调入一页更高效。但如果调入的一批页面中的大多数都未被访问，则浪费了内存。 请求调页策略当进程在运行中发生缺页时，就立即提出请求，由系统将缺页调入内存。 但这种策略每次仅调入一页，须花费较大的系统开销，增加了启动磁盘 I/O 的频率。 何处调页在请求分页系统中，外存分成了按离散分配方式存放文件的文件区和按连续分配 方式存放对换页的对换区。进程发出缺页请求时，从何处将缺页调入内存呢？ 对换区：如果系统有足够的对换区空间，运行前可将与进程相关的文件从文件 区复制至对换区，以后缺页时全部从对换区调页。 文件区：如果系统没有足够的对换区空间，凡是不会被修改的文件，直接从文 件区调页，不必回写（换出）。对可能会修改的文件第一次直接从文件区调页， 换出时换至对换区，以后从对换区调页。 UNIX 方式：凡未运行过的页面均从文件区调页，运行过的页面和换出的页面均 从对换区调页。 缺页率访问页 面成功（页在内存）次数为 S，缺页（页不在内存）次数为 F，则缺页率为：$$f= \\frac{F}{F + S}$$ 页面置换算法抖动刚被淘汰出内存的页面，过后不久又要访问它，需要再次将其调入，而该页调入内存后不久又再次被淘汰出内存，然后又要访问它，如此反复，使得系统把大部分时间用在了页面的调进换出上，这种现象称为抖动。 最佳置换算法（OPT）OPT：Optimal permutation algorithm 选择在最长时间内不再被访问的页面置换出 最佳置换算法是一种理想化的算法，性能最好，实际上这种算法无法实 现，因为页面访问的未来顺序很难精确预测，但可用该算法评价其它算 法的优劣。 例：假定系统为某进程分配了 3 个物理块，进程运行时的页面走向为1,2,3,4,1,2,5,1,2,3,4,5，开始时 3 个物理块均为空，计算采用最佳置换算 法时的缺页率？缺页率：7/12 先进先出置换算法（FIFO）选择先进入内存的页面予以淘汰 假定系统为某进程分配了3 个物理块， 进程运行时的页面走向为1,2,3,4,1,2,5,1,2,3,4,5，开始时 3 个物理块均为空，计算采用先进先出置换 算法时的缺页率？缺页率：9/12 先进先出算法存在一种异常现象，即在某些情况下会出现分配给进程的物理块数增多，缺页次数有时增加，有时减少的奇怪现象，这种现象称为Belady异常现象 最近最久未使用算法（LRU）LRU：Least recently used选择最近一段时间最长时间没有被访问过的页面予以淘汰 例： 假定系统为某进程分配了3 个物理块， 进程运行时的页面走向为1,2,3,4,1,2,5,1,2,3,4,5，开始时 3 个物理块均为空，计算采用最近最久未使 用算法时的缺页率？缺页率：10/12 硬件支持寄存器：记录某个进程在内存中各页的使用情况，为每个进程在内存中的页面配置一个移位寄存器，可表示为R=Rn-1Rn-2Rn-3……R2R1R0每当进程访问某页面时，将该页面对应寄存器的最高位 (Rn−1) 置 1，系统定期 (如 100ms) 将寄存器右移一位并将最高位补 0，如果把 n 位寄存器的数 看作是一个整数，于是寄存器数值最小的页面是最久未使用的页面。栈：利用一特殊的栈保存当前使用的页号，每当进程访问某页面时，把被访问 页面移到栈顶，于是栈底的页面就是最久未使用的页面。 最近最少使用置换算法（LFU）LFU：Least frequently used选择在最近时期使用最少的页面为淘汰页LFU 置换算法为在内存中的每个页面设置一个移位寄存器来记录该页面 被访问的频率。每当进程访问某页面时，将该页面对应寄存器的最高位 (Rn−1) 置 1，系统定期 (如 100ms) 将寄存器右移一位并将最高位补 0。在一段时间内，ΣRi最小的页面就是最近最少使用的页面。 LRU 是看时间长短，而 LFU 是看使用频率。 Clock置换算法该算法为每页设置一个访问位，并将内存中的所有页链接成一个循环队列。当某页被访问时，其访问位被置1置换算法在选择一页淘汰时，只需检查页的访问位，如果是0，就选择该页换出；若为1，则重新将它置0，暂不换出，再按照FIFO算法检查下一个页面（循环，不是回到队首） 注：上图中插入倒数第二个页面时，物理块2中的2不带星号，图片有误 改进型Clock置换算法除须考虑页面的使用情况外，还增加一个因素，即置换代价，这样选择页面换出时，既要是未使用过的页面，又要是未被修改过的页面。 由访问位 A 和修改位 M 可以组合成下面四种类型的页面： A=0, M=0: 最佳淘汰页 A=0, M=1 A=1, M=0 A=1, M=1 1 从指针所指示的当前位置开始扫描循环队列，寻找 A=0 且 M=0 的第一类页面，将所遇到的第一个页面作为所选中的淘汰页。在第一次扫描期间 不改变访问位 A。2 如果第一步失败，开始第二轮扫描，寻找 A=0 且 M=1 的第二类页面，将所遇到的第一个这类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的访问位都置 0。3 如果第二步也失败，则将指针返回到开始的位置，并将所有的访问位复0。然后重复第一步，如果仍失败，必要时再重复第二步。 页面置换算法的比较 页面缓冲算法页面缓冲算法：用FIFO算法选择被置换页，选择换出的页不是立即换出，而是放入两个链表之一，如果页面未被修改，就将其归入到空闲页面链表的末尾，否则将其归入以修改页面链表的末尾。这些空闲页面和已修改页面会在内存中停留一段时间。如果这些页面被再次访问，只需将其从相应链表中移出，就可以返回进程，从而减少一次 I/O 开销。需调入新页，则将新页读入到空闲页面链表的第一个页面中，然后将其从该链表中移出。当已修改的页面达到一定数目后，再将它们一起写入磁盘。这样能大大减少 I/O 操作的次数。 访问内存的有效时间（EAT） 被访问页在内存，且对应的页表项在快表中设访问快表的时间为 λ，访问内存的时间为 t。EAT = λ + t 被访问页面在内存，但对应的页表项不在快表中。这种情况不缺页，但需两次访问内存。一次读页表，并更新快表，一次读数据。EAT = λ（查快表） + t（读页表） + λ（更新快表） + t（读数据） 被访问页面不在内存。设缺页中断处理时间为 ϵ。EAT= λ（查快表） + t（读页表）+ ϵ（缺页中断处理） + λ（更新快表） + t（读数据） 考虑快表的命中率 a，和缺页率 fEAT = （查快表）λ + （快表命中）a × t + （快表未命中）（1 - a）× （（查页表）t + （缺页）f × （ϵ + λ + t）+ (不缺页)（1 - f）×（λ + t）） 内存访问时间 t 约为 100ns(纳秒)=0.1μs (微秒)缺页中断时间 ϵ 约为 25ms (毫秒) =25000 μs (微秒) 抖动与工作集产生抖动的根本原因是，同时在系统中运行的进程太多，由此分配给每一个进程的物理块太少，不能满足进程正常运行的基本要求，致使每个进程在运行时，频繁地出现缺页，必须请求系统将所缺之页调入内存。 驻留集：指请求分页存储管理中给进程分配的物理页面（块）的集合。每个进程的驻留集越小，则同时驻留内存的进程就越多，CPU 利用率越高。进程的驻留集太小的话，则缺页率高，请求调页的开销增大。抖动的原因：多道程序度过高，导致平均驻留集过小。 工作集是指在某段时间间隔 ∆ 里，进程实际要访问的页面的集合。把进程在某段时间间隔 ∆ 里，在时间 t 的工作集记为 w(t,∆)，变量 ∆ 称 为工作集“窗口尺寸”。 下图是某进程访问页面的序列和窗口大小分别为3，4，5时的工作集。可将工作集定义为，进程在时间间隔（t-∆，t）中引用页面的集合 如果页面正在使用，它就落在工作集中；如果不再使用，它将不出现在 相应的工作集中。工作集是局部性原理的近似表示。 抖动的预防方法 采取局部置换策略仅允许进程在自身范围内进行置换。即使发生抖动，也可以把影响限制 在较小范围内。 在处理机调度中引入工作集策略 用 L=S 准则调节缺页率（Denning, 1980）L：缺页之间的平均时间。S：平均缺页服务时间L 大于 S，很少缺页，磁盘能力没有被充分利用。L 小于 S，频繁缺页，超过磁盘的处理能力。调整并发程序度，使得 L 与 S 接近。这种情况下，磁盘和处理机到可以达 到最佳利用率。一种类似的策略称为“50% 准则”策略：让磁盘保持50% 的利用率，这时CPU也达到最高的利用率。 挂起若干进程当多道程序度偏高，已影响到处理机的利用率时，为了防止发生抖动，系统必须减少多道程序的数目。把某些进程挂起，从而腾出内存空间。 请求分段存储管理存取方式：由于应用程序中的段是信息的逻辑单位，可根据该信息的属性对它实施保护，故在段表中增加存取方式字段，如果该字段为两位，则存取属性是只执行、只读和允许读/写存在位：指示本段是否已调入内存增补位：表示本段在运行过程中是否做过动态增长 共享段表共享段计数count：记录有多少进程正在共享该分段 共享段的分配当第一个使用共享段的进程提出请求时，由系统为该共享段分配一物理 区，并调入该共享段，同时修改相应的段表（该段的内存地址）和共享 段表，把 count 置为 1 。当其它进程需要调用此段时，不需再调入，只 需修改相应的段表和共享段表，再执行 count :=count+1 操作。共享段的回收当共享共享段的某进程不再使用该共享段时，修改相应的段表和共享段 表，执行 count :=count-1 操作。当最后一共享此段的进程也不再需要此 段时，则系统回收此共享段的物理区，同时修改共享段表（删除该表项）。","link":"/2021/12/31/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%868%E2%80%94%E2%80%94%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8/"},{"title":"等概率抽样——水塘抽样","text":"​​点击阅读更多查看文章内容 等概率抽样——水塘抽样给出一个数据流，这个数据流的长度很大或者未知。并且对该数据流中数据只能访问一次，且不能使用额外的空间，请写出一个随机选择算法，使得数据流中所有数据被选中的概率相等。 从头开始遍历数据，当遍历到第n个数据时，从0到n-1中随机选取一个数字，如果选到数字0，则将答案置为该数据的值，否则答案不变继续向下抽样，遍历完所有数据后，抽到每个数据的概率都是$\\frac {1}{n}$ 证明：P(第i个数据为最终答案)=P(第i个数据抽到随机数0)×P(第i+1个数据没有抽到随机数0)×P(第i+2个数据没有抽到随机数0)×···×P(第n个数据没有抽到随机数0)=$\\frac {1}{i}$×(1-$\\frac {1}{i+1}$)×(1-$\\frac {1}{i+2}$)×···×(1-$\\frac {1}{n}$)=$\\frac {1}{i}$×$\\frac {i}{i+1}$×$\\frac {i+1}{i+2}$×···×$\\frac {n-1}{n}$=$\\frac {1}{n}$ 例题LeetCode382. 链表随机节点 给你一个单链表，随机选择链表的一个节点，并返回相应的节点值。每个节点 被选中的概率一样 。实现 Solution 类：Solution(ListNode head) 使用整数数组初始化对象。int getRandom() 从链表中随机选择一个节点并返回该节点的值。链表中所有节点被选中的概率相等。 123456789101112131415161718192021222324252627class Solution{public: ListNode *head; Solution(ListNode *head) { this-&gt;head = head; } int getRandom() { int ret = 0; int i = 1; ListNode *node = head; while (node) { int t = rand() % i; if (t == 0) { ret = node-&gt;val; } node = node-&gt;next; i++; } return ret; }};","link":"/2022/01/16/%E7%AD%89%E6%A6%82%E7%8E%87%E6%8A%BD%E6%A0%B7%E2%80%94%E2%80%94%E6%B0%B4%E5%A1%98%E6%8A%BD%E6%A0%B7/"},{"title":"操作系统笔记整理9——输入输出系统（1）","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：操作系统笔记整理——目录索引页 参考书籍：《计算机操作系统》第四版 汤小丹等编著 @[toc] 输入输出系统是操作系统对计算机系统中除 CPU 和内存之外的外部设备 进行管理、对数据传输进行控制的模块，是操作系统资源管理中最复杂、 最多样化的部分。 I/O系统的功能、模型和接口I/O 系统：用于实现数据输入、输出及数据存储的系统。 I/O 系统的任务 完成用户提出的I/O请求，提高I/O速率，提高设备的利用率，并能为更高层的进程方便地使用这些设备提供手段 I/O系统的基本功能1.隐藏物理设备的细节2.与设备的无关性3.提高处理机和I/O设备的利用率4.对I/O设备进行控制5.确保对设备的正确共享6.错误处理 I/O软件的层次结构 I/O设备和设备控制器由于设备中电子部分比机械部分的速度快得多，为了降低硬件成本，将 电子部分从设备中分离出来作为一个独立的部件，这就是设备控制器。 控制器常采用印刷电路卡的形式插入计算机中（接口卡）。 设备控制器：设备控制器负责控制一个或多个 I/O 设备，实现处理机与 I/O 设备之间的 数据交换。设备控制器是处于 CPU 与 I/O 设备之间的接口，接收从CPU发来的命令，去控制I/O设备工作，使处理机能从繁杂的设备控制事务中解脱出来设备控制器是一个可编址设备。当它仅控制一个设备时，它只有一个唯一的设备地址，若连接多个设备，则应含有多个设备地址 设备控制器的基本功能 接受和识别命令 数据交换 标识和报告设备的状态 地址识别 数据缓冲区 差错控制 设备控制器的组成 设备控制器与处理机的接口：用于实现 CPU 与设备控制器之间的通信。共有三类信号线: 数据线、地址线和控制线 设备控制器与设备的接口：一个接口连接一台设备。在每个接口中都存在数据、控制和状态三种类 型的信号。 I/O逻辑：用于实现对设备的控制。通过一组控制线与处理机交互，接收 命令并对命令和地址进行译码。 寄存器：控制寄存器（存放命令及参数）、数据寄存器（存放数据）、状态寄存器（记录设备状态）。 内存映像I/O 驱动程序把抽象的 I/O 命令变成具体的命令和参数，装入 设备控制器的寄存器中，由控制器执行有两种实现方式：利用特定的I/O指令把CPU 寄存器的内容复制到控制器寄存器中：Io-store cpu-reg, dev-no, dev-reg把CPU 寄存器的内容复制到内存地址为 k 的单元中：Store cpu-reg, k缺点：访问内存和访问设备需要两个不同的指令。 内存映像I/O：不区分内存单元地址和控制器寄存器地址（寄存器占用内存地址的一部 分），采用统一的 I/O 指令。Store cpu-reg, k k 小于 n 时，被认为是内存地址，大于等于 n 时，被认为是某个控制器寄存器地址。 通道虽然在CPU与I/O设备之间增加了设备控制器后，已能大大减少CPU对I/O的干预，但当主机所配置的外设很多时，CPU的负担仍然很重。为此，在CPU和设备控制器之间又增设了I/O通道。通道是一种特殊的专门执行 I/O 指令的处理机，与 CPU 共享内存，可以 有自己的总线。 引入通道的目的：解脱 CPU 对 I/O 的组织、管理。CPU 只需发送 I/O 命令给通道，通道通过调用内存中的相应通道程序完成 任务，仅当通道完成了规定的 I/O 任务后，才向 CPU 发中断信号。通道与一般处理机的差异执行的命令主要局限于与 I/O 操作有关的指令。通道没有自己的内存（与 CPU 共享内存）。 通道类型字节多路通道工作原理：主通道含有许多非分配型子通道，每一个子通道连接一台I/O设备，并控制该设备的I/O操作。这些子通道按时间片轮转方式共享主通道。当第一个子通道控制器I/O设备完成一个字节的交换后，便立即腾出主通道，让给第二个子通道使用；当第二个子通道也完成一个字节的交换后，同样也把主通道让给第三个子通道；以此类推。当所有子通道轮转一周后，重又返回第一个子通道优点：可连多台中/低速设备；能分时并行操作。缺点：传输率较低。 数组选择通道工作原理：数据传送是按成组方式进行工作，每次传输一批数据。主要用于连接高 速 I/O 设备。一个主通道含有多个子通道，每子通道通过一控制器与一台高速的 I/O 设备相连，在一段时间内只能选 择一个子通道程序执行。优点：可连多台高速设备；传输率较高。缺点：一段时间内只能执行一道通道程序。某子通道不传数据，而使主 通道闲置，其它子通道也不能传数据。所以通道的利用率很低。 数组多路通道工作原理：数据传送仍是按数组方式工作。工作原理（结合前两者：并行 + 数组）一个主通道含有多个子通道。每子通道通过一控制器与一台中/高速的 I/O 设备相连，可同时并行向主通道传数据。各子通道以时间片轮转方式按数组方式使用主通道。优点：可连多台中/高速设备；能分时并行操作，传输率较高。 “瓶颈”问题假设设备1至设备4是四个磁盘，为了启动磁盘4，必须用通道1和控制器2；但若这两者已经被其他设备占用，则无法启动，这就是通道不足所造成的“瓶颈”现象。解决“瓶颈”问题最有效的方法，便是增加设备到主机间的通路而又不增加通道，如下图，就是把一个设备连接到多个控制器上，而一个控制器有链接到多个通道上。多通路方式不仅解决了“瓶颈”问题，而且提高了系统的可靠性 中断机构和中断处理程序 中断在操作系统中有着特殊重要的地位，它是多道程序得以实现的基础，没有中断，就不可能实现多道程序，因为进程之间的切换是通过中断来完成的。另一方面，中断也是设备管理的基础，为了提高处理机的利用率和实现CPU与I/O设备并行执行，也必须有中断的支持。 中断：CPU 对外部某个事件作出的一种响应。某个事件发生时，系统中 止现运行程序的执行，引出处理事件程序对相应事件进行处理，处理完 毕后返回断点继续执行。陷入：由 CPU 内部事件引起的中断。如非法指令、地址越界等。（内中 断）中断处理程序：对中断事件进行处理的程序。如时钟中断处理、打印机 完成中断处理、打印机缺纸中断处理等。中断向量表：表项为中断处理程序的入口地址。当设备发出中断请求信 号后，根据中断号查中断向量表，取得该设备中断处理程序的入口地址对多中断源的处理方式： 屏蔽中断：在处理一个中断时屏蔽掉所有的中断，即处理机对任何新到的中断请求都暂时不予理睬，所有的中断都会按次序顺序处理。优点是简单，但不适合实时性要求较高的系统。 嵌套中断：①如果同时有多个中断请求，CPU 优先响应优先级最高的中 断请求。②高优先级中断请求抢占低优先级中断的处理机。 中断处理程序当一个进程请求 I/O 时，进程将被阻塞，直到 I/O 完成。I/O 完成后，设备控制器向 CPU 发出一个中断请求，CPU 响应中断请求 后转向中断处理程序。中断处理程序执行相应的处理后，唤醒被阻塞的进程。 中断处理程序是操作系统中与硬件最接近的一部分 处理过程： 检测是否有未响应的中断请求。每当设备完成一个字符的读入（或输出）时，设备控制器便向处理机发送一个中断请求信号。请求处理机将设备已读入的数据传送到内存的缓冲区中（读入），或者请求处理机将要输出的数据（输出）传送给设备控制器。程序每当执行完当前指令后，处理机都要测试是否有未响应的中断信号。若没有，继续执行下一条指令。若有，则停止原有进程的执行，准备转去执行中断处理程序。注意：缺页中断在指令执行期间 产生和处理中断信号，且一条指令在执行期间可能产生多次缺页中断。 保护被中断进程的CPU环境 转入相应的中断处理程序 中断处理 恢复被中断进程的现场并退出中断 设备驱动程序设备驱动程序通常又称为设备处理程序，它是 I/O 进程与设备控制器之间的通信程序，它常以进程的形式存在。系统处理输入输出请求的步骤： I/O软件系统接受用户发出的I/O请求，需要通过系统调用取得操作系统的服务。 执行到与I/O请求相对应的系统调用后，转去执行操作系统的核心程序（设备驱动程序），此时处理机状态由用户态转到核心态。 启动设备工作。 I/O 完成后，由通道（或设备）产生中断信号。CPU 接到中断请求后， 如条件符合，则响应中断，转去执行相应的中断处理程序。唤醒因等待I/O 而阻塞的进程，调度用户进程继续运行。 设备驱动程序的功能 接受由与设备无关的软件发来的命令和参数，并将命令中的抽象要求转换为具体要求。例如，将磁盘块号转换为磁盘的 盘面、磁道号及扇区号。 检查用户 I/O 请求的合法性、I/O 设备状态、传递有关参数、设置设备的 工作方式。 发出 I/O 命令。按处理机的 I/O 请求去启动指定的设备进行 I/O 操作。 及时响应由控制器或通道发来的中断请求，并进行相应处理。 设备驱动程序的特点 设备驱动程序是实现在与设备无关软件与设备控制器之间的一个通信和 转换程序。把抽象的命令转为具体的 I/O 操作。 与 I/O 设备的特性紧密相关。 与 I/O 控制方式紧密相关，常用的I/O控制方式是中断驱动和DMA方式。 与硬件紧密相关，因而其中一部分程序必须用汇编语言编写。很多驱动 程序的基本部分已经固化在 ROM 中。 驱动程序应允许可重入。一个正在运行的驱动程序常会在一次调用完成 前被再次调用。 设备处理的方式 为每一类设备设置一个进程，专门执行这类设备的 I/O 操作。 在整个系统中设置一个进程，执行所有的 I/O 操作。 不设置专门的设备处理进程，而为各类设备设置相应的设备驱动程序， 供用户进程或系统进程调用。这类方式目前使用最多。 设备驱动程序的处理过程 将抽象要求转为具体要求 对服务请求进行校验 检查设备的状态（是否为就绪态） 传送必要的参数（如内存始址和字节数） 设置设备的工作方式 按处理机的I/O请求去启动指定的设备 对I/O设备的控制方式采用可轮询的可编程I/O方式（程序直接控制方式）当 CPU 向设备控制器发送完命令后（状态寄存器中的忙/闲标志 busy 置 为 1），CPU 就循环检测设备控制器中的状态寄存器（轮询），看 I/O 操作是否 完成，直到 I/O 完成（busy=0）。CPU 大部分时间都处于检查和等待状态，整个计算系统的效率十分低下。 采用中断的可编程I/O方式进程向CPU发出指令启动I/O设备输入数据该进程放弃处理机（CPU转去做其它工作，此时CPU与I/O设备并行操作），等待输入完成输入完成后，I/O 控制器向 CPU 发出中断请求，CPU 收到后，转向中断服务程序。中断服务程序将输入寄存器中的数据送指定内存单元，并将原进程唤醒，继续执行。优点：CPU 不需等待数据传输完成，I/O 设备与 CPU 并行工作，CPU 的利用率因此提高。（例如，从终端输入一个字符的时间约为 100 ms，而将字符送入终端缓冲 区的时间小于 0.1 ms。若采用程序 I/O 方式，CPU 约有 99.9 ms 的时间 处于忙等待。采用中断驱动方式，CPU 可利用这 99.9 ms 的时间去做其 它事情，而仅用 0.1 ms 的时间来处理中断请求。）缺点：CPU 在响应中断后，还需要时间来执行中断服务程序。如果数据 量大，需要多次执行中断程序，CPU 的效率仍然不高 直接存储器访问方式（DMA）程序直接控制方式是以字 (节) 为单位进行 I/O。中断控制方式仍是以字 (节) 为单位进行 I/O。也就是说在采用中断控制方 式的 I/O 中，CPU 每字节的传送就产生一次中断。 直接存储器访问 (DMA)I/O 控制方式数据传输的基本单位是数据块。数据从设备直接送入内存或相反。整块数据的传送在 DMA 控制器的控制下完成，CPU 仅在数据传输的起止 时参与。 DMA控制器组成： 主机与 DMA 控制器的接口 DMA 控制器与块设备的接口 I/O 逻辑控制 DMA 控制器中设置如下四类寄存器： 命令/状态寄存器 (CR) 内存地址寄存器 (MAR)：输入时存放设备到内存的内存始址；输出存放由 内存到设备的内存源地址。 数据寄存器 (DR) 数据计数器 (DC)：存放本次 CPU 要读或写的字节数。 DMA工作过程 需要 I/O 的进程向 CPU 发出指令，向 DMA 控制器写入数据存放的内存 始址、传送的字节数，并置中断位和启动位，启动 I/O 设备输入数据并允 许中断。 进程放弃处理机等待输入完成，处理机被其它进程占据。 DMA 控制器挪用存储器周期，把一个字节的数据写入MAR所指示的内存单元，然后便对MAR内容加1，将DC内容减1，若DC内容不为0，表示传送未完，继续传送下一个字节。 DMA 控制器传送完数据后向 CPU 发中断请求，CPU 响应后转向中断服 务程序唤醒进程，返回被中断进程。 在以后该进程再被调度，从内存取出数据进行处理。 周期挪用是利用 CPU 不访问存储器的那些周期来实现 DMA 操作。周期挪用不减慢 CPU 的操作，但数据传送过程是不连续和不规则的。DMA 控制器在获得总线控制权后（窃取总线控制权、挪用存储器周 期），直接在内存与外设之间实现数据传送。CPU 和 DMA 传送不完全并行，会有总线竞争。处理器用总线时可能稍 作等待，但不会引起中断，不引起程序上下文的切换。 I/O通道方式通道相当于一个独立于 CPU 的专管 I/O 控制的处理机，用于控制设备与内存直 接进行数据交换。I/O 通道方式中以一组数据块为单位进行干 预。通道有自己的一套简单的指令系统，称为通道指令。每条通道指令规定了设备 的一种操作，通道指令序列便是通道程序，通道执行通道程序来完成规定动作。通道靠执行通道程序软件完成数据传输，通道控制器的功能比 DMA控制器更强 大，它能够承担外设的大部分工作。通道有自己的总线，不需要窃取总线控制 权。 通道控制工作过程 需要 I/O 的进程向 CPU 发出指令，CPU 发出启动设备指令，指明 I/O 操 作、设备号和对应的通道。 该进程放弃 CPU 等待输入完成，CPU 被其它进程占据。 通道接收到 CPU 发来的启动指令后，取出内存中的通道程序执行，控制 设备将数据传送到内存指定区域。 传送完数据后，通道向 CPU 发中断请求，CPU 响应后转向中断服务程 序，唤醒进程，并返回被中断进程。 在以后该进程再被调度，从内存取出数据进行处理。 通道指令的格式操作码：规定了指令所要执行的操作，如读、写等。计数：表示本条指令要读（写）数据的字节数。内存地址：数据要送入的内存地址或从内存何处取出数据。通道程序结束位 P：P=1 表示本条指令是通道程序的最后一条指令。记录结束位 R：R=0 表示本条指令与下一条指令所处理的数据属于一个 记录，R=1 表示该指令处理的数据是最后一条记录。 DMA 方式与中断方式的区别中断方式是在数据寄存器满之后发中断请求，而 DMA 方式则是在数据块 全部传送结束时请求中断。中断方式的数据传送是在中断处理时由 CPU 控制完成的，而 DMA 方式则 是在 DMA 控制器的控制下不经过 CPU 控制完成的。 DMA 方式与通道方式的区别在 DMA 方式中，数据的传送方向、存放数据的内存始址以及传送的数据块 长度等都由 CPU 控制，而在通道方式中，这些都由通道来进行控制。 例：假设幼儿园一个老师带 10 个孩子，要给每个孩子分 4 块糖。方法一：她先给孩子甲一块糖，盯着甲吃完，然后再给第二块，等吃完 第二块又给第三块，吃完第三块又给第四块。接着给孩子乙，其过程与 孩子甲完全一样。依次类推，直至到第 10 个孩子发完四块糖。孩子们吃 糖时她一直在守候，什么事也不能干。（程序直接控制方式）方法二：每人发一块糖各自去吃，并约定谁吃完后就向她举手报告，再 发第二块。在未接到孩子们吃完糖的报告以前，她还可以腾出时间给孩 子们改作业。（中断控制方式）方法三：每人拿 4 块糖各自去吃，吃完 4 块糖后再向她报告。这种方法 工作效率大大提高，她可以腾出更多的时间改作业。（直接存储器访问方 式 (DMA)）方法四：把发糖的事交给另一个人分管，只是必要时她才过问一下。（通 道控制方式） 与设备无关的I/O软件设备独立性：为提高 OS 的可适应性和可扩展性，将应用程序独 立于具体使用的物理设备。驱动程序是一个与硬件紧密相关的软件。为了实现设备独立性，必须再 在驱动程序之上设置一层软件，称为设备独立性软件（与设备无关的软 件）。 设备独立性软件执行所有设备的公有操作：1.设备驱动程序的统一接口2.缓冲管理3.差错控制4.对独立设备的分配与回收5.提供独立与设备的逻辑数据块 设备分配的数据结构 设备控制表（DCT）：每个设备一张，记录设备的情况 控制器控制表（COCT）：每个控制器一张，记录控制器的情况 通道控制表（CHCT）：每个通道一张 系统设备表（SDT）：记录系统中全部设备的情况 设备分配时应考虑的因素1.设备的固有属性2.设备分配算法 先来先服务 优先级高者优先3.设备分配的安全性 逻辑设备表LUT逻辑设备名到物理设备名映射的实现每个表目中包含三项：逻辑设备名、物理设备名和设备驱动程序的入口 地址。分配流程：进程给出逻辑名，通过 LUT 得到物理设备及其 driver 入口。","link":"/2022/01/01/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%869%E2%80%94%E2%80%94%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%B3%BB%E7%BB%9F%EF%BC%881%EF%BC%89/"},{"title":"数据结构——单调栈","text":"​​点击阅读更多查看文章内容 单调栈定义单调递增栈：单调递增栈就是从栈底到栈顶数据是从小到大单调递减栈：单调递减栈就是从栈底到栈顶数据是从大到小 实现以单调递增栈为例，向栈中推入元素时，如果栈顶元素比当前元素大，则将栈顶元素推出，直到栈顶元素比当前元素小或者栈为空，然后将当前元素推入栈中。 1234567stack&lt;int&gt; sta;for (遍历数组){ while (栈不为空 &amp;&amp; 栈顶元素大于当前元素) sta.pop(); sta.push(当前元素);} 作用找到左边（右边）第一个比当前元素小（大）的元素。 例题LeetCode 84","link":"/2021/08/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E2%80%94%E2%80%94%E5%8D%95%E8%B0%83%E6%A0%88/"},{"title":"算法模板总结","text":"​​点击阅读更多查看文章内容 （小菜鸡的第一篇博客保存了一些算法的模板+例题，以防用到的时候找不到）博客里面都是一些最最最基本的模板，大佬请自动忽略。。。。 一、BFS123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//#include&lt;bits/stdc++.h&gt;#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;queue&gt;const int maxx = 205;using namespace std;int n, m;int vis[maxx][maxx];int dis[maxx][maxx];int loc[4][4] = { {-1,0},{1,0},{0,1},{0,-1} };char s[maxx][maxx];int ans;void bfs(int ss,int sd){ //pair&lt;int,int&gt; p; //p.first 第一个元素 p.second 第二个元素 queue&lt;pair&lt;int, int&gt;&gt; q; q.push(make_pair(ss, sd)); vis[ss][sd] = 1; while (!q.empty()) { int l = q.front().first; int r = q.front().second; q.pop(); for (int i = 0; i &lt; 4; i++) { int u = l + loc[i][0]; int v = r + loc[i][1]; if (s[u][v] != '#' &amp;&amp; u &lt;= n &amp;&amp; u &gt; 0 &amp;&amp; v &lt;= m &amp;&amp; v &gt; 0&amp;&amp;vis[u][v]==0) { dis[u][v] = dis[l][r] + 1; if (s[u][v] == 'x') dis[u][v]++; vis[u][v] = 1; q.push(make_pair(u, v)); if (s[u][v] == 'r'&amp;&amp;dis[u][v]&lt;ans) ans=dis[u][v]; } } }}int main(){ ios::sync_with_stdio(0); int ss, sd; while (cin &gt;&gt; n &gt;&gt; m) { memset(vis, 0, sizeof vis); memset(dis, 0, sizeof dis); ans = 99999; for (int i = 1; i &lt;= n; i++) { cin &gt;&gt; (s[i] + 1); for (int j = 1; j &lt;= m; j++) { if (s[i][j] == 'a') { ss = i; sd = j; } } } bfs(ss, sd); if (ans==99999) { cout &lt;&lt; &quot;Poor ANGEL has to stay in the prison all his life.\\n&quot;; } else cout &lt;&lt;ans &lt;&lt; endl; }} 二、DFS1234567891011121314151617181920212223void dfs(){ if (到达终点状态) { ... return; } if (越界或者是不合法状态) return; if (特殊状态) return; for (扩展方式) { if (扩展方式所到达状态合法) { 修改操作;//根据题意来添加标记 dfs(); 还原标记; //是否还原标记根据题意 //如果加上(还原标记)就是回溯法 } }} 三、DP12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//动态规划dp//过河卒 洛谷P1002#include&lt;iostream&gt;using namespace std;int a[25][25] = {0};int dp[25][25] = {0};int fx[8] = { 2,1,-1,-2,-2,-1,1,2 };int fy[8] = { 1,2,2,1,-1,-2,-2,-1 };int n, m, p, q;void init(){ a[p][q] = 1; for (int i = 0; i &lt;= 7; i++) { if (p + fx[i] &gt;= 0 &amp;&amp; p + fx[i] &lt;= n &amp;&amp; q + fy[i] &gt;= 0 &amp;&amp; q + fy[i] &lt;= m ) { a[p + fx[i]][q + fy[i]] = 1; } }}void dpp(){ dp[0][0] = 0; for (int j = 1; j&lt;=m; j++) { if (a[0][j] != 1) dp[0][j] = 1; else break; } for (int i = 1; i&lt;=n; i++) { if (a[i][0] != 1) dp[i][0] = 1; else break; } for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= m; j++) { if (a[i][j] == 1) dp[i][j] == 0; else dp[i][j] = dp[i - 1][j] + dp[i][j - 1]; } }}int main(){ cin &gt;&gt; n &gt;&gt; m &gt;&gt; p &gt;&gt; q; init(); dpp(); cout &lt;&lt; dp[n][m];} 四、KMP1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include&lt;iostream&gt;using namespace std;void makeNext(const char P[], int next[]){ int q, k;//q是当前要计算第q个字符的next值，k是对应的next值 int m = strlen(P); next[0] = 0; for (q = 1, k = 0; q &lt; m; q++) { while (k &gt; 0 &amp;&amp; P[k] != P[q]) { k = next[k - 1]; } if (P[q] == P[k]) { k++; } next[q] = k; }}int kmp(const char T[], const char P[], int next[]){ int n, m; n = strlen(T); m = strlen(P); makeNext(P, next); int i = 0; int j = 0; while (i &lt; n &amp;&amp; j &lt; m) { if ( j==0||T[i] == P[j]) { i++; j++; } else { j = next[j-1]; } } if (j == m) return i - m + 1; else return -1; }int main(){ int next[100] = { 0 }; char T[] = &quot;abababababc&quot;; char P[] = &quot;abc&quot;; cout&lt;&lt;kmp(T, P, next); return 0;} 五、素数筛1234567891011121314151617181920212223242526#include&lt;iostream&gt;using namespace std;bool str[100010]; //开始定义一个全局变量数组 void prime() //这个函数可以将1~100010内的所有素数都找出来，所以在main()函数开头执行一遍就行了 { str[1] = 1; //希望读者能将这一块跟第二种方法进行一个比较，便于理解 for (int i = 2; i * i &lt;= 100010; i++) { if (!str[i]) { for (int j = i * i; j &lt;= 100010; j += i) str[j] = 1; } }}int main(){ prime(); //执行程序开始的打表操作 int n; while (cin &gt;&gt; n) { if (str[n]) cout &lt;&lt; &quot;不是素数！&quot; &lt;&lt; endl; //判断是否为素数 else cout &lt;&lt; &quot;是素数！&quot; &lt;&lt; endl; } return 0;} 六、拓扑排序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;queue&gt;#include&lt;vector&gt;using namespace std;const int MX = 500 + 10;int N, M;vector&lt;int&gt;G[MX];//可约当做声明了一个二维数组int indegree[MX];//记录各定点入度的数组queue&lt;int&gt;q;//初始化，将AOV网存储到数据结构中void init(){ for (int i = 1; i &lt;= M; i++)//M是关系数 { int node1, node2; cin &gt;&gt; node1 &gt;&gt; node2; G[node1].push_back(node2); //在G[node1]的尾部加入数据node2，表示node2是node1的直接后继 indegree[node2]++;//node2的入度加一 }}int topo_sort(){ for (int i = 1; i &lt;= N; i++) if (indegree[i] == 0) q.push(i);//若i的入度为0，则将i入队 int cnt = 0; while (!q.empty()) { cnt++; int tmp = q.front();//记录当前队头元素 q.pop(); for (int i = 0; i &lt; G[tmp].size(); i++)//遍历当前队头元素tmp的所有直接后继 { int node = G[tmp][i];//node记录tmp的第i个直接后继（i从0开始） indegree[node]--; if (indegree[node] == 0) q.push(node);//入度为0，则入队 } if (!q.empty()) cout &lt;&lt; tmp &lt;&lt; &quot; &quot;; else cout &lt;&lt; tmp;//使最后一个输出数据后面无空格 } if (cnt &lt; N) return -1;//说明存在点没有入队，即成环。} 七、字典树1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;const int MAXN = 26;struct Trie{ // 代表当前节点可以延伸出的边，数量可变 Trie* Next[MAXN]; // 标记当前节点是否是保存信息的结尾，也可以代表前缀个数 int Flag; Trie() { // 初始化以该信息为前缀的信息个数 Flag = 1; memset(Next, NULL, sizeof(Next)); }};Trie* root = new Trie();void Insert(string s){ int len = s.length(); int id; Trie* p = root; Trie* q; //将s的每一个字符插入trie树 for (int i = 0; i &lt; len; i++) { id = s[i] - 'a'; //如果没有边，则新建一个trie节点，产生一条边，用以代表该字符。 if (p-&gt;Next[id] == NULL) { q = new Trie(); p-&gt;Next[id] = q; p = p-&gt;Next[id]; } //如果存在边，则沿着该边走。 else { p = p-&gt;Next[id]; //累加以该信息为前缀的信息个数 ++(p-&gt;Flag); } }}int Query(const char* str){ int len = strlen(str); Trie* p = root; //在trie树上顺序搜索str的每一个字符 for (int i = 0; i &lt; len; ++i) { int id = str[i] - 'a'; p = p-&gt;Next[id]; if (p == NULL) return 0; } return p-&gt;Flag;}void Free(Trie* T){ if (T == NULL) return; //释放trie树的每一个节点占用的内存 for (int i = 0; i &lt; MAXN; ++i) { if(T-&gt;Next[i]) Free(T-&gt;Next[i]); } delete(T);}int main(){ const char* word[4] = {&quot;banana&quot;,&quot;band&quot;,&quot;bee&quot;,&quot;absolute&quot;}; const char* fore[4] = { &quot;ba&quot;,&quot;b&quot;,&quot;band&quot;,&quot;abc&quot; }; for (int i = 0; i &lt; 4; i++) { Insert(word[i]); } for (int i = 0; i &lt; 4; i++) { cout &lt;&lt; Query(fore[i]) &lt;&lt; endl; }} 八、最短路径123456789101112131415161718192021222324252627282930313233343536373839404142434445//最短路径// 1.floyed 时间复杂度O(n三次方)/*void floyed(){ for (int i = 1; i &lt;= n; i++)//通过中间顶点进行中转 { for (int k = 1; k &lt;= n; k++)//k为所有的起点 { for (int j = 1; j &lt;= n; j++)//j为终点 { m[k][j] = min(m[k][j], m[k][i] + m[i][j]); } } } return;}*/// 2.Dijkstra 时间复杂度O(n平方)void Dijkstra(){ for (int i = 1; i &lt;= n - 1; i++) { //找到离1号顶点最近的顶点 min1 = inf;//inf为无穷大 for (int j = 1; j &lt;= n; j++) { if (book[j] == 0 &amp;&amp; dis[j] &lt; min1)//找到距离起点最近的点 { min1 = dis[j];//更新离当前顶点最近的顶点 u = j; } } book[u] = 1;//标记u这个点进入S集合 for (int v = 1; v &lt;= n; v++) { if (e[u][v] &lt; inf)//u,v之间想通 { if (dis[v] &gt; e[u][v] + dis[u])//松弛 { dis[v] = dis[u] + e[u][v];//更新最短的路径 } } } }} 九、快速排序12345678910111213141516171819202122void quickSort(int s[], int l, int r){ int mid = s[(l + r) / 2]; int i = l, j = r; do { while (s[i] &lt; mid) i++; while (s[j] &gt; mid) j--; if (i &lt;= j) { swap(s[i], s[j]); i++; j--; } } while (i &lt;= j); if (l &lt; j) quickSort(s, l, j); if (i &lt; r) quickSort(s, i, r);} 十、背包123456789101112131415161718192021222324252627282930313233//01背包#include &lt;bits/stdc++.h&gt;using namespace std;int n,v,w,c,dp[1010];//dp[i]表示装入物品的质量为i时能获得的最大价值int main(){ cin&gt;&gt;v&gt;&gt;n;//v为背包容量，n为物品数量 for(int i=1;i&lt;=n;i++) { cin&gt;&gt;w&gt;&gt;c;//w为每个物品重量，c为每个物品价值 for(int j=v;j&gt;=w;j--)//背包容量从大到小遍历 dp[j]=max(dp[j],dp[j-w]+c);//选择不放入背包dp[j]还是放入背包dp[j-w]+c，更新为最大的dp[j] } printf(&quot;%d\\n&quot;,dp[v]);//装入物品的质量为v时能获得的最大价值 return 0;}//完全背包#include &lt;bits/stdc++.h&gt;using namespace std;int n,v,w,c,dp[100010];int main(){ cin&gt;&gt;v&gt;&gt;n; for(int i=1;i&lt;=n;i++) { cin&gt;&gt;w&gt;&gt;c; for(int j=w;j&lt;=v;j++)//背包容量从小到大遍历，这里与01背包循环顺序相反！ dp[j]=max(dp[j],dp[j-w]+c); } printf(&quot;%d\\n&quot;,dp[v]); return 0;}","link":"/2020/12/18/%E7%AE%97%E6%B3%95%E6%A8%A1%E6%9D%BF%E6%80%BB%E7%BB%93/"},{"title":"算法笔记——二分查找","text":"​​点击阅读更多查看文章内容 算法笔记——二分查找 二分查找：用于在有序数列中查找目标元素的位置 关于区间边界的问题二分法，区间的定义一般为两种，左闭右闭即[left, right]，或者左闭右开即[left, right)。 左闭右闭 while (left &lt;= right) 要使用 &lt;= ，因为left == right是有意义的，所以使用 &lt;= if (nums[middle] &gt; target) right 要赋值为 middle - 1，因为当前这个nums[middle]一定不是target，那么接下来要查找的左区间结束下标位置就是 middle - 1，因为寻找区间是左闭右闭，所以right必须更新为middle-1而不是middle 左闭右开 while (left &lt; right)，这里使用 &lt; ,因为left == right在区间[left, right)是没有意义的 if (nums[middle] &gt; target) right 更新为 middle，因为当前nums[middle]不等于target，去左区间继续寻找，而寻找区间是左闭右开区间，所以right更新为middle，middle不包含在区间内 如果可以自己选择区间的话建议使用左闭右闭区间 关于查找的值的问题这里查找目标值有三种情况 查找给定值 查找小于等于给定值的最大值 查找大于等于给定值的最小值 1.查找给定值这个比较简单，直接上代码具体实现细节写在注释中 1234567891011121314151617int BinarySearch(vector&lt;int&gt; nums, int target) { int n = nums.size(); int left = 0; int right = n - 1; //前闭后闭区间 while (left &lt;= right) { int mid = left + (right - left) / 2; //防止直接相加溢出 if (target == nums[mid]) //找到目标值，直接输出下标 return mid; else if (target &gt; nums[mid]) // target比nums[mid]大，目标值在mid右侧，更新区间为右侧区间 left = mid + 1; else right = mid - 1; // target比nums[mid]小，目标值在左侧，更新区间为左侧区间 } return -1; //没有找到目标值，输出-1 } 2.查找小于等于给定值的最大值123456789101112131415161718int LowerTarget(vector&lt;int&gt; nums, int target) { int n = nums.size(); int left = 0; int right = n - 1; //前闭后闭区间 while (left &lt; right) //这里是通过不断缩小区间来找要求的值，所以当left==right时，目标值已经找到循环就应该退出了 { int mid = left + (right - left + 1) / 2; //这里要加1，即mid要取高位的数，否则可能出现死循环 if (nums[mid] &lt;= target) // 如果nums[mid]小于等于target，那么最终要求的值可能是mid也可能在mid的左侧，所以left=mid而不是mid+1 left = mid; else right = mid - 1; // nums[mid]大于target，应该在左侧区间查找，所以right=mid-1 } //这里left与right相等，用哪个都一样 if (nums[left] &gt; target) //因为要找的小于等于target的最大值，如果最终得到的值比target还大的话就代表数组中的所有元素都比target大，找不到目标值输出-1 return -1; return left; } 这里有三个点需要注意 while(left&lt;right) int mid=left+(right-left+1)/2 if(nums[mid]&lt;=target) left=mid 具体原因在代码注释中已经写清楚了，第一第三点比较好理解，第二点可以自己带入一组数据试一下 如：在[1,9,25]中找小于等于10的最大值如果不加第二点 left=0,right=2 mid=1,nums[mid]=9,9&lt;target,left=mid=1 left=1,right=2;mid=1出现死循环 加上第二点后 left=0,right=2 mid=1,nums[mid]=9,9&lt;target,left=mid=1 left=1,right=2,mid=2,nums[mid]=25&gt;target,right=mid-1=1 left=right 退出循环 3.查找大于等于给定值的最小值这个与上一个类似，对比上一个看即可 123456789101112131415161718int UpperTarget(vector&lt;int&gt; nums, int target) { int n = nums.size(); int left = 0; int right = n - 1; //前闭后闭区间 while (left &lt; right) //这里是通过不断缩小区间来找要求的值，所以当left==right时，目标值已经找到循环就应该退出了 { int mid = left + (right - left) / 2; // mid取低位的数，否则可能出现死循环 if (nums[mid] &gt;= target) // 如果nums[mid]大于等于target，那么要求的值可能是mid也可能在mid的左侧，所以right=mid而不是mid-1 right = mid; else left = mid + 1; // nums[mid]小于target，应该在右侧区间查找，所以left=mid+1 } //这里left与right相等，用哪个都一样 if (nums[left] &lt; target) //因为要找的大于等于target的最小值，如果最终得到的值比target还小的话就代表数组中的所有元素都比target小，找不到目标值，输出-1 return -1; return left; } 关于C++内置函数的使用C++中有两个内置函数lower_bound和upper_bound，都是使用二分查找实现的 lower_bound在从小到大的排序数组中：lower_bound( begin,end,num)：从数组的begin位置到end-1位置二分查找第一个大于或等于num的数字，找到返回该数字的地址，不存在则返回end。通过返回的地址减去起始地址begin,得到找到数字在数组中的下标。 在从大到小的排序数组中，重载lower_bound()：lower_bound( begin,end,num,greater() ):从数组的begin位置到end-1位置二分查找第一个小于或等于num的数字，找到返回该数字的地址，不存在则返回end。通过返回的地址减去起始地址begin,得到找到数字在数组中的下标。 核心代码： 12345678while (left &lt; right) { mid = left + (right - left) / 2; if (nums[mid] &gt;= target) right = mid; else left = mid + 1; } upper_bound在从小到大的排序数组中：upper_bound( begin,end,num)：从数组的begin位置到end-1位置二分查找第一个大于num的数字，找到返回该数字的地址，不存在则返回end。通过返回的地址减去起始地址begin,得到找到数字在数组中的下标。 在从大到小的排序数组中，重载upper_bound()：upper_bound( begin,end,num,greater() ):从数组的begin位置到end-1位置二分查找第一个小于num的数字，找到返回该数字的地址，不存在则返回end。通过返回的地址减去起始地址begin,得到找到数字在数组中的下标。 核心代码： 12345678while (left &lt; right) { mid = left + (right - left) / 2; if (nums[mid] &lt;= target) left = mid + 1; else right = mid; } 使用方法123456vector&lt;int&gt; nums1{1, 3, 5, 7}; cout &lt;&lt; *lower_bound(nums1.begin(), nums1.end(), 3);//3 cout &lt;&lt; *upper_bound(nums1.begin(), nums1.end(), 3);//5 vector&lt;int&gt; nums2{9, 6, 3, 1}; cout &lt;&lt; *lower_bound(nums2.begin(), nums2.end(), 6, greater&lt;int&gt;());//6 cout &lt;&lt; *upper_bound(nums2.begin(), nums2.end(), 6, greater&lt;int&gt;());//3 例题34. 在排序数组中查找元素的第一个和最后一个位置33. 搜索旋转排序数组74. 搜索二维矩阵162. 寻找峰值","link":"/2022/02/27/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"},{"title":"算法笔记——动态规划","text":"​​点击阅读更多查看文章内容 算法笔记——动态规划 动态规划是一个非常灵活的算法，动态规划本身不难，无非就是一个状态转移的过程，难点就在于我们该如何去定义“状态”，而这就需要我们多做题来积累经验，这也是初学者遇到动态规划往往无从下手的原因。 动态规划的核心在于状态和状态转移方程，状态具体该如何去定义，需要大家多做题来体会，下面主要是记录一下动态规划的一般解题思路。 以122. 买卖股票的最佳时机 II为例给定一个数组 prices ，其中 prices[i] 表示股票第 i 天的价格。在每一天，你可能会决定购买和/或出售股票。你在任何时候最多只能持有一股股票。你也可以购买它，然后在同一天出售。返回你能获得的最大利润 。 1.将原问题分解为若干子问题这一步是为后续的状态定义做一个铺垫，注意分解的子问题一定要是连续的并且可以递推求得原问题的解，且分解的子问题一定要保证不能遗漏（有些情况下可以重复，比如求最大值，有些情况下不能重复，比如求序列和——重复的话就会有元素被用了两次）问题中是要求我们最终所能获得的最大利润，我们可以将其分解为截止到第一天所能获得的最大利润、截止到第二天所能所能获得的最大利润……截止到最后一天所能获得的最大利润，这样我们就将原来的问题分解为一系列的子问题 2.根据子问题定义状态根据第一步分解得到的子问题，我们可以根据其进行状态的定义了，状态其实就是对子问题的一种表示，状态的值就是我们所要求的解我们假设截止到第i天所能获得的最大利润为w，问题中还有一句话你在任何时候最多只能持有一股股票，由此我们可以用一个二维数组dp[][]来表示状态，第一维表示是第几天，第二维则表示你当前是否持有股票，我们可以用0表示没有股票，1表示有股票。综上，状态定义为：dp[i][0]-&gt;截止到第i天没有股票所能获得的最大利润；dp[i][1]-&gt;截止到第i天有股票所能获得的最大利润 3.确定边界条件所谓边界条件就是状态转移方程的初始条件或终止条件本问题中边界条件就是第1天的状态，第一天没有股票的话就是没有买也没有卖股票所获利润为dp[1][0]=0，第1天有股票的话就是在第一天买了一股股票此时因为没有卖出所以利润为dp[1][1]=-prices[1] 4.确定状态转移方程状态转移方程就是在确定得到当前状态的方法，即如何从一个已经求出的状态得到当前的状态，并最终递推得到最终值，状态转移方程是根据状态来定的。本题中第i天的状态为dp[i][0]和dp[i][1]，我们要找到从第i天到第i+1天的状态转移方程，注意题目中在每一天，你可能会决定购买和/或出售股票，我们在每一天可能发生的动作有购买/出售和不做任何操作三种首先考虑dp[i+1][0]，即第i+1天没有股票的状态，可能的状态转移方程有第i天没有股票，第i+1天不做任何操作；第i天有股票，第i+1天卖出了股票，最大的利润就是这两种转移方程的最大值，表示成代码为：dp[i+1][0]=max(dp[i][0],dp[i-1][1]+prices[i+1])然后考虑dp[i+1][1]，第第i+1天有股票的状态，可能的状态转移方程有第i天没有股票，第i+1天买入了股票；第i天有股票，第i+1天不做任何操作最大的利润就是这两种转移方程的最大值，表示成代码为：dp[i+1][1]=max(dp[i][0]-prices[i+1],dp[i][1]) 5.返回最终结果在状态转移方程确定后就可以按顺序计算出最终结果了，这里一定要注意状态转移方程执行的顺序，因为这是一个递推的过程，所以必须保证当前方程用到的上一个状态已经得到了。本题中，执行顺序就是从第1天开始，依次求到最后一天，然后返回从第一天截止到最后一天没有股票的最大利润即可（注意这里最后一天没有股票的最大利润一定是大于有股票的） 完整代码 12345678910int maxProfit(vector&lt;int&gt;&amp; prices) { int n = prices.size(); int dp[n][2]; dp[0][0] = 0, dp[0][1] = -prices[0]; for (int i = 1; i &lt; n; ++i) { dp[i][0] = max(dp[i - 1][0], dp[i - 1][1] + prices[i]); dp[i][1] = max(dp[i - 1][1], dp[i - 1][0] - prices[i]); } return dp[n - 1][0];} 动态规划总的来说还是需要多做题积累经验，难点就在于如何定义问题的状态，之后就是根据题意确定状态转移方程即可 以上是我对动态规划的理解，下面还有学习了y总的闫氏DP分析法，简单总结了一下，大家也可以参考一下 闫氏DP分析法将dp问题分成状态表示和状态计算，这里的状态表示就是我们上面说到的状态定义，状态计算就是确定状态转移方程状态表示化零为整即将一类情况表示为一个集合状态计算化整为零即将这个集合分解成各个子集，由子集递推出这个集合 01背包问题——题目链接1.状态表示(化零为整)f[i][j]-&gt;i为考虑前i个物品，j为某种限制，这里是物体体积 集合：所有只考虑前i个物品，且总体积不超过j的选法的集合属性：最大价值 2.状态计算：(化整为零)找最后一个不同点，选不选第i个物品，由此可以将状态表示的集合划分为所有不选第i个物品的方案和所有选第i个物品的方案-&gt;满足不重复不遗漏 求f[i][j]的最大值只需要分别求选/不选第i个物品的两个集合的最大价值，然后取其中较大的即可。 不选第i个物品的最大值：f[i-1][j] 选择第i个物品的最大值：分成变化和不变的部分，其中不变的部分即一定要选第i个物品价值为wi，变化的部分为前i-1个物品的最大值f[i-1][j-vi],两者相加为f[i-1][j-vi]+wi Ps:实际情况中还需要特判一下，比如第二种情况当j&lt;vi的时候是不可能包含第i个物品的 1234567891011121314151617181920212223242526272829#include &lt;bits/stdc++.h&gt;using namespace std;const int N = 1001;int f[N][N];int W[N];int V[N];int main(){ int n, v; cin &gt;&gt; n &gt;&gt; v; for (int i = 1; i &lt;= n; i++) cin &gt;&gt; V[i] &gt;&gt; W[i]; for (int i = 1; i &lt;= n; i++) { for (int j = 0; j &lt;= v; j++) { f[i][j] = f[i - 1][j]; if (j &gt;= V[i]) f[i][j] = max(f[i][j], f[i - 1][j - V[i]] + W[i]); } } cout &lt;&lt; f[n][v]; return 0;} 空间优化f[i][j]=max(f[i-1][j],f[i-1][j-vi]+wi)计算f[i]时只会用到f[i-1]的数据，可以使用滚动数组来存储结果，进一步第二维只会用j或者j-vi一个比自己小的数，这样只要保证从大到小循环保证f[j-vi]存放的是上一层的f[j-vi]即可简化为下列方程f[j]=max(f[j],f[j-vi]+wi) 1234567891011121314151617181920212223#include &lt;bits/stdc++.h&gt;using namespace std;const int N = 1001;int f[N];int W[N];int V[N];int main(){ int n, v; cin &gt;&gt; n &gt;&gt; v; for (int i = 1; i &lt;= n; i++) cin &gt;&gt; V[i] &gt;&gt; W[i]; for (int i = 1; i &lt;= n; i++) for (int j = v; j &gt;= V[i]; j--) f[j] = max(f[j], f[j - V[i]] + W[i]); cout &lt;&lt; f[v]; return 0;} 完全背包——题目链接状态表示与0/1背包相同状态计算完全背包每个物品都有无限多个，集合可以被分成选0/1/2……直到不能选为止 f[i][j]=max(f[i-1][j],f[i-1][j-v]+w,f[i-2][j-2v]+2w,……)将j替换为j-vf[i][j-v]=max(f[i-1][j-v],f[i-1][j-2v]+w,f[i-1][j-3v]+2w,……)结合上述两式可得:f[i][j]=max(f[i-1][j]],f[i][j-v]+w)Ps:也可从概念上理解，f[i][j]可以表示为不选i的最大值即f[i-1][j]和选了一件i之后继续从前i件物品(包括i)中选择的最大值f[i][j-v]+w 01背包： f[i][j]=max(f[i-1][j],f[i-1][j-v]+w)完全背包: f[i][j]=max(f[i-1][j],f[i][j-v]+w)两者只在最后一个f[i-1]/f[i]上有区别，到优化了空间的代码中就是从后往前枚举和从前往后枚举的区别 123456789101112131415161718192021222324252627#include &lt;bits/stdc++.h&gt;using namespace std;const int N = 1001;int f[N][N];int W[N];int V[N];int main(){ int n, v; cin &gt;&gt; n &gt;&gt; v; for (int i = 1; i &lt;= n; i++) cin &gt;&gt; V[i] &gt;&gt; W[i]; for (int i = 1; i &lt;= n; i++) for (int j = 0; j &lt;= v; j++) { f[i][j] = f[i - 1][j]; if (j &gt;= V[i]) f[i][j] = max(f[i - 1][j], f[i][j - V[i]] + W[i]); } cout &lt;&lt; f[n][v]; return 0;} 空间优化 1234567891011121314151617181920212223#include &lt;bits/stdc++.h&gt;using namespace std;const int N = 1001;int f[N];int W[N];int V[N];int main(){ int n, v; cin &gt;&gt; n &gt;&gt; v; for (int i = 1; i &lt;= n; i++) cin &gt;&gt; V[i] &gt;&gt; W[i]; for (int i = 1; i &lt;= n; i++) for (int j = V[i]; j &lt;= v; j++) f[j] = max(f[j], f[j - V[i]] + W[i]); cout &lt;&lt; f[v]; return 0;} 区间DP问题（石子合并）——题目链接状态表示f[i][j]：合并i到j堆石子的总代价 集合：所有将[i,j]合并成一堆的方案的集合属性：代价的最小值 状态计算集合可以分为[i,i]和[i+1,j]、[i,i+1]和[i+2,j]……共j-i类情况f[i][j]即为这j-i类情况的最小值 1234567891011121314151617181920212223242526272829#include &lt;bits/stdc++.h&gt;using namespace std;const int N = 310;int f[N][N];int s[N];int main(){ int n; cin &gt;&gt; n; for (int i = 1; i &lt;= n; i++) { cin &gt;&gt; s[i]; s[i] += s[i - 1]; } for (int i = n; i &gt;= 1; i--) { for (int j = i+1; j &lt;= n; j++) { f[i][j]=INT_MAX; for (int k = i; k &lt; j; k++) f[i][j] = min(f[i][j], f[i][k] + f[k + 1][j] + s[j] - s[i - 1]); } } cout &lt;&lt; f[1][n]; return 0;}","link":"/2022/03/24/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"title":"算法笔记——双指针","text":"​​点击阅读更多查看文章内容 算法笔记——双指针 双指针即使用两个指针对对象进行扫描，一般有快慢指针和左右指针两种，快慢指针指从一侧开始同时向另一侧移动但是移动速度不同，左右指针则是分别从两侧向对方移动 双指针的内容不多，但是使用起来非常灵活，需要多做题体会思路 快慢指针的常见用法1. 判断链表是否有环单链表的特点是每个节点只知道下一个节点，所以一个指针的话无法判断链表中是否含有环的。 如果链表中不含环，那么这个指针最终会遇到空指针 null 表示链表到头了，这还好说，可以判断该链表不含环。但是如果链表中含有环，那么这个指针就会陷入死循环，因为环形数组中没有 null 指针作为尾部节点。 经典解法就是用两个指针，一个每次前进两步，一个每次前进一步。如果不含有环，跑得快的那个指针最终会遇到 null，说明链表不含环；如果含有环，快指针最终会超慢指针一圈，和慢指针相遇，说明链表含有环。 2. 已知链表有环，返回环的起始位置参考文章当快慢指针相遇的时候，让其中任何一个指针指向链表头，然后让这两个指针以相同的速度前进，再次相遇时所在的节点位置就是环开始的位置。 第一次相遇的时候，假设慢指针slow走了k步，那么快指针一定走了2k步，也就是说slow多走了k步，这k步就是环的长度 假设相遇点与环的起点的距离为m（橙色曲线所示），那么环的起点与头节点head的距离为k-m。这是因为慢指针走了k步，这k步包含了头节点到环的起点（绿色直线部分），以及环起点到相遇点（橙色部分），而后者的距离为m，那么环的起点与头节点head的距离就为k-m。但因为整个环的长度为k，所以从相遇点继续前进k-m步（绿色曲线部分），也会到达环起点，正好与头节点和环起点的距离是一样的。 所以我们只需要把快慢指针的任意一个重新指向head，然后两个指针以向相同的速度前进，在走k-m步之后，两个指针必会相遇，而相遇点就是环的起点 3. 寻找链表的中点类似上面的思路，我们还可以让快指针一次前进两步，慢指针一次前进一步，当快指针到达链表尽头时，慢指针就处于链表的中间位置。 4. 寻找链表的倒数第 k 个元素我们的思路还是使用快慢指针，让快指针先走 k 步，然后快慢指针开始同速前进。这样当快指针走到链表末尾 null 时，慢指针所在的位置就是倒数第 k 个链表节点（为了简化，假设 k 不会超过链表长度） 5. 滑动窗口例如：求不含有重复字符的最长子串用到了滑动窗口的算法，滑动窗⼝的右边界不断的右移，只要没有重复的字符，就持续向右扩大窗口边界。⼀旦出现了重复字符，就需要缩小左边界，直到重复的字符移出了左边界，然后继续移动滑动窗口的右边界。以此类推，每次移动需要计算当前长度，并判断是否需要更新最大长度度，最终最大的值就是题目所求。 参考文章（含代码） 左右指针的常见用法二分查找在二分查找中我们分别定义了一个left和一个right来指向对应元素，这也属于左右指针的一种 双指针的用法还有很多，大家可以通过下面的例题继续加深理解 例题82. 删除排序链表中的重复元素 II15. 三数之和844. 比较含退格的字符串986. 区间列表的交集11. 盛最多水的容器","link":"/2022/03/01/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%8F%8C%E6%8C%87%E9%92%88/"},{"title":"算法笔记——回溯","text":"​​点击阅读更多查看文章内容 算法笔记——回溯 回溯法实际上就是把问题的解空间转化成了图或者树的结构表示，然后使用深度优先搜索策略进行遍历，如果遍历的过程中发现已不满足求解条件时，就“回溯”（即回退），尝试别的路径。 思想回溯法从根结点出发，按照深度优先策略遍历解空间树，搜索满足约束条件的解。当搜索至树中的任一结点时，先判断该结点对应的部分解是否满足约束条件，或者是否超出目标函数的界限，也就是判断该结点是否可能包含问题的可行解： 如果肯定不包含，则跳过对以该结点为根的子树的搜索，即所谓剪枝；否则，进入以该结点为根的子树，继续按照深度优先策略搜索并进行判断。注意：在算法运行时并不需要构造一棵真正的解空间树结构，只需要存储从根结点到当前结点的路径。 回溯算法需要设计合适的剪枝策略，尽量避免不必要的搜索。 常用的剪枝策略包括两大类： 约束函数剪枝：根据约束条件，状态空间图中的部分状态可能是不合法的。 因此，在状态空间图中以不合法状态为根的子树是不可能包含可行解的，故其子空间不需要搜索。限界函数剪枝：这种策略一般应用于最优化问题。假设搜索算法当前访问的状态为𝑆，且存在一个判定函数：它能判定以𝑺为根的子树不可能包含最优解， 因此该子树可以剪除而无需搜索。用约束函数在扩展结点处剪除不满足约束的子树，即剪除不可行解；用限界函数剪去得不到问题解或最优解的子树。 所以，回溯算法 = 深度优先搜索 + 剪枝策略 这一部分参考回溯算法 模板以八皇后为例 123456789101112131415161718192021222324void search(int cur){ if (cur == n) //递归边界，若走到这里，所有皇后必然不冲突 tot++; else { for (int i = 0; i &lt; n; i++) //枚举每一列 { int ok = 1; C[cur] = i; //尝试把第cur行的皇后放在第i列 for (int j = 0; j &lt; cur; j++) //检查是否和前面的皇后冲突 { if (C[cur] == C[j] || cur - C[cur] == j - C[j] || cur + C[cur] == j + C[j]) { ok = 0; break; //如果冲突，则退出循环，不必再递归这种情况，即“剪枝” } } if (ok) search(cur + 1); //如果合法，则继续递归 } }} 例题90. 子集 II47. 全排列 II40. 组合总和 II","link":"/2022/03/09/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%9B%9E%E6%BA%AF/"},{"title":"算法笔记——字典树","text":"​​点击阅读更多查看文章内容 算法笔记——字典树（Trie） 字典树又称为前缀树，是一种保存字符串（不限于字符串）的树形结构，字典树充分利用了字符串的公共前缀，节省了存储空间，同时可以用于求解一些与前缀有关的问题 结构字典树通过边来表示表示字符，每个节点所代表的字符序列就是从根节点到该节点的路径上的所有字符，同时为每个节点设置一个标志位来表示这个节点是否是单词的结尾。 以”able”、”cat”、”cater”,”can”、”to”、”two”所构成的字典树为例 实现节点定义：vector&lt;TrieNode *&gt; children：存储边如：children[‘c’-‘a’]不为空，那么该节点就有一条表示字符c的边isEnd：单词结束标志 12345678910struct TrieNode{ vector&lt;TrieNode *&gt; children; bool isEnd; TrieNode() { children.resize(26); isEnd = false; }}; 字典树定义：TrieNode *root：树的根节点，插入和查找操作都从根节点开始void insert(string word)：插入单词word从根节点开始按照word的单词顺序向下查找如果遇到null，就new一个新节点如果有节点，则直接走到已存在的节点单词结束时置节点的isEnd为truebool search()：查找单词从根节点开始按照word的单词顺序向下查找如果遇到空则不存在该单词，返回false如果查到结尾单词且节点的isEnd为true则返回true 12345678910111213141516171819202122232425262728struct Trie{ TrieNode *root = new TrieNode(); void insert(string word) { TrieNode *node = root; for (char c : word) { if (!node-&gt;children[c - 'a']) node-&gt;children[c - 'a'] = new TrieNode(); node = node-&gt;children[c - 'a']; } node-&gt;isEnd = true; } bool search(string word) { TrieNode *node = root; for (char c : word) { if (!node-&gt;children[c - 'a']) return false; node = node-&gt;children[c - 'a']; } return node-&gt;isEnd; }}; 应用1、字典树在串的快速检索中的应用。 给出N个单词组成的熟词表，以及一篇全用小写英文书写的文章，请你按最早出现的顺序写出所有不在熟词表中的生词。在这道题中，我们可以用字典树，先把熟词建一棵树，然后读入文章进行比较，这种方法效率是比较高的。 2、字典树在“串”排序方面的应用给定N个互不相同的仅由一个单词构成的英文名，让你将他们按字典序从小到大输出用字典树进行排序，采用数组的方式创建字典树，这棵树的每个结点的所有儿子很显然地按照其字母大小排序。对这棵树进行先序遍历即可。 3、字典树在最长公共前缀问题的应用对所有串建立字典树，对于两个串的最长公共前缀的长度即他们所在的结点的公共祖先个数，于是，问题就转化为最近公共祖先问题。 如果Trie树的平均高度为h，则Trie树的查询复杂度为O(h)，trie树的建立复杂度为O(n*h) 关于最近公共祖先问题可以先参考以下文章，等有时间再填这个坑最近公共祖先问题最近公共祖先问题 例题（待填）","link":"/2022/04/03/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%AD%97%E5%85%B8%E6%A0%91/"},{"title":"算法笔记——差分数组","text":"​​点击阅读更多查看文章内容 差分数组概念所谓差分数组就是对数组的相邻元素求差保存到一个新的数组中，这个数组就是差分数组。如下所示： 序号 0 1 2 3 4 原数组a 1 5 3 4 3 差分数组d 1 4 -2 1 -1 作用用于频繁的区间修改区间修改是对数组的一段区间同时加上或减去某一个数对上面的数组我们执行如下操作：1.对区间[0,3]中的每个元素加32.对区间[1,2]中的每个元素减2我们不难想到可以通过遍历区间中的每个元素来实现，但是如果区间很大，执行的操作很多时，这种方法很容易超时。这时就需要用到差分数组。 我们观察当我们对区间[0,3]中的每个元素进行加3操作时，差分数组只有d[0]和d[4]会发生变化。 序号 0 1 2 3 4 原数组a 4 8 6 7 3 差分数组d 4 4 -2 1 -4 同理，对区间[1,2]执行减2操作时，只有d[1]和d[3]会发生变化。 序号 0 1 2 3 4 原数组a 4 6 4 7 3 差分数组d 4 2 -2 3 -4 这就是差分数组所有的性质：当对区间[i,j]进行加减操作时，差分数组d[i]进行相同的操作，d[j+1]进行相反的操作。利用差分数组的这个性质，我们对数组任意长度的区间修改不再需要遍历每个元素而只需要修改差分数组两个元素的值即可。当进行完所有的区间操作后，对差分数组求一个前缀和即可得到原数组。因为d[i]=a[i]-a[i-1]，所以a[i]=a[i-1]+d[i]，并且有a[0]=d[0]，我们可以从前往后依次求出a[i]。 例题LeetCode1109 参考代码 12345678910111213141516171819202122class Solution{public: vector&lt;int&gt; corpFlightBookings(vector&lt;vector&lt;int&gt;&gt; &amp;bookings, int n) { vector&lt;int&gt; d(n, 0); for (int i = 0; i &lt; bookings.size(); i++) { int fir = bookings[i][0] - 1; int last = bookings[i][1] - 1; int seats = bookings[i][2]; d[fir] += seats; if(last+1&lt;n) d[last + 1] -= seats; } for (int i = 1; i &lt; n; i++) { d[i] += d[i - 1]; } return d; }};","link":"/2021/08/31/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%B7%AE%E5%88%86%E6%95%B0%E7%BB%84/"},{"title":"算法笔记——并查集","text":"​​点击阅读更多查看文章内容 算法笔记——并查集 并查集是一种树型的数据结构，用于处理一些不相交集合的合并及查询问题（即所谓的并、查）。 关于并查集的讲解有很多大佬的博客都写的很好，这里我主要是参考这篇文章——并查集 定义并查集实际上是一种树形结构，可以用来查询连通分支的个数，属于同一连通分支的在同一棵树上 主要变量pre[]:记录结点的前驱结点rank[]:记录结点的高度count:记录连通分支的个数 主要函数init():初始化join(x,y):合并x,y结点find(x):查找x结点所在树的根节点 函数定义1.find()这里通过find要一直找到根节点，当pre[x]=x时即找到根节点如果不等就一直往上查找即可，这里在返回时对pre[x]进行修改，可以压缩查找路径，具体原理在文章开头的博客中都有讲到 1234567int find(int x){ if (pre[x] == x) return x; else return pre[x] = find(pre[x]);} 2.join()要想连接两个结点，只需要把其中一个结点所在树的根节点接到另一棵树的根节点即可 首先判断两个结点是否属于同一棵树，即判断两个结点的根节点是否相等即可，如果相等，则两个结点已经连通，直接返回。 这里我们希望将高度小的树连接到高度大的树上，这样可以缩小连接后树的高度，所以首先分别对两棵树根节点的高度进行判断，如果高度不相等，则将小的连接到大的上，此时连接后原本的rank不变，如果两棵树高度相等的话，则被连接上的树的高度要加1，这里大家可以自己画图看看，还是比较好理解的。 两棵树相连后，总的连通分量的个数要减112345678910111213141516171819202122232425void join(int x, int y) { x = find(x); y = find(y); if (x == y) return; if (rank[x] &lt; rank[y]) { pre[x] = y; } else { if (rank[x] == rank[y]) { pre[x] = y; rank[y]++; } else { pre[y] = x; } } count--; } 3. init()关于init()函数主要是对pre[]以及rank[]的初始化，大家看文章最后的例题来加深理解。 例题并查集对不同题目中只有初始化方面有所不同，其它函数基本一致，下面通过两道例题主要感受一下并查集该怎么初始化，代码用到的都是上面刚刚写好的模板 547. 省份数量 代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class UnionFind{private: vector&lt;int&gt; pre; vector&lt;int&gt; rank; int count = 0;public: UnionFind(vector&lt;vector&lt;int&gt;&gt; isConnected) { int n = isConnected.size(); for (int i = 0; i &lt; n; i++) { pre.push_back(i); rank.push_back(1); count++; } } int find(int x) { if (x == pre[x]) return x; else return pre[x] = find(pre[x]); } void join(int x, int y) { x = find(x); y = find(y); if (x == y) return; if (rank[x] &lt; rank[y]) pre[x] = y; else { if (rank[x] == rank[y]) { pre[x] = y; rank[y]++; } else pre[y] = x; } count--; return; } int getCount() { return count; }};class Solution{public: int findCircleNum(vector&lt;vector&lt;int&gt;&gt; &amp;isConnected) { UnionFind uf(isConnected); int n = isConnected.size(); for (int i = 0; i &lt; n; i++) { for (int j = 0; j &lt; n; j++) { if (isConnected[i][j]) uf.join(i, j); } } return uf.getCount(); }}; 200. 岛屿数量 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106class UnionFind{private: vector&lt;int&gt; pre; vector&lt;int&gt; rank; int count = 0;public: UnionFind(vector&lt;vector&lt;char&gt;&gt; grid) { int n = grid.size(); int m = grid[0].size(); for (int i = 0; i &lt; n; i++) { for (int j = 0; j &lt; m; j++) { if (grid[i][j] == '1') { pre.push_back(i * m + j); rank.push_back(1); count++; } else { pre.push_back(-1); rank.push_back(-1); } } } } int find(int x) { if (pre[x] == x) return x; else return pre[x] = find(pre[x]); } void join(int x, int y) { x = find(x); y = find(y); if (x == y) return; if (rank[x] &lt; rank[y]) { pre[x] = y; } else { if (rank[x] == rank[y]) { pre[x] = y; rank[y]++; } else { pre[y] = x; } } count--; } int getCount() { return count; }};class Solution{private: int fx[4][2] = {{-1, 0}, {0, 1}, {1, 0}, {0, -1}};public: int numIslands(vector&lt;vector&lt;char&gt;&gt; &amp;grid) { int n = grid.size(); int m = grid[0].size(); UnionFind uf(grid); for (int i = 0; i &lt; n; i++) { for (int j = 0; j &lt; m; j++) { if (grid[i][j] == '1') { grid[i][j] = '0'; for (int k = 0; k &lt; 4; k++) { int newi = i + fx[k][0]; int newj = j + fx[k][1]; if (newi &gt;= 0 &amp;&amp; newi &lt; n &amp;&amp; newj &gt;= 0 &amp;&amp; newj &lt; m &amp;&amp; grid[newi][newj] == '1') { uf.join(i * m + j, newi * m + newj); } } } } } return uf.getCount(); }};","link":"/2022/03/04/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"title":"算法笔记——深度&#x2F;广度优先搜索","text":"​​点击阅读更多查看文章内容 算法笔记——深度/广度优先搜索 深度优先搜索和广度优先搜索主要是用在图的遍历中，模板性很强，我个人认为是比较简单的算法，下面主要写一下深搜和广搜的模板，照着模板多做题基本就能掌握了 深度优先搜索过程： 访问指定的起始顶点 若当前访问的顶点的邻接顶点有未被访问的,则选择其中一个顶点访问，然后回到第一步 若当前的顶点的邻接顶点都已经访问，则返回当前顶点的上一个顶点 如下图，其实就是先沿一条边访问到底，然后再返回访问另一条边 模板 DFS一般通过递归来实现 12345678910111213 void dfs(int x){ if (满足退出条件){ 退出处理 return; } for (;;){//枚举当前顶点的下一个邻接顶点 if (顶点满足条件) { 处理顶点 dfs(顶点);//向下深入遍历 } } return ;//退出 } 这里在枚举下一个邻接顶点的时候，如果是在图中，我习惯先定义一个方向向量，然后以此来枚举下一个顶点以上下左右四个方向为例：首先定义： 1int fx[4][2] = {{-1, 0}, {0, 1}, {1, 0}, {0, -1}}; 枚举： 1234for (int i = 0; i &lt; 4; i++){ dfs(x + fx[i][0], y + fx[i][1], board);} 广度优先搜索过程： 访问指定的起始顶点 将顶点的所有邻接顶点加入队列 返回第一步访问队列的队首元素，队首元素弹出 如下图，先将当前顶点的邻接顶点都加入队列，然后再访问下一层的邻接顶点 模板BFS一般通过队列来实现 12345678910111213141516queue&lt;int&gt; qu;//定义队列 qu.push(起始顶点); while (!qu.empty()) { auto front = qu.front(); qu.pop(); //获得首部顶点并将首部弹出 for (;;)//遍历当前顶点的所有邻接顶点并加入队列 { if (邻接顶点符合题目要求) { qu.push(邻接顶点); } } } 以上模板仅仅是最基础的样例，不同的题目肯定还会有所不同，大家还要在模板的基础上结合题意进行进一步的修改 例题1091. 二进制矩阵中的最短路径130. 被围绕的区域","link":"/2022/03/06/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E6%B7%B1%E5%BA%A6!%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2/"},{"title":"算法笔记——素数筛","text":"​​点击阅读更多查看文章内容 算法笔记——素数筛 求素数是我们经常会遇到的问题，如何能提高求解素数的效率对我们解决问题至关重要，本文会记录四种求素数的方法，分别是直观算法、朴素算法，埃氏筛法和欧拉筛法 素数的定义素数是指在大于1的自然数中，除了1和它本身以外不再有其他因数的自然数。（百度百科）这里需要注意素数的范围是大于1的自然数，即0和1都不是素数 直观算法直观算法是通过素数的定义来实现的，即除了1和它本身外不再有其他因素，那么我们要判断n是不是素数，只需要遍历看n是否能被2到n-1中的某个数整除即可 注：这种算法在实际判断中不会用到，这里只是为了解释素数的判断原理，实际判断某个数是否为素数推荐用下面的朴素算法 时间复杂度：O(n^2^) 代码实现 12345678910111213//从2到x-1遍历 bool isPrime(int x){ //0和1特判 if(x==0||x==1) return false; for(int i=2;i&lt;x;i++) { if(x%i==0) return false; } return true;} 朴素算法朴素算法对于上面直观算法的改进就在于，在判断n是否为素数时不会遍历到n-1，而是遍历到${\\sqrt{n}}$即可，因为我们在找n的因数时，n分解为的两个因数一定是一个小于等于${\\sqrt{n}}$，一个大于等于${\\sqrt{n}}$，极端情况就是两个因数都为${\\sqrt{n}}$，如果一直到${\\sqrt{n}}$都不存在n的因数，那么之后也一定不会存在n的因数 时间复杂度：O(n${\\sqrt{n}}$) 代码实现 123456789101112//从2到根号x遍历 bool isPrime(int x){ if(x==0||x==1) return false; for(int i=2;i*i&lt;=x;i++) { if(x%i==0) return false; } return true;} 埃氏筛法前面讲的都是判断一个数是否为素数，后面的两种方法则是筛选出一定范围内的所有素数 埃氏筛比较简单，假设要筛选出从2到N中的所有素数，通过一个数组将从2到N中的所有数都标记为素数，然后遍历从2到N，如果遍历到的数是素数，那么就把这个数在范围内的所有倍数都标记为非素数即可 埃氏筛的原理就是当我们遍历到一个数的时候，如果从2到这个数中有它的因数，那么在之前这个数就一定会被筛选出去。如果这个数没有被筛选出去，那么在这中间它就没有因数，从而可以判断其为素数 时间复杂度：O(nloglogn) 代码实现 123456789101112131415161718192021//埃氏筛//遍历从2到N，如果vis为0则是素数，同时将该素数在N以内的所有倍数置vis为1 const int N=100;//(筛选出1~100内的素数)int prime[N+1];//保存素数bool vis[N+1];//标记数组,vis=1表示不是素数 int cnt=0;//保存素数个数 void sieve(){ for(int i=2;i&lt;=N;i++) { if(!vis[i]) { prime[cnt++]=i; for(int j=2;i*j&lt;=N;j++) vis[i*j]=1; } } for(int i=0;i&lt;cnt;i++) cout&lt;&lt;prime[i]&lt;&lt;&quot; &quot;; return;} 欧拉筛法不知道大家有没有发现，在使用埃氏筛时有些数可能会被筛选多次，如12，它在i=2时会被26筛选一次，在i=3时又会被34筛选一次，这些重复的筛选影响了算法的执行效率欧拉筛即针对这些重复的筛选进行了一个改进——对于每个合数只由它的最小质因数筛选一次 时间复杂度：O(n) 欧拉筛的原理较为复杂，我们先上代码，根据代码来讲解 1234567891011121314151617181920212223//欧拉筛//在使用埃氏筛筛选素数时有些计算会重复，比如2*3与3*2，将6标记了两遍//欧拉筛的改进在于每个数只由它的最小素因数筛选一次const int N=100;//(筛选出1~100内的素数)int prime[N+1];//保存素数bool vis[N+1];//标记数组,vis=1表示不是素数 int cnt=0;//保存素数个数 void sieve(){ for(int i=2;i&lt;=N;i++) { if(!vis[i]) prime[cnt++]=i; for(int j=0;j&lt;cnt&amp;&amp;i*prime[j]&lt;=N;j++) { vis[i*prime[j]]=1; if(i%prime[j]==0) break; } } for(int i=0;i&lt;cnt;i++) cout&lt;&lt;prime[i]&lt;&lt;&quot; &quot;;} 变量的定义与埃氏筛相同，都是由vis来标记是否为素数，我们在这里重点关注内层循环 123456for(int j=0;j&lt;cnt&amp;&amp;i*prime[j]&lt;=N;j++){ vis[i*prime[j]]=1; if(i%prime[j]==0) break;} 这里是筛选出的是以prime[j]为最小素因子的合数，即prime[j]的i倍，这里筛选的顺序不太容易理解，我们先打一张表来详细看一下 注意这里，i为倍数，prime[j]为最小素因子以2为最小素因子的合数会从i=2开始一直筛到最后 然后我们以i=7为例，筛选以7为最小素因子的数时我们是从i=7开始筛的，那么7的2,3,4,5,6倍我们不就没有筛吗？实际上不是这样的，我们看i=7时prime[j]的值为2,3,5,7我们在筛选i*prime[j]时，实际上已经把小于7中的素数倍已经筛选出来了那么7的合数倍(4,6)又是怎么筛选的呢？以7*4为例我们可以将合数4分解为2*2，然后7*4就可以写成14*2，到这里我们就能看出来了，当i=14时我们就可以将14*2筛选出来了 说完上面这些好像跟埃氏筛也没有什么不同嘛，好像并没有实现每个合数只会由它的最小素因数筛选一遍，别急，下面我们就要看欧拉筛中最最最关键的一段代码了， 12if(i%prime[j]==0) break; 就是这一小段代码，就实现了只筛选一遍的改进，下面我们来分析这段代码当i%prime[j]==0时，i就可以写成k*prime[j]的形式，此时如果我们不退出循环，继续执行，则下一次要筛选出的数为i*prime[j+1]，我们将i代换为k*prime[j]那么下次筛选的数就是k*prime[j+1]*prime[j]，而这里这个数的最小质因数实际上应该是prime[j]（prime是单调递增的），即应该由prime[j]筛掉而不是prime[j+1]，如果这一步筛掉的话，那么后面必然会由prime[j]再重复筛选一次我们以i=4,prime[j]=2为例，这里筛选完之后因为4%2=0所以应该退出循环，我们假设其没有退出，继续筛选prime[j+1]=3此时筛掉的数字为4*3=12，12的最小质因数应该为2，那么当i=6，prime[j]=2时，12又会被筛选一次，这就导致了12的重复筛选 结语关于素数筛的部分到这里就讲完啦，其中欧拉筛的实现原理有些复杂，上面写的也有些繁琐不到位的地方，欢迎大家在评论区提出建议，希望这篇文章能帮助到大家。","link":"/2022/04/05/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%B4%A0%E6%95%B0%E7%AD%9B/"},{"title":"网络功能虚拟化（NFV）","text":"​​点击阅读更多查看文章内容 NFV基本概述转载文章：NFV基本概述 NFV介绍定义NFV，即网络功能虚拟化，Network Function Virtualization。通过使用x86等通用性硬件以及虚拟化技术，来承载很多功能的软件处理。从而降低网络昂贵的设备成本。可以通过软硬件解耦及功能抽象，使网络设备功能不再依赖于专用硬件，资源可以充分灵活共享，实现新业务的快速开发和部署，并基于实际业务需求进行自动部署、弹性伸缩、故障隔离和自愈等。 NFV的总体目标被定义为利用标准的IT虚拟化技术将众多网络设备类型合并成工业标准级的大容量服务器、交换机和存储设备，并在数据中心、网络结点和终端用户处所部署。 网络功能虚拟化（network functions virtualization，NFV）被定义为运行再虚拟机上且利用软件实现网络功能的虚拟化技术。 目标NFV的目标是取代通信网络中私有、专用和封闭的网元，实现统一通用硬件平台+业务逻辑软件的开放架构。 NFV与SDN结合使用将对未来通信网络的发展带来重大的影响，同时也带来新的问题和挑战。 发展缘由 网络运营商的网络通常是由大规模并且迅速增长的多种多样的硬件设备组成。开发一个新的网络业务经常需要新类型的设备，而为这些盒子需找空间、提供电源变得越来越困难；同时还伴随着能源成本的增加、投资额的挑战，基于硬件设备的复杂度提升，也增加了对设计、集成、运营所需要的各种稀有技能的要求。 更严重的问题是，基于硬件的设备很快就到了生命周期，这需要更多的“设计-集成-部署”循环，但收益甚少。糟糕的是，硬件生命周期变得越来越短而业务创新则在不断加速，所以这抑制了新增值业务的部署，并且限制了不断增长的网络为中心领域的创新。 网络虚拟化通过借用IT的虚拟化技术，许多类型的网络设备类型可以合并入工业界标准中，如servers、switches和storage，可以部署在数据中心、网络节点或是用户家里。网络虚拟化适用于固定、移动网络中任何数据面的分组处理和控制面功能。 来自企业、运营商、家庭用户的需求 随着云服务的不断发展和需求的不断增加，运营商只需要为企业私有云和公有云提供管道传输，因此运营商有被管道化的风险。 家庭用户在体验上不支持多屏应用、室外应用，业务开通周期长，费用昂贵。 企业用户需要高IT投入购买大量通信设备（路由器、交换机、服务器、存储设备）。 系统扩容需要更新设备，重复投资。 CPE（customer premises equipment）多为企业网的网关，对接运营商的PE设备。 NFV基本概念什么是NFVNFV即网络功能虚拟化（Network Functions Virtualization），将许多类型的网络设备（如servers，switches和storage等）构建为一个Data Center Network，通过借用IT的虚拟化技术虚拟化形成VM（虚拟机，Virtual Machine），然后将传统的CT(Communication Technology)业务部署到VM上。 在NFV出现之前设备的专业化很突出，具体设备都有其专门的功能实现，而之后设备的控制平面与具体设备进行分离，不同设备的控制平面基于虚拟机，虚拟机基于云操作系统，这样当企业需要部署新业务时只需要在开放的虚拟机平台上创建相应的虚机，然后在虚拟机上安装相应功能的软件包即可。这种方式我们就叫做网络功能虚拟化。 网络功能虚拟化的优点和面临的挑战网络功能虚拟化的优点： 通过设备合并、借用IT的规模化经济，减少设备成本、能源开销。 缩短网络运营的而业务创新周期，提升投放市场的速度，是运营商极大的减少网络成熟周期。 网络设备可以多版本、多租户共存，且单一平台为不同的应用、用户、租户提供服务，允许运营商跨服务和跨不同客户群共享资源。 基于地理位置、用户群引入精准服务，同时可以根据需要对服务进行快速扩张/收缩。 更广泛、多样的生态系统使能，促进开放，将开放虚拟装置给纯软件开发者、小商户、学术界，鼓励更多的创新，引入新业务，更低的风险带来新的收入增长。 NFV同样面临着很多技术挑战 虚拟网络装置运行在不同的硬件厂商、不同的Hypervisor上，如何获取更高的性能。 基于网络平台的硬件同时允许迁移到虚拟化的网络平台中，两者并能共存，重用运营商当前的OSS/BSS。 管理和组织诸多虚拟网络装置（尤其是管理系统），同时避免安全攻击和错误配置。 保证一定级别的硬件、软件可靠性。 不同运营商的虚拟装置（VA）集成。网络运营商需要能“混合和匹配”不同厂家的硬件、不同厂家的Hypervisors、不同厂家的虚拟装置（VA），而没有巨大的集成成本、避免与厂家绑定。 NFV架构NFV本质：重新定义网络设备架构Huawei CloudEdge方案包括四个层面以及对应的亮点如下： 软件应用层：华为提供丰富完善的电信业务应用，并且向第三方开放，加快业务创新和部署。 虚拟层面Cloud OS：实现设备资源的高效利用和业务的快速部署。 自动维护管理层MANO (Management And Network Orchestration)：自动的网络伸缩，简化管理。 硬件设备层：高可靠、高性能、多规格的COTS Server，充分满足电信级部署的需求，并支持多厂家的COTS Server部署。 在NFV架构中，底层为具体物理设备，如服务器，存储设备，网络设备。 计算虚拟化即虚拟机，在一台服务器上创建多个虚拟系统。 存储虚拟化，即多个存储设备虚拟化为一台逻辑上的存储设备。 网络虚拟化，即网络设备的控制平面与底层硬件分离，将设备的控制平面安装在服务器虚拟机上。 在虚拟化的设备层面上可以安装各种服务软件 NFV开放接口 NFVI：提供VNF的运行环境，包括所需的硬件及软件。硬件包括计算、网络、存储资源；软件主要包括Hypervisor、网络控制器、存储管理器等工具，NFVI将物理资源虚拟化为虚拟资源，供VNF使用。 VNF：包括VNF和EMS，VNF网络功能，EMS为单元管理系统，对VNF的功能进行配置和管理。一般情况下，EMS和VNF是一一对应的。 VIM：NFVI管理模块，通常运行于对应的基础设施站点中，主要功能包括：资源的发现、虚拟资源的管理分配、故障处理等，为VNF运行提供资源支持。 VNFM：VNF管理模块，主要对VNF的生命周期（实例化、配置、关闭等）进行控制，一般情况下与VNF一一对应。 NFVO：NS生命周期的管理模块，同时负责协调NS、组成NS的VNFs以及承载各VNF的虚拟资源的控制和管理。 OSS/BSS：服务提供商的管理功能，不属于NFV框架内的功能组件，但NFVO需要提供对OSS/BSS的接口。 SDN与NFV的关系 NFV不依赖与SDN，但是SDN中控制和数据转发的分离可以改善NFV网络性能。 SDN也可以通过使用通用硬件作为SDN的控制器和服务交换机以虚拟化形式实现。 结论：以移动网络，NFV是网络演进的主要架构。在一些特定场景，将引入SDN。 SDN与NFV对比： 类型 SDN NFV 主要主张 转发与控制分离，控制面集中，网络可编程化 将网络功能从原来专用的设备移到通用设备上。 校园网，数据中心、云 运营商网络 商用服务器和交换机 专用服务器和交换机 云资源调度和网络 路由器、防火墙、网关、CND、广域网加速器、SLA保证等 通用协议 OpenFlow 尚没有 ONF（Open Networking Forun）组织 将ETSI NFV工作组 NFV是具体设备的虚拟化，将设备控制平面运行在服务器上，这样设备是开放的兼容的。 SDN是一种全新的网络架构，SDN的思想是取消设备控制平面，由控制器统一计算，下发流表，SDN是全新的网络架构。 NFV和SDN是高度互补关系，但并不互相依赖。网络功能可以在没有SDN的情况下进行虚拟化和部署，然而这两个理念和方案结合可以产生潜在的、更大的价值。 网络功能虚拟化（NFV）的目标是可以不用SDN机制，仅通过当前的数据中心技术去实现。但从方法上有赖于SDN提议的控制和数据转发平面的分离，可以增强性能、简化与已存在设备的兼容性、基础操作和维护流程。 NFV可以通过提供给SDN软件运行的基础设施的方式来支持SDN。而且，NFV和SDN在都利用用基础的服务器、交换机去达成目标，这一点上是很接近的。","link":"/2022/06/12/%E7%BD%91%E7%BB%9C%E5%8A%9F%E8%83%BD%E8%99%9A%E6%8B%9F%E5%8C%96%EF%BC%88NFV%EF%BC%89/"},{"title":"网络安全笔记1——Internet协议的安全性","text":"​​点击阅读更多查看文章内容 网络安全笔记1——Internet协议的安全性 参考课程：中国大学MOOC《网络安全》——北京航空航天大学 @[toc] 一、网络层协议1.1、IP协议的安全问题及防护措施 安全问题1：IP数据报在传递过程中易被攻击者监听、窃取。这是一种被动攻击，攻击者可截取数据报，解析数据净荷，从而获得数据内容。防护措施1：对IP数据报进行加密。 安全问题2：由于IP层并没有采用任何机制保证数据净荷传输的正确性，攻击者可能截取数据报，修改数据报中的内容后，将修改结果发送给接收方。防护措施2：对IP数据报净荷部分实行完整性检测机制。 安全问题3：IP层不能保证IP数据报一定是从源地址发送的。攻击者可伪装成另一个网络主机，发送含有伪造源地址的数据包欺骗接受者。此攻击称为IP欺骗攻击。防护措施3：通过源地址鉴别机制加以防御。 安全问题4：IP数据报在传输过程中要经历被分段和重组的过程，攻击者可以在包过滤器中注入大量病态的小数据报，来破坏包过滤器的正常工作。防护措施4：许多防火墙能够重组分段的IP数据报，以检查其内容。 安全问题5：使用特殊的目的地址发送IP数据报也会引入安全问题。如攻击者可使用目的地址为定向广播地址的IP数据报来攻击许多不同类型的主机。防护措施5：配置路由器时启用禁止发送定向广播数据包的功能。 1.2、ARP协议的安全问题及防护措施 输入 arp -a指令可以看到本机缓存的ARP映射，其中动态类型是经过ARP查询之后得到的响应 1.2.1、ARP欺骗攻击在主机A询问主机B的MAC地址时，主机C会伪造ARP响应告诉主机A主机B的MAC地址为攻击者（主机C）的MAC地址同样在主机B询问主机A的MAC地址时，主机C会伪造ARP响应告诉主机B主机A的MAC地址为攻击者（主机C）的MAC地址这样在主机A和主机B向对方发送数据时都会被转发给攻击者C，攻击者就可以拿到A,B通信的数据报 防火措施 在交换机上配置IEEE 802.1x协议，攻击者连接交换机时需进行身份认证 （802.1x协议简述） 建立静态ARP表 1.3、ICMP协议的安全问题及防护措施 参考：icmp超详细讲解 网际控制报文协议（Internet Control Message Protocol，ICMP）是一个重要的错误处理和信息处理协议 它用于通知主机到达目的地的最佳路由，报告路由故障； 它有两个非常重要的监控工具——Ping和Tracert的重要组成部分 它是一种差错和控制报文协议，不仅用于传输差错报文，还传输控制报文 1.3.1、ICMP重定向攻击攻击者可以利用ICMP对消息进行重定向，使得目标机器遭受连接劫持和拒绝服务等攻击。 攻击原理这里首先假设有两台电脑，正常情况下，两台机器互相进行网络交流的时候需要经过路由，但是路由器有一个策略，就是当发现网络中有一台机器使用的是非优化路由的时候，路由就会向那台机器发送一个ICMP重定向的特殊报文，告诉机器改变路由，让机器的路由改为最优的，这个优化和非优化可以理解两点直接直线最短，怎么快就怎么弄，这本身是一个对网络有益的机制。但是这个更改路由的ICMP重定向特殊报文是可以伪造的，并且不需要经过一些校验，合法性检查。也就是说攻击者完全可以向他向受害主机发送ICMP重定向报文，迫使受害主机更改路由表。 危害ICMP重定向攻击的数据包可以迫使主机更改路由为攻击者的主机，那么主机的流量就需要经过攻击者的主机。攻击者就可以截获、提取、分析、修改、重放用户user的数据包，对流量进行嗅探劫持、中间人代理，造成多种安全威胁。 防护一般情况下现有网络的设计是很少发出重定向，那么我们可以禁止网关发出重定向消息，主机不处理重定向。华为设备已经取消发送 ICMP 重定向和接受ICMP重定向数据包 1.3.2、ICMP路由器发现攻击在进行路由发现时，ICMP并不对应答方进行认证，使得它可能遭受严重的中间人攻击。攻击者假冒正常的路由器，使用伪造信息应答ICMP询问。由于ICMP并不对应答方进行认证，因此接收方无法知道响应式伪造的。 1.3.3、防火墙穿越攻击通过防火墙穿越攻击技术（Firewalking），攻击者能够穿越某个防火墙的访问控制列表和规则集，进而确定该防火墙过滤的内容和具体的过滤方式。尽管防火墙面临启用ICMP所带来的风险，但由于主机采用Path MTU的机制，因此在防火墙封堵所有ICMP消息并不妥当。 1.3.4、ping泛洪攻击与smurf攻击ping泛洪它利用ping的原理，向目标服务器发送大量的ICMP回送请求。这是黑客向特定的机器连续发送大量的ICMP回送请求报文。目标机器回答到达的ICMP回送请求已经用尽全力了，原来的通信处理就变得很不稳定了。进一步，目标机器连接的网络也可能由于大量的ICMP数据包而陷入不可使用的状态。smurf黑客恶意的使用ICMP回送请求报文。这一点同ping泛洪是相同的。不过在smurf，对ICMP回送请求实施了一些加工。源IP地址被伪装成攻击对象服务器的地址，目标地址也不是攻击对象服务器的地址，而是成为中转台的网络的广播地址。 黑客发送伪装了的ICMP 回送请求后，到达在作为踏板的网络的入口处的路由器。这样，路由器将回送请求转发给网内所有的计算机（同2）。假如有100 台计算机，回送请求将到达100 台所有的计算机。收到回送请求的计算机对此作出反应，送出回送回答报文（同3）。这样，黑客送出的一个ICMP回送请求报文，一下子增加到了100 倍。这样增加的ICMP 回送回答报文面向的不是黑客的计算机，而是伪装成回送请求的源IP 地址的攻击对象服务器。变成到达了，从几百台计算机发出的巨大数量的ICMP 回送回答。smurf 与ping 洪水攻击不同，因为到达服务器的是ICMP 回送回答，服务器不用返回回答。但是为了处理大量的ICMP，服务器承受了大量的负载。网路被撑爆了也是一样的（同4） 1.4、IGMP协议的安全问题及防护措施网际组管理协议（Internet Group Management Protocol，IGMP）是TCP/IP协议族中负责IP组播成员管理的协议 主机通过IGMP通知路由器希望接收或离开某个特定组播组的信息 路由器通过IGMP周期性地查询局域网内的组播组成员是否处于活动状态，实现所连网段组成员关系的收集与维护 1.4.1、利用查询报文攻击当具有较低IP地址的路由器发送伪造的查询报文，那么当前的查询方就认为，查询任务由伪造的查询方执行，当前的查询方转变为响应查询请求，并且不再发出查询报文。 1.4.2、利用离开报文进行DoS攻击子网内非法用户通过截获某个合法用户信息来发送伪造的IGMP离开报文，组播路由器接受报文后误认为该合法用户已经撤离该组播组，则不再向该用户发送询问请求，从而造成拒绝服务攻击。 1.4.3、利用报告报文攻击非法用户伪装报告报文，或截获合法用户的报告报文向组播路由器发送伪造报文，使组播路由器误认为有新用户加入，于是将组播树扩展到非法用户所在的子网。 1.5、OSPF协议的安全问题及防护措施 开放最短路径优先协议（Open Shortest Path First，OSPF）是一个内部网关协议，用于在单一自治系统内决策路由。OSPF是分布式的链路状态路由协议在该协议中，只有当链路状态发生变化时，路由器才用洪泛法向所有路由器发送路由信息，每个路由器都有一个保存全网链路信息的链路状态数据库。 OSPF协议中规定了认证域（authentication），但其作用非常有限 即使OSPF提供了较强的认证，但某些节点仍然使用简单的口令认证 在路由对话中，如果有一个合法的用户遭到破坏，那么它的消息就不再可信 在许多路由协议中，邻近的计算机会重复旧的对话内容，导致欺骗得到传播扩散。 1.6、BGP协议的安全问题及防护措施 边界网关协议（Border Gateway Protocol，BGP）将单一管理的网络转化为由多个自治系统分散互连的网络。 安全问题BGP缺乏一个安全可信的路由认证机制，无法对所传播的路由信息的安全性进行验证。 解决方案路由认证类方案：MD5 BGP认证技术、S-BGP方案、soBGP方案等前缀劫持检测类方案：多源AS检测技术、主动探测技术 二、传输层协议2.1、TCP协议的安全问题及防护措施 传输控制协议（Transmission Control Protocol，TCP）是一种面向连接的、可靠的传输层通信协议。 2.1.1、SYN FLOOD攻击 TCP连接是一个三次握手过程，在服务器收到初始的SYN数据包后，该连接处于半开放状态。此后，服务器返回自己的序号，并等待第三个确认数据包确认。最后，客户机发送确认数据包，在客户机和服务器之间建立连接。 SYN Flood攻击攻击者不断向服务器的监听端口发送建立TCP连接的请求SYN数据包，使服务器一直处于半开放连接状态，无法接受其他正常的连接请求。这种攻击属于拒绝服务（DoS）攻击。 防护措施在服务器前端部署网络安全设备（防火墙）进行数据包过滤 2.1.2、TCP会话劫持攻击针对TCP协议不对数据包加密和认证的漏洞发起的TCP会话劫持攻击 攻击描述TCP协议确认数据包的真实性主要依据是判断数据包中独有的32位序列号是否正确。如果攻击者能够预测目标主机的起始序号，就可以欺骗该目标主机。 防护措施在TCP连接建立时采用一个随机数作为初始序列号 2.1.3、拥塞控制攻击针对TCP的拥塞控制机制的特性，在TCP连接建立后的数据阶段攻击 攻击描述拥塞控制功能旨在防止过多的数据注入网络。有经验的攻击者可以利用拥塞机制的特性，周期性地制造网络关键节点的拥塞，不断触发拥塞窗口的慢启动过程，最终达到降低正常传输能力的目的。 防护措施网关实时监测网络异常流量 2.2、UDP协议的安全问题及防护措施 用户数据报协议（User Datagram Protocol，UDP）是一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务无需连接，传输高效；无拥塞控制的不可靠交付；数据报首部仅8字节；网络拥塞不会降低发送速率 安全问题最常见的UDP攻击为DoS攻击，而UDP Flood攻击又是DoS攻击中最普遍的流量型攻击。 攻击原理攻击源发送大量的UDP小包到攻击目标，目标可以是服务器或网络设备，使其忙于处理和回应UDP报文，系统资源使用率飙高，最后导致该设备不能提供正常服务或者直接死机，严重的会造成全网瘫痪。 载荷检查和指纹学习 载荷检查：当UDP流量超过阈值时，会触发载荷检查。如果UDP报文数据段内容完全一样，例如数据段内容都为1，则会被认为是攻击而丢弃报文。 指纹学习：当UDP流量超过阈值时，会触发指纹学习。指纹由抗DDoS设备动态学习生成，将攻击报文的一段显著特征学习为指纹后，匹配指纹的报文会被丢弃。动态指纹学习适用于以下类型的UDP Flood攻击：报文载荷具有明显特征。报文负载内容完全一致。 UDP协议的防护措施UDP协议与TCP协议不同，是无连接状态的协议，并且UDP应用协议五花八门，差异极大，因此针对UDP Flood的防护非常困难。其防护要根据具体情况对待？ 判断包大小，如果是大包攻击则使用防止UDP碎片方法：根据攻击包大小设定包碎片重组大小，通常不小于1500。在极端情况下，可以考虑丢弃所有UDP碎片。 攻击端口为业务端口：根据该业务UDP最大包长设置UDP最大包大小以过滤异常流量。 攻击端口为非业务端口：一个是丢弃所有UDP包，可能会误伤正常业务；一个是建立UDP连接规则，要求所有去往该端口的UDP包，必须首先与TCP端口建立TCP连接。不过这种方法需要很专业的防火墙或其他防护设备支持 三、应用层协议 协议栈 3.1、RIP协议的安全问题及防护措施端口：UDP 520 动态路由选择协议（Routing Information Protocol，RIP）是一种动态内部路由/网关协议，用于自治系统内的路由信息的传递。 安全问题攻击者可以伪造RIP路由更新信息，并向邻居路由器发送，伪造内容为目的网络地址、子网掩码地址与下一跳地址，经过若干轮路由更新，网络通信将面临瘫痪的风险。此外，攻击者会利用一些网络嗅探工具（tcpdump和rprobe等）来获得远程网路的RIP路由表，通过欺骗工具（如srip）伪造RIP报文，再利用重定向工具（如fragroute）截取、修改和重写向外发送的报文，以控制网络中报文信息 防护措施针对RIP的不安全因素，中小型网络通常采取以下两种防护措施 将路由器的某些接口配置为被动接口，之后该接口停止向它所在的网络广播路由更新报文，但是允许它接收来自其他路由器的更新报文。 配置路由器的访问控制列表，只允许某些源IP地址的路由更新报文进入列表 3.2、HTTP协议的安全问题及防护措施端口：TCP 80 超文本传输协议（Hyper Text Transfer Protocol，HTTP）是一个客户端和服务器端请求和应答的标准，是互联网上应用最广泛的一种网络协议。 安全问题HTTP协议中数据是直接通过明文进行传输的，不提供任何方式的数据加密，因此存在较大的安全缺陷。 安全隐患1：攻击者可以通过网络嗅探工具轻易获得明文的传输数据，从而分析出特定的敏感信息，如用户的登录口令、手机号码和信用卡号码等重要资料。 安全隐患2：HTTP协议是一种无状态连接，在传输客户端请求和服务器响应时，唯一的完整性检验是报文头部的数据传输长度，而未对传输内容进行消息完整性检测。攻击者可以轻易篡改传输数据，发动中间人攻击。 防护措施在HTTP协议和TCP协议之间增加安全层来增强安全性。安全层主要通过安全套接层（SSL）及其替代协议传输层安全协议（TLS）实现，其中SSL协议通过443端口进行传输，主要包含记录协议和握手协议。 HTTPS协议及其安全性HTTPS协议通过增加安全层，可实现双向身份认证、生成会话密钥、传输数据加密、数据完整性验证和防止数据包重放攻击等安全功能。针对HTTPS协议的攻击方式主要是发生在SSL连接还未发生时的中间人攻击。 3.3、TELNET协议的安全问题及防护措施端口：TCP23 远程登录协议（Teletype Network，TELNET）是TCP/IP协议族中的一员，是Internet远程登录服务的标准协议和主要方式。 安全问题Telnet提供了简单终端到某台主机的访问。主叫用户输入账户名称和口令来进行登录。Telnet程序可能会泄露秘密信息，攻击者可以通过Sniffer记录用户名和口令组合，或者记录整个会话。攻击者还可以采取主动的攻击方式，比如劫持Telnet会话并在认证完成后篡改或插入一些命令。黑客可以使用TCP劫持攻击在某种条件下劫持Telnet会话。 防护措施对Telnet会话进行加密。目前出现了几种Telnet的加密解决方案，它们分别为Stel、SSLtelnet、Stelnet、SSH等协议。其中SSH已经成为远程登录的标准协议。 3.4、SSH协议的安全问题及防护措施端口：TCP 22 安全壳协议（Secure Shell，SSH）是一种在不安全的网络上建立安全的远程登录或其他安全网络服务的协议。 SSH支持身份认证和数据加密，对所有传输的数据进行加密处理，并采用“挑战/响应”机制替代传统的主机名和口令认证，它既可以代替Telnet作为安全的远程登录方式，又可以为FTP、POP等服务提供一个安全的“隧道”，能够有效防止中间人攻击。 SSH通信流程建立TCP连接-&gt;版本协商-&gt;算法协商-&gt;密钥建立和服务器认证-&gt;用户认证-&gt;通信会话 安全问题及防护措施 服务器认证 问题描述：SSH协议在不安全的网络环境中没有可信的认证机构对服务器的真实性进行验证；SSH协议提供了可选功能使得客户机第一次连接到服务器时可以不对服务器主机密钥验证。 防护措施：必须检验主机密钥来验证服务器的正确性 协议版本协商问题描述：SSH协议运行第一步是进行服务器与客户端协议版本的协商。如果攻击者采用有安全漏洞的版本建立连接，则可能采取进一步攻击。防护措施：对采用有安全问题软件的通信方，服务器可以中断TCP连接 主机密钥文件安全问题描述：SSH协议服务器的主机密钥存储在一个主机密钥文件中，若该文件被窃取或篡改，则会对协议的认证机制造成严重威胁，进一步实施假冒、重放和中间人攻击等防护措施：增强安全机制进行主机密钥文件的管理 3.5、DNS协议的安全问题及防护措施端口：UDP 53 域名系统（Domain Name System，DNS）是一个分布式数据库系统，用来实现域名与IP地址之间的映射。 安全问题 DNS欺骗攻击：攻击者假冒域名服务器的一种欺骗行为。 DNS缓存中毒攻击：攻击者给DNS服务器注入非法网络域名地址，若服务器接受此非法地址，此后域名请求的响应将会受黑客控制。当非法地址写入服务器缓存，用户就会跳转到DNS指定的非法地址。 DNS重定向攻击：攻击者将DNS名称查询重定向到恶意DNS服务器上，域名解析就会被劫持，完全处在攻击者的控制之下。 防护措施 强烈建议哪些暴露的主机不要采用基于名称的认证。基于地址的认证虽然也很脆弱，但要优于前者。 攻击者可以从主机名中找出有用的信息，因此不要把秘密的信息放在主机名中。 抵御DNS攻击的有效方法是采用DNSsec新标准，但目前此协议还存在很多问题，从而延缓推广。 3.6、SMTP协议的安全问题及防护措施端口：TCP 25 简单邮件传输协议（Simple Mail Transfer Protocol，SMTP）是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。 安全问题SMTP自身是完全无害的，但它可能成为拒绝服务攻击（DoS）的发源地，攻击者可以采用DoS攻击阻止合法用户使用该邮件服务器；邮件的别名有时也会给黑客提供一些有用的信息；“开放中继”允许在任何人之间进行邮件传递，这是非常危险的。 防护措施使用SMTP认证，并与加密SMTP会话结合使用，从而避免“开放中继”。 3.7、MIME协议的安全问题及防护措施 多用途网间邮件扩充协议（Multipurpose Internet E-mail Extention，MIME）是广泛应用的一种电子邮件技术规范。 安全问题 当MIME应用于电子邮件系统时，自动运行MIME编码消息隐藏着巨大的风险，这些消息中被编码的结构信息能够指示客户端软件要采取何种行动； 对MIME存在一种分段攻击； MIME的其它安全风险：邮递可执行程序或邮件含有危险的PostScript文件，是传播蠕虫和病毒的主要途径。 防护措施 禁用MIME客户端的自动运行功能 拒守不完整邮件 禁止下载带有可执行程序的MIME消息 3.8、POP3协议的安全问题及防护措施端口：TCP 110 邮局协议（Post Office Protocol，POP）是一个邮件协议，它的第三个版本称为POP3. 安全问题 POP3协议非常简单，甚至可采用Perl脚本程序非常容易地实现，所以非常不安全。 POP3口令以明文传输，使用sniffer等网络监听软件很容易捕获用户口令。 使用APOP对用户名和口令进行“挑战/响应”机制进行身份认证，但对邮件内容没有加密保护。 口令以明文形式存储在服务器上，一旦服务器受到攻击，口令也被黑客窃取。 防护措施 在防火墙上对邮件服务器的访问进行限制。 对POP3服务器的用户数据库进行安全加固。 采用IMAP4协议替代POP3协议，使用SSL/TLS对传输的数据进行加密。 3.9、IMAP4协议的安全问题及防护措施端口：TCP 110，993 消息访问协议（Internet Message Access Protocol，IMAP）是一个邮件获取协议，第4个版本是IMAP4 主要特点IMAP4与POP3一样，是收邮件协议，它具有对邮箱更强大的访问控制能力，它可方便地提供邮件下载服务，支持离线阅读；支持在线/离线传输数据；服务器端采用分布式存储邮件方式；支持用户对服务器的远程加密访问。 安全问题IMAP4采用“挑战/响应”机制实现用户认证，但这一机制用到保存在服务器端的共享秘密信息，一旦服务器被攻破，用户的秘密信息将被黑客窃取。 防护措施使用杂凑函数将共享秘密进行杂凑运算，消除共享秘密的等值性。 3.10、PGP协议的安全问题及防护措施 PGP（Pretty Good Privacy）协议是常用的安全电子邮件标准。PGP包括5种服务：认证、保密、压缩、电子邮件兼容和分段。 功能 使用算法 描述 数字签名 DSS/SHA或RSA/SHA 消息的hash码利用SHA-1产生，将此消息摘要和消息一起用发送方的私钥按DSS或RSA加密 消息加密 CAST或IDEA或使用3DES或RSA 将消息用发送方生成的一次性会话密钥按CAST-128或IDEA或3DES加密。用接收方公钥按DH或RSA加密会话密钥，并与消息一起加密 压缩 ZIP 消息在传送或存储时可用ZIP压缩 电子邮件兼容 基数64转换 为了对电子邮件应用提供透明性，一个加密消息可以用基数64转换为ASCII串 分段 为了符合最大消息尺寸限制，PGP执行分段和重新组装 安全问题及防范措施 公钥篡改：随着PGP的普及，多用户系统上也出现了PGP，因此暴露密钥和口令的可能性增大，篡改公钥将导致合法通信者无法解密文件，或导致攻击者可以伪造签名。防护措施：采用数字证书技术确保公钥的可信性。 时戳不可信：攻击者可以通过修改系统时间，对时戳进行伪造，从而攻击者可实施重放攻击。防护措施：1.建立第三方时间公证体系，由公证方在邮件上签上标准时间；2.采用国际标准时戳协议RFC3161。 信任模型缺陷：为得到未核实身份的通信对方的有效公钥，PGP中引入了第三方，这带来了对第三方的信任问题。此外，PGP没有采用有效的PKI证书管理体系。防护措施：对用户的信任度进行规范设置；建立有效的PGP证书管理体系。 3.11、FTP协议的安全问题及防护措施端口：TCP 20/21 文件传输协议（File Transfer Protocol，FTP）是Internet文件传送的基础，是TCP/IP协议族的重要协议之一。 安全问题 FTP 反弹攻击就是攻击者利用FTP协议的PORT命令，将数据发送到第三方，攻击者可利用FTP服务器对其他机器进行端口扫描和发送数据。 攻击者可以将Java程序伪装成FTP客户机发动攻击。 客户机与服务器之间的消息是以明文的形式传输的，运行FTP协议时，访问FTP服务器的口令很容易被探测或猜测到。 ftpd后台守护程序开始时以root用户权限运行，若攻击者取得了root权限，就可以为所欲为。 防护措施 主动模式下，FTP服务器限制PORT命令的IP地址为客户端IP且端口大于1024。在被动模式下，可使用PASV命令。 禁止运行含有Java的脚本程序。 使用SFTP协议对用户名和口令进行加密传输。 3.12、TFTP协议的安全问题及防护措施端口：UDP 69 简单文件传输协议（Trivial File Transfer Protocol，TFTP）是用来在客户机与服务器之间进行简单文件传输的协议TFTP用于提供简单、开销较小的文件传输服务，采用UDP协议，提供不可靠的数据流传输服务，不提供授权与认证机制，使用超时重传方式来保证数据的到达。 安全问题只提供文件传输而不验证文件是否成功传送，在可靠性与安全性上没有保证。 防护措施除非真的需要此协议，否则不应该在任何机器上运行该协议；若要使用应确保对其正确的配置，严禁上传配置文件。 口令破解攻击实例 12345$ tftp target.cs.boofhead.edutftp&gt; get /etc/passwd /tmp/passwd (下载密码)Received 1205 bytes in 0.5 secondsTftp&gt; quit$ crack &lt;/tmp/passwd（密码破译） 3.13、NFS协议的安全问题及防护措施端口：UDP 2049 网络文件系统（Network File System，NFS）是一个基于TCP/IP网络的文件共享协议。NFS允许一个系统在网络上与他人共享目录和文件。通过NFS协议，用户可以像访问本地文件一样访问远端系统上的文件，在远端系统的共享文件金西行创建、修改和删除操作。NFS协议采用基于远程过程调用的分布式文件系统结构 安全问题及防护措施 NFS协议缺乏用户验证机制：NFS只验证RPC/Mount请求，此类访问控制措施不安全。防护措施：加强客户端访问控制 2049号端口处于无特权范围：2049端口属于无特权端口，容易分配给其他普通进程。防护措施：使防火墙禁止其它进程访问2049端口 客户机可对服务器实施DoS攻击：客户机可伪造返回数据包，创建setuid程序来发动DoS攻击。防护措施：利用禁止加载不可信资源选项 服务器可对客户机植入恶意程序：服务器很容易在客户机上植入木马和病毒程序。防护措施：对外来文件进行病毒木马查杀 3.14、SNMP协议的安全问题及防护措施端口：UDP 161/162 简单网络管理协议（Simple Network Management Protocol，SNMP）是用于支持网络管理系统的协议。SNMP协议的应用范围广泛，被应用于诸多种类的网络设备、软件和系统中，被认为是首选管理协议。SNMP的主要作用是控制路由器、网桥及其他网络单元，用来读/写各种设备信息，如操作系统、版本、路由表、默认的TTL、流量统计、接口名称和ARP映射表等，其中有些信息时非常敏感的。 SNMP v1、v2版本的安全问题 SNMPv1和v2中代理可被多个管理站管理，管理站合法性认证依靠团体名和源地址检查。团体名为固定长度字符串，易被穷举攻击。 SNMP数据被封装在UDP中传输，攻击者可以通过嗅探监听，捕获管理站与被管设备之间的交互信息，即可获得SNMP消息中的明文团体名。 攻击者通过嗅探监听截获管理站发往被管系统的管理消息后，通过对消息数据恶意重组、延迟和重放即可实现对被管设备的攻击。 防护措施 在不必要情况下关闭SNMP代理，不提供SNMP服务。 修改设备缺失的团体名，设置为相对复杂的SNMP团体名。 管理站IP地址限定，只有SNMP管理站的IP地址可以发起SNMP请求。 设置访问控制，限制被管设备利用TFTP，FTP和RCP等方式下载上传文件。 SNMP已经出到v3版本，其认证和加密机制更加完善。 3.15、DHCP协议的安全问题及防护措施端口：UDP 67/68 动态主机配置协议（Dynamic Host Configuration Protocol，DHCP）用于分配IP地址、提供启动计算机其他信息的协议。 提供动态制定IP地址和配置参数的机制； 能够提供大量信息； 服务器对IP地址提供集中化管理，简化了管理任务。 出于安全性的考虑，此协议只能在本地网络上使用。 由于DHCP服务器通常没有对查询消息进行认证，所以查询响应容易受到中间人攻击和拒绝服务（DoS）攻击。 此外，攻击者可用假冒的DHCP服务器压制合法的服务器，对查询提供响应并导致各种类型的攻击。 3.16、H.323协议的安全问题及防护措施 H.323是一种用于VoIP（Voice over IP）在分组网上提供实时音频、视频和数据通信的标准（NetMeeting）。 安全问题 拒绝服务：在通信过程中，要求使用H.323协议的终端开放特定端口时刻处于监听状态，易受DoS攻击。 注册劫持：攻击者在注册环节截获终端的标识信息，并向网关发送取消注册信息，再冒用该合法用户的身份注册。 会话中断：会话控制和管理的指令以明文传送，攻击者可截获并伪造结束会话的数据包，强制中断合法用户会话。 3.17、SIP协议的安全问题及防护措施 会话启动协议（Session Initiation Protocol，SIP）是由IETF制定的基于文本编码的多媒体通信协议（如VoLTE） 安全问题注册劫持、伪装服务器、篡改消息、恶意修改或结束会话、拒绝服务 防护措施网络层和传输层的安全保护；HTTP摘要认证；应用层端到端加密。 3.18、NTP协议的安全问题及防护措施端口：UDP 123 网络时间协议（Network Time Protocol，NTP）可在分布式时间服务器和客户端之间进行时间同步。 安全问题 修改系统时间，将已过期或已撤销证书变为有效证书。 修改系统时间，使链接DNSSEC服务器的用户密钥和签名失效。 绕过时间戳检验，达到发动重放攻击的目的。 伪造受害主机向NTP服务器不断发送monlist请求，发动DoS攻击。 防护措施 采用密码技术对消息进行认证 对本地时间源到其他时间源直至根时间源的连接加以认证 管理员合理配置NTP守护程序，拒绝来自外部的跟踪请求 3.19、FINGER协议的安全问题及防护措施端口：UDP 79 Finger协议可以帮助用户查询系统中某一个用户的细节，如其全名、住址、电话号码、登录细节等。 安全问题 利用Finger协议可获得的用户信息或用户登录信息，可以被黑客用来调查并发现潜在的攻击目标。 它所提供的信息，很可能被黑客用来实施口令猜测攻击。 黑客可以发现用户最近与哪个实体相连，这个实体可能成为潜在的攻击目标；黑客还可以发现用户最后使用的是哪个账号。 防护措施 使用防火墙使其无法运行。 关闭Finger后台程序，或限制Finger协议的功能。 3.20、Whois协议的安全问题及防护措施端口：TCP 43 Whois协议是用来查询域名的IP以及所有者等信息的传输协议。Whois查询 3.21、LDAP协议的安全问题及防护措施端口：TCP 389 轻量级目录访问协议（Lightweight Directory Access Protocol,LDAP）是基于X.500的目录访问协议，以目录的形式来管理资源。 信息数据：适合于小数据的存取操作 目录访问：提供基于属性的目录访问 适合读操作：适合于读操作更多的应用 便于应用加载：为定制应用程序加上LDAP的支持 跨平台访问：可以提供跨平台的访问 协议用途 使用LDAP来替代地址簿 使用LDAP协议提供目录数据查询，实现对数字证书的存取 防护措施 用户认证：保证客户的身份与客户所声明身份相同 数据完整：保证服务器收到的数据没有被篡改 数据保密：在可能使数据暴露的地方，对数据进行加密 用户授权：保证用户的请求在用户的授权范围内得到允许 3.22、NNTP协议的安全问题及防护措施端口：TCP 119 网络新闻传输协议（Network News Transfer Protocol，NNTP）是一个用于阅读和张贴新闻文章到Usenet上的Internet应用协议。 网络消息通常通过网络消息传输协议NNTP进行传输，采用的会话与SMTP相类似，接收和发送的消息条目通过网关来处理和转发。这种协议只用来阅读新闻。 安全性缺陷 网络消息非常耗费系统资源 所有的这些程序可能会带来安全漏洞 很多的防火墙结构在设计时假设网关可能遭受攻击 若传递消息的NNTP存在漏洞，消息主机会很危险 防护措施增加对相邻节点的认证，从而拒绝恶意的连接请求","link":"/2022/07/22/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B01%E2%80%94%E2%80%94Internet%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/"},{"title":"网络安全笔记3——双钥密码体制","text":"​​点击阅读更多查看文章内容 网络安全笔记3——双钥密码体制 参考课程：中国大学MOOC《网络安全》——北京航空航天大学 @[toc] ●1976年，美国斯坦福大学电气工程系的研究员Diffie和Hellman教授在奠基性论文“密码学的新方向”中提出公开密钥密码体制的概念，旨在解决网络通信的两大安全问题:保密与认证。●公钥密码体制的基础，是计算复杂度理论（对称密码体制的基础是混淆和扩散）。其安全性主要取决于构造算法所依赖的数学难题。单向函数/单向陷门函数计算上困难问题/NP完全问题 Diffie-Hellman公钥密码思想 Alice与Bob交换公钥 双方将收到的对方的公钥和自己的密钥通过函数f计算得到K 这样就实现了在事先不共享秘密信息的情况下得到了一个共享的密钥K，K经过进一步加工就可以作为对称密钥供双方使用。 （注意：这里的函数f必须是单向函数，否则由已知的函数结果K以及自己的公开密钥可以推出对方的私钥，这不是我们希望的结果） 用于构造双钥密码的单向函数：多项式求根、离散对数DL（Elgamal、DH）、大整数分解FAC（RSA、Rabin）、Diffie-Hellman问题（DHP）公钥密码体制所基于的三大传统困难问题：有限域上的离散对数问题、大整数分解问题、椭圆曲线上的离散对数问题 理论基础单射 令函数f是集A到集B的映射，用f：A→B表示。若对于任意x1≠x2，x1,x2∈A,有f(x1)≠f(x2)，则称f为单射，或1-1映射，或可逆的函数。 单向函数 一个可逆函数f：A→B,若它满足: 对所有x∈A，易于计算f(x); 对“几乎所有x∈A”，由f(x)求x极为困难，以至于几乎是不可能的，则称f是一个单向函数。 陷门单向函数 陷门单向函数是一类满足下述条件的单向函数: fz：Az→Bz，z∈Z，Z是陷门信息集合。 对所有z∈Z，在给定z下容易找到一对算法Ez和Dz，使对所有x∈A，易于计算fz及其逆，即:fz(x) = Ez(x); Dz(fz(x)) = x 对所有z∈Z，当只给定Ez和Dz时，对所有x∈A，很难从y = fz(x)计算出x。 区别:单向函数是求逆困难的函数，而陷门单向函数是在不知道陷门信息下求逆困难的函数。当知道陷门信息后，求逆易于实现。 公钥加密方案 注意：公钥加密都是基于数学难题产生的，计算开销特别大，因此只有在迫不得已的情况下才使用公钥加密，对于大批量的报文还是采用对称加密算法 混合模式使用公钥加密进行对称密钥的分发，使用对称加密进行应用数据的保密通信。 公钥密码体制的特点每个用户都拥有两个密钥:公钥和私钥 公钥(public-key): 可以被任何人知道，用于加密或验证签名。 私钥(private-key): 只能由持有者知道，用于解密或签名。 由私钥及其他密码信息容易计算出公开密钥；而由公钥及算法描述，计算私钥却非常困难。 公钥密钥体制解决了密钥的发布和管理问题 通信双方可以公开其公开密钥，而保留私钥。 发方可以用收方公钥对发送的信息进行加密。 收方用自己的私钥对收到的密文进行解密 公钥密码体制的用途密钥分发 用于交换秘密信息； 用于交换对称加密密钥。 消息加密 用于对消息直接加密； 用公钥加密，用私钥解密； 公钥算法能够用于密钥分配。 数字签名 发送方采用自己的私钥对消息进行签名； 接收方采用发送方的公钥对签名进行验证。 公钥密码体制的安全性 安全性依赖于解数学上的困难问题。 穷搜索(exhaustive search)在理论上能够破解公钥密码，当密钥足够长时，破解极其困难。 目前，通常要求足够大的密钥长度抵抗穷举攻击(&gt;1024 bits)。 密钥太长会导致加密速度缓慢，因此公钥算法常用于密钥传递，而一般不用于实时的数据加密（实时数据加密使用对称密码算法）。 比如：https协议就是http协议加tls协议，tls协议是一个网络安全协议主要包括两个子协议——握手协议和记录协议，其中握手协议就在两个实体之间建立一个公共的密钥k，在记录协议阶段就可以凭借密钥k使用对称加密算法进行应用层数据的保密。 RSA密码体制 RSA是一种分组密码，其理论基础是一种特殊的可逆模指数运算，其安全性基于大整数分解的困难性；既可用于消息加密，也可用于数字签名；硬件实现时比DES慢约1000倍，软件实现时比DES慢约100倍；目前多使用RSA公司的PKCS系列标准；RSA-155（密钥长度为512bit）于1999年被破解。 算法说明密钥生成算法（选、算、选、算） （选）选择两个不同的大素数p，q （算）计算n = p × q，及其欧拉函数值φ(n) = (p- 1)(q- 1) （选）随机选一整数e，1 ≤ e &lt; φ(n)，使得GCD(φ(n),e) = 1（即φ(n)与e互素） （算）计算模φ(n)下e的逆元: d = e-1 mod φ(n) (费马小定理、扩展欧几里得) 加解密算法 取公钥为n,e，私钥为d (p, q不再需要，可销毁，但绝不可泄露)。 加密变换为：m → c = me mod n 解密变换为：c → m = cd mod n 密钥选择 模数大于1024bit，p，q为大素数 p - 1, q - 1有大的素因子 p + 1, q + 1也要有大的素因子 e不能太小，例如e值为3，17，65537，(216+1)（这些数字的二进制都只有两位1，在计算加密变换me可以通过快速幂加快计算速度；解密变换时解密方知道p和q，可以通过中国剩余定理加快计算速度） 注：这里的大素数选择，通常通过先产生伪随机数然后对产生的伪随机数判断是否是满足条件的素数，如果满足则采纳，如果不满足则再产生伪随机数进行判断。 算法使用及特点使用 设Bob的公钥为(e , n)，私钥为d，明文为m Alice用Bob的公钥做加密：c = me mod n，发给Bob Bob用Bob的私钥做解密：m = cd mod n 特点 即使A和B从来不认识，都可进行保密通信，只要A知道B的公钥。 速度慢，它不适用于对图像、话音等进行实时数据加密。 要求对公开密钥进行保护，防止攻击者对公钥的修改和替换。 算法实例 选p1 = 47, p2 = 71,则n = 47 × 71 = 3337, φ(n) = 46 × 70 = 3220。 若选e = 79，可计算d = e -1(mod 3220) = 1019。 公开钥n = 3337和e = 79, 秘密钥d = 1019。销毁p1和p2。 令明文为x = 688 232 687 966 668 3，分组得x1=688,x2=232,x3=687, x4=966, x5=668, x6=3。 对x1加密为: (688)79 mod 3337 = 1570 = C1。 同样可计算出其它各组密文: y = 1570 2756 2714 2423 158 对C1解密: (1570)1019 mod 3337 = 668 = x1。类似地可解出其它各组密文，恢复出明文。 算法安全性 RSA算法的安全性主要基于模n分解的困难性，即给定两个大素数p和q，p * q = n，计算它们的乘积n是简单的，但是由n分解出p和q是困难的，注意这里的困难程度与n的大小有关，这里的n必须足够大 常见的攻击方法 低加密指数攻击 迭代攻击法 定时攻击法 选择密文攻击 消息隐匿问题 公用模攻击 其他途径 理论上，RSA的安全性取决于模n分解的困难性。 采用广义域筛所需计算机资源 密钥长(bit) 所需MIPS年 116 400 129 5000 512 30000 768 200 000 000 1024 300 000 000 000 2048 300 000 000 000 000 现代计算机的性能远超于MIPS（每秒百万条指令）数量级，一般选择1024bit长的密钥才能保证安全 单钥和双钥密码在相同安全性下的等价密钥长度 单钥体制 RSA体制 56 b 384 b 64 b 512 b 80 b 768 b 112 b 1792 b 128 b 2304 b ElGamal密码体制 EIGamal于1985年基于离散对数问题提出了一个既可用于数字签名又可用于加密的密码体制;(此方案的修改版被NIST采纳为美国的数字签名标准DSS) 算法说明密钥生成算法 选择素数p，设GF(p)上的本原元为g通过计算 h = gα (mod p)可以求出有限域GF(p)中的任何一个元素 α∈[1,p-1]，也就是说给定一个α一定可以计算得到一个有限域中的元素h；反过来给定一个有限域中的元素h，要求解α需要做对数运算，并且这里α取得是1到p-1中的离散值，因此称这种运算为离散对数运算。当p足够大的时候还不存在一个多项式时间有效的解法求解α，因此称其为有限域上的离散对数困难问题。 选择密钥: α in GF(p)* (except 0) 计算公钥: β = gα mod p 加密算法 加密方选择一个随机数: k，且GCD(k,p - 1) = 1 加密: m → (gk,mβk) mod p = (y1,y2) = c 解密算法 解密: m = y2y1-α mod p 注意：加密方在每次加密时都会重新选择一个随机数k而不会重用之前的随机数，也就是说Elgamal每次加密相同信息时得到的结果是不同的 Elgamal在加密时会产生两个密文具有一个密文的扩张增加了通信的开销 有学者认为RSA是直线型的密码算法是一维的，Elgamal是平面型的密码算法是二维的，因为它需要发送方交互，即发送方也产生一部分密文信息（随机数k）来进行密码算法的完成，RSA算法则不需要发送方产生密文信息 Diffie-Hellman公钥密码体制密钥交换过程 实例 协议的安全性D-H协议可以抵抗被动攻击，但不能抵抗中间人攻击。中间人攻击：通过拦截正常的网络通信数据，对通信内容进行嗅探和篡改，在这一过程中，正常通信的双方往往毫不知情。 椭圆曲线密码体制（ECC） 椭圆曲线作为代数几何中的重要问题已有一百多年的研究历史。1985年，N. Koblitz和V. Miller才将其独立引入密码学中，使其成为构造公钥密码体制的一个有力工具。我们知道有限域上的椭圆曲线点集可以构成群，在此群上定义离散对数系统，可以构造出基于有限域上离散对数问题的公钥密码体制。 优势椭圆曲线密码体制的安全性基于ECC离散对数问题，目前尚未发现明显的弱点。在公钥密码的标准化过程中，IEEE P1363标准已经采用了ECC。相比于RSA密码体制，椭圆曲线密码体制最大的优势在于可以使用比 RSA 更短的密钥来获得相同水平的安全性，从而使计算量大大减少。 ECC的密钥长度 RSA的密钥长度 MIPS年 ECC:RSA密钥长度比 106 512 104 1:5 132 768 108 1:6 160 1024 1011 1:7 210 2048 1020 1:10 600 21000 1078 1:35 因此，椭圆曲线适合于存储空间受限、通信能力受限的环境中： 无线MODEM: ECC可以实现快速Diffie- Hellman密钥交换，占用带宽达到最小化，计算时间从60s降到20s。 Web服务器: ECC可以节省计算的时间和带宽，并且通过算法的协商更易于处理兼容性问题。 集成电路卡: ECC无需协处理器就可以在IC卡上实现快速安全的数字签名，大大降低了IC卡的成本。 实数域上椭圆曲线的概念实数域上的椭圆曲线可以定义为满足方程：y2 = x3 + ax + b的所有点(x, y)的集合。注意：椭圆曲线并不是椭圆，只因为该方程与计算椭圆周长的方程相似。 可以证明：如果x3 + ax + b没有重复因子，或者满足4a3 + 27b2≠0，那么椭圆曲线上的点集E(a, b)可构成一个Abel群。 椭圆曲线群包括所有曲线上的点以及一个特殊的点，我们称其为无限远点O。 椭圆曲线实例 实数域椭圆曲线上加法一、P + Q = RP,Q都取一般点的计算，连接P,Q作延长线与曲线交于点-R，取交点-R与x轴的对称点R即可得到P+Q的值 二、P + (-P) = O当Q取-P即P,Q连线与x轴垂直时，P + (-P)的结果是无穷远点三、2P = P + P = R当Q等于P时，做P点的切线，与曲线交于点-R，取-R关于x轴的对称点就是2P的结果R 有限域Ep(a, b)上的椭圆曲线有限域GF(p)上的椭圆曲线 y2 = x3 + ax+ b，其点集(x, y)构成有限域上的Abel群，记为Ep(a, b)。条件为:4a3 + 27b2 ≠ 0 mod p 设P = (x1,y1)，Q = (x2,y2)， P + Q = (x3, y3)计算公式与之前实数域上的相同，只需要再加一个模p 当P ≠ Q时：λ = ($\\frac{y_2-y_1}{x_2-x_1}$) mod px3 = (λ2 - x1 - x2) mod py3 = (λ(x1 - x3) - y1) mod p 当P = Q时：λ = ($\\frac{3x_1^2 + a}{2y_1}$) mod px3 = (λ2 - x1 - x2) mod py3 = (λ(x1 - x3) - y1) mod p 举例说明——E23(1,1)的椭圆曲线 取p = 23, a = b = 1,则椭圆曲线方程为: y2 = x3 + x + 1 mod p 把满足上式的所有点(x, y)和元素O所组成的点集记为E23(1,1)。 对于E23(1, 1)，只关心满足模p方程的、从(0, 0)到(p-1,p-1)的象限中的非负整数。下表列出E23(1,1)若干点(O点除外)。 (0,1) (6,4) (12,19) (0,22) (6,19) (13,7) (1,7) (7,11) (13,16) (1,16) (7,12) (17,3) (3,10) (9,7) (17,20) (3,13) (9,16) (18,3) (4,0) (11,2) (18,20) (5,4) (11,20) (19,5) (5,19) (12,4) (19,18) y2 mod p = (x3 + ax + b) mod p (1)系数满足: 4a3 + 27b2 ≠ 0 mod p (2)说明:对于有限域GF(p)上的椭圆曲线，使用变元和系数均在0到p-1的整数集上取值的三次方程，其中p是大素数，所执行的运算均为模p运算。 例如: a=1,b=1,p=23, 椭圆曲线E23(1,1)系数可满足(2)式:4 × 13 + 27 × 12 = 31 mod 23 ≠ 0且x=9,y=7时，(1)式的两边分别为:72 mod 23 = (93 + 9 + 1) mod 2349 mod 23 = 739 mod 233 mod 23 = 3 mod 23 相等，所以(9,7)在曲线上 将表格中的点在图像上表示出来，可以看到曲线上的点都是离散分布的 例如: E23(1,1)为一椭圆曲线，设P=(3,10), Q=(9,7)，则:λ = ($\\frac{y_2-y_1}{x_2-x_1}$) mod px3 = (λ2 - x1 - x2) mod py3 = (λ(x1 - x3) - y1) mod p 可以求出：λ = ($\\frac{7-10}{9-3}$) mod 23 = ($\\frac{-1}{2}$) mod 23 = 11x3 = (112 - 3 - 9) mod 23 = 109 mod 23 = 17y3 = (11 × (3 - 17) - 10) mod 23 = -164 mod 23 = 20 所以：P+Q=(17,20)可以看出P+Q仍然为椭圆曲线E23(1,1)上的点 设P=(3,10)，则2P的计算为:λ = ($\\frac{3x_1^2 + a}{2y_1}$) mod px3 = (λ2 - x1 - x2) mod py3 = (λ(x1 - x3) - y1) mod p 可以求出：x3 = 7，y3 = 12所以：2P=(7,12)可以看出: 2P仍然为椭圆曲线E23(1,1)上的点。同理，我们可以求出: 4P=P+P+P+P 有限域Ep(a,b)上的椭圆曲线结论 从上例可以看出:加法运算在E23(1,1)上是封闭的，且还能验证满足交换律。 对于一般形式的Ep(a,b)，可证明其上的加法运算是封闭的，且满足交换律。 同样，我们还可以证明Ep(a,b)上的加法逆元运算也是封闭的。 根据群的定义可知，Ep(a,b)是一一个Abel群。 有限域Ep(a,b)上的椭圆曲线的性质 关于X轴对称 画一条直线跟椭圆曲线相交，它们最多有三个交点 1P= P2P=P+P3P=2P+P…k*P=(k-1)*P+P举例:因为23=16+4+2+1,所以23P=16P+4P + 2P + P总共只需要7次加法（P+P、2P+2P、4P+4P、8P+8P、P+2P、3P+4P、7P+16P）。 建立在椭圆曲线上的密码为了使用椭圆曲线构造公钥密码体制，需要找出椭圆曲线上的数学难题。 椭圆曲线上的离散对数问题——ECDLP 在椭圆曲线构成的Abel群Ep(a,b)上，考虑方程: Q=kP,其中P,Q∈Ep(a,b)，k&lt;p由 k 和 P 计算 Q 非常容易；而由 P ，Q 计算 k 则非常困难。 由于Diffie-Hellman以及EIGamal是基于有限域上的离散对数问题构造的公钥体制，因此我们也可以采用椭圆曲线来构造它们。 椭圆曲线上的Diffie- Hellman密钥交换 首先取一素数p≈2180，以及参数a, b，则椭圆曲线上的点构成Abel群Ep(a,b)。 取Ep(a,b)上的一个生成元G(x1, y1)，要求G的阶是一个非常大的数n，G的阶n是满足nG=O的最小正整数。 将Ep(a,b)和生成元G作为公钥密码体制的公开参数对外公布，不保密。 A选择一小于n的整数 nA 作为私钥，由 PA=nAG 产生Ep(a,b)上的一点作为公钥。 B选取自己的私钥 nB ，并计算自己的公钥 PB=nBG 。 A可以获得B的公钥PB。 B可以获得A的公钥PA。 A计算: K=nA × PB= nAnBG。 B计算: K=nB × PA= nAnBG。 至此，A和B共同拥有密钥K= nAnBG。攻击者如果想获得密钥K，他就必须由 PA和G求出nA ，或者由 PB和G求出nB ， 而这等价于求椭圆曲线上的离散对数问题ECDLP，因此是不可行的。 举例说明 选择p=211, E211(0, -4),即椭圆曲线为y2≡x3-4 mod 211 G=(2, 2)是E211(0, -4)上的一个生成元，阶n=241，241G=O A取私钥为nA=121， 可计算公钥PA=121 × (2, 2)=(115, 48) B取私钥为nB =203，可计算公钥PB =203 × (2, 2)=(130, 203) A计算共享密钥: 121 × PB = 121 × (130, 203) = (161, 169) B计算共享密钥: 203 × PA=203 × (115, 48)=(161, 169) 可见，此时A和B共享密钥是一对数据(161, 169)。如果在后续采用单钥体制加密时，可以简单地取其中的一个坐标，比如x坐标161，或x坐标的一个简单函数作为共享的密钥进行加密/解密运算 椭圆曲线公钥加密/解密算法 准备阶段A选择一小于n的整数nA作为私钥，由PA=nAG产生Ep(a,b)上的一点作为公钥。B选取自己的私钥nB，并计算自己的公钥PB=nBG。 加密阶段若A要将消息m加密后发给B，则A选择一个随机数k, 计算: C={C1, C2}={ kG,m+ kPB} 解密阶段B收到密文C后，需用C2减去C1与B的私钥之乘积得到消息m:(m + kPB) - (nBkG) = m + k(nBG) - nBkG = m 举例说明 RSA算法与ECC算法比较 中国商用密码SM2算法 2010年12月17日，国家密码管理局颁布了中国商用公钥密码标准算法SM2。SM2是一组基于椭圆曲线的公钥密码算法。国家密码管理局公告(第21号)详细描述了SM2系列算法。 特点 SM2是一组基于椭圆曲线的公钥密码算法 包含加解密算法、数字签名算法和密钥交换协议 采取了检错措施，提高了系统的数据完整性和可靠性 SM2推荐使用的椭圆曲线参数SM2椭圆曲线公钥密码算法推荐使用256位素数域GF(p)上的椭圆曲线，椭圆曲线方程描述为：y2 = x3 + ax + b 曲线参数： p=FFFFFFFE FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF 00000000 FFFFFFFF FFFFFFFF a=FFFFFFFE FFFFFFFF FFFFFFFF FFFFFFFF FFFFFFFF 00000000 FFFFFFFF FFFFFFFC b=28E9FA9E 9D9F5E34 4D5A9E4B CF6509A7 F39789F5 15AB8F92 DDBCBD41 4D940E93 n=FFFFFFFE FFFFFFFF FFFFFFFF FFFFFFFF 7203DF6B 21C6052B 53BBF409 39D54123 基点G(xG, yG)： xG=32C4AE2C 1F198119 5F990446 6A39C994 8FE30BBF F2660BE1 715A4589 334C74C7 yG=BC3736A2 F4F6779C 59BDCEE3 6B692153 D0A9877C C62A4740 02DF32E5 2139F0A0 SM2加解密算法涉及的辅助函数SM2椭圆曲线公钥加解密算法涉及3类辅助函数: 杂凑函数Hash(·):将任意长的数字串映射成一个较短的定长输出数字串的函数。 密钥派生函数KDF(·):从一个共享的秘密比特串中派生出密钥数据。本质上，密钥派生函数是一个伪随机数产生函数,用来产生所需的会话密钥或进一步加密所需的密钥数据。 随机数发生器:从指定的集合范围内产生随机数。随机数发生器必须满足随机性和不可预测性。 辅助函数的安全性直接影响加密算法的安全性。因此，实际使用SM2加解密算法时应使用标准中指定的辅助函数。 密钥生成用户A的密钥对包括其私钥d和公钥P，其中: 私钥为一个随机数d :d∈{1,2,..,n- 1} 公钥为椭圆曲线上的P点:P= dG注:其中G = G(xG, yG)是基点。 SM2加密算法 SM2解密算法 公钥算法总结功能总结 部分其他公钥密码 Rabin密码体制，是RSA的一个特例，安全。 Merkle- Hellman背包密码体制，已攻破。 McEliece体制，1978年提出的基于纠错码的体制，已攻破。 LUC密码体制，新西兰学者Smith提出，安全。 椭圆曲线密码体制(ECC), 1985年实现，安全。（基于椭圆曲线上的离散对数困难问题） 有限自动机体制，中国学者陶仁骥等提出，已攻破。 概率加密体制，不能用于数字签名。","link":"/2022/08/04/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B03%E2%80%94%E2%80%94%E5%8F%8C%E9%92%A5%E5%AF%86%E7%A0%81%E4%BD%93%E5%88%B6/"},{"title":"网络安全笔记2——单钥密码体制","text":"​​点击阅读更多查看文章内容 网络安全笔记2——单钥密码体制 参考课程：中国大学MOOC《网络安全》——北京航空航天大学 @[toc] 密码体制的语法定义 明文消息空间M：可能的明文字母串集合 密文消息空间C：可能的密文字母串集合 加密密钥空间K：可能的加密密钥集合 解密密钥空间K^’^：可能的解密密钥集合 有效的密钥生成算法ζ：N → K × K^’^ 加密算法E：M × K → C 解密算法D：C × K^’^ → M 密钥生成算法：∀整数1^l^，ζ(1^l^)输出长为l的密钥对：(ke,kd) ∈ K × K^’^ 加密/解密过程：∀m ∈ M，c ∈ Cc = Eke(m)m = Dkd(c) = Dkd(Eke(m)) 密钥体制的分类 若ke=kd，则加密算法称为单钥加密体制（对称加密体制或私钥加密体制） 若ke≠kd，则加密算法称为双钥加密体制（非对称加密体制或公钥加密体制） 单钥密码按照加解密运算的特点分类 流密码（Stream Cipher）：数据逐比特加密，即数据流与密钥流逐比特进行异或（XOR）运算； 分组密码（Block Cipher）：对数据分组进行处理。 古典密码古典密码学有两大基本方法 置换密码：明文字母保持不变，但顺序被打乱。 代换密码：明文字母被替换，但顺序保持不变。代换密码主要包括：单表代换（一个明文字母对应的密文字母是确定的）；多表代换（一个明文字母可以表示为多个密文字母）；弗纳姆密码：将每消息比特和相应的密钥比特进行比特异或运算 代换密码单表代换 凯撒密码（单表代换） 维吉尼亚密码（多表代换） 引入密钥的概念：根据密钥来决定用哪一行的密表来进行代换。 使用词组作为密钥：词组中每一个字母都作为索引来确定采用某个代换表，加密时需要循环使用代换表完成明文字母到密文字母的代换，最后所得到的密文字母序列即为密文。 弗纳姆密码（代换密码） 弗纳姆密码（Vernam Cipher）的基本原理是：将明文与密钥进行模2加法运算。如果M=C=K={0,1}^*^，则弗纳姆密码就是代换密码的特例；如果密钥串只使用一次，那么弗纳姆密码就是一次一密密码。弗纳姆密码也可以看成序列密码（流密码）的雏形。 置换密码置换密码又称换位密码，是通过重新排列明文中元素的位置而不改变元素本身来实现加密的体制，它广泛应用于现代分组密码的构造。 置换就是简单的换位，每次置换都可以用一个置换矩阵来表示，且都有一个与之对应的逆置换矩阵。 流密码原理 明文m=m1,m2,… …ml 伪随机序列k=k1,k2,… …kl 密文ci = Eki(mi) 解密过程与加密过程相同且互逆 流密码的安全性完全依赖于伪随机数的强度 有限状态自动机 若密钥流是一个完全随机的非周期序列，则我们可以用它来实现一次一密体制。 但实用中的流密码大多采用有限存储单元和确定性算法，可用有限状态自动机（Finite State Automation）来描述。 因此，由有限状态机产生的序列是伪随机序列。 流密码的分类 同步流密码 自同步流密码 祖冲之密码 2011年，我国商用密码算法——祖冲之密码算法（ZUC）被批准成为新一代宽带无线移动通信系统（LTE）国际标准，即4G的国际标准 我国向3GPP提交的算法标准包含如下内容： 祖冲之密码算法（ZUC）：用于产生密钥序列 128-EEA3：基于ZUC的机密性算法 123-EIA3：基于ZUC的完整性保护算法 分组密码概念分组密码（Block Cipher）是将明文消息编码表示后的数字序列x1,x2,…,xi，划分成长为m的组x = (x0,x1,…,xm-1)，各组(长为m的矢量)分别在密钥k = (k0,k1,…,kt-1)控制下变换成输出长度为n的数字序列y = (y0,y1,…,yn-1)(长为n的矢量)，其加密函数E:Vm × K → Vn，Vm和Vn是m、n维矢量空间，K为密钥空间。 设计要求 分组长度足够大（≥128~256比特，都是64的倍数，计算机总线长度为64位，便于计算） 密钥量要足够大（≥128~192~256比特） 算法足够复杂（包括子密钥产生算法） 加密、解密算法简单，易软、硬件实现 数据无扩展（只在引入同态置换和随机化加密时仍有扩展） 差错传播尽可能得小 Shannon的密码设计思想 扩散（diffusion）将每位明文及密钥数字的影响尽可能迅速地散布到较多个输出的密文数字中，以便隐蔽明文数字的统计特性。产生扩散的最简单方法是通过“置换（Permutation）”（比如：重新排列字符） 混淆（confusion）其目的在于使作用于明文的密钥和密文之间的关系复杂化，使明文和密文之间，密文和密钥之间的统计相关特性极小化，从而使统计分析攻击不能奏效。通常的方法是“代换（Substitution）” 数据加密标准（DES）DES：Data Encryption StandardDES数据加密标准是美国于1977年在全球范围内公开的第一个现代单钥加密算法，DES是一种分组密码，其输入的明文长度为64bit，密钥长度为56bit，输出的密文长度为64bit。 运算步骤 对输入分组进行固定的“初始置换”IP，可以将这个初始置换写为(L0,R0) ← IP(Input Block)，注意：这里L0和R0称为左、右半分组，各为32比特。IP是固定的、公开的函数。 迭代运算，即将下面的运算迭代16轮：Li ← Ri-1；Ri ← Li-1 ⊕ f(Ri-1,ki) 将16轮迭代后得到的结果(L16,R16)输入到IP的逆置换IP-1中：Output Block ← IP-1(R16,L16) 注意事项 DES算法的加密和解密均采用上述3个步骤。 初始置换过程实际上为香农信息论中的“扩散(Diffusion)”；迭代运算过程就是香农信息论中的“混淆(Confusion)”。 如果加密时使用的轮密钥次序为k1,k2,…,k16，那么解密时使用的轮密钥次序为k16,k15,…,k1。 DES采用Feistel网络结构。Feistel密码结构是一种对称结构，满足对合性。采用此结构的密码，其好处是加解密可以使用同一个芯片。 DES算法详细图解S盒和P盒 S盒的作用是混淆（Confusion），主要增加明文和密文之间的复杂度（包括非线性度等）。DES的安全性直接取决于S盒的安全性。 P盒的作用是扩散（Diffusion），目的是让明文和密钥的影响迅速扩散到整个密文中。即一位的明文或密钥的改变会影响到密文的多个比特。 S盒和P盒的作用体现了Shannon的扩散和混淆的密码设计思想。 DES的安全性1997年1月28日，美国RSA公司悬赏10000美元破译DES。美国程序员RockeVerser用140天破译成功。从此宣布了DES时代的终结。2008年SciEngines公司的Rivyera将破解DES的时间缩减到1天以内，并一直保持着暴力破解DES的记录。于是，有人提出了TripleDES算法。DES、TripleDES算法(3DES)已经不再使用，需要提出新的、更安全的数据加密标准。 高级加密标准（AES）AES: Advanced Encryption StandardAES是美国联邦政府采用的一种用来替代DES的加密标准，其于2001年发布并在2002年成为有效的加密标准，已经被多方分析且广为使用。Rijndael是分组长度和密钥长度均可变的分组密码，其密钥长度和分组长度可以独立指定为128/192/256bit（都是64的倍数）。AES的密钥长度为128/192/256bit, 但分组长度固定为128bit。 算法简介 AES加密算法详解（图文解释）AES对应用密码学的积极影响 AES具有加长可变的密钥128/192/256b及数据分组长度128b，为各种应用要求提供了大范围可选的安全强度。 128/192/256b密钥对应的加密轮数为10/12/14。 避免了多重加密（例如3DES）的使用，减少了实际应用中的密钥数量，可以简化安全协议和系统的设计。 AES的广泛使用将导致同样强度的新型杂凑函数的出现。 SM4密码算法 2006年，我国国家密码管理局公布了无线局域网产品使用的SM4 (原名SMS4)密码算法,这是我国第一次公布自己的商用密码算法，旨在加密与保护静态储存和传输信道中的数据。 特点 分组密码算法，分组长度和密钥长度128bit, 32轮迭代 以字节为单位对数据进行处理 解密算法与加密算法结构相同，轮密钥的使用顺序相反 基本运算 模2加和循环移位计算32bit异或计算(⊕)和32bit循环左移(&lt;&lt;&lt;) 置换运算: S盒(Sbox)8bit输入、8bit输出的置换运算，起混淆作用 非线性变换τ以字为单位的非线性变换，由4个并行的S盒构成 线性变换L以字为单位的线性变换，起扩散作用 合成变换T由τ和L复合而成，起扩散和混淆作用 轮函数F非线性迭代结构，以字为单位进行加密运算 加密算法 解密算法 SM4的安全性SM4广泛应用于无线局域网产品。从算法设计上看，SM4在计算过程中增加了非线性变换，理论上能大大加强算法的安全性。近年来，国内外密码学者对SM4进行了充分的分析与实验，致力于SM4的低复杂度实现、混合加密技术的商用化、SM4抗攻击能力的增强等方面，这些研究成果对改进SM4密码和设计新密码都是有帮助的。至今， 我国国家密码管理局仍然支持使用SM4密码 分组密码的工作模式分类参考：分组密码的模式——ECB、CBC、CFB、OFB、CTR 分组密码算法只能加密固定长度的分组，但需要加密的明文长度可能会超过分组密码的分组长度，这就需要对分组密码算法进行迭代，以便将一段很长的明文全部加密。迭代的方法就被称为分组密码的工作模式。分组密码的模式主要有以下5种： 电码本模式（ECB：Electronic CodeBook mode） 密码分组链接模式（CBC：Cipher Block Chaining mode） 密码反馈模式（CFB：Cipher FeedBack mode） 输出反馈模式（OFB：Output FeedBack mode） 计数器模式（CTR：CounTeR mode） 电码本模式（ECB）对连续排列的消息进行加密(或解密)的最直接方式就是对它们逐段加密(或解密)。在这种情况下，消息分段恰好是消息分组。由于这种模式类似于在电报密码本中查找指定的码字，因此称为电码本模式(ECB， Electric Code Book) ECB加密: Ci ← E(Pi)，i=1,2,…,m ECB解密: Pi ← D(Ci)，i=1,2,…,m 注意: ECB模式是确定性的加密模式，也就是说，如果在相同的密钥作用下，将P1,P2,…Pm加密2次，那么输出的密文分组也是相同的。如果明文消息是可猜测的，那么攻击者就会用试凑法猜测出明文。 因此， 在大多数应用中， 建议不要使用ECB模式。 加密 解密 密码分组链接模式（CBC）密码分组链接(CBC, Cipher Block Chaining)运行模式是分组密码算法。使用CBC模式，输出是密码分组的一个序列，这些密码分组链接在一起使得每个密码分组不仅依赖于所对应的原文分组，而且依赖于所有以前的数据分组。 加密 解密 初始化向量当加密第一个明文分组时，由于不存在“前一个密文分组”，因此需要事先准备一个长度为一个分组的比特序列来代替“前一个密文分组”，这个比特序列称为初始化向量，通常缩写为IV。 一般来说，每次加密时都会随机产生一个不同的比特序列来作为初始化向量。 由于IV的随机性，密文分组Ci都将被随机化，因此CBC的密文输出是随机化的。 发送给接收者的密文消息应该包括IV。因此对于m个明文分组，CBC将输出m+1个密文分组。 分组损坏和比特缺失的影响 假设CBC模式加密的密文分组中有一个分组损坏了，例如由于硬盘故障导致密文分组的值发生了改变等，这种情况下，只要密文分组的长度没有发生变化，则解密时最多只会有2个分组收到数据损坏的影响。 假设CBC模式加密的密文分组中有一些比特缺失了，例如由于通信错误导致没有收到某些比特等，那么此时即使缺失1比特，也会导致密文分组的长度发生变化，此后的分组发生错位，这样一来，缺失比特的位置之后的密文分组也就全部无法解密。 密码反馈模式（CFB）密码反馈模式(CFB，Cipher Feedback Mode)的特点是:将CFB模式输出的密码分组反馈至移位寄存器，作为分组密码算法的输入，经分组加密算法加密后形成密钥流分组，再与输入明文分组相异或。 加密 解密 输出反馈模式（OFB）输出反馈模式(OFB，Output Feedback Mode)的特点是:将分组密码的输出分组反馈回去，这些反馈分组经分组加密后输出一个密钥流分组，再将密钥流分组与明文分组相异或。 加密 解密 OFB模式和CFB模式的区别仅仅在于密码算法的输入。CFB模式中，密码算法的输入是前一个密文分组，也就是将密文分组反馈到密码算法中，因此被称为“密文反馈模式”；OFB模式中，密码算法的输入是密码算法的前一个输出，也就是将输出反馈给密码算法，因此被称为“输出反馈模式”。 计数器模式（CTR）计数器模式(CTR, Counter) 的特征是:将计数器从初始值开始计数，所得到的值馈送给分组密码算法。随着计数的增加，分组密码算法输出连续的密钥流分组，再将密钥流与明文分组相异或。 加密 解密 计数器的生成方法，前8个字节为nonce，这个值在每次加密时必须时不同的。后8个字节为分组序号，这个部分逐次累加。 OFB模式与CTR模式的对比 两者都是流密码。 OFB模式是将加密的输出反馈到输入，CTR模式是将计数器的值用作输入。 分组密码总结 分组密码算法 分组长度 密钥长度 加密轮数 安全性 DES 64 bits 56 bits 16 密钥太短且分组长度不适应64-bits总线 AES 128 bits 128/192/256 bits 10/12/14 安全 SM4 128 bits 128 bits 32 安全","link":"/2022/08/04/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B02%E2%80%94%E2%80%94%E5%8D%95%E9%92%A5%E5%AF%86%E7%A0%81%E4%BD%93%E5%88%B6/"},{"title":"网络安全笔记4——消息认证与杂凑函数","text":"​​点击阅读更多查看文章内容 网络安全笔记4——消息认证与杂凑函数 参考课程：中国大学MOOC《网络安全》——北京航空航天大学 @[toc] 消息认证认证(authentication) 保密性(confidentiality) → 加密机制➢其他人看不懂消息的内容 真实性(authenticity) → 认证机制➢消息内容的完整性➢消息内容的真实性➢消息来源的真实性➢实体身份的真实性 认证方式的分类 通信双方相互信任的认证(如企业内部人员之间)对称认证( symmetric authentication)主要防止来自第三方的攻击例如检查文件是否被人修改过 通信双方相互不信任的认证(如商业伙伴之间)非对称认证( asymmetric authentication)主要防止来自对方的攻击例如查验收到的文件是否真实 杂凑函数 信息的真实性可以通过验证一个数据的短烙印(imprint) 或Hash值的真实性来确认。 Hash函数来源于计算机技术:将任意串压缩成定长的比特串。 Hash函数的一些常见称谓:中文:杂凑函数、散列函数、哈希函数。英文: hash code, hash total, hash result, imprint, checksum, compression, compressed encoding, authenticator, fingerprint, Message Integrity Code, message digest. 常见的hash函数有MD5、SHA、SM3(国产) 单向杂凑函数 杂凑(Hash)函数是将任意长的数字串m映射成以个较短定长输出数字串的函数，我们关心的通常是单向杂凑函数。 y = H(x)可将任意长度的x变换成固定长度的y，并满足: 快速性:任给x，计算y = H(x)容易; 单向性:任给y,由y = H(x)计算x困难; 无碰撞:寻找x1≠X2, 满足H(x1) = H(x2)是困难的。 杂凑函数的性质 变量x可以是任意长度， 而H(x)的结果具有固定的长度n bits (如64b/80b/ 160b等); 抗原象攻击:已知一个杂凑值y，找一个输入串x，使得y= H(x)在计算上不可行; 抗碰撞攻击:找两个输入x1和x2(x1 ≠ x2)，使得H(x1) = H(x2)在计算上不可行。 算法特点：不定长度输入，固定长度输出(MD5输出为16字节、 SHA-1输出长度为20字节)。 雪崩效应：若输入发生很小的变动，则可引起输出较大变动。 完全单向：已知输出无法推算出输入，已知两个输出的差别无法推算出输入的差别。 抗碰撞杂凑函数 强单向杂凑函数 VS 弱单向杂凑函数 若杂凑函数H(x)是单向的，则称其为单向杂凑函数。 给定单向杂凑函数H(x)，对任意给定M，其杂凑值h = H(M)，要找出另外一个M’，使h = H(M’)在计算上不可行，则称H(x)为弱单向杂凑函数。 给定单向杂凑函数H(x)，若要找到任意一对输入M1、M2，且M1≠M2，使H(M1) = H(M2)在计算.上不可行，则称H(x)为强单向杂凑函数。 Hash码的分类 校验和CRC: Cyclic Redundancy Check即循环冗余校验码，是数据通信中常用的一种差错校验码 消息认证码MAC: Message Authentication CodeMAC算法是有密钥参与杂凑运算的算法 消息检测码MDC: Message Detection CodeMDC算法是无密钥参与杂凑运算的算法 无碰撞性Hash函数: Collision-Free Hash Function无碰撞的Hash函数是存在的，但在实际中很难找到它们 消息认证码(MAC)与消息检测码(MDC)消息认证码MACMAC也称为密码校验和，它由下述函数产生 MAC = H(m||k) （||表示首尾拼接） 其中，m是一个变长的消息，k是收发双方共享的密钥，H(m||k)是定长的认证符。 发送者：将消息m和此认证符一起发给接收者：**{m, H(m||k)}** 接收者：接收者在收到消息m’之后，计算：MAC’ = H(m’||k)比较MAC’与MAC是否相等若相等，则说明消息未被篡改;若不等，则说明消息被改动了。 消息的真实性依赖于共享密钥的真实性和保密性。 任何拥有这一密钥的人均可以验证该消息的真实性。 对消息真实性的保护已经转化成安全地在通信双方之间建立共享密钥的问题。 消息检测码MDCMDC也称为篡改检测码，它由下述函数产生 MDC = H(m) 其中，m是一个变长的消息，H(m)是定长的杂凑函数值作为认证符。 发送者：将消息m和此认证符一起发给接收者：**{m, H(m)}** 接收者：接收者在收到消息m’之后，计算：MDC’ = H(m’)比较MDC’与MDC是否相等若相等，则说明消息未被篡改;若不等，则说明消息被改动了。 如果采用MDC，消息的真实性就转化成检验一个固定长度比特串的真实性(不需共享密钥)，即MDC = H(m) ; 需要认证信道传输MDC：发送者需要将MDC通过一特定的信道传送给对方。例如，发送者可以打电话告诉对方MDC值。而这个消息的真实性依赖于电话中对于发送者声音的确认。 若消息很长，MDC可以用迭代方法构造 迭代Hash函数 信息X被分为t个分组: X1,X2,…Xt (如必要，需填充补位padding) 计算: h0=IV(初始化向量)，hi=f(Xi,hi-1),…, H(X)=g(ht)➢H为Hash函数，f为轮函数，g为输出变换➢IV (初始值)和padding(填充)将对安全有重要影响 杂凑函数的基本应用方式1. 既提供保密性，又提供消息认证 提供保密性：只有Alice和Bob共享密钥K； 提供认证：H(M)受密码保护。 2. 仅提供消息认证 提供认证：H(M)受密码保护。 3. 既提供消息认证，又提供数字签名 提供数字签名:只有Alice能产生SKsA[H(M)]； 提供认证: H(M)受密码保护 4. 既提供保密性，又提供消息认证和数字签名 提供保密性: 只有Alice和Bob共享密钥K; 提供数字签名：只有Alice能产生SKsA[H(M)]； 提供认证: H(M)受密码保护 5. 仅提供消息认证 提供认证：只有Alice和Bob共享随机状态S 6. 既提供保密性，又提供消息认证 提供保密性：只有Alice和Bob共享密钥K; 提供认证：只有Alice和Bob共享随机状态S 常用杂凑函数MD系列杂凑函数介绍MD（Message-Digest Algorithm） Ron Rivest设计的杂凑函数系列 MD2[RFC1319]，已被Rogier等于1995年攻破; MD4[RFC1320]，已被攻破; MD5是MD4的改进型[RFC1321]，被王小云攻破。 MD5的Hash值长度为128bits； MD5被标准化组织IETF接纳并获得广泛应用； 但是，目前MD5已经过时，不能再使用。 SHA系列杂凑函数SHA（Secure Hash Algorithm） NIST和NSA为配合DSS，设计了安全杂凑标准(SHS)，其算法为SHA[FIPS PUB 180]，修改的版本被称为SHA-1[FIPS PUB 180-1]。 SHA/SHA-1采用了与MD4相似的设计准则，其结构也类似于MD4，但其输出为160bit。 Google于2017年2月公布了一个攻破SHA-1算法的实例，因此国内外正转向使用SHA-256和SHA-512算法。 中国商用密码SM3算法 2010年，国家密码管理局颁布了中国商用密码杂凑函数SM3。SM3是 一种采用Merkle-Damgard结构的杂凑函数。国家密码管理局公告(第22号) 详细描述SM3密码杂凑算法。 特点： 消息分组512比特，输出杂凑值256比特，采用Merkle-Damgard结构。 SM3的压缩函数与SHA-256的压缩函数结构相似，但是SM3更复杂。 SM3算法具有快速扩散能力，能抵抗各种已知攻击，具有很高的安全性。 SHA与MD4、MD5的比较","link":"/2022/08/06/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B04%E2%80%94%E2%80%94%E6%B6%88%E6%81%AF%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%9D%82%E5%87%91%E5%87%BD%E6%95%B0/"},{"title":"网络安全笔记6——数字证书与公钥基础设施","text":"​​点击阅读更多查看文章内容 网络安全笔记6——数字证书与公钥基础设施 参考课程：中国大学MOOC《网络安全》——北京航空航天大学 @[toc] 公钥基础设施（PKI）关于PKI与数字证书的简单理解也可以阅读我的另一篇博客——PKI详解 PKI:公钥基础设施(Public Key Infrastructure)它基于公钥密码理论，可为信息系统提供安全服务，是一一种普适性的安全基础设施。 目的：解决网上身份认证、电子信息的完整性和不可抵赖性等安全问题，为网络应用提供可靠安全服务。 任务：在电子商务和电子政务中，可以为网络用户提供可信的数字身份认证。 组成： 证书机构CA 注册机构RA 证书发布库 密钥备份与恢复 证书撤销 PKI应用接口 证书机构CA (Certificate Authority) CA为电子商务环境中各个实体颁发数字证书，以证明各实体身份的真实性，并负责在交易中检验和管理证书；它是电子商务和网上银行交易的权威性、可信赖性及公正性的第三方机构。。 CA系统功能： 证书生成 证书颁发 证书撤销 证书更新 证书归档 CA自身审计 日志审计 密钥恢复 证书机构CA的功能： CA负责签发和管理数字证书。 提供网络身份认证、负责证书签发及证书的管理。跟踪证书状态在证书需要撤销时发布证书撤销通知 维护证书档案和证书相关的审计。 注册机构RA（Registration Authority） 注册机构(RA) 是数字证书注册审批机构，是认证中心的延伸。RA按照政策与管理规范对用户的资格进行审查，并执行“是否同意给该申请者发放证书、撤销证书”等操作。 RA系统功能 填写用户注册信息 提交用户注册信息 用户资料审核 发送生成证书申请 发送证书 登记黑名单 证书撤销列表管理 日志审计 自身安全保证 证书发布库 用于集中存放CA颁发证书和证书撤销列表。 支持分布式存放，以提高查询效率。 LDAP协议是创建高效大规模PKI认证的关键技术。 密钥备份和恢复 密钥的备份仅备份和恢复CA的公钥/私钥对，而不备份用户的签名密钥。 密钥的恢复若用户声明公钥/私钥对是用于数据加密的，则CA即可对该用户的私钥进行备份。当用户丢失密钥后，可通过可信任的密钥恢复中心完成密钥恢复。 证书撤销证书撤销的两种实现方法 周期性发布机制：证书撤销列表CRL（Certificate Revocation List） 在线证书查询机制：在线证书状态协议OCSP（Online Certificate Status Protocol） PKI应用 认证服务 数据完整性服务 数据保密性服务 不可否认服务 公证服务 数字证书 数字证书的概念:将用户身份ID与其所持有的公钥PK绑定，再由CA对该用户身份及对应公钥的组合**{ID|PK}进行数字签名得到S，然后将{签名S|身份ID||公钥PK}**加以存储，即数字证书。 结构 生成最终用户与RA和CA的关系： 注意：注册机构RA主要帮助证书机构CA与最终用户交互，注册机构RA不能签发证书,证书只能由证书机构CA签发。 注册机构RA提供的服务：接受与验证最终用户的注册信息为最终用户生成密钥接收与授权证书撤销请求 证书机构CA提供的服务：负责为用户生成数字证书负责为用户颁发数字证书 生成步骤： 密钥生成 用户注册 验证信息 证书生成 第一步：密钥生成的两种基本方式 用户自己生成公钥/私钥对（很少使用） RA为用户生成公钥/私钥对（常用） 第二步：注册 第三步：验证信息 RA验证用户材料,明确是否接受用户注册。若用户是组织，则检验营业记录、历史文件和信用证明；若用户是个人，则需要简单证明，如邮政地址、电子邮件地址等。 检验用户私钥的拥有证明POP(Proof Of Possession)。RA要求用户采用私钥对证书签名请求进行数字签名；RA生成随机数挑战信息，用该用户公钥加密，并将加密后的挑战值发送给用户。若用户能用其私钥解密，则验证通过。（用户自己生成公私钥对的情况） 第四步：证书生成 RA将用户申请数据信息传递给证书机构CA。 证书机构验证后生成数字证书。 证书机构将证书发给用户。 在CA维护的证书目录中保留一份证书记录。 RA将数字证书采用用户公钥加密后，发送给用户。用户需要用与公钥匹配的私钥解密方可取得明文证书。（如果公私钥对是由RA生成的，通常情况下采用离线分发的形式如光盘、U盘等介质发送给用户） 签名与验证签发 验证 层级结构 同一根CA中不同CA所辖用户 Alice验证Bob证书链的过程 不同根CA交叉验证 撤销 脱机证书撤销状态检查 联机证书撤销状态检查 漫游证书 证书应用的普及自然产生了证书的便携性需要，而到目前，能提供证书和其对应私钥移动性的实际解决方案只有两种：第一种是智能卡技术。在该技术中，公钥／私钥对存放在卡上，但这种方法存在缺陷，如易丢失和损坏，并且依赖读卡器（虽然带USB接口的智能钥匙不依赖读卡器，但成本太高）；第二种选择是将证书和私钥复制到一张软盘备用，但软盘不仅容易丢失和损坏，而且安全性也较差。一个新的解决方案就是使用漫游证书，它通过第三方软件提供，只需在任何系统中正确地配置，该软件（或者插件）就可以允许用户访问自己的公钥/私钥对。它的基本原理很简单，即将用户的证书和私钥放在一个安全的中央服务器上，当用户登录到一个本地系统时，从服务器安全地检索出公钥/私钥对，并将其放在本地系统的内存中以备后用，当用户完成工作并从本地系统注销后，该软件自动删除存放在本地系统中的用户证书和私钥。 授权管理设施（PMI） 定义:权限管理基础设施或授权管理基础设施(PMI)，是属性证书、属性权威机构、属性证书框架等部件的集合体，用来实现属性证书的产生、管理、存储、分发和撤销等功能。 属性机构（AA）：用来生成并签发属性证书(AC) 的权威机构。 属性证书（AC）：若要将一个实体绑定某个权限，可由属性证书AC来提供，AC中包含了AA对该实体属性的数字签名。 X.509属性证书框架：该框架提供了一个构建权限管理基础设施(PMI)的基础架构，可支持基于权限的访问控制等应用。 PKI与PMI的关系","link":"/2022/08/09/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B06%E2%80%94%E2%80%94%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E4%B8%8E%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/"},{"title":"网络安全笔记5——数字签名","text":"​​点击阅读更多查看文章内容 网络安全笔记5——数字签名 参考课程：中国大学MOOC《网络安全》——北京航空航天大学 @[toc] 基本概念类似于手书签名，数字签名也应满足以下要求: 收方能够确认或证实发方的签名，但不能伪造签名简记为R1-条件。 发方发出签名的消息给收方后，不能再否认他所签发的消息简记为S-条件。 收方对已收到的签名消息不能否认，即有收报认证简记为R2-条件。 第三者可以确认收发双方之间的消息传送，但不能伪造这一过程简记为T条件。 Alice采用自己的私钥对消息m签名，Alice将m和签名发送给Bob;Bob收到m和签名后，Bob采用Alice的公钥验证签名的有效性。 分类按照消息是否被压缩分类：对整体消息进行签名对压缩的消息进行签名 按照消息/签名的对应关系分类：确定性数字签名 (Deterministic Signature) :消息与签名一一对应， 对同一消息的签名永不变化，如RSA算法;随机化数字签名 (Randomized Signature) :对同一消息的签名是变化的。因此，此类签名取决于算法中随机参数的取值，如ElGamal算法。 数学表示 RSA数字签名机制 显然，由于只有签名者知道私钥d,根据RSA体制知，其他人不可能伪造签名; 易于证实{m, s}是否是合法的消息/签名对，只要计算m=se mod n即可。 安全性RSA体制的安全性依赖于n= P1 x p2分解的困难性。 ElGamal数字签名机制 未知私钥时，伪造签名相当于求解离散对数; 若攻击者掌握了同一随机数k下两个消息m1、m2 的合法签名(r1,s1)、(r2,s2)， 就会构造如下的方程:m1 = r1 * x + s1 * km2 = r2 * x + s2 * k 安全性要确保此签名体制的安全性，就必须保证每次签名时，选择不同的随机数k。 Schnorr数字签名机制 大部分随机数生成依赖于可信第三方机构等NIST随机数生成器、Random.org网站、区块链上数据 DSS数字签名机制 DSA是DSS数字签名标准中所采用的数字签名算法； SM2数字签名算法 2010年12月17日，国家密码管理局颁布了中国商用公钥密码标准算法SM2。SM2是一组基于椭圆曲线的公钥密码算法。国家密码管理局公告(第21号) 详细描述了SM2系列算法。 SM2是一组基于椭圆曲线的公钥密码算法 包含加解密算法、数字签名算法和密钥交换协议 本节讲解SM2公钥密码算法中的数字签名算法 具有特殊功能的数字签名机制不可否认签名1989年，Chaum和Antwerpen提出不可否认签名的概念 为什么需要不可否认签名?普通签名可以精确地被复制，适合公开声明之类文件的发布;但对于个人或公司信件，特别是有价值文件签名，不允许随意复制和发布。 这类签名要求在签名者合作下才能验证签名。如果无签名者合作，这类签名不可验证，从而可以防止恶意的攻击者随意复制和散布签名者所签的文件。 这一性质可以用于知识产权的保护等，可在电子出版物的知识产权保护中大显身手。产权拥有者可以控制产品的发布。 防失败签名1991年Pfitzmann和Waidner提出防失败签名的概念 这是一种强安全性的数字签名，可防范有充足计算资源的攻击者。 当用户Alice的签名受到攻击，甚至在分析出Alice私钥的情况下，攻击者也难以伪造Alice的签名。 同时，用户Alice也难以对自己的签名进行抵赖。 van Heyst和Pederson曾提出了一个防失败签名方案，它是一次性签名方案， 即给定密钥只能签署一个消息。 盲签名1983年，Chuam等人最先提出了盲签名的概念 对于一般的数字签名来说，签名者总要先知道文件内容后才签名，这是正常的应用情形。 有时需要签名者对一 个文件做数字签名，但文件所有者不想让签名者知道文件的内容。 利用盲变换可以实现盲签名。 在选举投票中，可以采用盲签名。(在不知道选票内容的情况下对选票签名) 在数字货币协议中，可以采用盲签名。 在电子商务系统中，盲签名有重要的应用。 群签名1991年Chaum和van Heys提出群签名的概念 只有群中的成员才能代表该群体进行数字签名。 接收方用公钥验证群签名，但无法知道由群体中的哪个成员所签。 发生争议时，由群体中的成员或可信赖机构识别群签名的签名者。 此类签名可以用于项目投标。例如:各投标公司组成一个群体，且各公司都匿名地采用群签名对自己的标书签名。当某公司中标后，招标方就可以识别出签名的公司，而其他标书仍保持匿名。中标方若想反悔已无济于事，因为在没有他参与的情况下，仍可以正确地识别出签名人是谁。 代理签名1995年，Membo等人最先提出代理签名的概念 代理签名就是委托人授权某个代理人进行的签名，在委托签名时，签名密钥不交给代理人。代理签名有如下几个特性: 不可区分性：代理签名与委托人的签名不可区分; 不可伪造性：只有委托人和代理人可以建立合法的签名; 代理签名的差异：代理人无法伪造一个合法的代理签名， 即伪造的代理签名可以被检测出来; 可证实性：签名验证人可以相信委托签名就是委托人认可的签名消息; 可识别性：委托人可从代理签名中确定出代理人的身份; 不可抵赖性：代理签名人不能抵赖已被接受的代理签名。 指定证实人签名1994年，Okamoto等人最先提出指定证实人签名的概念 在一个机构中，指定一个人负责证实所有人的签名。 任何成员的签名都具有不可否认性， 但证实工作均由指定人完成。签名者必须限定由谁才能证实他的签名。 证实人充当了仲裁角色，使用证实人的公钥验证所有人的签名。 此类签名有助于防止签名失效。 例如，在签名人的公钥确实丢失，或者在他休假、病倒或去世时，证实人都能对其签名进行验证。 一次性签名1978年，Rabin最先提出一次性签名的概念 签名者至多只能对一个消息进行签名，否则签名就可能被伪造。 在公钥签名体制中，一次性签名要求对每个签名消息都要采用一个新的公钥作为验证参数。 现有的一次性签名方案包括Rabin、Merkle、 GMR、Bos等方案。 这类方案多与可信第三方(TTP) 结合，并通过认证树结构实现。 一次性签名的优点是签名和验证速度非常快，特别适用于计算能力比较低的芯片和智能卡实现。","link":"/2022/08/07/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B05%E2%80%94%E2%80%94%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D/"},{"title":"网络安全笔记8——虚拟专网技术","text":"​​点击阅读更多查看文章内容 网络安全笔记8——VPN技术 参考课程：中国大学MOOC《网络安全》——北京航空航天大学 本文偏向于有关协议的概述，关于VPN的详细介绍（实现技术、作用等）可以阅读我的另一篇文章——虚拟专用网络详解 @[toc] VPN概述VPN：(虚拟专网， Virtual Private Network）是指将物理上分布在不同地点的网络通过公用网络连接而构成逻辑上的虚拟子网。 特点 可节省投资成本 保障传输数据安全 安全可管可控 使用灵活方便 可实现远程访问 服务质量有保证 分类 网关-网关VPN 远程访问VPN 按照应用分类 内联网VPN（Intranet VPN） 外联网VPN（Extranet VPN） 远程访问VPN 按隧道协议分类 IPSEC VPN SSL/TLS VPN PPTP VPN L2TP VPN MPLS VPN 关键技术 隧道技术 加/解密技术 密钥管理技术 身份认证技术 访问控制 隧道协议二层隧道协议PPTP由微软、Asend、 3COM等公司支持的点对点隧道协议(Point to Point Tunneling Protocol)。 L2F由Cisco、Nortel等公司支持的第2层转发协议(Layer 2 Forwarding)。 L2TP由IETF起草，微软、Cisco、 3COM等公司共同制定的第2层隧道协议(Layer2 Tunneling Protocol)。 PPTPPPTP具有两种工作模式:被动模式和主动模式。 PPTP是一种让远程用户拨号连接到本地ISP、通过互联网安全远程访问公司网络。 远程用户采用PPTP经由互联网访问企业的网络和应用，不需要直接拨号至企业网络。 PPTP是为中小企业提供的VPN解决方案，但在具体实现上存在安全隐患。 L2F由思科系统公司开发，用于创建在互联网上的虚拟专用网络连接的隧道协议。 完全独立于用户的链路层协议。L2F远程用户能够通过任何拨号方式接入公共IP网络。 L2F隧道的建立和配置对用户是完全透明的。L2F协议本身并不提供加密或保密。 L2TPPPTP和L2F的缺点 PPTP协议是为中小企业提供的VPN解决方案，安全性差。 L2F没有把标准加密算法定义在内，已经过时。 L2TP结合了PPTP和L2F协议的优点，适合组建远程接入方式的VPN，已成为事实上的工业标准。 三层隧道协议IPSecIPSec是专为IP设计提供安全服务的一种协议，IPSec主要由AH (认证头)、 ESP (封装安全载荷)、IKE (Internet密钥交换) 3个协议组成。 GREGRE隧道允许用户使用IP包封装IP、IPX、 AppleTalk包，并支持全部路由协议。GRE只提供数据包封装没有采用加密功能防止网络侦听和攻击。 MPLSMPLS用标签机制将选路和转发分开，用标签规定一个分组通过网络的路径，适于对服务质量、服务等级及网络资源利用率、网络可靠性有较高要求的VPN业务（也没有加密机制）。 IPSec VPNIPSec总结在 RFC 6071 中，是一组基于网络层的，应用密码学的安全通信协议族。IPSec不是具体指哪个协议，而是一个开放的协议簇。IPSec可在 IP 网络上创建加密隧道。它的加密和身份验证机制可防止窃听和数据修改，这解释了虚拟专用网络( VPN ) 一词。 IPSec协议由AH和ESP提供了两种工作模式。这两个协议可以组合起来使用，也可以单独使用。 AH、ESP或AH+ESP既可以在隧道模式中使用，又可以在传输模式中使用。 工作原理 无论是加密还是认证，IPSec都有两种工作模式：传输模式和隧道模式 IPSec网关通过查询安全策略数据库(SPD) 决定对接收到的IP数据包进行转发、丢弃或IPSec处理 IPSec网关可以对IP数据包只进行加密或认证，也可以对数据包同时实施加密和认证 采用传输模式时IPSec只对IP数据包的净荷进行加密或认证；封装数据包继续使用原IP头部，只对部分域进行修改;IPSec协议头部插入到原IP头部和传送层头部之间。 采用隧道模式时IPSec对整个IP数据包进行加密或认证；产生一个新的IP头，原IP头被放在新IP头和原IP数据包之间。 主要协议 IPSec中主要由AH、ESP和IKE三个协议来实现认证、加密和密钥交换 AH（Authentication Header） AH有两种实现方式：传输模式和隧道模式 AH只涉及认证，不涉及加密 ESP (Encapsulating Security Payload) ESP也有两种工作模式:传输模式和隧道模式 ESP主要用于对IP数据包进行加密，也对认证提供某种程度的支持 IKE (Internet Key Exchange) IKE用于动态建立安全关联(SA, Security Association) IKE协议分两个阶段： 第一阶段:建立IKE安全关联，即在通信双方之间协商密钥 第二阶段:利用这个既定的安全关联为IPSec建立安全通道 安全关联 IPSec的中心概念之一是“安全关联”（SA） 每个SA的标识由三部分组成：安全性参数索引(SPI) 、IP目的地址和安全协议标识 SA有两种模式，即传输模式和隧道模式 也可以将不同的SA组合起来使用，以提供多层次的安全性或封装能力 构成 管理模块 密钥分配和生成模块 身份认证模块 数据加/解密模块 数据分组封装/分解模块 加密函数库 SSL/TLS VPNSSL/TLS VPN也称做传输层安全协议(TLS) VPN，TLS是SSL的升级版。 TLS协议主要用于HTTPS协议中，TLS也可以作为构造VPN的技术。 TLS VPN最大优点是用户不需要安装和配置客户端软件。 由于TLS协议允许使用数字签名和证书，所以它可以提供强大的认证功能。 连接建立 与许多C/S方式一样： 客户端向服务器发送”Client hello”信息打开连接 服务器用”Server hello”回答 要求客户端提供数字证书 完成证书验证，执行密钥交换协议 密钥交换协议的任务： 产生一个主密钥 由主密钥产生两个会话密钥：A→B的密钥和B→A的密钥 由主密钥产生两个消息认证码密钥 原理 TLS VPN需要在企业网络防火墙的后面放置一个TLS代理服务器 用户与服务器之间的安全通信建立过程: 用户首先要在浏览器上输入一个URL； 该连接请求将被TLS代理服务器取得； TLS代理服务器对用户进行身份验证； TLS代理服务器提供用户与各种不同应用服务器之间的连接。 协议TLS VPN主要依靠三种协议支持——握手协议、TLS记录协议、告警协议 握手协议 TLS客户机连接至TLS服务器，要求服务器验证客户机的身份; TLS服务器通过发送它的数字证书证明其身份; 服务器发出一个请求，对客户端的证书进行验证; 协商用于消息加密的加密算法和用于完整性检验的杂凑函数; 客户机生成一个随机数，用服务器的公钥对其加密后发送给TLS服务器; TLS服务器通过发送另- -随机数据做出响应; 对以上两个随机数进行杂凑函数运算,从而生成会话密钥。 TLS记录协议 协议建立在TCP/IP协议上; 在实际数据传输开始前通信双方进行身份认证、协商加密算法和交换加密密钥等。 告警协议 告警协议用于提示何时TLS协议发生了错误，或者两个主机之间的会话何时终止; 只有在TLS协议失效时告警协议才会被激活。 优缺点优点 无须安装客户端软件 适用于大多数设备 适用于大多数操作系统 支持网络驱动器访问 不需要对网络做改变 较强的资源控制能力 费用低且有良好安全性 可绕过防火墙进行访问 已内嵌在浏览器中 缺点 认证方式单一 应用的局限性很大 只对应用通道加密 不能对应用层消息签名 缺少LAN to LAN连接方案 加密级别不如IPSec VPN高 不能保护UDP通道安全 是应用层加密，性能较差 不能实施访问控制 需CA支持，证书管理复杂 应用 在客户与TLS VPN的通信中，人们通常采用TLS Proxy技术来提高VPN服务器的通信性能和安全身份验证能力 主要用于访问内部网中的一-些基于Web的应用：电子邮件内部网页浏览其他基于Web的查询工作 TLS VPN与IPSec VPN的比较 TLS VPN有很多优点，但并不能取代IPSec VPN。 IPSec VPN主要提供LAN-to-LAN的隧道安全连接。 在为企业高级用户提供远程访问及为企业提供LAN-to-LAN隧道连接方面，IPSec具有无可比拟的优势。 IPSec VPN厂商开始研究让IPSec VPN 兼容TLS VPN，以增强可用性。届时，IPSec VPN的扩展性将大大加强。 PPTP VPN点对点隧道协议(PPTP) 是第一个建立VPN的协议 使用灵活，容易部署，而且能得到大多数运营商的解决方案的支持 该协议最初于1998年提出，但由于存在严重的安全问题，随后进行了大量修改，即便如此，声誉仍受到损害 PPTP VPN最早是Win NT 4.0支持的隧道协议标准，是PPP的扩展。 PPTP的主要功能是开通VPN隧道，仍采用PPP拨号建立网络连接。 PPTP只是将用户的PPP帧采用GRE封装成IP数据包，在Internet 上传输。 PPTP本身没有定义新的加密机制，它只是继承了PPP的认证和加密机制。 PPTP支持Client-to-LAN型VPN隧道方案，用于移动办公和远程访问服务器。 PPTP也支持企业网络之间建立LAN-to-LAN的VPN隧道连接。 原理PPTP由RFC2637定义，是一种应用比较广泛的VPN PPTP基于C/S结构，将认证和连接设置功能分离。 PPTP将传统网络访问服务器的功能分解成PAC和PNS来分别执行。 PPTP利用NAS的功能分解机制的支持，从而在Internet上实现VPN。 建立PPTP连接时，首先需要建立的是客户端与本地ISP的PPP连接。 优缺点优点 不依赖于TCP/IP协议族，可以与Novell的IPX或Microsoft的NetBEUI协议一起使用。 缺点 由于现今的大多数网络都基于TCP/IP，所以应用具有一定的局限性。 由于PPTP中没有定义加密功能，所以PPTP VPN的安全性是所有类型的VPN中最低的。 MPLS VPNMPLS VPN是一种基于多协议标记交换技术的IP VPN 在网络路由和交换设备上应用MPLS技术可以简化核心路由器的路由选择方式 MPLS利用传统路由中的标记交换技术来实现IP虚拟专网 MPLS VPN可用来构造宽带的Internet和Extranet 特点 MPLS是基于标记的IP路由选择方法。 MPLS技术利用显式路由选择,可灵活选择优质路径来传输数据。 MPLS协议实现了从第三层路由到第二层交换的转换。 IP数据包进入网络时，边界路由器给它分配一个标记。 对于到达同一目的地的IP数据包，可根据其 TOS（三层数据包的服务标志） 值的要求建立不同转发路径，以确保传输质量。 原理MPLS由Cisco的标记交换技术演变而来，已成为IETF的标准协议，与传统的网络层技术相比，它引入了以下一些新概念： 流 标记 标记交换 MPLS节点 标记交换路径 MPLS域 MPLS边界节点 标记交换路由器 标记分发协议 步骤 网络自动生成路由表 将连续的网络层数据包看做流，MPLS边界节点可以首先通过传统的网络层数据转发方式接收这些数据包，有选择的在数据包中加入一个标记，并把它们转发出去 当加入标记的链路层数据包在MPLS域中转发时，就不再需要经过网络层的路由选择，而由标记交换路径上的MPLS节点在链路层通过标记交换进行转发 将加入标记的链路层数据包发送离开此MPLS域 MPLS用最简化的技术来完成第三层路由向第二层交换的转换 优缺点优点 成本较低 提高了资源利用率 提高了网络速度 提高了灵活性可扩展性 业务综合能力强 MPLS的QoS保证 适用于城域网网络环境 缺点 由于ATM技术本身目前备受争议，所以MPLS VPN的存在价值大打折扣; MPLS VPN与L2F VPN、PPTP VPN一样，本身没有采用加密机制，因此MPLS VPN实际上安全性比较低。 总之，IPSec VPN和SSL VPN是目前使用最普遍、安全性最高的协议，其安全性优于其他类型的VPN。","link":"/2022/08/12/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B08%E2%80%94%E2%80%94%E8%99%9A%E6%8B%9F%E4%B8%93%E7%BD%91%E6%8A%80%E6%9C%AF/"},{"title":"网络安全笔记7——防火墙技术","text":"​​点击阅读更多查看文章内容 网络安全笔记7——防火墙技术 参考课程：中国大学MOOC《网络安全》——北京航空航天大学 @[toc] 防火墙概述 防火墙是由软件和硬件组成的系统，它处于安全的网络和不安全的网络之间，属于网络边界防护设备，由系统管理员设置访问控制规则，对进出网络边界的数据流进行过滤。 防火墙是Internet安全的最基本组成部分，但对于防御内部的攻击以及绕过防火墙的连接却无能为力。 防火墙对数据流的处理方式 根据安全策略，防火墙对数据流的处理方式有如下3种： 允许：允许满足规则的数据流通过防火墙。 拒绝：拒绝不满足规则的数据流通过，并回复一条消息，提示发送者该数据流已被拒绝。 丢弃：直接将数据流丢弃，不对这些数据包作任何处理，也不会向发送者发送任何提示信息。 防火墙需满足的要求 所有进出网络数据流都必须经过防火墙。 只允许经授权的数据流通过防火墙。 防火墙自身对入侵免疫，即确保自身安全。 防火墙默认规则：凡是没有明确允许的，一律都是禁止的。 防火墙的类型及结构防火墙的发展史 防火墙的分类防火墙分类： 包过滤防火墙 电路级防火墙 应用级网关防火墙 防火墙设计结构： 静态包过滤 动态包过滤 电路级网关 应用层网关 状态检查包过滤 切换代理 空气隙（物理隔离） OSI模型与防火墙的关系 防火墙工作于OSI模型的层次越高，能提供的安全保护等级就越高。 防火墙工作原理：不同类型的防火墙，将分别对IP头、TCP头、应用级头、数据/净荷等部分数据进行过滤。 静态包过滤防火墙工作在网络层 操作 防火墙接收到从外部网络到达防火墙的数据包，对数据包过滤。 对数据包施加过滤规则，对数据包IP头和传输字段内容进行检查。 如果没有规则与数据包头信息匹配，则对数据包施加默认规则。 对于静态包过滤防火墙来说，决定接收还是拒绝一个数据包，取决于对数据包中IP头和协议头等特定域的检查和判定。 工作原理 过滤规则防火墙可根据数据包的源地址、目的地址、端口号确定是否允许和丢弃数据包；符合，则允许；不符合，丢弃。 过滤位置可以在网络入口处过滤也可在网络出口处过滤入口和出口同时对数据包进行过滤 访问控制策略网管需预先编写一访问控制列表需明确规定哪些主机或服务可接受，哪些主机或服务不接受 实例 拒绝来自130.33.0.0的数据包，这是一种保守策略。 拒绝来自外部网络的Telnet服务(端口号为23)的数据包。 拒绝试图访问内网主机193.77.21.9的数据包。 禁止HTTP服务(端口号为80)的数据包通过防火墙。 某大学的防火墙过滤规则设置 某公司的防火墙过滤规则设置 优缺点优点 对网络性能影响较小 成本较低 缺点 安全性较低 缺少状态感知能力 容易遭受IP欺骗攻击 创建访问控制规则比较困难 动态包过滤防火墙工作在传输层 动态包过滤防火墙： 具有状态感知能力 典型动态包过滤防火墙工作在网络层 先进的动态包过滤防火墙位于传输层 检查的数据包头信息： 源地址 目的地址 应用或协议 源端口号 目的端口号 工作原理 与普通包过滤防火墙相似，大部分工作于网络层。有些安全性高的动态包过滤防火墙，则工作于传输层。 动态包过滤防火墙的不同点：对外出数据包进行身份记录，便于下次让具有相同连接的数据包通过。 动态包过滤防火墙需要对已建连接和规则表进行动态维护，因此是动态的和有状态的。 典型的动态包过滤防火墙能够感觉到新建连接与已建连接之间的差别。 实现动态包过滤器有两种主要的方式： 实时地改变普通包过滤器的规则集 采用类似电路级网关的方式转发数据包 优缺点优点 采用SMP技术时，对网络性能的影响非常小。 动态包过滤防火墙的安全性优于静态包过滤防火墙。 “状态感知”能力使其性能得到了显著提高。 如果不考虑操作系统成本，成本会很低。 缺点 仅工作于网络层，仅检查IP头和TCP头。 没过滤数据包的净荷部分，仍具有较低的安全性。 容易遭受IP欺骗攻击。 难于创建规则，管理员创建时必须要考虑规则的先后次序。 如果在建立连接时没有遵循三步握手协议，会引入风险。 电路级网关工作在会话层 与包过滤的区别： 除了进行基本的包过滤检查外，还要增加对连接建立过程中的握手信息SYN、ACK及序列号合法性的验证。 检查内容： 源地址 目的地址 应用或协议 源端口号 目的端口号 握手信息及序列号 电路级网关通常作为应用代理服务器的一部分，在应用代理类型的防火墙中实现。 它的作用就像一台中继计算机，用于在两个连接之间来回地复制数据； 它也可以记录和缓存数据。 采用C/S结构，网关充当了服务器的角色； 作为代理服务器，在Internet和内部主机之间过滤和转发数据包。 它工作于会话层，IP数据包不会实现端到端流动； 在有些实现方案中，电路连接可自动完成。 过滤内容 工作原理 在转发该数据包前，首先将数据包的IP头和TCP头与规则表相比较，以决定将数据包丢弃，还是通过。 若会话合法，包过滤器将逐条扫描规则，直到发现一条规则与数据包中的有关信息一致。否则，丢弃。 电路级网关与远程主机之间建立一个新连接，这一切对内网中用户都是完全透明。 电路级网关实例——SOCKS SOCKS由David和Michelle Koblas设计并开发是现在已得到广泛应用的电路级网关(SSL)事实上，SOCKS是一种网络代理协议 内网主机请求访问互联网 与SOCKS服务器建立通道 将请求发送给服务器 收到请求后向目标主机发出请求 响应后将数据返回内网主机 优缺点优点 性能比包过滤防火墙稍差，但是比应用代理防火墙好。 切断了外部网络到防火墙后的服务器直接连接。 比静态或动态包过滤防火墙具有更高的安全性。 缺点 具有一些固有缺陷。例如，电路级网关不能对数据净荷进行检测，无法抵御应用层攻击等。 仅提供一定程度的安全性。 当增加新的内部程序或资源时，往往需要对许多电路级网关的代码进行修改。 应用级网关工作在应用层 与包过滤的区别 包过滤防火墙：过滤所有不同服务的数据流不需要了解数据流的细节，它只查看数据包的源地址和目的地址或检查UDP/TCP的端口号和某些标志位。 应用级网关：只能过滤特定服务的数据流必须为特定的应用服务编写特定的代理程序，被称为“服务代理”，在网关内部分别扮演客户机代理和服务器代理的角色。 当各种类型的应用服务通过网关时，必须经过客户机代理和服务器代理的过滤。 工作特点 必针对每个服务运行一个代理。 对数据包进行逐个检查和过滤。 采用“强应用代理” 在更高层上过滤信息自动创建必要的包过滤规则。 当前最安全的防火墙结构之一。 代理对整个数据包进行检查，因此能在应用层上对数据包进行过滤。 应用代理与电路级网关有两个重要区别:代理是针对应用的。代理对整个数据包进行检查，因此能在OSI模型的应用层上对数据包进行过滤。 优缺点优点 在已有的安全模型中安全性较高。 具有强大的认证功能。 具有超强的日志功能。 规则配置比较简单。（对已经给定的应用配置规则比较简单） 缺点 灵活性很差,对每一种应用都需要设置一个代理。 配置烦琐，增加了管理员的工作量。（对新的应用重新配置应用规则比较繁琐） 流量吞吐性能不高，有可能成为网络的瓶颈。 状态检测防火墙工作在所有七层上 应用状态能够理解并学习各种协议和应用，以支持各种最新的应用；能从应用程序中收集状态信息并存入状态表中，以供其他应用或协议做检测策略。 操作信息状态监测技术采用强大的面向对象的方法。 通信信息防火墙的检测模块位于操作系统的内核，在网络层之下，能在数据包到达网关操作系统之前对它们进行分析。 通信状态状态检测防火墙在状态表中保存以前的通信信息，记录从受保护网络发出数据包的状态信息 优缺点优点 具备动态包过滤所有优点，同时具有更高的安全性。 它没有打破C/S结构，因此不需要修改很多应用程序。 提供集成的动态(状态)包过滤功能。 当以动态包过滤模式运行时，其速度很快。 当采用对称多处理器SMP模式时，其速度更快。 缺点 采用单线程进程，对防火墙性能产生很大影响。 因未打破C/S结构，可能会产生很大的安全风险。 不能满足对高并发连接数量的要求。 切换代理工作过程 连接建立时安全层次提高到会话层，对会话信息进行检测，在连接建立完成回到正常通信状态后就将安全层次降低到网络层，对数据包进行简单的过滤提高效率。 优缺点优点 与传统电路级网关相比，对网络性能造成影响要小。 由于对三步握手进行了验证，降低了IP欺骗的风险。 缺点 它不是一个电路级网关。 它仍然具有动态包过滤器遗留的许多缺陷。 由于没检查数据包的净荷部分，因此具有较低的安全性。 难于创建规则(受先后次序的影响)。 其安全性不及传统的电路级网关。 空气隙防火墙在内外网之间有一个开关，不能同时只能接通内网和外网，存在物理隔离。 数据首先暂存在硬盘中，对其进行检查、杀毒、人工筛查等，然后再将数据整体转移到内网。 在高保密的军工企业中应用比较广泛。 效率较低，数据转移经常以分、时为单位。 优缺点优点 切断与防火墙后面服务器的直接连接，消除隐信道攻击的风险。 采用应用代理对协议头长度进行检测，消除缓冲器溢出攻击。 与应用级网关结合使用， 空气隙防火墙能提供很高的安全性。 缺点 降低网络的性能。 不支持交互式访问。 适用范围窄。 系统配置复杂。 结构复杂，实施费用高。 带来瓶颈问题。 分布式防火墙分布在网络的各个位置，内外网之间、内部各子网之间等，通过管理中心收集各防火墙的日志信息，对整体防火墙进行管理配置以达到最优的配置策略。 工作原理网络防火墙 内部网与外部网之间、内部网各子网之间 对内部子网之间的安全防护层 主机防火墙 对服务器和桌面机进行防护 内核模式应用，过滤和限制信息流 管理中心 服务器软件 管理、分发总体安全策略；汇总日志 优缺点优点 增强了系统安全性。 提高了系统性能。 提供了系统的扩展性。 可实施主机策略。 缺点 系统部署时间长、复杂度高，后期维护工作量大。 可能受到来自系统内部的攻击或系统自身安全性的影响。","link":"/2022/08/11/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B07%E2%80%94%E2%80%94%E9%98%B2%E7%81%AB%E5%A2%99%E6%8A%80%E6%9C%AF/"},{"title":"群、循环群、交换群","text":"​​点击阅读更多查看文章内容 群一个群（Group）是一个代数结构，它包含了一个集合以及一个在这个集合上定义的二元运算，满足以下四个主要性质。 封闭性：对于群中的任意两个元素 a 和 b，通过群的二元运算，它们的组合 a * b 也必须属于该群。换句话说，运算结果不会使元素离开群。 结合性：群中的二元运算是结合的，即对于任意元素 a、b 和 c，(a * b) * c = a * (b * c)。 单位元素：群中存在一个特定的元素 e，称为单位元素，它满足对于群中的任何元素 a，e * a = a * e = a。 逆元素：对于群中的每个元素 a，必须存在一个逆元素 a^-1^，使得 a * a^-1^ = a^-1^ * a = e，其中 e 是单位元素。 群的阶：群中元素个数称为群G的阶，记为|G| 群内元素a的阶（有时称为周期）：使得a^k^ = e成立的最小正整数k为元素a的阶（其中的e为这个群的单位元素）。若k不存在，则称a的阶数为无穷大。有限群的所有元素都有有限阶（证明）。 循环群循环群是一种特殊的群，其元素由一个生成元重复作用而生成。具体来说，如果群G中存在一个元素g可以通过重复的使用二元运算（通常是乘法或加法）生成 G 中的所有元素，则群G就是循环群，元素g称为生成元。 形式化的，设（G，·）为一个群，若存在一个元素 g ∈ G，使得 G = &lt; g &gt; = { g^k^ | k ∈ Z }，则（G，·）形成一个循环群。群G内任意一个元素所生成的群都是循环群，而且是G的子群。 例如：模8加法群，{0，1，2，3，4，5，6，7}，其中0是单位元，生成元为1，3，5，7 交换群交换群，也被称为可交换群或阿贝尔群，是一个满足交换性质的群。交换性质意味着群中的任何两个元素在群运算下都可以交换位置，即对于所有的元素 a 和 b，a * b = b * a，其中 * 表示群运算。 经典的例子包括整数集合上的加法群（Z, +），实数集合上的加法群（R，+），以及整数集合上的乘法群（Z，*）其中 * 表示乘法。这些群都是交换群，因为它们的运算满足交换性质。","link":"/2023/10/16/%E7%BE%A4%E3%80%81%E5%BE%AA%E7%8E%AF%E7%BE%A4%E3%80%81%E4%BA%A4%E6%8D%A2%E7%BE%A4/"},{"title":"虚拟计算技术","text":"​​点击阅读更多查看文章内容 虚拟计算的本质是资源共享。P2P计算、云计算、网格计算、普适计算都属于虚拟计算。 一、概述虚拟计算（Virtual Computing)的本质是资源共享。虚拟计算技术不仅能使人们更有效地共享现有的资源，而且能通过重组等手段，为人们提供更多、更完善的共享服务。 作为计算机技术与通信技术融合的产物，互联网正由一般意义下的计算机通信平台逐步演变成为广泛存在的虚拟计算环境。所谓虚拟计算环境，是指建立在开放的网络基础设施之上，通过对分布自治资源的集成和综合利用，为终端用户或应用系统提供和谐、安全和透明的一体化服务的环境，实现有效资源共享和便捷合作工作。虚拟计算环境的核心是网络资源的聚合与协同。 P2P计算、云计算、网格计算、普适计算都属于虚拟计算。 二、P2P计算P2P（Peer To Peer，对等网络）是一种新型分布式网络通信技术，使得计算机之间可以直接访问和交换文件，而无须像过去那样连接到服务器去浏览与下载。 具体原理是，P2P参与者通过网络共享他们的部分硬件资源（如处理能力，存储能力，网络连接能力、打印机等），其他节点（peer）可以直接访问而无须通过中间实体。在P2P系统中，参与者既是资源提供者，又是资源使用者。 P2P技术改变了传统互联网以大网站为中心的状态，使得网络资源处于“非中心化”的地位，并把访问权交还给对等的用户。P2P计算模式的三大关键问题是：1）资源存放2）资源定位3）资源获取 1、资源存放P2P系统中，个人资源并非都放在本机，很可能是所有机器共同管理资源，即你的部分资料会放在别的用户机器上。2、资源定位通过集中方式、广播方式和DHT方式进行资源定位。集中方式就是有若干个目录服务器，首先通过它们进行资源定位；广播方式通过相邻节点直接广播传递查找；DHT（Distributed Hash Table，分布式哈希表）是大多数P2P系统的资源定位方式。3、资源获取充分发挥所有节点的带宽资源，并行下载。电驴吧。 P2P引导网络计算模式从集中式向分布式偏移，网络应用的核心从中央服务器向网络边缘的终端设备扩散，使得Internet上的共享提高了一个层次。 三、云计算云计算是一种基于并高度依赖于Internet，用户与实际服务提供的计算资源相分离，集合了大量计算设备和资源，并向用户屏蔽底层差异的分布式处理架构。 事实上，人们很早就提出和实现了基于网络的多台计算机的协同技术，比如分布式、服务器集群、负载均衡和Web Service等，在互联网的基础上对这些技术进行扩展，再加以创新，基本就构成了现在的云计算。 1、云计算的特点1）集合了大量计算机，规模成千上万2）多种软硬件技术相结合，比如分布式、负载均衡、服务器集群等3）对客户端设备的要求低4）规模化效应。服务器和客户都规模宏大，使得管理和维护集中，降低成本，资源利用充分。当然也加深了灾难的蝴蝶效应，一旦出现问题，影响太大。 2、云计算的架构从总体功能上可以分为6层，从上到下分别是1）客户层2）服务层3）应用层4）平台层5）存储层6）基础设施层 四、网格计算网格是把一个局域网、城域网甚至整个Internet整合成一台巨大的超级计算机，实现知识资源、存储资源和计算资源的全面共享。网格可以分为各种地区性网格，比如公司集团内部网格、局域网网格、甚至个人网格，但网格的根本特征是资源共享而不是它的规模。 1、网格的3个条件一般认为，网格满足3个条件：1）网格能协调非集中式的资源和用户在不同控制域内的活动。2）使用标准、开放、通用的协议和接口3）提供高质量服务 2、网格的分类网格可分为1）计算网格整合专门留出用于计算能力的资源。 2）拾遗网格常用于大量桌面系统，收集机器上可用的CPU周期和其他资源，以便完成某一个功能。 3）数据网格负责容纳和提供跨多个组织的数据访问。用户无须关心数据存放于哪里。 3、网格计算的特点 1）异构性资源的异构性。物理位置不同，操作系统，存储设备等可能也不同。 2）结构的不可预测性整体结构经常变化 3）可适应性网格中的资源是异构的、分布式的、经常变化，甚至发生故障。网格需要做到动态适应。 4）可扩展性网格系统必须能够适应规模的增加，克服规模膨胀造成的性能下降或计算延迟。 5）多级管理域由于构成网格系统的计算资源通常属于不同组织，使用不同的安全机制，因此需要不同的组织共同参与，解决多级管理域问题。 五、普适计算普适计算（Ubiquitous computing（ubicomp）、pervasive computing），又称普存计算、普及计算、遍布式计算、泛在计算，是一个强调和环境融为一体的计算概念，而计算机本身则从人们的视线里消失。在普适计算的模式下，人们能够在任何时间、任何地点、以任何方式进行信息的获取与处理。 普适计算的核心思想是小型、便宜、网络化的处理设备广泛分布在日常生活的各个场所，计算设备将不只依赖命令行、图形界面进行人机交互，而更依赖“自然”的交互方式，计算设备的尺寸将缩小到毫米甚至纳米级。 间断连接与轻量计算是普适计算最重要的两个特征，普适计算系统就是要实现在这种环境下的事务和数据处理。","link":"/2022/06/07/%E8%99%9A%E6%8B%9F%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF/"},{"title":"虚拟专用网络详解","text":"​​点击阅读更多查看文章内容 VPN的概念虚拟专用网络（Virtual Private Network，VPN）是利用Internet等公共网络的基础设施，通过隧道技术，为用户提供的与专用网络具有相同通信功能的安全数据通道。其中，“虚拟”是指用户不需要建立各自专用的物理线路，而是利用Internet等公共网络资源和设备建立一条逻辑上的专用数据通道，并实现与专用数据通道相同的通信功能。“专用网络”是指虚拟出来的网络并非任何连接在公共网络上的用户都能使用，只有经过授权的用户才可以使用。该通道内传输的数据经过加密和认证，可保证传输内容的完整性和机密性。 VPN的实现技术隧道技术概念隧道是一种封装技术，它利用一种网络协议来传输另一种网络协议，即利用一种网络传输协议，将其他协议产生的数据报文封装在它自己的报文中，然后在网络中传输。隧道（Tunnel）是一个虚拟的点对点的连接。在实际应用中仅支持点对点连接的虚拟接口为Tunnel接口。一个Tunnel提供了一条使封装的数据报文能够传输的通路，并且在一个Tunnel的两端可以分别对数据报文进行封装及解封装。隧道技术就是指包括数据封装、传输和解封装在内的全过程。 隧道协议要创建隧道，隧道的客户机和服务器双方必须使用相同的隧道技术，隧道协议有二层隧道协议与三层隧道协议两类。 二层隧道协议对应OSI模型中数据链路层，使用帧作为数据交换单位，PPTP（Point to Point Tunneling Protocol）、L2TP（Layer 2 Tunneling Protocol）、L2F（Layer 2 Forwarding）都属于二层隧道协议。是将数据封装在点对点协议的帧中通过互联网络发送，主要应用于构建远程访问虚拟专网（Access VPN） 三层隧道协议对应OSI模型中网络层，使用包作为数据交换单位，GRE（Generic Routing Encapsulation）、IPSec（Internet Protocol Security）都属于三层隧道协议。都是数据包封装在附加的IP包头中通过IP网络传送，主要应用于构建企业内部虚拟专网（Intranet VPN）和扩展的企业内部虚拟专网（Extranet VPN） GRE协议隧道协议_GRE面试官：GRE 和 IPsec 隧道有什么区别？ 概念GRE（General Routing Encapsulation ，通用路由封装）由 RFC（Request for Comments）2784 定义并由 RFC 2890 更新，是对某些网络层协议(如IP和IPX)的数据报文进行封装，使这些被封装的报文能够在另一网络层协议(如IP)中传输。GRE 最好在受信任的网络路径上使用，因为数据包未加密，但如果需要加密，它可以与 IPsec 隧道结合使用。 封装过程系统接收到一个需要封装和路由的数据报文，我们称之为有效负载（Payload）。这个有效负载首先被GRE封装然后被称之为GRE报文，这个报文接着被封装在IP报文中，然后完全由IP层负责此报文的转发（Forwarding）。我们也称这个负责向前传输的IP 协议为传递（Delivery）协议或传输（Transport）协议。 GRE实际上是第三层隧道的一种运载协议（Carrier Protocol）。GRE的协议号47。 解封装过程当IP层接收到GRE报文，检查到外层IP报文头部中的协议号是47时（UDP为17，TCP为6，ICMP为1），那么，IP层输入入口函数会根据协议开关表，直接调用GRE的解封装处理函数，对GRE解封装。解封装完成后，再将原始数据报文送入IP输入队列中，以便进行进一步的传输。 IPSec协议ipsec 详解什么是IPsec？（工作方式、协议） 概念IPSec总结在 RFC 6071 中，是一组基于网络层的，应用密码学的安全通信协议族。IPSec不是具体指哪个协议，而是一个开放的协议簇。IPSec可在 IP 网络上创建加密隧道。它的加密和身份验证机制可防止窃听和数据修改，这解释了虚拟专用网络( VPN ) 一词。 IPSec协议的设计目标：是在IPV4和IPV6环境中为网络层流量提供灵活的安全服务。 IPsec 隧道经常用于在组织的分支机构或移动用户与家庭办公室或数据中心之间提供安全的数据路径，VPN 隧道终端可以是分支机构或家庭设备的网络网关。 加解密技术、 密钥管理技术、 身份认证技术身份认证、数据加密、数据验证可以有效保证VPN网络和数据的安全性身份认证：VPN网关对接入VPN的用户进行身份认证，保证接入的用户都是合法用户。 数据加密：将明文通过加密技术成密文，哪怕信息被获取了，也无法识别。 数据验证：通过数据验证技术验证报文的完整性和真伪进行检查，防止数据被篡改。 VPN的分类按VPN的协议分类VPN的隧道协议主要有三种， PPTP，L2TP和IPSec。其中PPTP和L2TP协议工作在OSI模型的第二层，又称为二层隧道协议； IPSec是第三层隧道协议，也是最常见的协议。L2TP和IPSec配合使用是目前性能最好，应用最广泛的一种。 按VPN的应用分类 Access VPN(远程接入VPN，Client-LAN类型)：它提供了一种安全的远程访问手段，使用公网作为骨干网在设备之间传输VPN数据流量。例如，出差在外的员工，有远程办公需要的分支机构，都可以利用这种类型的VPN，实现对企业内部网络资源进行安全的远程访问。 Intranet VPN(内联网VPN，LAN-LAN类型）：为了在不同局域网之间建立安全的数据传输通道，例如在企业内部各分支机构之间或者企业与其合作者之间的网络进行互联，可以采用LAN-LAN类型的VPN。而采用LAN-LAN类型的VPN，可以利用基本的Internet和Intranet网络建立起全球范围内物理的连接，再利用VPN的隧道协议实现安全保密需要，就可以满足公司总部与分支机构以及合作企业间的安全网络连接。 Extranet VPN(外联网VPN，ExtranetVPN类型)：即与合作伙伴企业网构成Extranet，将一个公司与另一个公司的资源进行连接，这和第一种VPN类似。 按所用的设备类型进行分类： 路由器式VPN：路由器式VPN部署较容易，只要在路由器上添加VPN服务即可； 交换机式VPN：主要应用于连接用户较少的VPN网络； 防火墙式VPN：防火墙式VPN是最常见的一种VPN的实现方式，许多厂商都提供这种配置类型 VPN的作用 加密传输：此作用是VPN的最为原始的作用，也是国外使用vpn的原因，加密传输功能，使的网络更加安全，保密。 VPN的用途 互联网远程访问：近年来，许多企业机构的一些员工的办公地点流动性越来越大，比如，员工到不同的城市出差时需要访问企业的内部网络，若没有vpn是访问不了的。 局域网互联：除了使用虚拟专用网络进行远程访问， VPN也可以两个局域网联系在一起。在这种工作模式下，整个远程网络可以加入到一个不同的公司网络，以形成一个扩展的企业内部网。该解决方案是采用一台VPN服务器， 实现两个局域网的互联。 内部网络的vpn使用：比如，在每一个公司，由于每个人的职位与职责不一样，内部网络也可以利用VPN技术来实现一个私有网络内的受控访问单个子网。在这种操作模式下，VPN客户端连接到一个VPN服务器作为网络网关。这种类型的VPN使用不会影响互联网服务提供商（ISP）或公共网络布线。但是，它允许组织内部署VPN的安全利益。作为企业保护他们的无线本地网络的一种方式，这种方法目前比较受欢迎。","link":"/2022/08/13/%E8%99%9A%E6%8B%9F%E4%B8%93%E7%94%A8%E7%BD%91%E7%BB%9C%E8%AF%A6%E8%A7%A3/"},{"title":"网络虚拟化（NV）","text":"​​点击阅读更多查看文章内容 网络虚拟化（NV）参考视频：云计算通识知识-网络虚拟化-5 定义将物理网络虚拟出多个相互隔离的虚拟网络，从而使得不同用户之间使用独立的网络资源，从而提高网络资源利用率，实现弹性的网络 VLAN就是一种网络虚拟化，在原有网络基础上通过VLAN Tag划分出多个广播域 网络虚拟化保障我们创建出来的虚拟机可以正常通信，访问网络 目的节省物理主机的网卡设备资源，并且可以提供应用的虚拟网络所需的L2-K7层的网络服务 网络虚拟化软件提供逻辑上的交换机和路由器（L2-L3）逻辑负载均衡器，逻辑防火墙（L4-L7）等，且可以以任何形式进行组装，从而为虚拟机提供一个完整的L2-L7层的虚拟网络拓扑 特点 与物理层解耦 接管所有的网络服务、特性和应用的虚拟网络必要的配置，简化这些服务、配置将它们映射给虚拟化层，使用服务的应用只需要和虚拟化网络层打交道 网络服务抽象化 虚拟网络层可以提供逻辑接口、逻辑交换机和路由器等，并确保这些网络设备和服务的监控、服务质量（QoS）和安全。可以和任意安全策略自由组合成任意拓扑的虚拟网络 网络按需自动化通过API自动化部署，一个完整的、功能丰富的虚拟网络可以自由部署在底层物理设施上。通过网络虚拟化，每个应用的虚拟网络和安全拓扑拥有移动性 多租户网络安全隔离计算虚拟化使多种业务或不同租户资源共享同一个数据中心资源，虚拟网络则可以同时为多租户提供安全隔离网络，租户之间的网络在逻辑上互相隔离，互不影响。 虚拟化中的网络架构网卡虚拟化软件网卡虚拟化主要通过软件控制各个虚拟机共享同一块物理网卡实现。软件虚拟出来的网卡可以有单独的MAC地址、IP地址 所有虚拟机的网卡通过虚拟交换机以及物理网卡连接至物理交换机。虚拟交换机负责将虚拟机上的数据报文从物理网口转发出去 硬件网卡虚拟化（应用较多）主要用到的技术是单根I/O虚拟化（SingleRootI/O Virtualization，SR-IOV），就是I/O直通技术，通过硬件的辅助可以让虚拟机直接访问物理设备，而不需要通过VMM。该技术可以直接虚拟出128-512张网卡，可以让虚拟机都拿到一块独立的网卡，直接使用IO资源。SR-IOV能够让网络传输绕过软件模拟层，直接分配到虚拟机，这样就降低了软件模拟层中的I/O开销。 交换机虚拟化OVS（OpenvSwitch）开放虚拟化软件交换机，是一款基于软件实现的开源虚拟以太网交换机，使用开源Apache20许可协议，主要用于虚拟机VM环境、 与众多开源的虚拟化平台相整合（支持Xen、KVM及VirtualBox多种虚拟化技术），主要有两个作用： 传递虚拟机之间的流量 实现虚拟机和外界网络的通信 网络架构虚拟化中的网络架构通常使用虚拟交换机来连接虚拟机与物理交换机，实现虚拟机之间的通信 虚拟化中的关键网络资源虚拟化中的关键网络资源大致可以分为： 物理资源：物理服务器（提供物理网卡）、物理交换机（提供物理网络） 虚拟资源：虚拟机（提供虚拟网卡）、虚拟交换机（提供虚拟交换端口（组）和上行链路） 虚拟交换机在虚拟化网络中起到承上启下的作用 虚拟化中的数据转发路径 相同端口组不同服务器内的虚拟机通讯需要经过物理网络 相同端口组相同服务器内的虚拟机通讯不需要经过物理网络 不同端口组相同服务器的虚拟机通讯需要经过物理网络 虚拟化网络链路虚拟化：虚链路聚合VPC（Virtual Port Channel）虚链路聚合，是最常见的二层虚拟化技术 链路聚合将多个物理端口捆绑在一起，虚拟成为一个逻辑端口。但传统链路聚合不能跨设备，VPC很好解决了这个问题，既可以跨设备，又可以增加链路带宽、实现链路层的高可用性 链路虚拟化：隧道协议隧道协议（Tunneling Protocol）：指通过隧道协议使多个不同协议的网络实现互联。使用隧道传递的数据可以是不同协议的数据帧或包。隧道可以将数据流强制送到特定的地址，并隐藏中间结点的网络地址，还可根据需要，提供对数据加密的功能。 典型的隧道协议：GRE（Generic Routing Encapsulation）通用路由封装IPsec（Internet Protocol Security）Internet协议安全 虚拟网络虚拟网络（Virtual Network）：是由虚拟链路组成的网络 虚拟网络节点之间的连接并不使用物理线缆连接，而是依靠特定的虚拟化链路相连 典型的虚拟网络包括：层叠网络（虚拟二层延伸网络）VPN网络 VXLANVXLAN（VirtualXtensible Local Area Network）虚拟扩展局域网：很好地解决了现有VLAN技术无法满足大二层网络需求的问题VXLAN技术是一种大二层的虚拟网络技术原理是引入一个UDP格式的外层隧道作为数据链路层，而原有数据报文内容作为隧道净荷加以传输 虚拟专用网 VPN（Virtual Private Network）虚拟专用网：是一种常用于连接中、大型企业或团体与团体间的私人网络的通信方法。 通过公用的网络架构（比如互联网）来传送内联网的信息。 利用已加密的隧道协议来达到保密、终端认证、信息准确性等安全效果。这种技术可以在不安全的网络上传送可靠的、安全的信息。","link":"/2022/06/13/%E7%BD%91%E7%BB%9C%E8%99%9A%E6%8B%9F%E5%8C%96%EF%BC%88NV%EF%BC%89/"},{"title":"虚拟化概念详解","text":"​​点击阅读更多查看文章内容 虚拟化的定义虚拟化技术可以认为是一种对物理资源抽象化，进而形成虚拟化的版本的技术 虚拟化的目的物理资源组成庞大的资源池，然后可以按需分配，随意切割物理资源 虚拟化资源分类 服务器虚拟化服务器虚拟化就是将虚拟化技术应用于服务器，将一台服务器虚拟成若干虚拟服务器，在该服务器上可以支持多个操作系统同时运行 网络虚拟化将一个物理网络逻辑拆分为多个逻辑网络的方法（VLAN） 存储虚拟化存储设备的能力、接口协议等差异性很大，存储虚拟化技术可以将不同存储设备进行格式化，将各种存储资源转化为统一管理的数据存储资源，可以用来存储虚拟机磁盘、虚拟机配置信息、快照等信息 桌面虚拟化桌面虚拟化（Desktop Virtualization）是指将计算机的终端系统（也称作桌面）进行虚拟化，以达到桌面使用的安全性和灵活性。可以通过任何设备，在任何地点，任何时间通过网络访问属于我们个人的桌面系统。 特权级别大部分的现代计算机体系结构都有两个或两个以上的特权级别，用来分隔内核和应用软件。以x86为例，为了得到更高的保护控制，在x86的保护模式下定义了当前特权级别(Current Previleged Level，简称CPL)，一共有四个特级层次(0 to 3)被定义，我们一般称之为Ring。Ring后面的数字越大特权越小，我们的操作系统一般都运行在Ring0上，而Ring1和2一般用来支持设备驱动，Ring3上面跑的就是应用软件了。而在现在的x86处理器中，64位架构已经非常普遍，64位CPU因为必须支持页表模式，所以只有两个特权级别，我们可以简单理解为Ring0和Ring3(实际上另有明确定义)，这种模型我们常称为0/3模型。 系统中有一些关键操作指令只能在最高特权级别上执行，它们一般被称为特权指令，特权指令仅仅在当前的特权级别为零时(CPL=0)才会执行。如果在非特权级别上试图执行特权指令，将生成一个一般保护异常(这通常会生成一个应用程序错误)，而非特权指令则可以在任何一个权限级别执行。 敏感指令：在虚拟化世界的VMM模型中，我们可以看到所有的客户机操作系统都运行在非特权模式下，即非Ring0级。因为Guest OS已经不处在特权级别，所以存在一部分原本应该在特权级别执行但现在因为层级权限不够必须转交VMM进行处理的指令，这部分指令就叫敏感指令。 虚拟化技术分类VMM(virtual machine monitor,虚拟机管理层)，统一管理虚拟机，对虚拟机的请求进行集中调度，虚拟操作系统与硬件通信必须经过VMM层 全虚拟化优点：不需要修改虚拟机OS VMM（虚拟化层）用来统一管理上层虚拟机，工作在Ring 0级别，对虚拟机的请求进行集中调度 全虚拟化中客户操作系统没有做任何修改，虚拟机中的CPU指令集与工作在物理机上的CPU指令集一致 客户操作系统工作在Ring 1级别，那么如果客户操作系统发出Ring 0级别的指令就会导致异常（权限不够），这里的这个异常会被VMM层捕获。VMM层将捕获的异常进行翻译找出客户操作系统发出的什么样的高权限指令，然后模拟这个指令并将结果反馈给客户操作系统。全虚拟化中每个请求都要经过异常捕获、翻译、模拟、反馈四个步骤，所以其性能比较低 典型产品：VMware Workstation、Virtual PC、QEMU 半虚拟化（操作系统辅助虚拟化）需要对客户操作系统的内核做修改 对操作系统的内核进行修改，使客户机工作在Ring 0级别，此时VMM不需要监控异常，只需要在客户操作系统发出Ring 0级别的指令时，在VMM层提供超级调用接口，将指令转发到计算机系统硬件即可。 半虚拟化需要对内核进行修改，但是windows的内核是不开源的，不能进行修改，所以windows不能使用半虚拟化技术，linux内核是开源的，可以使用半虚拟化技术不能跨平台，操作系统发出的指令相当于通过超级调用转发到硬件，那么OS发出的指令必须与硬件匹配 硬件辅助全虚拟化硬件本身支持虚拟化技术，引入了Root模式和非Root模式 客户操作系统直接工作在Ring 0，此时不需要对OS做任何修改，发出的CPU指令不会出现异常 VMM工作在Ring 0层以下，通过超级调用转发客户操作系统的指令典型产品：VMware EXSI、Xen3.0及以后的产品、MicroSoft Hyper-V、KVM 虚拟化体系架构宿主模型（OS-Hosted VMM） 物理服务器上需要安装如Windows、Linux等操作系统，这些传统操作系统并不是为虚拟化而设计的，因此本身并不具备虚拟化功能，所有的虚拟化功能都由VMM来提供 VMM通常是宿主机操作系统独立的内核模块（工作在Ring 0层），有些实现中还包括用户态进程，如负责I/O虚拟化的用户态设备模型。VMM通过调用宿主机操作系统的服务来获得资源，实现处理器、内存和I/O设备的虚拟化 VMM层依托于宿主机 原生架构模型（Hypervisor VMM）只需要Hypervisor VMM层，底层不需要原始的操作系统，但要调动硬件需要各种接口以及各种硬件的驱动。在原生架构模型（Hypervisor VMM）中，VMM首先可以被看作是一个完备的操作系统，与传统操作系统不同的是，VMM是为虚拟化而设计的，因此其本身就具备虚拟化功能。从架构上看，首先所有的物理资源如处理器、内存和I/O设备等都归于VMM所有，因此，VMM承担着管理物理资源的责任；其次，VMM需要向上提供虚拟机用于运行客户机操作系统，因此，VMM还负责虚拟环境的创建和管理。 混合模型（Hybrid VMM）混合模型（Hybrid VMM）是上述两种模式的混合体。VMM依然位于最底层，拥有所有的物理资源，包括处理器、内存和I/O设备等。与Hypervisor模型不同的是，VMM会腾让出大部分I/O设备的控制权，将他们交由一个运行在特权虚拟机中的特权操作系统来控制，相应的，VMM虚拟化的职责也会被分担。处理器、内存虚拟化依然由VMM来完成，I/O设备虚拟化则由VMM和特权操作系统共同来完成","link":"/2022/05/18/%E8%99%9A%E6%8B%9F%E5%8C%96%E6%A6%82%E5%BF%B5%E8%AF%A6%E8%A7%A3/"},{"title":"计算机网络笔记整理 ——目录索引页","text":"​​点击阅读更多查看文章内容 计算机网络笔记整理 ——目录索引页 参考书籍：《计算机网络》第八版 谢希仁编著 以下笔记整理主要包含了前六章的内容，具体包含的内容会在下面详细说明 笔记尚有许多不足之处，如果大家发现错误还请私信我修改，感谢！ 目录即链接，点击目录即可跳转到对应笔记页面 @[toc] 一、概述 计算机网络定义、类别 互联网 分组交换技术 性能指标 网络协议 体系结构 二、物理层 基本概念 数据通信(极限容量、香农公式) 传输媒体 信道复用技术 数字传输系统 三、数据链路层 数据链路层的三个基本问题 PPP协议及其透明传输 CRC差错检测技术 局域网的拓扑类型及特点 CSMA/CD协议 以太网的MAC层 四、网络层 两种服务(虚电路、数据报) 网路互联的概念 分类IP地址 无分类编址CIDR IP数据报 ARP协议 ICMP协议 NAT 路由表 路由协议(RIP、OSPF、BGP) IPv6 五、运输层 运输层、UDP和TCP概述 TCP数据报 TCP发送窗口机制 TCP确认机制 TCP连接 TCP的拥塞控制 六、应用层 域名系统DNS 文件传送协议FTP 万维网 电子邮件 动态主机配置协议DHCP","link":"/2022/01/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%86%20%E2%80%94%E2%80%94%E7%9B%AE%E5%BD%95%E7%B4%A2%E5%BC%95%E9%A1%B5/"},{"title":"计算机网络笔记整理1——概述","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：计算机网络笔记整理——目录索引页 参考书籍：《计算机网络》第八版 谢希仁编著 @[toc] 计算机网络的定义计算机网络主要是由一些通用的、可编程的硬件互连而成的，而这些硬件并非专门用来实现某一特定目的（例如，传送数据或视频信号）。这些可编程的硬件能够用来传送多种不同类型的数据，并能支持广泛的和日益增长的应用。 通过以上定义可知：1.计算机网络所连接的硬件，并不限于一般的计算机，还包括智能手机2.计算机网络并非专门用来传送数据，而是能够支持很多种的应用 可编程的硬件表明这种硬件一定包含有CPU 计算机网络的类别按照作用范围分类 广域网（WAN）：几十到几千公里 城域网（MAN）：5~50公里 局域网（LAN）：1公里左右 个人局域网（PAN）：10米左右 按照网络的使用者分类： 公用网：按规定缴纳费用的人都可以使用的网络 专用网：为特殊业务工作的需要而建造的网络 用来把用户接入到互联网的网络 接入网AN：又称为本地接入网，它本身既不属于互联网的核心部分，也不属于互联网的边缘部分，它是从某个用户端系统到互联网中的第一个路由器（边缘路由器）之间的一种网络 互联网计算机网络（简称为网络）：由若干结点和连接这些结点的链路组成互联网（Internet）：特指Internet，起源于美国，现已发展成为世界上最大的、覆盖全球的计算机网络互连网（internetwork或internet）：通过路由器把网络互连起来，这就构成了一个覆盖范围更大的计算机网络，称之为互连网。（“网络的网络”） 网络把许多计算机连接在一起互连网把许多网络通过路由器连接在一起与网络相连的计算机常称为主机 互联网的两个重要特点 连通性：使上网用户之间都可以交换信息。注意：互联网具有虚拟的特点，无法准确知道对方是谁，也无法知道对方的位置。 共享：指资源共享，资源共享的含义是多方面的，可以是信息共享、软件共享、也可以是硬件共享。由于网络的存在，这些资源好像就在用户身边一样，方便使用。 互联网的组成边缘部分：由所有连接在互联网上的主机组成。这部分是用户直接使用的，用来进行通信（传送数据、音频或视频）和资源共享核心部分：由大量网络和连接这些网络的路由器组成。这部分是为边缘部分提供服务的（提供连通性和交换） 两种通信方式端系统：连接在互连网上，处在互联网边缘部分的所有主机，它们都有合法的IP地址，在功能上可能有很大差别端系统之间的通信方式可分为两类 客户-服务器方式（C/S） 对等方式（P2P） 客户-服务器方式客户和服务器都是指通信中所涉及的两个应用进程客户-服务器方式所描述的是进程之间服务和被服务的关系，客户是服务的请求放，服务器是服务的提供方，两者都要使用网络核心部分所提供的服务客户与服务器的通信关系建立后，通信可以是双向的，客户和服务器都可发送和接受数据 对等连接方式两个主机在通信时并不区分哪一个是服务请求方还是提供方只要两个主机都运行了对等连接软件，它们就可以进行平等的、对等连接通信。 三种交换方式 电路交换（电话）：源点直达终点 报文交换（电报）：整个报文传送 分组交换（计算机网络、互连网）：单个分组传送 分组交换技术分组交换采用存储转发技术 在发送端，先把较长的报文划分成较短的、固定长度的数据段每一个数据段前面添加上首部构成分组分组交换网以分组作为数据传输单元，依次把各分组发送到接收端接收端收到分组后剥去首部还原成报文，恢复为原来的报文 分组交换的优点 高效：在分组传输的过程中动态分配传输带宽，对通信链路是逐段占用 灵活：为每一个分组独立地选择最合适的转发路由 迅速：以分组为传送单位，可以不先建立连接就能转发分组 可靠：保证可靠性的网络协议；分布式多路由的分组交换网，使网络有很好的生存型 若要传送大量数据，且传送时间远大于连接建立时间，则电路交换的速率较快报文交换和分组交换不需要预先分配传输带宽，在传送突发数据时可提高整个网络的信道利用率分组长度往往远小于报文长度，因此分组交换比报文交换的时延小，同时也具有更好的灵活性 性能指标速率、带宽、吞吐率、时延、时延带宽积、往返时间RTT、利用率 速率速率指的是数据的传送速率，也称为数据率或比特率速率的单位是：bit/s、kbit/s、Mbit/s、Gbit/s等速率往往是指额定速率或标称速率，非实际运行速率 带宽单位时间内网络中的某信道所能通过的“最高数据率”单位是bit/s 吞吐量单位时间内通过某个网络（或信道、接口）的数据量吞吐量经常用于对网络的测量，检验实际上到底有多少数据量能够通过网络吞吐量受网络的带宽或网络的额定速率限制 时延指数据从网络的一端传送到另一端所需的时间网络中的时延有：发送时延、传播时延、处理时延、排队时延数据传送的总时延就是上述四种时延之和 四种时延所产生的地方 发送时延也称为传输时延数据帧从结点进入传输媒体所需要的时间从发送数据帧的第一个比特算起，到该帧的最后一个比特发送完毕所需的时间发送时延=$\\frac{数据帧长度（bit）}{发送速率（bit/s）}$ 传播时延电磁波在信道中需要传播一定距离而花费的时间发送时延与传播时延有本质上的不同信号发送速率和信号在信道上的传播速率是完全不同的概念传播时延=$\\frac{信道长度（米）}{信号在信道上的传播速率（米/秒）}$ 处理时延主机或路由器在收到分组时，为处理分组（如：分析首部、提取数据、差错检验、查找路由）所花费的时间 排队时延分组在路由器输入输出队列中排队等待处理所经历的时延排队时延的长短往往取决于网络中当时的通信量 例题解：分组大小为1000B，其中头部大小20B,则数据部分大小为980B文件大小为980000B，所以共有$\\frac{980000}{980}=1000$个分组每个分组的大小为1000B，故每个分组的发送时延为$\\frac{10008}{10010^6}=0.08ms$如上图传输这1000个分组一共需要1002个传输时延，时间最少应由最短路径传输，中间需要经过两个路由器转发，每经过一个时延，分组向前传送一个链路，一个分组需要传送三次才能到达，最后一个分组在经过1000个传输时延后才开始传送，此时它还需要两次传送才能到达终端主机，所以共需要1002个传输时延总时间为1002*0.08=80.16ms 时延带宽积链路的时延带宽积又称为以比特为单位的链路长度时延带宽积=传播时延*带宽 往返时间RTT往返时间表示从发送方发送数据开始，到发送方收到来自接收方的确认，总共经历的时间在互联网中，往返时间还包括各中间结点的处理时延、排队时延以及转发数据时的发送时延 利用率分为信道利用率和网络利用率信道利用率：某信道有百分之几的时间是被利用的（有数据通过）。完全空闲的信道的利用率是零网络利用率：全网络的信道利用率的加权平均值信道利用率并非越高越高。当某信道的利用率增大时，该信道引起的时延也就迅速增加时延与网络利用率的关系：D0表示网络空闲时的时延，D表示网络当前的时延，U是网络的利用率，数值在0到1之间，则在适当的假定条件下D=$\\frac{D_0}{1-U}$ 网络协议网络协议，简称为协议，是为进行网络中的数据交换而建立的规则、标准或约定三要素 语法：数据与控制信息的结构或格式 语义：需要发出何种控制信息，完成何种动作以及作出何种响应 同步：事件实现顺序的详细说明 计算机网络的体系结构计算机网络的体系结构是计算机网络的各层及其协议的集合 OSI的七层协议体系结构的概念清楚，理论也较为完整，但他既复杂又不实用。TCP/IP是四层体系结构：应用层、运输层、网际层和网络接口层，但最下面的网络接口层并没有具体内容因此往往采取这种的办法，综合OSI和TCP/IP的优点，采用一种只有五层协议的体系结构","link":"/2021/12/29/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%861%E2%80%94%E2%80%94%E6%A6%82%E8%BF%B0/"},{"title":"计算机网络笔记整理2——物理层","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：计算机网络笔记整理——目录索引页 参考书籍：《计算机网络》第八版 谢希仁编著 @[toc] 物理层的基本概念物理层考虑的是怎样才能在连接各种计算机的传输媒体上传输数据比特流，而不是指具体的传输媒体 物理层接口的基本特性机械特性：指明接口所用接线器的形状和尺寸、引线数目和排列、固定和锁定装置等。电气特性：指明在接口电缆的各条线上出现的电压的范围。功能特性：指明某条线上出现的某一点电平的电压表示何种意义过程特性：指明对于不同功能的各种可能事件的出现顺序 物理层的四个特性与协议三要素的对应关系机械特性——语法电气特性——语法功能特性——语义过程特性——同步 数据通信的基础知识通信系统的一般模型:信号：数据的电气的或电磁的表现模拟信号：代表消息的参数的取值是连续的数字信号：代表消息的参数的取值是离散的信道：表示向某一个方向发送信息的媒体码元：在使用时间域的波形表示数字信号时，代表不同离散值的基本波形 基带信号：基本频带信号，来自信源的信号基带调制：仅对基带信号的波形进行变换，使它能够与信道特性相适应。变换后的信号仍然是基带信号。这种过程称为编码带通调制：使用载波进行调制，把基带信号的频率范围搬移到较高的频段，并转换为模拟信号，这样能更好地在模拟信道中传输。带通信号：经过载波调制后的信号。 不归零制：正电平代表1，负电平代表0。电平在整个码元周期保持不变归零制：正脉冲代表1，负脉冲代表0曼彻斯特编码：位周期中心的向上跳变代表0，位周期中心的向下跳变代表1。但也可以反过来定义差分曼彻斯特编码：在每一位的中心处始终都有跳变。位开始边界有跳变代表0，而位开始边界没有跳变代表1. 信道的极限容量码元传输的速率越高、信号传输的距离越远、噪声干扰越大或传输媒体质量越差，在接收端的波形的失真就越严重。 从概念上讲，限制码元在信道上的传输速率的因素有以下两个： 信道能够通过的频率范围 信噪比 信道能够通过的频率范围奈氏准则：给出了在假定的理想条件下，为了避免码间串扰，码元的传输速率的上限值。W是理想低通新道的带宽，单位为赫(Hz)理想低通信号的最高码元传输速率=2W Baud（例如：信道的带宽为4000Hz，那么最高码元传输速率就是每秒8000个码元）每赫带宽的理想低通信道的最高码元传输速率为每秒2个码元Baud是波特，是码元传输速率的单位，1波特为每秒传送1个码元 理想带通特性信道的最高码元传输速率=W Baud 注意：实际的信道所能传输的最高码元速率，要明显地低于奈氏准则给出上限数值设码元传输速率为RB，信息传输速率为Rb对二进制码元 Rb=RB对M进制码元 Rb=RBlog2M 信噪比信噪比是信号的平均功率和噪声的平均功率之比，记为S/N，并用分贝(dB)作为度量单位信噪比(dB)=10log10(S/N) (dB) 香农公式香农公式指出信号的极限信息传输速率C可表示为：C=Wlog2(1+S/N) (bit/s)W为信道的带宽(以Hz为单位)S为信道内所传信号的平均功率N为信道内部的高斯噪声功率 信道的带宽或信道中的信噪比越大，则信息的极限传输速率就越高只要信息传输速率低于信道的极限信息传输速率，就一定可以找到某种办法来实现无差错的传输若信道带宽W或信噪比S/N没有上限，则信道的极限信息传输速率C也就没有上限实际信道上能够达到的信息传输速率要比香农的极限传输速率低不少 物理层下面的传输媒体传输媒体也称为传输介质或传输媒介，它就是数据传输系统中在发送器和接收器之间的物理通路 传输媒体可分为两大类：导引型传输媒体：电磁波被导引沿着固体媒体传播非导引型传输媒体：指自由空间，在非导引型传输媒体中，电磁波的传输常称为无线传输。 导引型传输媒体双绞线：最常用的传输媒体，把两根互相绝缘的铜导线并排放在一起，然后用规则的方法绞合起来就构成了双绞线。绞合可减少对相邻导线的电磁干扰。模拟传输和数字传输都可以使用双绞线，其通信距离一般为几到十几公里 同轴电缆：同轴电缆具有很好的抗干扰特性，被广泛用于传输较高速率的数据同轴电缆的带宽取决于电缆的质量 **光缆(光纤)**：利用光导纤维(光纤)传递光脉冲来进行通信，传输带宽远远大于其他各种传输媒体的带宽多模光纤：可以存在多条不同角度入射的光线在一条光纤中传输。光脉冲在多模光纤传输时会逐渐展宽，造成失真。因此多模光纤只适合于近距离传输单模光纤：若光纤的直径减小到只有一个光的波长，则光纤就像一根波导那样，它可使光线一直向前传播，而不会产生多次反射。这样的光纤称为单模光纤 光纤优点 通信容量非常大 传输损耗小，中继距离长 抗雷电和电磁干扰性能好 无串音干扰，保密性好 体积小，重量轻 通信的三种基本方式 单向通信（单工通信）—— 只能有一个方向的通信而没有反方向的交互 双向交替通信（半双工通信）—— 通信的双方都可以发送信息，但不能双方同时发送、接收 双向同时通信（全双工通信）—— 通信的双方可以同时发送和接收信息 信道复用技术复用是通信技术中的基本概念它允许用户使用一个共享信道进行通信，降低成本，提高利用率 频分复用FDM(Frequency Division Multiplexing)将整个带宽分为多份，用户在分配到一定的频带后，在通信过程中都占用这个频带频分复用的所有用户在同样的时间占用不同的带宽资源 时分复用TDM(Time Division Multiplexing)时分复用将时间划分为一段段等长的时分复用帧(TDM帧)，每一个时分复用的用户在每一个TDM帧中占用固定序号的时隙时分复用的所有用户在不同的时间占用同样的频带宽度时分复用可能会造成线路资源的浪费 统计时分复用(STDM Statistic TDM) 波分复用WDM(Wavalength Division Multiplexing)波分复用就是光的频分复用，使用一根光纤来同时传输多个光载波信号 码分复用CDM(Code Division Multiplexing)常用名词：码分多址CDMA(Code Division Multiple Access)各用户使用经过特殊挑选的不同码型，因此彼此不会造成干扰这种系统发送的信号有很强的抗干扰能力，其频谱类似于白噪声，不易被敌人发现 每一个比特时间划分为m个短的间隔，称为码片每个站被指派一个唯一的m bit码片序列 如发送比特1，则发送自己的m bit码片序列 如发送比特0，则发送该码片序列的二进制反码 例如，S站的8bit码片序列是00011011。发送比特1时，就发送序列00011011,发送比特0时，就发送序列11100100。S站的码片序列: (-1-1-1+1+1-1+1+1) 码片序列实现了扩频假定S站要发送信息的数据率为b bit/s。由于每一个比特要转换成m个比特的码片，因此S站实际上发送的数据率提高到mb bit/s，同时S站所占用的频带宽度也提高到原来数值的m倍 CDMA的重要特点每个站分配的码片序列不仅必须各不相同，并且还必须互相正交在实用的系统中是使用伪随机码序列 令向量S表示站S的码片向量，令T表示其他任何站的码片向量。两个不同站的码片序列正交，就是向量S和T的规格化内积等于0： 一个码片向量和自己的规格化内积是1 一个码片向量和该码片反码的向量的规格化内积值是-1 CDMA的工作原理当接收站打算收S站发送的信号时，就用S站的码片序列与收到的信号求规格化内积即S*(Sx+Tx)，这相当于分别计算S*Sx和S*Tx，显然S*Sx就是S站发送的数据比特，S*Tx一定是零 数字传输系统宽带接入技术：有线宽带接入、无线宽带接入有线宽带接入：xDSL技术：DSL就是数字用户线，xDSL技术就是用数字技术对现有的模拟电话用户线进行改造，使它能够承载宽带业务 xDSL的几种类型 FTTx技术：是一种实现宽带居民接入网的方案，代表多种宽带光纤接入方式 FTTH(Fiber To The Home)：光纤到户 FTTB(Building)：光纤到大楼 FTTC(Curb)：光纤到路边","link":"/2022/01/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%862%E2%80%94%E2%80%94%E7%89%A9%E7%90%86%E5%B1%82/"},{"title":"计算机网络笔记整理4——网络层","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：计算机网络笔记整理——目录索引页 参考书籍：《计算机网络》第八版 谢希仁编著 @[toc] 网络层提供的两种服务虚电路服务网络负责可靠交付 采用面向连接的通信方式，通信之前先建立虚电路，以保证双方通信所需的一切网络资源，再使用可靠传输的网络协议，使所发送的分组无差错、按序到达终点，不丢失、不重复。 数据报服务网络层向上只提供简单灵活的、无连接的、尽最大努力交付的数据报服务 网络在发送分组时不需要先建立连接，每一个分组(即IP数据报)独立发送。网络层不提供服务质量的承诺。所传送的分组可能出错、丢失、重复和失序(不按序到达终点)，也不保证分组传送的时限。 虚电路服务与数据报服务的对比 网络互联的概念、设备、层次、协议网络互连是指将不同的网络连接起来，以构成更大规模的网络系统，实现网络间的数据通信、资源共享和协同工作。网络互连都是只用路由器进行网络互连和路由选择。 网际协议IP是TCP/IP体系中两个最主要的协议之一，与之配套使用的还有三个协议： 地址解析协议ARP 网际控制报文协议ICMP 网际组管理协议IGMP 实现网络互联的中间设备： 物理层中继系统：转发器 数据链路层中继系统：网桥或桥接器 网络层中继系统：路由器 网桥和路由器的混合物：桥路器 网络层以上的中继系统：网关 分类IP地址每一类地址都有两个固定长度的子段组成，其中一个是网络号net-id，它标志主机(或路由器)所连接到的网络，另一个是主机号host-id，它标志该主机(或路由器) 各类IP地址的指派范围 注：根据最新标准B类地址网络号128.0以及C类地址网络号192.0.0不再保留，故B类地址最大可指派网络数应该为16384，第一个可指派的网络号应为128.0；C类地址最大可指派网络数应该为2097152，第一个可指派的网络号应为192.0.0参考：B类地址第一个可分派的网络号为什么不是128.0？ - tckidd的回答 - 知乎https://www.zhihu.com/question/37927675/answer/82062124 5类IP地址的范围：A：1.0.0.0 - 126.255.255.255B：128.0.0.0 - 191.255.255.255C：192.0.0.0 - 223.255.255.255D：224.0.0.0 - 239.255.255.255E：240.0.0.0 - 247.255.255.255私有地址的范围分别是：A类地址范围：10.0.0.0—10.255.255.255B类地址范围：172.16.0.0—172.31.255.555C类地址范围：192.168.0.0—192.168.255.255 一般不指派的特殊IP地址 无分类编址CIDRCIDR：无分类域间路由选择CIDR消除了传统的A类、B类和C类地址以及子网的概念，可以更有效的分配IPv4的地址空间 2级结构：网络前缀和主机号网络前缀的位数可以取0~32之间的任意值CIDR记法：斜线记法 a.b.c.d/n：二进制IP地址的前n位是网络前缀 地址块CIDR把网络前缀都相同的连续的IP地址组成“CIDR地址块”一个CIDR地址块包含的IP地址数，取决于网络前缀的位数 128.14.32.0/20表示的地址块共有2^12^个地址，因为斜线后面的20是网络前缀的位数，所以主机号是12位这个地址块的起始地址是128.14.32.0最小地址：128.14.32.0最大地址：128.14.47.255全0和全1第主机号地址一般不使用 注意：地址表示的含义 地址掩码地址掩码长度=32位由一连串1和接着的一连串0组成，1的个数就是网络前缀的长度(IP地址)AND(地址掩码)=网络地址 三个特殊的CIDR地址块 全球国家及地区分配IP数排名 路由聚合 路由聚合有利于减少路由器之间的路由选择信息的交换，从而提高了整个互联网的性能 IP数据报一个IP数据包由首部和数据两部分组成首部的前一部分是固定长度，共20字节，是所有IP数据报必须具有的。 版本：IP协议的版本，目前的IP协议版本号为4(即IPv4) 首部长度：占4位，可表示的最大数值是15个单位(一个单位4字节),因此IP首部的最大长度为60字节 总长度：首部和数据之和的长度，占16位，因此数据报的最大长度为65535字节，总长度必须不超过最大传送单元MTU 标识：计数器，用来产生IP数据报的标识，同一数据报的分片使用同一标识 标志：占3位，目前只有两位有意义，标志字段的最低位是MF(More Fragment)。MF=1表示后面“还有分片”。MF=0表示最后一个分片。标志字段中间的一位是DF(Don’t Fragment)，只有当DF=0时才允许分片 片偏移：占13位，指出：较长的分组在分片后，某片在原分组中的相对位置。片偏移以8个字节为偏移单位。(除最后一个数据报片外，其他每个分片的长度一定是8字节的整数倍) 生存时间：记为TTL，指示数据报在网络中可通过的路由器数的最大值 协议：指出此数据报携带的数据使用何种协议，以确定目的主机的IP层需将数据部分上交给哪个协议进程 首部校验和：只校验数据报的首部 可变部分：就是一个选项字段，用来支持排错、测量以及安全等措施，内容很丰富，实际上这些选项很少被使用。 例题 ARP协议IP地址与MAC地址的区别 MAC地址(或物理地址)：是数据链路层和物理层使用的地址；IP地址：是网络层和以上各层使用的地址，是一种逻辑地址 MAC地址具有唯一性；IP地址不具有唯一性 MAC地址是Ethernet网卡上的地址，长度为48位；IP地址目前主流是32位长 IP地址放在IP数据报的首部，MAC地址放在MAC帧的首部 从源主机到目的主机的通信中，IP数据报首部中的源IP地址和目的IP地址始终不变，而数据链路层的帧首部中的源地址和目的地址在随着网络的不同而不断变化。 地址解析协议ARP作用：从网络层使用的IP地址，解析出在数据链路层使用的硬件地址ARP高速缓存：存放所在局域网内各主机和路由器的IP地址到硬件地址的映射表 当主机A向本局域网上的主机B发送IP数据报时，现在其ARP高速缓存中查找B的IP地址 如有，就可查出其对应的硬件地址写入MAC帧，然后通过局域网将该MAC帧发往此硬件地址 如没有，ARP进程在本局域网上广播发送一个ARP请求报文。收到ARP相应分组后，将得到的IP地址到硬件地址的映射写入ARP高速缓存 ARP请求分组：包含发送方硬件地址/发送方IP地址/目标方硬件地址(未知时填1)/目标方IP地址本地广播ARP请求：路由器不转发ARP请求ARP响应分组：包含发送方硬件地址/发送方IP地址/目标方硬件地址/目标方IP地址ARP分组封装在物理网络的帧中传输 ARP是解决同一个局域网上的主机或路由器的IP地址和硬件地址的映射问题，当目的主机和源主机不在同一个局域网，则通过ARP找到本局域网上的某个路由器的硬件地址，剩下的工作由这个路由器完成发送方是路由器，要把IP数据包转发到本网络上的另一个主机。这时用ARP找到目的主机的硬件地址发送方是路由器，要把IP数据包转发到另一个网络上的一个主机。这时用ARP找到本网络上另一个路由器的硬件地址。剩下的工作由这个路由器完成。 网际控制报文协议ICMPICMP是IP层的协议 ICMP报文有三大类：ICMP差错报告报文、ICMP控制报文、ICMP询问报文 ICMP差错报告报文有3种：终点不可达、时间超过、参数问题ICMP控制报文有2种：源点抑制报文(不再使用)/改变路由(重定向)ICMP请求报文有2种：回送请求或回送回答、时间戳请求或时间戳回答 ICMP的应用：PING：用来测试两个主机之间的连通性,应用层直接使用网络层ICMP，没有通过运输层TCP或UDPTraceroute：用来跟踪一个分组从源点到终点的路径MTU：利用IP数据报标志字段的中间位DF 将IP数据报的标志字段的DF位置1； 当路由器发现IP数据报长度大于MTU时，丢弃并发回一个要求分片的ICMP报文； 将IP数据报长度递减，DF位置1重发，知道不再收到ICMP报文。 ICMP的作用：为了更有效的转发IP数据报和提高交付成功的机会，在网际层使用了网际控制报文协议ICMP。 ICMP协议是TCP/IP协议的一个子协议。用在IP主机、路由器之间传递控制消息，控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。即提供差错报告和询问报文。 NAT装有NAT软件的路由器叫做NAT路由器，它至少有一个有效的外部全球地址 使用本地地址的主机在和外界通信时，都要在NAT路由器上将其本地地址转换成全球IP地址，才能和互联网互联 内部主机A用本地地址IPA和互联网上主机B通信所发送的数据报必须经过NAT路由器。 NAT路由器将数据报的源地址IPA转换成全球地址IPG,并把转换结果记录到NAT地址转换表中，目的地址IPB保持不变，然后发送到互联网。 NAT路由器收到主机B发回的数据报时，知道数据报中的源地址是IPB而目的地址是IPG 根据NAT转换表，NAT路由器将目的地址IPG转换为IPA，转发给最终的内部主机A 当NAT路由器具有n个全球IP地址时，专用网内最多可以同时有n台主机接入到互联网。这样就可以使专用网内较多数量的主机，轮流使用NAT路由器有限数量的全球IP地址 路由器的构成、转发分组、路由表路由器的构成路由器是一种具有多个输入端口和多个输出端口的专用计算机，其任务是转发分组整个的路由器结构可分为两大部分：路由选择部分和分组转发部分 路由选择部分也叫作控制部分，主要任务是构造路由表，同时不断地更新和维护路由表 分组转发部分，是数据层面，由交换结构、一组输入端口和一组输出端口组成。 转发分组的流程分组在互联网中是逐跳转发的基于终点的转发：基于分组首部中的目的地址传送和转发 最长前缀匹配：在查找路由表时可能会得到不止一个匹配结果，应从匹配结果中选择具有最长网络前缀的路由 两种特殊路由： 主机路由：对特定目的主机的IP地址专门指明的一个路由，网络前缀就是a.b.c.d/32，放在转发表的最前面，可方便地控制网络和测试网络，或需要考虑某种安全问题时采用 默认路由：不管分组的最终目的网络在哪里，都由指定的路由器R来处理，用特殊前缀0.0.0.0/0表示，可减少路由表所占用的空间和搜索路由表所用的时间 路由表按主机所在的网络地址来制作路由表 路由协议互联网采用分层次的路由选择协议，这是因为 互联网的规则非常大 许多单位不愿意外界了解自己单位网络的布局细节和本部门采用的路由选择协议，但同时还希望连接到互联网上 自治系统AS：在单一技术管理下的许多网络、IP地址以及路由器，而这些路由器使用一种自治系统内部的路由选择协议和共同的度量。每一个AS对其他AS表现出的是一个单一的和一致的路由选择策略 两类路由选择协议： 内部网关协议IGP：在一个自治系统内部使用的路由选择协议，包括RIP、OSPF 外部网关协议EGP：在不同自治系统之间进行路由选择时使用，使用最多：BGP-4 自治系统之间的路由选择叫做域间路由选择，自治系统内部的路由选择叫做域内路由选择 内部网关协议RIPRIP是一种分布式、基于距离向量的路由选择协议每个路由器都要维护从它自己到其他每一个目的网络的距离记录 距离：一个路由器到直接连接的网络的距离为1，到非直接连接的网络的距离为所经过的路由器数加1；“距离”也称为“跳数”，每经过一个路由器，跳数就加1。 一条路径最多只能包含15个路由器。“距离”等于16时即相当于不可达，只适用于小型互联网 RIP协议的特点 仅和相邻路由器交换信息 交换的信息是当前本路由器所知道的全部信息，即自己现在的路由表 按固定的时间间隔交换路由信息(如30秒) 路由表的建立 路由器在刚刚开始工作时，路由表为空，它只知道和他直连的网络，并将其加入路由表 以后，每一个路由器也只和相邻路由器交换并更新路由信息 经过若干次更新后，所有的路由器都会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器的地址 RIP协议的收敛过程较快。“收敛”就是在自治系统中所有的结点都得到正确的路由选择信息的过程 距离向量算法 例题：路由表更新 坏消息传播慢 R1说：我到网1的距离是16(表示无法到达)，是直接交付 R2在收到R1的更新报文之前，还发送原来的报文，R2并不知道R1出了故障 R1收到R2发的更新报文后，误以为可以通过R2到达网1，于是修改自己的路由信息为1，3，R2。表示“我到网1的距离为3，下一条经过R2” R2收到后又更新自己的路由表为1，4，R1 这样不断更新下去，知道R1和R2到网1的距离都增大到16时，R1和R2才知道网1是不可达的 优缺点优点：实现简单，开销较小缺点：RIP限制了网络的规则，它能使用的最大距离为15路由器之间交换的路由信息是路由器中的完整路由表，因而随着网络规模的扩大，开销也就增加“坏消息传播得慢”，使更新过程的收敛时间过长 内部网关协议OSPF开放最短路径优先OSPF使用了Dijkstra提出的最短路径算法SPF最主要的特征就是使用链路状态协议，而不像RIP那样的距离向量协议 特点 OSPF直接用IP数据报传送 向本自治系统中所有路由器发送信息，这里使用的方法是洪泛法，路由器向所有相邻的路由器发送信息，而每一个相邻的路由器又再将此信息发往其所有的相邻路由器(但不再发送给刚刚发来信息的那个路由器) 发送的信息就是与本路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息(“链路状态”就是说明本路由器都和哪些路由器相邻，以及该链路的“度量”，也称为“代价”) 当链路状态发生变化或每隔一段时间(如30分钟),路由器才用洪泛法发送链路状态信息 链路状态数据库：各路由器之间频繁地交换链路状态信息，因此所有的路由器最终都能建立一个链路状态数据库，这个数据库实际上就是全网的拓扑图，在全网范围内是一致的。OSPF的链路状态数据库能较快的更新，OSPF的更新过程收敛得快是其重要优点 区域OSPF将一个自治系统再划分为若干个更小的范围，叫做区域，每个区域都有一个32位的区域标识符(用点分十进制表示) 划分区域的好处是将利用洪泛法交换信息的范围局限于每一个区域中，在一个区域内部的路由器只知道本区域的完整网络拓扑 OSPF采用层次结构的区域划分。在上层的区域叫做主干区域(标识符为0.0.0.0)，作用是连通其他在下层的区域，从其他区域来的信息都由区域边界路由器进行概括，在主干区域内的路由器叫做主干路由器，主干路由器可以同时是边界路由器，在主干区域内还要有一个路由器专门和其他自治系统交换路由信息，这样的路由器叫做自治系统边界路由器 其它特点 OSPF对于不同类型的业务可计算出不同的路由 到同一网络有多条相同代价的路径，可以将通信量分配给这几条路径。叫做多路径间的负载均衡 支持可变长度的子网划分和无分类编址CIDR 每一个链路状态都带上一个32位的序号，序号越大状态越新。 OSPF分组类型 问候分组：发现和维持邻站的可达性 数据库描述：给出自己的链路状态数据库的摘要信息 链路状态请求：向对方请求发送自己缺少的某些链路状态的详细信息 链路状态更新：用洪泛法对全网更新链路状态 链路状态确认：对链路更新分组的确认 OSPF不用UDP而是直接用IP数据报传送 外部网关协议BGPBGP是不同自治系统的路由器之间交换路由信息的协议 力求选择出一条能够到达目的网络且比较好的路由，而并非要寻找一条最佳的路由 采用路径向量路由选择协议 BGP路由 eBGP连接(external BGP)：两个边界路由器进行通信时，必须先建立TCP连接，运行eBGP协议，这种TCP连接又称为半永久性连接(双方交换完信息后仍然保持着连接状态) iBGP连接(internal BGP)：在AS内部，两个路由器之间还需要建立一个逻辑连接(也使用TCP连接)。运行iBGP协议，在一个AS内部所有的iBGP必须是全连通的。即使两个路由器之间没有物理连接，但它们仍然有iBGP连接 IGP、iBGP、eBGP的关系 BGP发言人往往就是BGP边界路由器一个BGP发言人与其他自治系统中的BGP发言人要交换路由信息，就要先建立TCP连接，然后在此连接上交换BGP报文以建立BGP会话，利用BGP会话交换路由信息。利用TCP连接交换路由信息的两个BGP发言人，彼此成为对方的邻站或对等站。 BGP路由=[前缀，BGP属性]=[前缀，AS-PATH，NEXT-HOP]前缀：指明到哪一个子网（用CIDR记法表示）AS-PATH：自治系统路径，通告BGP路由所经过的自治系统，每经过一个AS，就将其自治系统号加入AS-PATHNEXT-HOP：下一跳，通告的BGP路由起点 三种不同的自治系统 BGP路由如何避免兜圈子？AS在检查收到的BGP路由的AS-PATH中已经有了自己，立即删除掉这条路由(在属性AS-PATH中，不允许出现相同的AS号) BGP的路由选择 本地偏好值最高的路由 AS跳数最小的路由 热土豆路由选择算法(分组在AS内转发次数最少的路由) 路由器BGP标识符的数值最小的路由 IPv6IPv6仍支持无连接的传送，但将协议数据单元PDU称为分组，而不是数据报 主要变化： 更大的地址空间 扩展的地址层次结构 灵活的首部格式 改进的选项 允许协议继续扩充 支持即插即用(自动配置) 支持资源的预分配 首部改为8字节对齐 IPv6数据报由两大部分组成：基本首部、有效载荷(也称为净负荷。允许有零个或多个扩展首部，再后面是数据部分) 地址格式IPv6数据报的目的地址可以是以下三种之一： 单播：点对点 多播：一对多 任播：IPv6新增的一种类型，任播的终点是一组计算机，但只交付其中的一个，通常是距离最近的一个 IPv6采用冒号十六进制记法每个16位的值用十六进制表示，各值之间用冒号分割 允许把数字前面的0省略，例如可以把“0000”中的前3个0省略，写成1个0 零压缩：一连串连续的0可以为一对冒号所取代。FF05:0:0:0:0:0:0:B3 可压缩为 FF05::B3在任一地址中只能使用一次零压缩 点分十进制记法的后缀冒号十六进制记法可结合使用点分十进制记法的后缀，在IPv4向IPv6的转换阶段特别有用0:0:0:0:0:0:128.10.2.1零压缩-&gt;::128.10.2.1 CIDR的斜线表示法仍然可用60位的前缀12AB00000000CD3可记为12AB:0000:0000:CD30:0000:0000:0000:0000/60或：12AB::CD30:0:0:0:0/60或：12AB:0:0:CD30::/60 IPV6地址分类","link":"/2022/01/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%864%E2%80%94%E2%80%94%E7%BD%91%E7%BB%9C%E5%B1%82/"},{"title":"计算机网络笔记整理3——数据链路层","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：计算机网络笔记整理——目录索引页 参考书籍：《计算机网络》第八版 谢希仁编著 @[toc] 数据链路层的三个基本问题链路：一条无源的点到点的物理线路段，中间没有任何其他的交换结点。一条链路只是一条通路的一个组成部分数据链路：除了物理线路外，还必须有通信协议来控制这些数据的传输。若把实现这些协议的硬件和软件加到链路上，就构成了数据线路 三个基本问题： 封装成帧：在一段数据的前后分别添加首部和尾部，构成一个帧。首部和尾部的一个重要作用就是进行帧定界 透明传输：如果数据中的某个字节的二进制代码恰好和SOH或EOT一样，数据链路层就会错误地“找到帧的边界” 解决方法：字节填充或字符填充，发送端的数据链路层在数据中心出现控制字符“SOH”或“EOT”的前面插入一个转义字符“ESC” 差错控制：在传输过程中可能会产生比特差错，1变成0，0变成1在一段时间内，传输错误的比特占所传输比特的总数称为误码率BER 点到点协议PPP及其透明传输的实现PPP协议应满足的需求： 简单：首要要求 封装成帧 透明性 多种网络层协议 多种类型链路 差错检测 检测连接状态 最大传送单元 网络层地址协商：使通信的两个网络层实体能知道或能配置彼此的网络层地址 数据压缩协商 PPP协议不需要的功能： 纠错、流量控制、序号、多点线路、半双工或单工链路 PPP协议的组成：PPP协议有三个组成部分： 一个将IP数据报封装到串行链路的方法 链路控制协议LCP 网络控制协议NCP PPP协议的帧格式： F:标志字段；A:地址字段，实际上不起作用；C：控制字段 PPP是面向字节的，所有的PPP帧的长度都是整数字节 透明传输问题当PPP用在同步传输链路时，协议规定采用硬件来完成比特填充 当PPP用在异步传输时，使用一种特殊的字符填充法 字符填充 将信息字段中出现的每一个0x7E字节转变成为2字节序列(0x7D, 0x5E)。 若信息字段中出现一个0x7D的字节，则将其转变成为2字节序列(0x7D, 0x5D)。 若信息字段中出现ASCII码的控制字符(即数值小于0x20的字符)，则在该字符前面要加入一个0x7D字节，同时将该字符的编码加以改变（0x03 -&gt; 0x7D，0x23） 零比特填充PPP协议用在SONET/SDH链路时，使用同步传输(一连串的比特连续传送)。这时PPP协议采用零比特填充方法来实现透明传输在发送端，只要发现有5个连续的1，则立即填入一个0接收端对帧中的比特流进行扫描，每当发现5个连续1时，就把这5个连续1后的一个0删除PPP协议已不是纯粹的数据链路层协议，它还包含了物理层和网络层的内容 差错检测技术(CRC) 在发送端，先把数据划分为组。假定每组有k个比特，用M表示。 用二进制的模2运算进行2^n^×M，相当于在M后面添加n个0 得到的(k+n)位的数除以事先选定好的长度为(n+1)的除数P，得出商是Q，余数是R，余数R比除数P少1位，即R是n位 将余数R作为冗余码拼接在数据M后面发送出去 关于模2除法的运算可参考https://blog.csdn.net/weixin_39450145/article/details/83987836 在数据后面添加上的冗余码称为帧检验序列FCS FCS可以用CRC这种方法得出，但CRC并非是获得FCS的唯一方法 接收端对收到的每一帧进行CRC检验若得出的余数R=0，则判定这个帧无差错，就接受若余数R≠0，则判定有差错，就丢弃 局域网的拓扑类型、特点等局域网最主要的特点就是：网络为一个单位所拥有，且地理范围和站点数目均有限局域网具有如下的优点： 具有广播功能，从一个站点可很方便的访问全网 便于系统的扩展和逐渐的演变，各设备的位置可灵活调整和改变 提高了系统的可靠性、可用性和生存性 局域网的拓扑类型：星形网、环型网、总线网 适配器的作用：网络接口板又称为通信适配器或网络接口卡，或网卡 进行串行/并行转换 对数据进行缓存 在计算机的操作系统安装设备驱动程序 实现以太网协议 CSMA/CD协议工作过程CSMA/CD含义：载波监听多点接入 / 碰撞检测 多点接入：表示许多计算机以多点接入的方式连接在一根总线上载波监听：指每一个站在发送数据之前要检测一下总线上是否有其他计算机在发送数据，如果有，则暂时不要发送数据，以免发生碰撞碰撞检测：计算机边发送数据边检测信道上的信号电压大小，当一个站检测到信号电压摆动值超过一定的门限值时，就认为总线上至少有两个站同时在发送数据，表明发生了碰撞。 为什么要进行碰撞检测？电磁波在总线上的传输速率是有限的，当某个站监听到总线是空闲时，可能并非真正是空闲的 检测到碰撞后 停止发送，每一个正在发数据的站，一旦发现总线上出现了碰撞，就要立即停止发送，免得继续浪费网络资源，然后等待一段随机时间后再次发送 强化碰撞，停止发送数据后，再继续发送若干比特的认为干扰信号，以便让所有用户都知道现在已经发生了碰撞 CSMA/CD重要特性 只能进行半双工通信，不能进行全双工通信 每个站在发送数据之后的一小段时间内，存在着遭遇碰撞的可能 这种发送的不确定性使整个以太网的平均通信量远小于以太网的最高数据率 争用期以太网的端到端往返时延2τ称为争用期，或碰撞窗口。经过征用期这段时间还没有检测到碰撞，才能肯定这次发送不会发生碰撞。 通常的争用期时间是51.2μs，对于10Mbit/s以太网，在争用期内可发送512比特。也可以说争用期是512比特时间。也可以直接使用比特作为争用期的单位。争用期是512比特，即争用期是发送512比特所需的时间。 王道书上在涉及以太网的最小帧长的描述是这样的：由CSMA/CD算法可知以太网最小帧长是64B而在CMSA/CD中对于争用期的描述是：以太网规定取51.2μs作为争用期这里要指出，以太网规定的51.2μs争用期，是基于10Mb/s的以太网的。即在10Mb/s速度下的以太网，最小帧长为64B，争用期为51.2μs。而对于100BASE-T，即100Mb/s的以太网，争用期变成了5.12μs而最短帧长不变依旧是64B。最短帧长不变，而争用期改变。 二进制指数类型退避算法 最短有效帧长：以太网规定了最短有效帧长为64字节，凡长度小于64字节的帧都是由于冲突而异常中止的无效帧。 例题 以太网信道的利用率一个站在发送帧时出现了碰撞。经过一个征用期2τ后，可能又出现了碰撞。这样经过若干个征用期后，一个站发送成功了。假定发送帧需要的时间是T0。成功发送一个帧需要占用信道的时间是T0 + τ，比这个帧的发送时间要多一个单程端到端时延τ 要提高以太网的信道利用率，就必须减少τ与T0之比。在以太网中定义了参数α。它是以太网单程端到端时延τ与帧的发送时间T0之比：α = τ / T0a→0,表示一发生碰撞就立即可以检测出来，并立即停止发送，因而信道利用率很高。a越大，表明争用期所占的比例增大，每发生一次碰撞就浪费许多信道资源，使得信道利用率明显降低。 对以太网参数α的要求：当数据率一定时，以太网的连线的长度受到限制，否则τ的数值会太大以太网的帧长不能太短，否则T0的值会太小，使α值太大 理想情况下的极限信道利用率Smax为：$$Smax=\\frac{T_0}{T_0+τ}=\\frac{1}{1+α}$$ 以太网的MAC层在局域网中，硬件地址又称为物理地址，或MAC地址 名字指出我们所要寻找的那个资源，地址指出那个资源在何处，路由告诉我们如何到达该处 严格地讲，局域网的“地址”应该是每一个站的“名字”，但人们习惯将其称为“地址” 这种48位“地址”应当是某个接口的标识符IEEE的注册管理机构RA负责向厂家分配地址字段6个字节中的前三个字节地址字段6个字节中的后三个字节由厂家自行指派 发往本站的帧包括以下三种 单播帧(一对一) 广播帧(一对全体) 多播帧(一对多) 所有的适配器都至少能识别单播地址和广播地址有的适配器可用编程方法识别多播地址只有目的地址才能使用广播地址和多播地址 MAC帧的格式常用的以太网MAC帧格式有两种标准 DIX Ethernet V2标准 IEEE的802.3标准 最常用的MAC帧是以太网V2的格式类型字段：用来标志上一层使用的是什么协议数据字段：正式名称是MAC客户数据字段最小长度64字节-18字节的首部和尾部=数据字段的最小长度46字节当数据字段的长度小于46字节时，应在数据字段的后面加入整数字节的填充字段，以保证以太网的MAC帧长不小于64字节FCS：帧检验序列 在帧的前面插入(硬件生成)的8字节中，第一个字段共7个字节，是前同步码，用来迅速实现MAC帧的比特同步。第二个字段1个字节是帧开始定界符，表示后面的信息就是MAC帧 无效的MAC帧： 数据字段的长度与长度字段的值不一致； 帧的长度不是整数个字节 用收到的帧检验序列FCS查出有差错 数据字段的长度不再46~1500字节之间 有效的MAC帧长度为64~1518字节之间 对检查出的无效MAC帧就简单地丢弃，以太网不负责重传丢弃的帧。 IEEE 802.3 MAC帧格式与以太网V2 MAC帧格式相似，区别在于：1.IEEE 802.3规定的MAC帧的第三个字段是“长度/类型”当这个字段值大于0x0600时(相当于十进制的1536)就表示“类型”。这样的帧和以太网V2 MAC帧完全一样。当这个字段值小于0x0600时才表示“长度”。2.当“长度/类型”字段值小于0x0600时，数据字段必须装入上面的逻辑链路控制LLC子层的LLC帧。 帧间最小间隔：帧间最小间隔为9.6μs，相当于96bit的发送时间。一个站在检测到总线开始空闲后，还要等待9.6μs才能再次发送数据。这样做是为了使刚刚收到数据帧的站的接收缓存来得及清理，做好接收下一帧的准备。","link":"/2022/01/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%863%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82/"},{"title":"计算机网络笔记整理5——运输层","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：计算机网络笔记整理——目录索引页 参考书籍：《计算机网络》第八版 谢希仁编著 @[toc] 运输层、UDP和TCP运输层 负责主机中两个进程之间的通信 因特网的运输层 TCP、UDP 运输层的数据传送单元是报文段(TCP)或用户数据报(UDP) 运输层只存在于分组交换网外面的主机之中 运输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层 只有位于网络边缘部分的主机的协议栈才有运输层，网络核心部分中的路由器在转发分组时都只用到下三层的功能。 通信的两端应当是两个主机中的进程。也就是说，端到端的通信是应用进程之间的通信 网络层为主机之间的通信提供服务，而运输层则在网络层的基础上，为应用程序之间的通信提供服务 在一台主机中经常有多个应用进程同时分别和另一台主机中的多个应用进程通信，这表面运输层有一个很重要的功能——复用和分用 当运输层采用面向连接的TCP协议时，尽管下面的网络是不可靠的，但这种逻辑通信信道就相当于一条全双工的可靠信道。但当运输层采用无连接的UDP协议时，这种逻辑通信信道仍然是一条不可靠信道。 用户数据报协议UDPUDP只在IP数据报服务之上增加了复用和分用的功能以及差错检测的功能 UDP是无连接的 UDP使用尽最大努力交付，即不保证可靠交付 UDP是面向报文的，对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界，一次交付一个完整的报文 UDP没有拥塞控制，因此网络拥塞不会导致主机的发送速率降低，适合实时应用 UDP支持一对一、一对多、多对一和多对多的交互通信 UDP的首部开销小，只有8字节，TCP首部则有20字节 UDP是面向报文的 应用程序必须选择合适大小的报文若报文太长：UDP把它交给IP层后，IP层需要分片，这会降低IP层的效率若报文太短，交给IP层后，会使IP数据报的首部相对太大，也会降低IP层的效率 UDP的检验和是把首部和数据部分一起都检验 例题以太网的MTU为1500字节，将IP数据报封装到以太网帧中除去20字节的首部，一次最多只能传输1480字节UDP数据字段8192字节，首部字段8字节共8200字节8200/1480=5 8200%1480=800故应当划分为6个IP数据报片，前五个为数据字段长1480，最后一个数据字段长800片偏移以8字节为单位，1480/8=185，可得：0,185,370,555,740,925 传输控制协议TCP TCP是面向连接的运输层协议 每一条TCP连接只能由两个端点，每一条TCP连接只能是点对点的 TCP提供可靠交付的服务 TCP提供全双工通信 面向字节流。TCP中的“流”指的是流入或流出进程的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块，但TCP把应用程序交下来的数据看成仅仅是一连串无结构的字节流；TCP不保证接收方应用程序收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系，但接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。 TCP连接是一条虚连接而不是一条真正的物理连接TCP对应用进程一次把多长的报文发送到TCP缓存中是不关心的TCP根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节(UDP的报文长度是应用进程给出的)TCP可把太长的数据块划分短一些再传送TCP也可等待积累有足够多的字节后再构成报文段发送出去 TCP的连接：每一条TCP连接有两个端点，TCP连接的端点叫做套接字或插口端口号拼接到IP地址即构成了套接字套接字socket=(IP地址：端口号)每一条TCP连接唯一地被通信两端的两个端点所确定TCP连接::={socket1，socket2}={(IP1:port1)，(IP2：port2)} TCP数据报 源端口和目的端口：各占2字节，端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现 序号字段：TCP连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值指的是本报文段发送的数据的第一个字节的序号 确认号字段：期望收到对方的下一个报文段的数据的第一个字节的序号(只有当ACK=1时确认号字段才有效)；若确认号=N，则表明：到序号N-1位置的所有数据都已正确收到 数据偏移：指出TCP报文段的数据起始处距离TCP报文段的起始处有多远，以4字节为计算单位 保留字段：保留为今后使用，目前置为0 紧急URG：当URG=1时，表明紧急指针字段有效，应尽快传送(紧急指针字段，指出在本报文段中紧急数据共有多少个字节，紧急数据放在本报文端数据的最前面) 确认ACK：仅当ACK=1时确认号字段才有效，当ACK=0时，确认号无效。 推送PSH：接受TCP收到PSH=1的报文段内，就尽快地交付接受应用进程，而不再等到整个缓存都填满了后再向上交付 复位RST：当RST=1时，表明TCP连接中出现严重差错，必须释放连接，然后再重新建立运输连接 同步SYN：当SYN=1，ACK=0表示这是一个连接请求报文，对方若同意建立连接，则在相应的报文段中使用SYN=1和ACK=1。因此SYN=1就表示这是一个连接请求或连接接受报文。 终止FIN：用来释放一个连接，FIN=1表明此报文段是其发送的最后数据，并要求释放运输连接 窗口字段：用来让对方设置发送窗口的依据，单位为字节 检验和：检验范围包括首部和数据两部分，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部 选项字段：长度可变，最长可达40字节。当没有使用“选项”时，TCP的首部长度是20字节，TCP最初只规定了一种选项，即最大报文段长度MSS，MSS是每一个TCP报文段中的数据字段的最大长度。 填充：为了使整个首部长度是4字节的整数倍 TCP发送窗口机制TCP的滑动窗口是以字节为单位的 发送缓存用来暂时存放：发送应用程序传送给发送方TCP准备发送的数据TCP已发送出但尚未收到确认的数据接受缓存用来暂时存放：按序到达的、但尚未被接收应用程序读取的数据不按序到达的数据 超时重传时间设置TCP采用了一种自适应算法，它记录一个报文段发出的时间，以及收到相应的确认的时间。这两个时间之差就是报文段的往返时间RTT。TCP保留了RTT的一个加权平均往返时间RTTs(又称为平滑的往返时间),第一次测量RTT样本时，RTTs值就取为所测量到的RTT样本值。以后每测量到一个新的RTT样本，就按下式重新计算一次RTTs：新的RTTs = (1-α) x (旧的RTTs) + α x (新的RTT样本)注意：0 ≤ α &lt; 1，若接近于零，表示RTT值更新较慢；若接近于1，表示RTT值更新较快。推荐取的α值为1/8，即0.125 超时重传时间RTO应略大于RTTs，建议使用下式计算：RTO=RTTs+4×RTTD RTTD是RTT偏差的加权平均值第一次测量时，RTTD值取为RTT的一半，以后的测量中，使用下式计算新的RTTD=(1 - β) × (旧的RTTD) + β × | RTTS - 新的RTT样本 |β是个小于1的系数，推荐值为1/4，即0.25 γ的典型值是2 TCP确认机制选择确认SACK 只能指明4个字节块是因为，4个字节快共有8个边界，每个边界用掉4个字节(因为序号有32位，需要使用4个字节表示),因而需要用32个字节，另外还需要两个字节，一个字节用来表明SACK选项，另一个字节指明这个选项要占用多少字节。 TCP连接运输连接有三个阶段： 连接建立 数据传送 连接释放 TCP连接的建立采用客户服务器方式主动发起连接建立的应用进程叫做客户被动等待连接建立的应用进程叫做服务器 TCP的连接建立TCP建立连接的过程叫做握手握手需要在客户和服务器之间交换三个TCP报文。称之为三报文握手A向B传送的连接请求报文段中的seq = x，表明传送数据时的第一个数据字节的序号是x。SYN=1的报文段不能携带数据，但要消耗掉一个序号ACK报文段可以携带数据，如果不携带数据则不消耗序号CLOSED——关闭状态LISTEN——收听状态SYN-SENT——同步已发送状态SYN-RCVD——同步收到状态ESTABLISHED——已建立连接状态 TCP的连接释放数据传输结束后，通信的双方都可以释放连接TCP连接释放过程是四报文握手 第一个报文seq=u，它等于前面以传送过的数据的最后一个字节的序号加1，FIN报文段即使不携带数据，也消耗掉一个序号 B在收到第一个报文后即发出确认，seq=v，它等于B前面已传送过的数据的最后一个字节的序号加1.然后B就进入CLOSE-WAIT状态，此时A到B这个方向的连接就释放了，这时的TCP连接处于半关闭状态，即A无数据发送，但B若发送数据，A仍要接受 若B没有数据发送了，就通知TCP释放连接，此时seq=w(在半关闭状态，B可能又发送了一些数据)，重复上次的ack A收到B的连接释放报文后，发出确认ack=w+1，seq=u+1(前面发送的FIN报文段要消耗掉一个序号) A等待2MSL(最长报文段寿命)后才进入CLOSED状态，保证A发送的最后一个报文能够到达B。若这个报文丢失，A能在2MSL时间内收到重传的FIN+ACK报文，接着A重传确认，重启2MSL计时器；同时经过2MSL时间，可以使本连接持续的时间内所产生的所有报文段都从网络中消失，这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。 TCP的拥塞控制拥塞：某段时间，若对网络中某资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。最坏结果：系统崩溃 TCP采用基于窗口的方法进行拥塞控制，这种方法属于闭环控制方法。 TCP发送方维持一个拥塞窗口CWND，大小取决于网络的拥塞程度，并且动态地变化，发送窗口大小不仅取决于接收方公告的接收窗口，还取决于网络的拥塞状况真正的发送窗口值=Min(公告窗口值，拥塞窗口值) 拥塞的判断 重传定时器超时 收到三个相同(重复)的ACK TCP拥塞控制算法慢开始由小到大逐渐增大拥塞窗口数值初始拥塞窗口cwnd设置为不超过2至4个SMSS(发送方的最大报文段)的数值**慢开始门限ssthresh(状态变量)**：防止拥塞窗口cwnd增长过大引起网络拥塞拥塞窗口cwnd控制方法：在每收到一个对新的报文段的确认后，可以把拥塞窗口增加最多一个SMSS的数值拥塞窗口cwnd每次的增加量 = min(N,SMSS)N是原先未被确认的、但现在被刚收到的确认报文段所确认的字节数。 慢开始门限ssthresh的用法如下：当cwnd&lt;ssthresh时，使用慢开始算法当cwnd&gt;ssthresh时，停止使用慢开始算法而改用拥塞避免算法当cwnd=ssthresh时，即可使用慢开始，也可使用拥塞避免 拥塞避免算法让拥塞窗口cwnd缓慢增大，每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞(重传定时器超时)： ssthresh = max(cwnd/2,2) cwnd = 1 执行慢开始算法 快重传算法快重传FR(Fast Retransmission)算法可以让发送方尽早知道发生了个别报文段的丢失。发送方只要一连收到三个重复确认,就知道接收方确实没有收到报文段，因而应当立即进行重传(即“快重传”)，这样就不会出现超时，发送方也就不会误认为出现了网络拥塞 快恢复算法当接收端收到连续三个重复的确认时，由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，而是执行快恢复算法： 慢开始门限ssthresh = 当前拥塞窗口 cwnd/2 新拥塞窗口cwnd = 慢开始门限 ssthresh 开始执行拥塞避免算法","link":"/2022/01/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%865%E2%80%94%E2%80%94%E8%BF%90%E8%BE%93%E5%B1%82/"},{"title":"计算机网络笔记整理6——应用层","text":"​​点击阅读更多查看文章内容 点此链接可跳转到：计算机网络笔记整理——目录索引页 参考书籍：《计算机网络》第八版 谢希仁编著 @[toc] 应用层确定进程之间通信的性质 域名系统DNS域名：因特网上主机的名字；与IP地址对应。域名系统DNS：是因特网使用的命名系统，用来把便于人们使用的域名(机器名字)转换为IP地址。 互联网采用层次结构的命名树作为主机的名字，并使用分布式的域名系统DNS 域名服务器一个服务器所负责管辖的范围叫做区，每一个区设置相应的权限域名服务器，用来保存该区中的所有主机的域名到IP地址的映射。DNS服务器的管辖范围以“区”为单位。 域名服务器的种类 根域名服务器最高层次的域名服务器，也是最重要的域名服务器，所有的根域名服务器都知道所有的顶级域名服务器的域名和IP地址。根域名服务器并不直接把域名转换成IP地址在使用迭代查询时，根域名服务器把下一步应当找的顶级域名服务器的IP地址告诉本地域名服务器 顶级域名服务器顶级域名服务器(即TLD服务器)负责管理在该顶级域名服务器注册的所有二级域名。当收到DNS查询请求时，就给出相应的回答(可能是最后的结果，也可能是下一步应当找的域名服务器的IP地址) 权限域名服务器负责一个区的域名服务器当一个权限域名服务器不能给出最后的查询回答时，就会告诉发出查询请求的DNS客户，下一步应当找哪一个权限域名服务器。 本地域名服务器(又称为默认域名服务器)当一个主机发出DNS查询请求时，这个请求报文就发送给本地域名服务器。每一个互联网服务提供ISP，或一个大学，甚至一个大学里的系，都可以拥有一个本地域名服务器，当所要查询的主机也属于同一个本地ISP时，该本地域名服务器立即就能将所查询的主机名转换为它的IP地址，而不需要再去询问其他的域名服务器。 域名的解析过程递归查询主机向本地域名服务器的查询一般都是采用递归查询，如果主机所询问的本地域名服务器不知道被查询域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其他根域名服务器继续发出查询请求报文 迭代查询本地域名服务器向根域名服务器的查询通常采用迭代查询，当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地域名服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地域名服务器进行后续的查询 文件传送协议FTP文件传送协议FTP是互联网上使用的最广泛的文件传送协议 FTP提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存取权限 FTP屏蔽了个计算机系统的细节，因而适合于在异构网络中任意计算机之间传送文件。 FTP只提供文件传送的一些基本的服务，它使用TCP可靠的运输服务。FTP的主要功能是减少或消除在不同操作系统下处理文件的不兼容性 FTP使用客户服务器方式，一个FTP服务器进程可同时为多个客户进程提供服务。FTP的服务器进程由两大部分组成：一个主进程，负责接受新的请求；另外有若干个从属进程，负责处理单个请求 主进程的工作步骤 打开熟知端口(端口号为21)，使客户进程能够连接上 等待客户进程发出连接请求 启动从属进程来处理客户进程发来的请求。从属进程对客户进程的请求处理完毕后即终止 回到等待状态，继续接受其他客户进程发来的请求。主进程与从属进程的处理是并发地进行。 两个连接在进行文件传输时，FTP的客户和服务器之间要建立两个并行的TCP连接：“控制连接”和“数据连接”。 控制连接在整个会话期间一直保持打开，FTP客户端发出的传送请求通过控制连接发送给服务器端的控制进程，但控制连接不用来传送文件。 实际用于传输文件的是数据连接。服务器端的控制进程在接收到FTP客户发送来的文件传输请求后就创建数据传送进程和数据连接，用来连接客户端和服务器端的数据传送进程。数据传送进程实际完成文件的传送，在传送完毕后关闭“数据传送连接”并结束运行 FTP使用了一个分离的控制连接，因此FTP的控制信息是带外传送的 客户进程发起连接请求时要连接服务器进程的熟知端口(21),同时还要告诉服务器进程自己的另一个端口号码，用于建立数据传送连接。接着，服务器进程用自己传送数据的熟知端口(20）,与客户进程所提供的的端口号建立数据传送连接。使用了两个不同的端口号，所以数据连接与控制连接不会发生混乱。 万维网万维网WWW(world Wide Web)并非某种特殊的计算机网络，而是一个大规模的、联机式的信息储藏所。 万维网以客户-服务器访视工作，浏览器就是客户程序，万维网文档所驻留的计算机则运行服务器程序，因此这个计算机也称为万维网服务器 统一资源定位符URL由以冒号隔开的两大部分组成，在URL中的字符对大小写没有要求 协议：指出使用何种协议来获取该万维网文档，必写主机名：万维网文档所存放主机的域名，通常以www开头，也可用点分十进制IP地址代替。:端口：端口号，通常就是协议默认端口号(如：HTTP默认端口号为80),可省略，如不使用默认端口则必须写明。路径：有时也不需要使用 有些浏览器再输入URL时，可以把最前面的“http://”甚至把主机名最前面的“www”省略，由浏览器自动补全。 超文本传送协议HTTPHTTP是一个面向事务的应用层协议，它使用TCP连接进行可靠的传送定义了浏览器与万维网服务器通信的格式和规则。 访问响应时间建立TCP连接需要使用三报文握手，当前两个报文完成后，万维网客户就把HTTP请求报文，作为三报文握手中的第三个报文的数据，发送给万维网服务器。 HTTP/1.0协议的主要缺点——非持续连接 HTTP/1.1协议使用持续连接持续连接：万维网服务器在发送响应后仍然在一段时间内保持这条连接，不局限于传送同一页面上链接的文档，而是只要这些文档都在同一个服务器上就行两种工作方式：非流水线方式：流水线方式： HTTP/2协议1.可以并行发回响应2.允许客户复用TCP连接进行多个请求3.所有报文划分为较小的二进制编码帧，采用新的压缩算法，不发送重复首部字段，减小了首部开销，提高了传输效率4.向后兼容 电子邮件电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人的邮箱中，收件人可随时上网到自己使用的邮件服务器进行读取。 简单邮件传送协议：SMTP，由于SMTP只能传送可打印的7位ASCII码邮件，在1996年又发布了通用互联网邮件扩充协议MIME 一个电子邮件系统应具有下图中的三个主要组成构件：用户代理、邮件服务、以及邮件发送协议和邮件读取协议 用户代理UA：用户与电子邮件系统的接口，大多数情况下它就是运行在用户计算机中的一个程序。因此用户代理又称为电子邮件客户端软件。用户代理的功能：撰写：给用户提供编辑信件的环境显示：能方便地在计算机屏幕上显示邮件内容处理：包括发送、接受、转发、删除等通信：发信人写完邮件后，要利用邮件发送协议将邮件发送到用户所使用的邮件服务器。收件人在接收邮件时，要使用邮件读取协议从本地邮件服务器接收邮件。 邮件服务器：邮件服务器的功能是发送和接受邮件，同时还要向发信人报告邮件传送的情况。邮件服务器按照客户-服务器方式工作。邮件服务器需要使用两个不同的协议。SMTP：用于发送邮件邮局协议POP：用于用户代理UA接收邮件 SMTP和POP3都是使用TCP连接来传送邮件的，目的是为了保证可靠地传送邮件。 电子邮件由信封和内容两部分组成，在邮件的信封上，最重要的就是收件人的地址。 电子邮件使用的协议简单邮件传送协议：SMTP通用因特网扩充协议：MIME邮局协议：POP因特网报文存取协议：IMAP 简单邮件传送协议SMTPSMTP所规定的就是在两个相互通信的SMTP进程之间应如何交换信息 SMTP使用客户服务器方式，因此，负责发送邮件的SMTP进程就是SMTP的客户，而负责接受邮件的SMTP进程就是SMTP服务器。 SMTP通信的三个阶段 连接建立：SMTP客户每隔一定时间(如30分钟)对邮件缓存扫描一次。如发现有邮件，就是用SMTP的熟知端口25与接收方邮件服务器的SMTP服务器建立TCP连接。SMTP不使用中间的邮件服务器。 邮件传送 连接释放：邮件发送完毕后，SMTP应释放TCP连接 邮件读取协议POP3和IMAPPOP也使用客户-服务器的工作方式接受邮件的用户PC机中运行POP客户程序在用户所连接的ISP的邮件服务器中运行POP服务器程序 IMAP也是客户服务器的工作方式用户在自己的PC机上就可以操纵ISP的邮件服务器的邮箱，就像在本地操作一样IMAP是一个联机协议 通用互联网邮件扩充MIMEMIME并没有改动SMTP或取代他，但增加了邮件主体的结构，并定义了非ASCII码的编码规则 base64编码先把二进制代码划分为一个个24位长的单元，然后把每一个24位单元划分为4个6位组。每一个6位组按以下方法转换成ASCII码6位二进制共有64种取值，从0到63.用A表示0，用B表示1，以此类推，等26个大写字母排列完毕后，，再排26个小写字母，再后面是10个数字，最后用“+”表示62，用“/”表示63。再用两个连在一起的等号“==”和一个等号“=”分别表示最后一组的代码只有8位或16位。 动态主机配置协议DHCP因特网上的主机需要配置的项目： IP地址 子网掩码 默认路由器的IP地址 域名服务器的IP地址 互联网广泛使用的动态主机配置协议DHCP提供了即插即用连网的机制这种机制允许一台计算机加入新的网络和获取IP地址而不用手工参与 需要IP地址的主机在启动时就向DHCP服务器广播发送发现报文，这时该主机就成为DHCP客户 本地网络上所有主机都能收到此广播报文，但只有DHCP服务器才回答此广播报文 DHCP服务器现在其数据库中查找该计算机的配置信息。若找到，则返回找到的信息。若找不到，则从服务器的IP地址池中取一个地址分配给该计算机。DHCP服务器的回答报文叫做提供报文。 租用期：DHCP服务器分配给DHCP客户的IP地址是临时的，DHCP客户只能在一段时间内使用这个IP地址，DHCP称这段时间为租用期。租用期的数值由DHCP服务器自己决定，DHCP客户也可在自己发送的报文中提出对租用期的要求。 DHCP协议的工作过程： DHCP服务器被动打开UDP端口67，等待客户端发来的报文 DHCP客户从UDP端口68发送DHCP发现报文 凡受到DHCP发现报文的DHCP服务器都发出DHCP提供报文，因此在DHCP客户可能收到多个DHCP提供报文 DHCP客户从几个DHCP服务器中选择其中的一个，并向所选择的DHCP服务器发送DHCP请求报文 被选择的DHCP服务器发送确认报文，进入已绑定状态，并可开始使用得到的临时IP地址了DHCP客户现在要根据服务器提供的租用期T设置两个计时器T1和T2，它们的超时时间分别是0.5T和0.875T。当超时时间到就要请求更新租用期。 租用期过了一半(T1时间到)，DHCP发送请求报文要求更新租用期 DHCP服务器若同意，则发回确认报文。DHCP客户得到了新的租用期，重新设置计时器。 DHCP服务器若不同意，则发回否认报文。这时DHCP客户立即停止使用原来的IP地址，而必须重新申请IP地址，若DHCP服务器不响应步骤6的请求报文，则在租用期过了87.5%时，DHCP客户必须重新发送请求报文（重复步骤6），继续后面的步骤 DHCP客户可随时提前终止服务器所提供的租用期，这时只需向DHCP服务器发送释放报文即可","link":"/2022/01/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%E6%95%B4%E7%90%866%E2%80%94%E2%80%94%E5%BA%94%E7%94%A8%E5%B1%82/"},{"title":"软件定义网络（SDN）","text":"​​点击阅读更多查看文章内容 SDN基本概述参考文章：SDN基本概述、解读SDN的东西、南北向接口 传统网络数据控制与转发传统网络是分布式控制的架构，每台设备都包含独立的控制平面，数据平面。 传统网络是分布式控制的架构： 这里的分布式控制指在传统IP网络中，用于协议计算的控制平面和报文转发的数据平面位于同一台设备中。 路由计算和拓扑变化后，每台设备都要重新进行路由计算过程，并称为分布式控制过程。 在传统IP网络中，每台设备都是独立收集网络信息，独立计算，并且都只关心自己的选路。 这种模型的弊端就是所有设备在计算路径时缺乏统一性。 传统网络结构体系传统网络的管理平面、控制平面、数据平面： 管理平面：管理设备（SNMP） 控制平面：路由协议(IGP、BGP) 数据平面：转发表（FIB） OSS：Operation Support System，运营支撑系统。 NMS：Network Management Server，网络管理服务器 传统网络架构： 传统网络分为管理平面、控制平面和数据平面。 管理平面主要包括设备管理系统和业务管理系统，设备管理系统负责网络拓扑、设备接口、设备特性的管理，同时可以给设备下发配置脚本。业务管理系统用于对业务进行管理，比如业务性能监控、业务告警管理等。 控制平面负责网络控制，主要功能为协议处理与计算。比如路由协议用于路由信息的计算、路由表的生成。 数据平面是指设备根据控制平面生成的指令完成用户业务的转发和处理。例如路由器根据路由协议生成的路由表对接收的数据包从相应的出接口转发出去。 传统网络局限性 流量路径的灵活调整能力不足。 网络协议实现复杂，运维难度较大。 网络新业务升级速度较慢。 传统网络通常部署网管系统作为管理平面，而控制平面和数据平面分布在每个设备上运行。 流量路径的调整需要通过在网元上配置流量策略来实现，但对于大型网络的流量进行调整，不仅繁琐而且还很容易出现故障；当然也可以通过部署TE隧道来实现流量调整，但由于TE隧道的复杂性，对于维护人员的技能要求很高。 传统网络协议较复杂，有IGP、BGP、MPLS、组播协议等，而且还在不断增加。 设备厂家除标准协议外都有一些私有协议扩展，不仅设备操作命令繁多，而且不同厂家设备操作界面差异较大，运维复杂。 传统网络中由于设备的控制面是封闭式的，且不同厂家设备实现机制也可能有所不同，所以一种新功能的部署可能会造成周期较长；且如果需要对设备软件进行升级，还需要在每台设备上进行操作，大大降低了工作效率。 SDN概述SDN（Software Defined Netrork）软件定义网络。 2006年，以斯坦福大学教授Nike Mckewn为首的团队提出了OpenFlow的概念，并基于OpenFlow技术实现网络的可编程能力，是网络像软件一样灵活编程，SDN技术应运而生。 SDN的三个主要特征： 转控分离：网元的控制平面在控制器上，负责协议计算，产生流表；而转发平面只在网络设备上。 集中控制：设备网元通过控制器集中管理和下发流表，这样就不需要对设备进行逐一操作，只需要对控制器进行配置即可。 开放接口：第三方应用只需要通过控制器提供的开放接口，通过编程方式定义一个新的网络功能，然后在控制器上运行即可。 SDN控制器既不是网管，也不是规划工具： 网管没有实现转控分离：网管只负责管理网络拓扑、监控设备告警和性能、下发配置脚本等操作，但这些仍然需要设备的控制平面负责产生转发表项。 规划工具的目的和控制器不同：规划工具是为了下发一些规划表项，这些表项并非用于路由器转发，是一些为网元控制平面服务的参数，比如IP地址，VLAN等。控制器下发的表项是流表，用于转发器转发数据包。 SDN网络体系架构SDN是对传统网络架构的一次重构，由原来分布式控制的网络架构重构为集中控制的网络架构。 SDN网络体系架构的三层模型： 协同应用层：这一层主要是体现用户意图的各种上层应用程序，此类应用程序称为协同层应用程序，典型的应用包括OSS（Operation support system 运营支撑系统）、Openstack等。传统的IP网络同样具有转发平面、控制平面和管理平面，SDN网络架构也同样包含这3个平面，只是传统的IP网络是分布式控制的，而SDN网络架构下是集中控制的。 控制层：控制层是系统的控制中心，负责网络的内部交换路径和边界业务路由的生成，并负责处理网络状态变化事件。 转发层：转发层主要由转发器和连接器的线路构成基础转发网络，这一层负责执行用户数据的转发，转发过程中所需要的转发表项是由控制层生成的。 SDN架构下的接口北向接口（Northbound Interface）是为厂家或运营商进行接入和管理网络的接口，即向上提供的接口。 南向接口（Southbound Interface）是提供对其他厂家网元的管理功能，支持多种形式的接口协议。 SDN控制器及北向接口技术初探控制层是SDN的大脑，负责对底层转发设备的集中统一控制，同时向上层业务提供网络能力调用的接口，在SDN架构中具有举足轻重的作用，SDN控制器也是SDN关注的焦点。从技术实现上看，控制器除了南向的网络控制和北向的业务支撑外，还需要关注东西的扩展，以避免SDN集中控制导致的性能和安全瓶颈问题，SDN控制器也在南向、北向、东西向上引入了相应的核心技术，有效解决与各层通信以及控制集群横向扩展的难题。 当前，业界有很多基于OpenFlow控制协议的开源的控制器实现，例如NOX、Onix、Floodlight等，它们都有各自的特色设计，能够实现链路发现、拓扑管理、策略制定、表项下发等支持SDN网络运行的基本操作。虽然不同的控制器在功能和性能上仍旧存在差异，但是从中已经可以总结出 SDN控制器应当具备的技术特征，从这些开源系统的研发与实践中得到的经验和教训将有助于推动SDN控制器的规范化发展。 另外，用于网络集中化控制的控制器作为SDN网络的核心，其性能和安全性非常重要，其可能存在的负载过大、单点失效等问题一直是SDN领域中亟待解决的问题。当前，业界对此也有了很多探讨，从部署架构、技术措施等多个方面提出了很多有创见的方法。 SDN控制器对网络的控制主要是通过南向接口协议实现,包括链路发现、拓扑管理、策略制定、表项下发等，其中链路发现和拓扑管理主要是控制其利用南 向接口的上行通道对底层交换设备上报信息进行统一监控和统计;而策略制定和表项下发则是控制器利用南向接口的下行通道对网络设备进行统一控制。 SDN北向接口是通过控制器向上层业务应用开放的接口，其目标是使得业务应用能够便利地调用底层的网络资源和能力。通过北向接口，网络业务的开发者能以软件编程的形式调用各种网络资源;同时上层的网络资源管理系统可以通过控制器的北向接口全局把控整个网络的资源状态，并对资源进行统一调度。因为北向接口是直接为业务应用服务的，因此其设计需要密切联系业务应用需求，具有多样化的特征。同时，北向接口的设计是否合理、便捷，以便能被业务应用广泛调用，会直接影响到SDN控制器厂商的市场前景。 与南向接口方面已有OpenFlow等国际标准不同，北向接口方面还缺少业界公认的标准，因此，北向接口的协议制定成为当前SDN领域竞争的焦点， 不同的参与者或者从用户角度出发，或者从运营角度出发，或者从产品能力角度出发提出了很多方案。据悉,目前至少有20种控制器,每种控制器会对外提供北向接口用于上层应用开发和资源编排。虽然北向接口标准当前还很难达成共识，但是充分的开放性、便捷性、灵活性将是衡量接口优劣的重要标准，例如REST API就是上层业务应用的开发者比较喜欢的接口形式。部分传统的网络设备厂商在其现有设备上提供了编程接口供业务应用直接调用，也可被视作是北向接口之一，其目的是在不改变其现有设备架构的条件下提升配置管理灵活性，应对开放协议的竞争。 控制器负责整个SDN网络的集中化控制，对于把握全网置资源视图、改善网络资源交付都具有非常重要的作用。但控制能力的集中化，也意味着控制器局的 安全性和性能成为全网的瓶颈;另外，单一的控制器也无法应对跨多个地域的SND网络问题，需要多个SDN控制器组成的分布式集群，以避免单一的控制器节点 在可靠性、扩展性、性能方面的问题。目前，用于多个控制器之间沟通和联系的东西向接口还没定义标准，但专家表示，一些非常成熟的集群技术可以被运用到 SDN网络中来解决上述难题。 SDN交换机及南向接口技术初探SDN的核心理念之一就是将控制功能从网络设备中剥离出来，通过中央控制器实现网络可编程，从而实现资源的优化利用，提升网络管控效率。 工作在基础设施层的SDN交换机虽然不在需要对逻辑控制进行过多考虑，但作为SDN网络中负责具体数据转发处理的设备，为了完成高速数据转发，还是要遵循交换机工作原理。本质上看，传统设备中无论是交换机还是路由器，其工作原理都是在收到数据包时，将数据包中的某些特征域与设备自身存储的一些表项进行比对，当发现匹配时则按照表项的要求进行相应处理。SDN交换机也是类似的原理，但是与传统设备存在差异的是，设备中的各个表项并非是由设备自身根据周边的网络环境在本地自行生成的，而是由远程控制器统一下发的，因此各种复杂的控制逻辑(例如链路发现、地址学习、路由计算等等)都无需在SDN交换机中实现。 SDN交换机可以忽略控制逻辑的实现，全力关注基于表项的数据处理，而数据处理的性能也就成为评价SDN交换机优劣的最关键指标，因此，很多高性能转发技术被提出，例如基于多张表以流水线方式进行高速处理的技术。另外，考虑到SDN和传统网络的混合工作问题，支持混合模式的SDN交换机也是当前设备层技术研发的焦点。同时，随着虚拟化技术的出现和完善，虚拟化环境将是SDN交换机的一个重要应用场景，因此SDN交换机可能会有硬件、软件等多种形态。 例如，OVS(Open vSwitch，开放虚拟交换标准)交换机就是一款基于开源软件技术实现的能够集成在服务器虚拟化Hypervisor中的交换机，具备完善的交换机功能，在虚拟化组网中起到了非常重要的作用。 SDN交换机的出现，对传统的网络设备厂商造成了最直接的威胁，如何将新兴的网络技术与传统设备产品的优势相融合，是这些厂商正在苦苦思索的问题。 虽然SDN交换机已经对传统的网络产业链造成了巨大的冲击，但是仅凭单独的数据转发设备还不足以支撑起整个SDN的天空，未来更激烈地竞争必将会在SDN 的控制层和应用层发生。 SDN交换机只负责网络高速转发，保存的用于转发决策的转发表信息来自控制器，SDN交换机需要在远程控制器的管控下工作，与之相关的设备状态和控制指令都需要经由SDN的南向接口传达，从而实现集中化统一管理。 当前，最知名的南向接口莫过于ONF倡导的OpenFlow协议。作为一个开放的协议，OpenFlow突破了传统网络设备厂商对设备能力接口的壁垒，经过多年的发展，在业界的共同努力下，当前已经日臻完善，能够全面解决SDN网络中面临的各种问题。 当前，OpenFlow已经获得了业界的广泛支持，并成为了SDN领域的事实标准，例如OVS交换机就能够支持OpenFlow协议。 OpenFlow解决了如何由控制层把SDN交换机所需的用于和数据流做匹配的表项下发给转发层设备的问题，同时ONF还提出了OF-CONFIG协议， 用于对SDN交换机进行远程配置和管理，其目标都是为了更好地对分散部署的SDN交换机实现集中化管控。 OpenFlow在SDN领域中的重要地位不言而喻，甚至大家一度产生过OpenFlow就等同于SDN的误解。实际上，OpenFlow只是基于 开放协议的SDN实现中可使用的南向接口之一，后续可能还会有很多的南向接口(例如ForCES、PCE-P等等)被陆续应用和推广。但必须承认的 是，OpenFlow就是为SDN而生的，因此它与SDN的契合度最高。相信在以ONF为领导的产业各方的大力推动下，它在未来的发展前景也将更加明朗。 SDN交换机及东西向接口技术初探在开放了南北向接口以后，SDN发展中面临的一个问题就是控制平面的扩展性问题，也就是多个设备的控制平面之间如何协同工作，这涉及到SDN中控制平面的东西向接口的定义问题。如果没有定义东西向接口，那么SDN充其量只是一个数据设备内部的优化技术，不同SDN设备之间还是要还原为IP路由协议进行互联，其对网络架构创新的影响力就十分有限。如果能够定义标准的控制平面的东西向接口，就可以实现SDN设备“组大网”，使得SDN技术走出IDC内部和数据设备内部，成为一种有革命性影响的网络架构。SDN控制平面性能拓展方案中，目前的设计方案有两种，一种是垂直架构的，另一种是水平架构的。垂直架构的实现方案是在多个控制器之上再叠加一层高级控制层，用于协调多个异构控制器之间的通信，从而完成跨控制器的通信请求。水平架构中，所有的节点都在同一层级，身份也相同，没有级别之分。 SDN基本工作原理网元资源信息收集：转发器注册信息、上报资源过程、MPLS标签信息、VLAN资源信息、接口资源信息 拓扑信息收集：节点对象、接口对象、链路对象（LLDP、IGP、BGP-LS）。 SDN网络内部交路由的生成。 通常控制器作为服务端，转发器主动向控制器发起控制协议建立，通过认证后，控制协议即建立连接。 注册信息中的设备信息包括资源信息（接口、标签、VLAN资源等）、设备厂家信息（设备类型信息和设备版本号以及设备ID信息）。控制器采集这些信息是为了根据这些信息来进行本地搜索和加载相应驱动程序。 网络拓扑是描述网络中节点和链路以及节点之间连接关系的信息。 控制器收集拓扑信息的目的是为了根据网络资源，计算合理的路径信息，通过流表方式下发给转发器。 OpenFlow的思想和功能两个角色： OpenFlow Controller：用于控制OpenFlow Switch，计算路径，维护状态和将信息流规则下发给交换机。 OpenFlow Switch：从OpenFlow Controller控制器接收命令或者流信息，以及返回状态信息。 OpenFlow Switch基于流表并根据流规则进行转发、处理数据。 “Flow”指的是一组具有相同性质的数据包，例如“五元组”（SIP、DIP、SPORT、DPORT、Protocol）。 OpenFlow协议是控制器和转发器之间的控制协议。 交换机与控制器之间可以通过加密的OpenFlow协议通信。 OpenFlow交换机是数据平面，基于Flow Table进行数据转发，并负责网络策略的具体执行。 OpenFlow Controller是控制平面设备，负责生成OpenFlow交换机上的Flow Table，以及对Flow Table的更新和维护。 OpenFlow Switch的基本组成： Flow Table：保存对每一个流的定义及相应处理行为。 安全网络通道：连接交换机和控制器，用于传输控制信令。当一个新数据包第一次到达交换机时，交换机通过这个隧道将数据包送往控制器进行路由解析。 OpenFlow协议：一套公开标准接口，用于读写Flow Table的内容。 OpenFlow网络交换模型该模型的指导思想是：底层的数据通信（交换机、路由器）是“简化的”，并定义一个对外开放的关于流表FLowTable的公用API（应用程序接口），同时采用控制器来控制整个网络。 SDN的价值网络业务快速创新SDN的可编程性和开放性，使得我们可以快速开发新的网络业务和加速业务创新。如果希望在网络上部署新业务，可以通过针对SDN软件的修改实现网络快速编程，业务快速上线。 SDN网络关键的地方是在网络架构中增加了一个SDN控制器，把原来的分布式控制平面集中到一个SDN控制器上，由这个集中的控制器来实现网络集中控制。SDN网络架构具备3个基本特征：转控分离、集中控制、开放接口。 SDN通过在网络中增加一个集中的SDN控制器，可以简化网络和快速进行业务创新。但是其本质的技术原理是通过SDN控制器的网络软件化过程来提升网络可编程能力。通信平面仍包含管理平面、控制平面和数据平面，SDN网络架构只是把系统的三个平面的功能进行了重新分配，传统网络控制平面是分布式的，分布在每个转发设备上，而SDN网络架构则是把分布式控制平面集中到一个SDN控制器内，实现集中控制，而管理平面和数据平面并没有太多什么变化。 SDN网络具备快速网络创新能力，如果这个新业务有价值则保留，没有价值可以快速下线。不像传统网络那样，一个新业务上线需要经过需求提出、讨论和定义开发商开发标准协议，然后在网络上升级所有的网络设备，经过数年才能完成一个新业务。SDN使得新业务的上线速度从几年提升到几个月或者更快。 简化网络SDN的网络架构简化了网络，消除了很多IETF的协议。协议的去除，意味着学习成本的下降，运行维护成本下降，业务部署快速提升。这个价值主要得益于SDN网络架构下的网络集中控制和转控分离。 因为SDN网络架构下的网络集中控制，所以被SDN控制器所控制的网络内部很多协议基本就不需要了，比如RSVP协议、LDP协议、MBGP协议、PIM组播协议等等。原因是网络内部的路径计算和建立全部在控制器完成，控制器计算出流表，直接下发给转发器就可以了，并不需要协议。未来大量传统的东西向协议会消失，而南北向控制协议比如Openflow协议则会不断的演进来满足SDN网络架构需求。 网络设备白牌化基于SDN架构，如果标准化了控制器和转发器之间的接口，比如OpenFlow协议逐渐成熟，那么网络设备的白牌化将成为可能，比如专门的OpenFlow转发芯片供应商，控制器厂商等，这也正是所谓的系统从垂直集成开发走向水平集成。 垂直集成是一个厂家供应从软件到硬件到服务。水平集成则是把系统水平分工，每个厂家都完成产品的一个部件，有的集成商把他们集成起来销售。水平分工有利于系统各个部分的独立演进和更新，快速进化，促进竞争，促进各个部件的采购价格的下降。 业务自动化SDN网络架构下，由于整个网络归属控制器控制，那么网络业务网自动化就是理所当然的，不需要另外的系统进行配置分解。在SDN网络架构下，SDN控制器可以自己完成网络业务部署，提供各种网络服务，比如L2VPN、L3VPN等，屏蔽网络内部细节，提供网络业务自动化能力。 网络路径流量优化通常传统网络的路径选择依据是通过路由协议计算出的“最优”路径，但结果可能会导致“最优”路径上流量拥塞，其他非“最优”路径空闲。当采用SDN网络架构时，SDN控制器可以根据网络流量状态智能调整网络流量路径，提升网络利用率。 传统网络向SDN的演进方式仅交换网SDN化 交换网SDN化是指把域内交换网的路径计算功能进行集中控制。 控制器：仅负责域内路径计算和控制 仅业务SDN化 此方案仅仅将自治域AS所接入的业务由控制器接管，域内路径计算和控制依然由转发器负责。 统一部署增值业务VAS资源池，通过SDN COntroller业务链解决方案，集中控制管理，同时实现VAS资源共享。 提升增值业务快速创新能力，提供新的创收来源","link":"/2022/06/12/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C%EF%BC%88SDN%EF%BC%89/"},{"title":"零信任架构","text":"​​点击阅读更多查看文章内容 零信任架构参考文章：基于SDP技术构建零信任安全、怎样实现零信任安全架构？ 什么是零信任物理边界曾经是可信网络和不可信网络之间的有效分割，防火墙通常位于网络的边缘，基于静态策略来控制网络流量。位于防火墙内部的用户会被授予高信任等级来访问企业的敏感资源，因为他们被默认是可信的。但随着业务迁移到云端，APT攻击的泛滥，以及移动办公的趋势，传统的安全边界变的模糊，既然网络和威胁已经发生了变化，我们的防御模型也要跟着变化。 零信任是一种安全模型。首先我们要抛弃传统的边界观念，不再依据用户所处的网络位置而决定这个人是否可信。取而代之的是我们对每个请求都进行严格验证信任建立起来之前，网络上的任何资源都是隐身的。未授权用户和设备是隔离的。完全看不到网络上的任何东西。验证过程包括人的因素和设备的因素人的因素包括验证用户的身份，看看他的身份是不是真的。和验证用户是不是有授权，看看他是否被允许访问相应的资源。除此之外，我们还要了解用户是否使用了合法的设备，设备是否未被攻陷。通过对用户使用的设备进行验证，我们可以避免将敏感数据暴露给被攻陷的设备，并避免被该设备横向攻击网络上的其他用户。一旦通过了验证过程，就建立了信任。用户就可以访问到请求的资源了。当然其它未授权访问的资源还是隐身的。因为零信任是建立在按需授权的理念之上的。我只能访问我需要的资源。其它的都不行。除非我发起新的请求，并通过同样的验证和授权过程。在零信任模型中，对用户的验证是动态的，持续发生的。这意味着合法用户被攻陷后，设备验证会立即报错。他们对资源的访问将立即被切断，不安全设备和其它资源之间的连接也会立即被切断，以避免数据泄露和横向攻击。零信任仅仅只是一个理论模型。有很多实际的产品可以帮我们实现它。 零信任理念的基本假设 内部威胁不可避免； 从空间上，资源访问的过程中涉及到的所有对象（用户、终端设备、应用、网络、资源等）默认都不信任，其安全不再由网络位置决定； 从时间上，每个对象的安全性是动态变化的（非全时段不变的）。 零信任的基本原则 任何访问主体（人/设备/应用等），在访问被允许之前，都必须要经过身份认证和授权，避免过度的信任； 访问主体对资源的访问权限是动态的（非静止不变的）； 分配访问权限时应遵循最小权限原则； 尽可能减少资源非必要的网络暴露，以减少攻击面； 尽可能确保所有的访问主体、资源、通信链路处于最安全状态； 尽可能多的和及时的获取可能影响授权的所有信息，并根据这些信息进行持续的信任评估和安全响应。 零信任在所有需要对资源访问进行安全防护的场景都可以使用，但是否采用，应根据企业可接受的安全风险水平和投入综合考虑决定。 零信任的三大核心技术目前零信任主要有三大核心技术，分别是SDP（软件定义边界）、IAM（身份识别与访问管理）和MSG（微隔离） 黑客攻击步骤 SDPSDP详解可参考：软件定义边界（SDP） SDP，即软件定义边界，由CSA国际云安全联盟在2013年提出。相较于传统的企业内外网区分的形式，其核心是通过软件的方式，为企业构建起虚拟边界，利用基于身份的访问控制及权限认证机制，为企业应用和服务提供隐身保护，使网络黑客因找寻不到目标而无法对企业资源发动攻击，从而有效的保护企业数据安全。 SDP主要包括SDP访问端、SDP控制器以及SDP网关三大组件，访问端指的是安装在用户终端设备上的软件，主要功能包括用户身份验证、用户行为分析、终端设备检测等，以检测设备有无异常、是否被攻击，同时将用户访问请求发送给网关。控制器是访问端与企业资源之间的信任协调者，主要负责用户身份认证及访问权限的配置，管控企业内部资源权限分配的全过程，通常只为通过了访问请求的用户提供特定资源的访问权限。而网关指的是部署在网络入口的“守门人”，主要负责保护企业内部资源及业务系统，防止各类网络攻击；在默认情况下，网关关闭所有网络端口，拒绝一切连接，只会对来自访问端的合法IP开放指定端口。 SDP也就是在三者的相互作用下，做到了应用程序与企业资源之间的网络“隐身”。同时三者之间的通信与连接都将通过加密的方式，在访问端与被访问端之间进行点对点传输，一旦连接失效则会立即断开连接，并且切断网络上所有应用系统的可见性及访问权限。这不仅可以有效解决企业业务拓展中的安全问题，同时也使SDP技术成为了目前零信任安全架构中的最佳践行技术之一。 IAMIAM详解可参考：身份识别与访问管理（IAM） IAM，身份权限管理技术，是将企业内部所有数字实体进行唯一资源标识身份化处理的技术。同时IAM向下兼容现有的各类身份协议，灵活支持多因子身份认证，可以轻松实现以身份为中心的全生命周期动态信任管理，并根据信任评估结果，判断当前身份是否可以访问企业内部资源或数据资产。 IAM主要围绕用户身份、终端设备、访问应用及活动数据四大方面，为企业提供统一且权威的身份鉴别服务，确保用户以正确的身份、在正确的访问环境中、正当的访问资源，不仅可以助力企业将原本分散的用户体系与认证体系整合起来，同时还进一步加强了用户的最小化权限控制，有助于实现企业级的统一访问控制。 随着数字化转型的进一步深化，企业内部的用户访问关系变得越来越复杂，业务和数据资源的云化、员工入职离职、公司兼并等场景，在用户身份生命周期管理与身份认证的这两大需求上对企业提出了更高的要求。基于这样的现状，IAM所包括的身份鉴别、授权、管理、分析审计等功能，逐渐发展成为了零信任安全架构中支撑企业业务和数据安全的重要基础功能。 MSGMSG详解可参考：微隔离（MSG） MSG，微隔离技术。要想弄明白什么是微隔离技术，首先我们要知道对于一个数据中心而言，分别有南北向流量与东西向流量。南北向流量通常指的是网关进出数据中心的外部流量，东西向流量指的是数据中心内部服务器彼此相互访问所造成的内部流量，这两者可以简单理解为坐标轴，横轴即东西向内部流量，纵轴即南北向外部流量。传统防护模式通常采用防火墙等安全设备部署在数据中心出口处，作为南北向外部流量的安全防护手段；可一旦有攻击者突破防护的边界，东西向内部流量就会缺少有效的安全防护。 而据统计，当代数据中心 75%以上的流量为东西向内部流量，随着东西向流量的占比越来越大，微隔离技术也因此应运而生。微隔离顾名思义其实就是更细粒度的网络隔离技术，它能应对传统环境、虚拟化环境、混合云等环境下对于东西向内部流量的隔离需求，现重点被企业或组织用来阻止攻击者进入数据中心网络内部后的东西向移动访问。","link":"/2022/06/09/%E9%9B%B6%E4%BF%A1%E4%BB%BB%E6%9E%B6%E6%9E%84/"},{"title":"软件定义边界（SDP）","text":"​​点击阅读更多查看文章内容 软件定义边界（SDP Software Defined Perimeter）参考文章：软件定义边界SDP、基于SDP技术构建零信任安全参考视频：Zero trust and SDP details参考文献： X Xie, Gan G , Y Chen. Research on SDP Software Defined Perimeter Initiating Host Protocol Configuration Algorithm[J]. IOP Conference Series: Earth and Environmental Science, 2020, 428(1):012054 (10pp). 出现背景传统的网络架构都是通过一个固定的边界来实现内部网络与外部网络的分离，这个边界通常包含一系列的防火墙策略来阻止外部用户的访问，但是内部用户可以随意的对外访问。这种边界封锁了外部对于内部应用和设施的可见性和可访问性，确保了网络内部不受外部威胁的入侵。但是这种模型正在迅速变得过时，原因有两个： 黑客可以通过网络钓鱼等劫持边界内的设备，然后从网络内部进行横向的攻击。此外，由于自带设备、外包工作人员和合作伙伴的存在，边界内部设备增多，导致漏洞不断增加 随着云计算的普及，除了传统数据中心，企业正在不断采用外部云计算资源，如SaaS、PaaS、IaaS。因此，边界安全网络设备在拓扑上并不能很好地保护企业应用基础设施 由于以上问题，我们需要一种新的安全模型，这个模型可以理解上下文信息，如用户位置，用户使用什么设备来建立连接的，何时建立连接的，以及用户的角色。使应用程序所有者能够保护公共云或私有云中的基础架构，数据中心中的服务器，甚至保护应用程序服务器内部。 概念 软件定义的边界（SDP Software Defined Perimeter），也被Gartner称作零信任网络访问（ZTNA）。是2007年提出的，由云安全联盟（CSA）开发的一种安全框架，它根据身份控制对资源的访问。该框架基于美国国防部的“need to know”模型——每个终端在连接服务器前必须进行验证，确保每台设备都是被允许接入的。其核心思想是通过SDP架构隐藏核心网络资产与设施，使之不直接暴露在互联网下，使得网络资产与设施免受外来安全威胁。 在SDP架构中，服务器没有对外暴露的DNS或者IP地址，只有通过授权的SDP客户端才能使用专有的协议进行连接。 架构SDP的体系结构由两部分组成：SDP主机和SDP控制器。SDP主机可以发起连接或接受连接。这些操作通过安全控制通道与SDP控制器交互来管理。因此，在SDP中，控制平面与数据平面分离以实现完全可扩展的系统。 SDP控制器：SDP控制器决定哪些SDP主机可以相互通信。SDP控制器可以将信息中继到外部认证服务，例如认证地理位置或身份服务器SDP连接发起主机（Initiating Host）：SDP连接发起主机（IH）与SDP控制器通信以请求它们可以连接的SDP连接接收方（AH）列表。在提供任何信息之前，控制器可以从SDP连接发起主机请求诸如硬件或软件清单之类的信息。SDP连接接收主机（Accepting Host）：默认情况下，SDP连接接收主机（AH）拒绝来自SDP控制器以外的所有主机的所有通信。只有在控制器指示后，SDP连接接收主机才接受来自SDP连接发起主机的连接 工作流 一个或多个SDP控制器服务上线并连接至适当的可选认证和授权服务（例如，PKI颁发证书认证服务、设备验证、地理位置、SAML、OpenID、Oauth、LDAP、Kerberos、多因子身份验证等服务） 一个或多个SDP连接接收主机（AH）上线，这些主机连接到控制器并由其进行身份验证。但是，他们不会应答来自任何其他主机的通信，也不会响应非预分配的请求 每个上线的SDP连接发起主机（IH）都与SDP控制器连接并进行身份验证 在验证SDP连接发起主机（IH）之后，SDP控制器确定可授权给SDP连接发起主机（IH）与之通信的SDP连接接受主机（AH）列表 SDP控制器通知SDP连接接收主机（AH）接受来自SDP连接发起主机（IH）的通信以及加密通信所需的所有可选安全策略 SDP控制器向SDP连接发起主机（IH）发送可接受连接的SDP连接接受主机（AH）列表以及可选安全策略 SDP连接发起主机（IH）向每个可接受连接的SDP连接接收主机（AH）发起单包授权，并创建与这些SDP连接接受主机（AH）的双向TLS连接 工作例子一个安装了SDP客户端的用户点击了桌面上的一个应用程序，这时开始了单包授权过程，SPA数据包包含一把秘钥，SDP控制器通过秘钥识别身份，PKI之后还会用于验证、授权、设备完整性检测，随后，控制器将用户的IP信息发给AH，这样，AH就知道了一会谁会过来进行建立连接，这时SDP客户端会和AH建立一个TLS隧道，之后客户端会穿过这个隧道运行应用程序，与此同时，客户端与AH始终保持和控制器的通信，随时交换信息，如果客户端的秘钥被窃取或变为无效，则会立即断开连接，并切断网络上所有应用系统与服务器的可见性。如果设备有被攻陷的迹象，它将不再被认为是可信的，也将立即与网络断开并不能访问任何资源。 SDP与NAC（终端准入控制系统）的区别NAC通常只在第二层（链路层）工作，而SDP到7层都有效，这意味着用户可以被授权访问服务器1上的应用系统A，而不让访问同一个服务器上的B或者C，在SDP中，未授权用户甚至无法看到该服务器上除A之外的任何其它应用系统对比而言，NAC方案中授权用户可以看到整个网络中的任何资源，这样是无法避免被黑客进行横向攻击的。 部署模式客户端—网关模型在客户端—网关的实施模型中，一个或多个服务器在 SDP 连接接受主机（AH）后面受到保护， 这样，SDP 连接接受主机（AH）就充当客户端和受保护服务器之间的网关。此实施模型可以在企业网络内执行，以减轻常见的横向移动攻击，如服务器扫描、操作系统和应用程序漏洞攻击、中间人攻击、传递散列和许多其他攻击。或者，它可以在 Internet 上实施，将受保护的服务器与未经 授权的用户隔离开来，并减轻诸如拒绝服务（DoS）、SQL 注入、操作系统和应用程序漏洞攻击、 中间人攻击、跨站点脚本（XSS）、跨站点请求伪造（CSRF）等攻击。 客户端—服务器模型客户机到服务器的实施在功能和优势上与上面讨论的客户机到网关的实施相似。然而，在这种情况下，受保护的服务器将运行可接受连接主机（AH）的软件，而不是位于运行该软件的服务器前面的网关。客户机到网关实施和客户机到服务器实施之间的选择通常基于受保护的服务器数量、负载平衡方法、服务器的弹性以及其他类似的拓扑因素。 服务器—服务器模型在服务器到服务器的实施模型中，可以保护提供代表性状态传输（REST）服务、简单对象访问协议（SOAP）服务、远程过程调用（RPC）或 Internet 上任何类型的应用程序编程接口（API） 的服务器，使其免受网络上所有未经授权的主机的攻击。例如，对于 REST 服务，启动 REST 调用的服务器将是 SDP 连接发起主机（IH），提供 REST 服务的服务器将是可以接受连接的主机（AH）。为这个用例实施一个软件定义边界可以显著地减少这些服务的负载，并减轻许多类似于上面提到 的攻击。这个概念可以用于任何服务器到服务器的通信。 客户端—服务器—客户端模型客户端到服务器到客户端的实施在两个客户端之间产生对等关系，可以用于IP电话、聊天和视频会议等应用程序。在这些情况下，软件定义边界会混淆连接客户端的 IP 地址。作为一个微小的变化，如果用户也希望隐藏应用服务器，那么用户可以有一个客户端到客户端的配置。 应用场景企业应用隔离对于企业网络内部，攻击者可能通过入侵网络中的一台计算机进入内部网络，然后横向移动获得高价值信息资 产的访问权限。 在这种情况下，企业可以在其数据中心内部署 SDP，以便将高价值应用程序与数 据中心中的其他应用程序隔离开来，并将它们与整个网络中的未授权用户隔离开来。 未经授权的用户将无法检测到受保护的应用程序，这将减轻这些攻击所依赖的横向移动。 私有云和混合云SDP 的软件覆盖特性使其可以轻松集成到私有云中，以利用此类环境的灵活性和弹性。 此外，企业可以使用 SDP 隔离隐藏和保护其公共云实例，或者作为包含私有云和公共云实例和/或跨云集群的统一系统。 软件即服务（SaaS）软件即服务（SaaS）供应商可以使用 SDP 架构来保护他们提供的服务。在这种应用场景下，SaaS 服务是一个SDP连接接受主机（AH），而所有连接服务的终端用户就是 SDP 连接发起主机（IH）。这样使得 SaaS 产商可以通过互联网将其服务提供给全球用户的同时不再为安全问题担忧。 基础设施即服务（IaaS）基础设施即服务（IaaS）供应商可以为其客户提供 SDP 即服务作为受保护的入口。 这使他们 的客户可以充分利用 IaaS 的灵活性和性价比，同时减少各种潜在的攻击。 平台即服务（PaaS）平台即服务（PaaS）供应商可以通过将 SDP 架构作为其服务的一部分来实现差异化。 这为最 终用户提供了一种嵌入式安全服务，可以缓解基于网络的攻击。 基于云的虚拟桌面基础架构（VDI）虚拟桌面基础架构（VDI）可以部署在弹性云中，这样 VDI 的使用按小时支付。 然而，如果 VDI 用户需要访问公司网络内的服务器，VDI 可能难以使用，并且可能会产生安全漏洞。 但是， VDI 与 SDP 相结合，可通过更简单的用户交互和细粒度访问解决了这两个问题。 物联网（IoT）大量的新设备正在连接到互联网上。管理这些设备或从这些设备中提取信息抑或两者兼有的 后端应用程序的任务很关键，因为要充当私有或敏感数据的保管人。软件定义边界可用于隐藏这些服务器及其在 Internet 上的交互，以最大限度地提高安全性和正常运行时间。 SDP和VPN的区别目前，虚拟专用网络（VPN）是很多公司远程访问的解决方案之一。但是，VPN用户一旦获得授权就可以广泛访问公司网络上的资源。这种广泛访问的方法使潜在的敏感资源和信息暴露给VPN用户和攻击者。因此，围绕软件定义的边界解决方案（SDP）成为安全远程访问的一个更具吸引力的替代方案。传统的VPN具有过度信任、访问广泛、复杂等问题。首先传统VPN遵循以网站为中心的拓扑结构，具有广泛的信任度。其次在传统的VPN网络访问中，一旦用户登陆了VLAN，他们的主机就可以广播地址解析协议（ARP），以检查是否有其他东西连接到这个网段。由于地址解析协议是建立在网络中各个主机互相信任的基础上的，网络上的主机可以自主发送ARP应答消息，其他主机收到应答报文时不会检测该报文的真实性就会将其记入本机ARP缓存；由此攻击者就可以向某一主机发送伪ARP应答报文，使其发送的信息无法到达预期的主机或到达错误的主机，这最终会创建一个相当大的攻击界面，供黑客使用。最后，在企业迁移到云时，VPN管理变得复杂。IT管理员必须在不同的地理位置配置和协调VPN、防火墙策略。这反过来又很难拦截未经授权的访问。 SDP和VPN之间的差异概述如下： 与受 VPN 网关保护的服务器相比，创建受 SDP 保护的服务器需要不同的工作量。在 SDP 情况 下，一旦 SDP 控制器上线，用户可以通过软件设置，根据需要创建尽可能多的受保护服务器， 并且可以通过 LDAP 关联区分授权用户和未授权用户。 与 SDP 相比，设置 VPN 网关以保护单个服务器的资本和运营成本更高。 SDP 是可以部署在云环境中的软件架构。 SDP 可以同时用于安全和远程访问，而 VPN 网关则不能。如果要尝试在企业内使用 VPN 客户端和 VPN 网关来保护某个服务器，则用户无法使用远程访问 VPN 来访问服务器（因为 VPN 客户端已连接到远程访问 VPN 网关）然而 SDP 通信则可以在远程访问 VPN 之上进行。 SDP 可防止 DDoS 攻击，而 VPN 网关则不会。 SDP 连接接受方可以部署在与其保护的应用服务器不同的拓扑不同的位置，甚至从而对授权用户隐藏真实位置 SDP带来的改变SDP改变了传统的网站连接方式。在传统的连接中，首先，客户端需要建立与服务器端的连接，这一步骤使服务端暴露在公网中，若服务端有漏洞，则有可能被利用；其次，用户通过登录页面输入用户名和密码，这一步骤有可能使得用户名和密码被窃取；最后，除用户名和密码外还可使用多因素认证，通过多因素认证，可以抵抗用户名和密码的丢失，但是多因素认证对于用户而言不是很友好。而在SDP中，首先，客户端进行多因素认证，认证设备的可靠性等，这一步对用户而言是透明的。认证通过之后，才进入用户登录阶段。这两步均是客户端与Controller进行交互，不涉及对于具体服务的访问。当认证通过后，客户端才能够与可访问的服务建立连接。 因此，SDP通过三种方式对抗基于网络的攻击：透明多因素认证可以抵抗用户凭据丢失、服务器隔离可以抵抗服务器利用、TLS双向认证可以抵抗连接劫持。SDP可以提供对于网络系统、服务和应用的以人为中心、可管理的、普遍存在的、安全的和敏捷的访问。它解决了TCP/IP中的一个设计漏洞（在认证之前即对报文进行处理）。由于SDP的部署代价更低，因此，SDP可能颠覆网络防火墙和VPN技术。SDP同样有可能颠覆传统的网络安全技术部署，如NAC，Switch-to-Switch加密，内部的VPN能力。这是因为SDP的软件Agent技术可以部署在任何其支持的操作系统上，从而创建一个及时的和动态的网络边界。","link":"/2022/06/09/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E8%BE%B9%E7%95%8C%EF%BC%88SDP%EF%BC%89/"},{"title":"身份识别与访问管理（IAM）","text":"​​点击阅读更多查看文章内容 身份识别与访问管理（IAM Identity and Access Management）参考文章：【涨知识】认识IAM，向着“零信任”安全架构迈进什么是身份和访问管理（IAM）？IAM （身份识别与访问管理（简称大4A））——百度百科身份访问与管理(IAM) 定义定义和管理个人网络用户的角色和访问权限，以及规定用户获得授权（或被拒绝授权）的条件。IAM系统的核心目标是为每个用户赋予一个唯一的身份。使用身份这种唯一用户配置文件管理用户并将用户安全连接到 IT 资源，包括设备、应用、文件、网络等，从而控制对 WiFi 和企业服务器等资源的访问，同时限制其访问工作内容以外的数字资产。该数字身份一经建立，在用户的整个“访问生命周期”存续期间都应受到良好的维护、调整与监视 Gartner 将 IAM 定义为一种安全规则：“让对的人在对的时间以对的理由访问对的资源。” 关键术语 访问管理指用于控制和监视网络访问的过程及技术。访问管理功能，比如身份验证、授权、信任和安全审计，是企业内部及云端系统顶级ID管理系统不可缺少的重要部分。 生物特征识别身份验证依靠用户独特的生物特征来验证用户身份的安全过程。生物特征识别身份验证技术包括指纹传感器、虹膜和视网膜扫描，还有人脸识别等。 上下文感知网络访问控制一种基于策略的授权方法，根据索要访问权限的用户的当前上下文来授予网络资源访问权。比如说，某用户试图通过身份验证，但其IP地址却没在白名单之内，那该用户就不能获得授权。 凭证用户用以获取网络访问权的标识，比如用户的口令、公钥基础设施(PKI)证书，或者生物特征信息(指纹、虹膜扫描等)。 撤销将某身份从ID存储中移除并终止其访问权限的过程。 数字身份ID本身，包括对用户及其访问权限的描述。(笔记本电脑或手机之类的终端也可拥有自己的数字身份。) 权益指已验证安全主体所具备的访问权限的一系列属性。 身份即服务(IDaaS)基于云的IDaaS为位于企业内部及云端的系统提供身份及访问管理功能。 身份生命周期管理与访问生命周期管理类似，该术语指的是维护和更新数字身份的一整套过程和技术。身份生命周期管理包括身份同步、配置、撤销和对用户属性、凭证及权益的持续管理。 轻量级目录访问协议(LDAP)用于管理和访问分布式目录服务（比如微软AD）的开放标准协议。 多因子身份验证(MFA)网络或系统的身份验证中要求不止一个因子(比如用户名和口令)的情况。验证过程中至少还有额外的一步，比如用手机接收通过短信发送的验证码、插入智能卡或U盘、满足生物特征识别验证要求(指纹扫描等)。 口令重置口令重置指的是ID管理系统允许用户重新设置自身口令的功能。该功能可将管理员从繁琐的口令重置工作中解脱出来，还能减少客户服务接到的求助电话。用户通常可通过浏览器访问重置应用，提交相应的密语或回答一系列问题即可验证用户身份。 特权账户管理基于用户权限对账户和数据访问进行管理与审计。一般来讲，特权用户因其工作或功能需求而往往被赋予管理员权限。比如说，特权用户可能拥有添加或删除用户账户和角色的权限。 配置创建身份，定义其访问权限，并将其添加到ID存储中的过程。 基于风险的身份验证(RBA)在用户尝试身份验证时根据用户情况动态调整验证要求的身份验证方法。比如说，如果用户尝试从之前未关联过的地理位置或IP地址发起身份验证，可能就会面临额外的验证要求。 安全主体具备1个或多个可被验证或授权的凭证以访问网络的数字身份。 单点登录(SSO)对相关但独立的多个系统实施的一种访问控制。单点登录模式下，用户仅凭同一套用户名和口令就可访问1个或多个系统，无需多个不同凭证。 用户行为分析(UBA)UBA技术检查用户行为模式，并自动应用算法和分析以检测可能昭示潜在安全威胁的重要异常。UBA区别于专注跟踪设备或安全事件的其他安全技术，有时候也会与实体行为分析归到一类，被称为UEBA。 关键功能单点登录 (SSO)通过对跨多种不同Web 应用程序、门户和安全域的无缝访问允许单点登录，还支持对企业应用程序（例如，SAP、Siebel、PeopleSoft 以及Oracle应用程序）的无缝访问。单点登录（Single Sign On），简称为 SSO，是比较流行的企业业务整合的解决方案之一。SSO的定义是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。 强大的认证管理提供了统一的认证策略，确保Internet 和局域网应用程序中的安全级别都正确。这确保高安全级别的应用程序可受到更强的认证方法保护，而低安全级别应用程序可以只用较简单的用户名/密码方法保护。为许多认证系统（包括密码、令牌、X.509 证书、智能卡、定制表单和生物识别）及多种认证方法组合提供了访问管理支持。 基于策略的集中式授权和审计将一个企业Web 应用程序中的客户、合作伙伴和员工的访问管理都集起来。因此，不需要冗余、特定于应用程序的安全逻辑。可以按用户属性、角色、组和动态组对访问权进行限制，并按位置和时间确定访问权。授权可以在文件、页面或对象级别上进行。此外，受控制的“模拟”（在此情形中，诸如客户服务代表的某个授权用户，可以访问其他用户可以访问的资源）也由策略定义。 动态授权从不同本地或外部源（包括Web服务和数据库）实时触发评估数据的安全策略，从而确定进行访问授权或拒绝访问。通过环境相关的评估，可获得更加细化的授权。例如，限制满足特定条件（最小帐户余额）的客户对特定应用程序（特定银行服务）的访问权。授权策略还可以与外部系统（例如，基于风险的安全系统）结合应用。 企业可管理性提供了企业级系统管理工具，使安全人员可以更有效地监控、管理和维护多种环境（包括管理开发、测试和生产环境）。 IAM趋势对于企业而言，现在是实现零信任架构理想时机，因为身份泄露造成的数据泄露威胁正与日俱增。而IAM“武器库”的建设，正是企业迈向零信任的第一步。根据安全牛资料，2020年，IAM三大趋势如下： 身份和访问管理即服务管理一组应用程序和文件的访问可能很棘手，且要求很高。尽管IAM早已迁移到云中（即使Microsoft的古老Active Directory软件也跳到了Azure），但对应用程序进行精细维护的责任仍然在于管理员。借助IAM即服务（IAMaaS），许多IAM功能被转移到云中并实现了自动化。远程用户可以轻松而轻松地访问其工具：他们只需使用一次登录（SSO）即可访问所需的所有资源和解决方案。借助IAMaaS，用户可以轻松、自动化地连接安全和防欺诈保护系统，提高应用程序和文件的安全性，而无需付出额外的努力。此外，自动化工具将大大减少管理员的工作负担。 微服务的身份和访问管理微服务已经席卷了IT世界。开发人员使用链接的容器化小程序而不是单个整体应用程序来执行以前由单个集成应用程序完成的功能。即使一个组件失败，整个应用程序也不会崩溃。取而代之的是，自动化系统启动了故障组件的副本，使用户的停机时间降至零。从传统的IAM的角度来看，这是有问题的。现在，应用程序的各个组件可以通过网络进行通信，这意味着攻击者有可能窃听或伪造这些通信。有时，这些服务使用公共互联网在多个数据中心之间进行通信，这使得加密和安全性变得更加重要。因此，IAM解决方案开始与微服务集成。在一个这样的解决方案中，微服务之间的每个通信还包括一个唯一的令牌，该令牌在收到后便会得到验证。应用程序仅在收到有效令牌后才执行请求的功能。这对应用程序造成的性能影响很小，但却可以防止不良行为者假冒微服务或窃听您的应用程序。 自主身份用户所拥有的身份数据，需重复证明，也不属于自己，这是一件怪诞但现实的事情，这不仅仅带来不便，而且是数据泄露的万恶之源。自主主权身份是搭建在区块链上的数字身份，也是用户对数字身份掌控度最高的形式，此类数字身份因为结合了区块链的去中心化、分布式、共识机制、哈希加密等特性，因此在自主、安全、可控层面更上一层楼。在物理世界中，用户可以通过多种方式来验证其身份，而无需用户名或密码。他们可能会出示驾照、护照、社会保险卡或其他身份证。过去，显示完整账号的信用卡收据使身份盗窃变得容易。而所谓的自主身份，指的是当个人使用这些实体来验证其身份时，没有第三方（发行机构除外）维护副本，因此被盗的风险较小。简而言之，自我主权身份使用户在网上也能够以“亲自证明”相同的方式对自己进行身份验证。用户可以存储自己的个人识别数据，而不必将其提交到某个公司管理的集中化数据库中，因为如果这些公司被黑客入侵，数据泄露将不可避免。自我主权身份的问题在于，目前还没有一种普遍认同的媒介可以用来存储自己的身份并对其进行验证。现在，许多自我主权身份的支持者认为，区块链是一种加密的去中心化个人信息数据库，代表了个人可以轻松地在线验证其身份的理想机制。因此，整合区块链有可能在很大程度上改变IAM。根据您的居住地、您的用户名和密码可能会替换为政府颁发的数字身份。这已经在瑞士的楚格（Zug）市发生，您的城镇可能是下一个。","link":"/2022/06/10/%E8%BA%AB%E4%BB%BD%E8%AF%86%E5%88%AB%E4%B8%8E%E8%AE%BF%E9%97%AE%E7%AE%A1%E7%90%86%EF%BC%88IAM%EF%BC%89/"},{"title":"存储与数据库","text":"​点击阅读更多查看文章内容 RDBMS经典案例事务ACID 原子性： 一致性：（强调状态的合法性） 隔离性： 持久性： 高并发 高可靠 数据模型 关键技术一条SQL的一生 SQL引擎Parser 解析器 所有的代码在执行之前，都存在一个解析编译的过程， 差异点无非在于是静态解析编译还是动态的。SQL语言也类似，在SQL查询执行前的第一步就是查询解析 词法分析:将一条SQL语句对应的字符串分割为一个个token, 这些token可以简单分类。 语法分析:把词法分析的结果转为语法树。根据token序列匹配不同的语法规则，比如这里匹配的是update语法规则，类似的还有insert、 delete、 select. create、 drop等等语法规则。根据语法规则匹配SQL语句中的关键字，最终输出一个结构化的数据结构。 语义分析:对语法树中的信息进行合法性校验。 Optimizer 优化器 为什么需要优化器？ 表连接有多种方式： 基于规则的优化： 基于代价的优化：（通常考虑整体的代价） Executor 执行器 火山模型：逐层向下调用，逐层向上返回 向量化模型：每次计算一批数据 编译执行模型： 存储引擎InnoDB 内存中进行数据缓存 磁盘中存储：数据元信息（ibdata1）、用户真实数据（xxx.ibd）、日志信息（xxx.ibu、ib_logfileN）、临时表（xxx.ibt） Buffer Pool MySQL中每个chunk的大小一般为128M， 每个block对应一个page, 一个chunk 下面有8192个block。这样可以避免内存碎片化。 分成多个instance,可以有效避免并发冲突。 Page id % instance num得到它属于哪个instance HashMap：page寻址 LRU：内存替换策略 Page B+ Tree：构建索引 叶子节点通过双向链表连接 点查：从根到叶查到数据 范围查询：根据叶子的链表继续遍历叶子节点查询 事务引擎原子性：如果事务执行失败需要回退，通过undo log记录数据回退的操作 一致性：主要在业务层实现 隔离性：通过加锁实现 ​ 读读：共享锁，可以同时读 ​ 写写：排他锁，一个人写另一个人就不能再写 ​ 读写：读写互不阻塞，MVCC机制，为数据创建多个版本来支持多个事务同时读取和修改数据库。 持久性 随机IO：随机访问磁盘效率较低 写放大：数据的最小管理单元是页面16（KB），写数据可能只修改几个字节，但是要占用整个页面 WAL：修改并不直接写入到数据库文件中，而是写入到另外一个称为WAL的文件中; 如果事务失败，WAL中的记录会被忽略，撤销修改; 如果事务成功，它将在随后的某个时间被写回到数据库文件中，提交修改。 ​ 优点：只记录增量变化，没有写放大；Append only,没有随机IO 企业实践流量大、流量突增、稳定性 大流量Sharding：将数据水平拆分，分给多个服务器存储 流量突增扩容 代理连接池 稳定性&amp;可靠性3AZ高可用 HA管理 总结 对象存储需求短视频架构： 存储需求： 存储量： 要求： 易用：好的存储能够解放业务，让业务专注于业务逻辑开发 海量：从前面分析，这个存储系统一定要能够存储如此大的海量 便宜：这么大的存储量，越便宜就越能省下宝贵的经费 为什么需要对象存储存储系统的分类： 分布式数据库适合存储大量结构化数据，例如身份证号 分布式存储包括分布式文件系统和对象存储 适用场景静态不变 对象存储怎么使用 Restful接口 通过restful接口直接操作对象存储 MultiUpload接口 大文件上传 ListPrefix接口 分页列举 总结","link":"/2025/02/13/bytedance/%E5%AD%98%E5%82%A8%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"Go语言原理与实践","text":"​点击阅读更多查看文章内容 什么是Go语言 高性能、高并发 与C++、Java相近的性能 标准库内置高并发的支持 语法简单、学习曲线平缓 丰富的标准库 完善的工具链 编译、错误检查、包管理、代码提示 单元测试框架 静态链接 只需要拷贝编译后的可执行文件就可以部署运行，在容器中运行可以使镜像体积非常小 C++需要附加.so文件才能运行、Java需要附加JRE 快速编译 跨平台 Windows、Linux、MacOS、Android、IOS、路由器、树莓派 垃圾回收 字节为什么使用GO？ 学习路线 Go语言进阶与依赖管理并发编程并发：多线程程序在一个核的CPU上运行，通过时间片切换交替执行多个程序 并行：利用多核实现多个线程的同时运行 协程 Goroutine 协程开销很小，是Go语言适合高并发场景的原因 CSP（Communicating Sequential Processes） 协程间通信 Channel 通过通信共享内存 通过共享内存实现通信 对共享内存的访问需要加锁 WaitGroup 之前的例子是通过等待1s来等待协程执行完毕，这里可以通过WaitGroup使用计数器优雅的等待协程执行完毕 依赖管理Go依赖管理演进 GOPATH 所有项目共享同一个GOPATH 弊端： Go Vendor 弊端： Go Module go.mod version major是大版本，不同major可能是不兼容的，minor是大版本下的下版本，同一大版本下是兼容的，patch是对bug的修复 版本前缀-时间戳-哈希 indirect incompatible 如果两个依赖库需要不同版本的同一依赖库，而这些版本无法同时兼容，Go Vendor 无法解决此问题。 Go Modules 会自动选择一个最小兼容版本，避免冲突。 依赖分发 不会直接去Github等依赖的源仓库拉取 通过Go Proxy缓存源站中的软件内容，缓存的软件版本不会改变，并且在源站删除之后依然可用 GOPROXY 工具 - go get 工具 - go mod 测试 回归测试：一般是QA同学手动通过终端回归些固定的主流程场景 集成测试：对系统功能维度做测试验证 单元测试：测试开发阶段，开发者对单独的函数、模块做功能验证 层级从上至下，测试成本逐渐减低，而测试覆盖率确逐步上升，所以单元测试的覆盖率定程度上决定这代码的质量。 单元测试 规则： 覆盖率： 依赖：单元测试可能需要依赖外部的文件数据库等，单元测试要求外部依赖是幂等且稳定的 幂等：重复运行case的结果是相同的 稳定：单元测试是隔离的，能在任何时间，任何环境，运行测试。 要实现稳定和幂等就需要Mock函数 例子：文件处理，将第一行字符串中的11替换成00，需要依赖本地文件，如果文件修改测试就会fail 使用开源mock测试库monkey，对method进行mock Monckey Patch 的作用域在 Runtime，在运行时通过Go的unsafe包，能够将内存中函数的地址替换为运行时函数的地址，将target的方法实现跳转到replacement 基准测试 Benchmark开头，入参为testing.B，用b中的N值反复递增循环测试 (对一个测试用例的默认测试时间是1秒，当测试用例函数返回时还不到1秒，那么testing.B中的N值将按1、2、5、10、 20、 ….递增，并以递增后的值重新进行用例函数测试。) Resttimer重置计时器，我们再reset之前做了init或其他的准备操作，这些操作不应该作为基准测试的范围; runparaller是多协程并发测试;执行2个基准测试，发现代码在并发情况下存在劣化，主要原因是rand为了保证全局的随机性和并发安全，持有了一把全局锁。 使用fastrand优化 高质量编程简介及编码规范编码规范代码格式 注释 Open()的注释解释了函数的作用，IsTableFull()的注释实际上没有提供一些额外的信息 第二个for循环的注释没有什么作用 命名规范 控制流程 错误和异常处理 性能优化性能优化建议 benchmark 函数命名必须以Benchmark开头，后面跟的单词必须以大写字母开头 Slice 预分配内存 data := make([]int, 0, size)：长度为0，容量为size data := make([]int, size)：长度，容量都为size 大内存未释放 123456func main() { data := make([]int, 100) data2 := data[:2] fmt.Println(cap(data2))}// 100 12345678func main() { data := make([]int, 100) // 必须先为data2分配内存才能copy，否则会panic data2 := make([]int, 2) copy(data2, data[:2]) fmt.Println(cap(data2)) // 2} Map 预分配内存 字符串处理 使用strings.Builder 空结构体 atomic包 小结 性能优化分析工具 性能分析工具pprof 启动main函数，访问 http://localhost:6060/debug/pprof/ 在浏览器查看指标 采集10s的CPU数据 go tool pprof &quot;http://localhost:6060/debug/pprof/profile?seconds=10&quot; 输入top查看占用资源最多的函数 Eat函数占用资源最多，使用list Eat查看函数","link":"/2025/02/13/bytedance/Go%E8%AF%AD%E8%A8%80%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"},{"title":"开发与迭代","text":"​点击阅读更多查看文章内容 开发流程拆解与介绍开发阶段单体架构vs微服务架构 微服务的缺点：不同服务之间需要进行rpc通信，网络开销比较大 代码规范： 养成良好的注释习惯，超过三个月的代码，自己都会忘了当时在想什么 不要有魔法数字，魔法字符串 例如 if x==2，这里的2就是魔法数字，没有明确的含义，可以通过定义一个常量通过常量命名来明确数字的含义 重复的逻辑抽象成公共的方法，不要copy代码 正确使用IDE的重构功能，防止手动修改错误不彻底 自测： 单元测试 功能环境测试 测试数据构造 文档： 大型改造需要有技术设计文档，方案评审 好的接口文档能更方便的和前端进行沟通 测试阶段 发布阶段发布模式：常用的发布方式 - HackerVirus - 博客园 蛮力发布：直接用新版本覆盖老版本 金丝雀发布：先发一台机器，没问题再发送到全部机器 滚动发布 蓝绿发布（在流量较少的时候进行发布） 红黑发布 运维阶段 用户量增加引起流量洪峰 数据库表的数据量增长导致查询速度变慢 内存/进程泄露导致服务资源不足 止损-&gt;周知-&gt;定位-&gt;修复 流程怎样优化DevOps解决方法：开发和运维行程闭环 架构架构定义解析 微服务架构： 服务网格： 企业级后端架构的挑战 离在线资源并池 自动扩缩容（指标：cpu利用率） 微服务亲和性部署 流量治理 CPU水位负载均衡 GitGit的前世今生Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. Git是一个分布式版本控制系统： 版本控制：一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。 版本控制可以更好的关注变更，了解到每个版本的改动是什么，方便对改动的代码进行检查，预防事故发生；也能够随时切换到不同的版本，回滚误删误改的问题代码； 分布式：每个开发者都有一个完整的代码库副本，包括代码和历史记录。 本地版本控制： 集中式版本控制： 分布式版本控制： Git基本使用方式Git配置 不同级别：低级别会覆盖高级别配置 local：.git/config global：~/.gitconfig system：$(prefix)/etc/gitconfig 一次commit会创建 commit/tree/blob 三个object blob：存储文件的内容 tree：存储文件的目录信息 commit：存储提交信息，一个commit对应唯一版本的代码 将这三个文件串联在一起： tree中可以存储多个文件信息也可以再存储tree refs文件存储的内容：一个commit就对应一个完整的代码，refs的内容是对应的Commit ID，因此把ref当作指针，指向对应的Commit来表示当前Ref对应的版本。 不同种类的ref：.git/refs/heads前缀表示的是分支，.git/refs/tags前缀表示的是标签 Branch：分支一般用于开发阶段，是可以不断添加Commit进行迭代的 Tag：标签一般表示的是一个稳定版本，指向的Commit一般不会变更 修改历史版本： commit –amend：通过这个命令可以修改最近一次commit信息，修改之后commit id会变 rebase：通过 git rebase -i HEAD~3 可以实现对最近三个commit的修改 合并 commit 修改具体的commit message 删除某个commit Clone：拉取完整的仓库到本地目录，可以指定分支，深度。 Fetch：将远端某些分支最新代码拉取到本地，不会执行merge操作，会修改refs/remote内的分支信息，如果需要和本地代码合并需要手动操作。 Pull：拉取远端某分支，并和本地代码进行合并，操作等同于 git fetch + git merge，也可以通过 git pull –rebase 完成 git fetch + git rebase 操作。可能存在冲突，需要解决冲突。 Push：将本地代码同步到远端，冲突问题：如果本地的commit记录和远端的commit历史不一致，则会产生冲突，比如 git commit –amend or git rebase 都有可能导致这个问题。如果该分支就自己一个人使用，或者团队内确认可以修改历史则可以通过git push origin master -f 来完成强制推送 代码合并 Fast-Forward（git merge test –ff-only）：不会产生merge节点，合并后保持线性历史，如果target分支有更新，则需要通过rebase操作更新source branch后才可以合入。 Three-Way Merge（git merge test –no-ff）：三方合并，会产生一个新的merge节点 保护分支：防止用户直接向主干分支提交代码，必须通过PR来进行合入 Code Review，CI：都是在合入前的检查策略，Code Review 是人工进行检查，CI则是通过一些定制化的脚本来进行一些校验。 代码历史混乱，代码合并方式不清晰：不理解 Fast Forward 和 Three Way Merge 的区别，本地代码更新频繁的使用Three Way 方式，导致生成过多的merge节点，使提交历史变得复杂不清晰。","link":"/2025/02/13/bytedance/%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%AD%E4%BB%A3/"},{"title":"算法、安全、性能优化","text":"​点击阅读更多查看文章内容 排序插入排序、快速排序、堆排序理论时间复杂度 实际场景的性能测试 完全随机 元素有序 结论 pdqsort Version1 首先使用快排，快排分成两部分之后如果子数组长度小于24则针对该子数组不再使用快排转而使用插入排序，如果limit为0则使用堆排序。limit是根据数组初始长度计算的值，当快排表现不佳时会将limit减1，当limit最终为0时就不再使用快排。 Version2 采样多个元素选择中位数 partialInsertionSort，在插入一定次数后仍未有序，就放弃使用插入排序 最终版本 安全网站常见安全漏洞 服务端漏洞第三方组件漏洞 log4j、fastjson SQL注入 不要把用户传入的数据当作代码 命令执行 越权漏洞 SSRF 本身发起请求的就是内网的机器，所以可以访问到本机的admin页面 文件上传漏洞 上传一个php脚本，php是解释型语言，可以直接执行 基于企业的CDN存储自己的文件生成url，可以快速访问 站库分离：如果上传php文件不会存储到网站，而是存储到其它的服务器上，不具备执行php的能力，就不会有问题。 客户端漏洞开放重定向 对重定向地址做一个白名单 XSS CSRF 点击劫持 CORS跨域配置错误 WebSocket","link":"/2025/02/13/bytedance/%E7%AE%97%E6%B3%95%E3%80%81%E5%AE%89%E5%85%A8%E3%80%81%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"title":"消息队列","text":"​点击阅读更多查看文章内容 消息队列引入 什么是消息队列 Kafka使用场景： 日志信息（离线信息） Metrics数据 （程序状态采集） 用户行为（搜索、点赞、评论、收藏） 一个业务场景对应一个topic，该业务的所有数据都存储在这个topic中 一个topic可以分为不同的partition，多个partition可以并发处理提高单个topic的吞吐量 对于每一个Partition来说，每条消息都有一 个唯一的Offset, 消息在partition内的相对位置信息，并且严格递增 Replica:分片的副本，分布在不同的机器上，可用来容灾，Leader对外服务， Follower异步 去拉取leader的数据进行一个同步， 如果leader挂掉了，可以将Follower提升成leader再对外进行服务 ISR:意思是同步中的副本，对于Follower来说， 始终和leader是有一 定差距的， 但当这个差距比较小的时候，我们就可以将这个follower副本加入到ISR中，不在ISR中的副本是不允许提升成Leader的 上面这幅图代表着Kafka中副本的分布图。图中Broker代表每一个Kafka的节点， 所有的Broker节点最终组成了一个集群。整个图表示，图中整个集群，包含了4个Broker机器节点，集群有两个Topic, 分别是Topic1和Topic2, Topic1有两个分片，Topic2有1个分片， 每个分片都是三副本的状态。这里中间有一个Broker同时也扮演 了Controller的角色，Controller是整 个集群的大脑，负责对副本和Broker进行分配 ZooKeeper与Controller相配合，Controller计算好的方案都会放到这个地方 批量发送 数据压缩 Broker存储数据 查找数据 消息消费 对于一个Consumer Group来说，多个分片可以并发的消费，这样可以大大提高消费的效率，但需要解决的问题是，Consumer和Partition的分配问题， 也就是对于每一个Partition来讲， 该由哪一个Consumer来消费的问题。对于这个问题，我们一般有两种解决方法，手动分配和自动分配。 手动分配，也就是Kafka中所说的Low Level消费方式进行消费,这种分配方式的一个好处就是 启动比较快，因为对于每一个Consumer来说， 启动的时候就已经知道了自己应该去消费哪个消费方式，就好比图中的Consumer Group1来说，Consumer1去消费Partition1,2,3 Consumer2, 去消费456，Consumer3去消费78。 这些Consumer再启动的时候就已经知道分配方案了，但这样这种方式的缺点又是什么呢，想象一下，如果我们的Consumer3挂掉了，我们的7,8分片是不是就停止消费了。又或者，如果我们新增了一台Consumer4, 那是不是又需要停掉整个集群，重新修改配置再上线，保证Consumer4也可以消费数据，其实上面两个问题，有时候对于线上业务来说是致命的。 所以Kafka也提供了自动分配的方式，这里也叫做High Level的消费方式，简单的来说，就是在我们的Broker集群中， 对于不同的Consumer Group来讲，都会选取一台Broker当做Coordinator, 而Coordinator的作用就是 帮助Consumer Group进行分片的分配，也叫做分片的rebalance,使用这种方式，如果ConsumerGroup中有发生宕机，或者有新的Consumer加入，整个partition和Consumer都会 重新进行分配来达到一个稳定的消费状态 BMQ兼容Kafka协议，存算分离，云原生消息队列 运维操作对比 通过前面的介绍，我们知道了，同一个副本是由多个segment组成，我们来看看BMQ对于单个文件写入的机制是怎么样的，首先客户端写入前会选择一定数量的DataNode, 这个数量是副本数，然后将个文件写入到这 三个节点上，切换到下一个segment之后，又会重新选择三个节点进行写入。这样-来， 对于单个副本的所有segment来讲，会随机的分配到分布式文件系统的整个集群中 BMQ文件结构 对于Kafka分片数据的写入，是通过先在Leader上面写好文件，然后同步到ollower上，所以对于同一个副本的所有Segment都在同一 台机器 上面。就会存在之前我们所说到的单分片过大导致负载不均衡的问题，但在BMQ集群中，因为对于单个副本来讲，是随机分配到不同的节点上面的，因此不会存在Kafka的负载不均问题 Broker-Partition 状态机 其实对于写入的逻辑来说，我们还有一个状态机的机制， 用来保证不会出现同一个分片在两个Broker 上同时启动的情况，另外也能够保证一个分片的正常运行。 首先，Cortoller做好分片的分配之后， 如果在该Broker分配到了Broker,首先会start这个分片， 然后进入Recover状态，这个状态主要有两个目的获取分片写入权利，也就是说，对于hdfs来讲， 只会允许我一个分片进行写入， 只有拿到这个权利的分片我才能写入，第二-个目的是如果 上次分片是异常中断的，没有进行save checkpoint,这里会重新进行- -次savecheckpoint, 然后就进入了正常的写流程状态，创建文件，写入数据，到一定大小之后又开始建立新的文件进行写入。 RocketMQ使用场景 基本概念： 可以看到Producer, Consumer, Broker这三 个部分，Kafka和RocketMQ是一 样的， 而Kafka中的Partition概念在这里叫做ConsumerQueue, 架构： 先说数据流也是通过Producer发送给Broker集群,再由Consumer进行消费 Broker节点有Master和Slave的概念 NameServer为集群提供轻量级服务发现和路由 接下来我们来看看RocketMQ消息的存储模型，对于一个Broker来说所有的消 息的会append到一个CommitLog 上面，然后按照不同的Queue,重新Dispatch到不同的Consumer中， 这样Consumer就可以按照Queue进行拉取消费，但需要注意的是，这里的ConsumerQueue所存储的并不是真实的数据，真实的数据其实只存在CommitLog中， 这里存的仅仅是这个Queue所有消息在CommitLog.上面的位置，相当于是这个Queue的一个密集索引 事务","link":"/2025/02/13/bytedance/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"title":"DNS查询流程","text":"DNS查询流程 客户端通过浏览器访问域名为www.baidu.com的网站，发起查询该域名的IP地址的 DNS 请求。该请求发送到了本地DNS服务器上。本地DNS服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果。如果没有，本地DNS服务器还要向 DNS根服务器进行查询 本地DNS服务器向根服务器请求域名www.baidu.com的IP地址。 根服务器经过查询，没有记录该域名及 IP 地址的对应关系。但是会告诉本地 DNS 服务器，可以到顶级域名服务器(.com 服务器)上继续查询。 本地 DNS 服务器向 .com 服务器发送 DNS 请求，请求域名www.baidu.com的 IP 地址。 com 服务器收到请求后也没有找到该域名及 IP 地址的对应关系，但是告诉本地DNS服务器，该域名可以在权威域名服务器 baidu.com上进行解析。 本地 DNS 服务器向baidu.com域名服务器请求域名www.baidu.com的 IP 地址。 baidu.com服务器收到请求后，发现了该域名和 IP 地址的对应关系，并将 IP 地址返回给本地 DNS 服务器。 本地 DNS 服务器将获取到与域名对应的 IP 地址返回给客户端，并且将域名和 IP 地址的对应关系保存在缓存中，以备下次别的用户查询时使用。 其中客户端与本地DNS服务器之间是递归查询，本地DNS服务器与其他服务器直接是迭代查询 高速缓存缓存的目的是将数据临时存储在某个位置，从而提高数据请求的性能和可靠性。DNS 高速缓存涉及将数据存储在更靠近请求客户端的位置，以便能够更早地解析 DNS 查询，并且能够避免在 DNS 查找链中进一步向下的额外查询，从而缩短加载时间并减少带宽/CPU 消耗。由于域名到IP地址的映射关系并不是永久不变，为保持高速缓存中的内容正确，DNS中的每项记录都会设置对应的TTL，超过TTL就会删除这段记录。 查询baidu.com的查询过程： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556C:\\Users\\19613&gt;dig baidu.com +trace; &lt;&lt;&gt;&gt; DiG 9.16.30 &lt;&lt;&gt;&gt; baidu.com +trace;; global options: +cmd. 945 IN NS a.root-servers.net.. 945 IN NS e.root-servers.net.. 945 IN NS j.root-servers.net.. 945 IN NS i.root-servers.net.. 945 IN NS f.root-servers.net.. 945 IN NS h.root-servers.net.. 945 IN NS c.root-servers.net.. 945 IN NS m.root-servers.net.. 945 IN NS l.root-servers.net.. 945 IN NS b.root-servers.net.. 945 IN NS d.root-servers.net.. 945 IN NS g.root-servers.net.. 945 IN NS k.root-servers.net.;; Received 783 bytes from 172.19.2.1#53(172.19.2.1) in 0 mscom. 172800 IN NS d.gtld-servers.net.com. 172800 IN NS f.gtld-servers.net.com. 172800 IN NS b.gtld-servers.net.com. 172800 IN NS j.gtld-servers.net.com. 172800 IN NS e.gtld-servers.net.com. 172800 IN NS m.gtld-servers.net.com. 172800 IN NS h.gtld-servers.net.com. 172800 IN NS a.gtld-servers.net.com. 172800 IN NS l.gtld-servers.net.com. 172800 IN NS c.gtld-servers.net.com. 172800 IN NS g.gtld-servers.net.com. 172800 IN NS i.gtld-servers.net.com. 172800 IN NS k.gtld-servers.net.com. 86400 IN DS 19718 13 2 8ACBB0CD28F41250A80A491389424D341522D946B0DA0C0291F2D3D7 71D7805Acom. 86400 IN RRSIG DS 8 1 86400 20240430200000 20240417190000 5613 . dB2Vlmf6lsKLbMiZZqDF2cHn0gF/dJguw4/786WLE9Z2iqtlBaULEMnr W3Qp9qHb2WqkatIxqKTktiGxHfklTdTz92MIyHZm8ow1wLPr9zDPZekM wk/Q29PnFonB0F71qWQI1vCLnljwWBFXYX6/CC6zOJalmqhThm4q13az 6qaOvvVTBICX5UwX/JXysFUdhquLBg/KsVN9D7vRzGuDaXmeVhZ8Zone 9RIAPJVHHntKAfjMEv6EDO/DOjf5wJCh9WWFVsPiYixaAIgIOK8JVW89 KYb8y+zKUZaTDiP4laXOtMN965vT/uEDJwKQW/4G64b3rMXnH31x2zJx YWzSng==;; Received 1197 bytes from 2801:1b8:10::b#53(b.root-servers.net) in 19 msbaidu.com. 172800 IN NS ns2.baidu.com.baidu.com. 172800 IN NS ns3.baidu.com.baidu.com. 172800 IN NS ns4.baidu.com.baidu.com. 172800 IN NS ns1.baidu.com.baidu.com. 172800 IN NS ns7.baidu.com.CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN NSEC3 1 1 0 - CK0Q2D6NI4I7EQH8NA30NS61O48UL8G5 NS SOA RRSIG DNSKEY NSEC3PARAMCK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN RRSIG NSEC3 13 2 86400 20240422042504 20240415031504 4534 com. ecgUBNoIjF0/2NK5qbLLoESdr1gCp2UQeruasASkce/2OC1+tbNorpx2 zr2HsO8bFW7BEvnN11MdmPyQBU3Csg==HPVV1UNKTCF9TD77I2AUR73709T975GH.com. 86400 IN NSEC3 1 1 0 - HPVVP23QUO0FP9R0A04URSICJPESKO9J NS DS RRSIGHPVV1UNKTCF9TD77I2AUR73709T975GH.com. 86400 IN RRSIG NSEC3 13 2 86400 20240421050941 20240414035941 4534 com. KZ64CrlCZZr8BzEWnjMvpCDh6irfCyr9b6wtP29HpF/JlK+eIQXPEfKv 3lrPrlWgyhKKv7ONmdSctID2FUrMbg==;; Received 653 bytes from 192.26.92.30#53(c.gtld-servers.net) in 40 msbaidu.com. 600 IN A 39.156.66.10baidu.com. 600 IN A 110.242.68.66baidu.com. 86400 IN NS ns2.baidu.com.baidu.com. 86400 IN NS ns3.baidu.com.baidu.com. 86400 IN NS ns4.baidu.com.baidu.com. 86400 IN NS ns7.baidu.com.baidu.com. 86400 IN NS dns.baidu.com.;; Received 356 bytes from 180.76.76.92#53(ns7.baidu.com) in 4 ms","link":"/2024/04/08/other/DNS%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B/"},{"title":"DNS服务器","text":"DNS服务器本地域名服务器本地域名服务器也叫做递归域名服务器、递归解析服务器等，当一个主机发出DNS查询请求时，会首先请求本地域名服务器，再由本地域名服务器进行递归查询 根域名服务器根域名服务器是DNS中最高级别的域名服务器，所有的根域名服务器都知道所有的顶级域名服务器的IP地址。由于DNS和某些协议的共同限制，根域名服务器地址的数量被限制为13个。幸运的是，采用任播技术架设镜像服务器可解决该问题，并使得实际运行的根域名服务器数量大大增加。截至2023年6月，全球共有1719台根域名服务器在运行根域名服务器用来管辖顶级域(如.com)， 通常它并不直接把待查询的域名直接转换成IP地址，而是告诉本地域名服务器下一步应当找哪个顶级域名服务器进行查询根域文件：所有根域名服务器都是以同一份根域文件（Root Zone file，文件名为root.zone）返回顶级域名权威服务器（包括通用顶级域和国家顶级域），文件只有2MB大小。截至2017年10月9日，一共记录了1542个顶级域。对于没被收录的顶级域，是没法通过根域名服务器查出相应的权威服务器。而其他递归DNS服务器则只需要配置Root Hits文件，只包含根域名服务器的地址。本地域名服务器如何找到根域名服务器？由于根域名服务器位于 DNS 层次结构的顶部，因此本地域名服务器无法在DNS查找中被引导到这些位置。因此，每个本地域名服务器都在其软件中内置了13个IP根服务器地址的列表。每次发起DNS查找时，本地域名服务器的第一个通信就是与这13个IP地址之一进行的。 顶级域名服务器顶级域名（TLD）是互联网中最高一级的域名，用于标识互联网中的不同组织、地理位置、网络类型等。顶级域名分为通用顶级域名（gTLDs）和国家和地区顶级域名（ccTLDs）。通用顶级域名如.com（商业）、.org（非赢利组织）、.net（网络服务）等，而国家和地区顶级域名则代表特定的国家或地区，如.cn（中国）、.us（美国）等。 顶级域名服务器负责管理在该顶级域名服务器注册的所有二级域名。收到DNS查询请求时,就给出相应的回答(可能是最后的结果（缓存），也可能是下一步应当查找的域名服务器的IP地址)。顶级域名服务器通常保存的是其下二级域名的NS记录，用于确定解析该二级域名的权威服务器，这些权威服务器保存具体的A记录 权威域名服务器权威域名服务器负责具体的域名解析，通常是查找IP地址过程中的最后一步，权威域名服务器负责特定的域名解析（例如，google.com），它可为本地域名服务器提供在DNS A记录中找到的服务器的IP地址","link":"/2024/04/08/other/DNS%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"title":"DNSSEC详解","text":"DNSSEC DNS 客户端不能确信来自给定 DNS 名称服务器的回复是真实的，且未被篡改。DNS 协议没有为客户端提供了一种机制来确保它不受中间人攻击。引入 DNSSEC 以解决使用 DNS 解析域名时缺少身份验证和完整性检查。它没有解决保密性的问题。DNSSEC 通过向现有 DNS 记录添加加密签名，确保域名系统的安全性。这些数字签名与 A、AAAA、MX、CNAME 等常见记录类型一起存储在域名服务器中。当用户发送DNS查询请求时，DNS服务器会返回数字签名和相应的资源记录，接收到DNS响应后，客户端会使用相应区域的公钥对数字签名进行验证，以确保DNS查询的完整性、真实性和认证性。 参考资料 DNSSEC新增的资源记录RRSIG记录即资源记录签名（英语：Resource Record Signature），资源记录除了A和AAAA之外，也包括DNSKEY、DS、NSEC等记录，RRSIG用于存放各个资源记录的签名，包括 算法类型 标签 (泛解析中原先 RRSIG 记录的名称) 原 TTL 大小 签名失效时间 签名签署时间 Key 标签 (用来迅速判断应该用那个 DNSKEY 记录来验证的一个数值) 签名名称 (用于验证该签名的 DNSKEY 名称) 签名 DNSKEY记录该记录用于存放用于检查 RRSIG 的公钥。其包括 标识符 (Zone Key (DNSSEC密钥集) 以及 Secure Entry Point (KSK和简单密钥集)) 协议 (固定值3 向下兼容) 算法类型 公钥内容 DS记录即委派签名者（英语：Deligated Signer），该记录用于存放 DNSKEY 中公钥的散列值 ，包括 Key 标签：用来判断应该用哪个 DNSKEY 记录进行验证的一个数值 算法类型：常见的有RSASHA1、RSASHA256、ECDSAP256SHA256，具体可参考附录“算法类型列表” 摘要类型：创建摘要值的加密散列算法，主要使用SHA256，具体可参考附录“摘要类型列表” 摘要内容: 一串散列数据，由DNSKEY经由摘要类型算法得出 NSEC和NSEC3记录即下一个安全（英语：Next Secure）记录，用于明确表示特定域名的记录不存在。 CDNSKEY和CDS记录用于请求对父区域中的 DS 记录进行更新的子区域。 RRSET首先需要将DNS记录按照名称和类型分组为资源记录集（Resource record set，RRSet）中。例如，如果您的区域中有三个具有相同标签（如label.example.com）的 AAAA 记录，它们将全部捆绑到一个 AAAA RRset 中。 实际上，是整个 RRset 获得数字签名，而不是单独的 DNS 记录获得。当然，这也意味着您必须从具有相同标签的区域中请求并验证所有 AAAA 记录，而不是仅验证其中一个。 区域签名密钥（ZSK）DNSSEC 中的每个区域都有一个区域签名密钥对（ZSK）：私钥用于对区域中的RRset进行数字签名，公钥用于验证签名。区域管理员会使用ZSK私钥为每个RRset创建数字签名，并将其作为RRSIG记录存储在域名服务器中。同时DNSSEC的区域管理员会将自己的ZSK公钥以DNSKEY记录的形式公布出来，这样解析器即可验证RRSIG的值。当 DNSSEC 解析器请求特定的记录类型（例如 AAAA）时，名称服务器还会返回相应的 RRSIG。然后，解析器可以从域名服务器中提取包含公用 ZSK 的 DNSKEY 记录。RRset、RRSIG 和公共 ZSK 将一同用于验证响应。如果我们信任 DNSKEY 记录中的区域签名密钥，则可以信任该区域中的所有记录。但是，如果区域签名密钥被泄露怎么办？我们需要一种方法来验证公开 ZSK。 密钥签名密钥（KSK）除了区域签名密钥之外，域名服务器还具有密钥签名密钥（KSK）。KSK 验证 DNSKEY 记录的方式与上一节中描述的ZSK保护RRset的方式完全相同：它签署ZSK公钥（存储在 DNSKEY 记录中），从而为 DNSKEY 创建 RRSIG。 与ZSK公钥一样，域名服务器会将KSK公钥存储在另一个DNSKEY记录中，ZSK公钥和KSK公钥共同组成了上面显示的 DNSKEY RRset 由KSK私钥签名。然后，解析器就可以使用KSK公钥来验证ZSK公钥。 解析器验证流程如下： 请求所需的 RRset，系统还将返回相应的 RRSIG 记录。 请求包含ZSK公钥和KSK公钥的DNSKEY记录，系统还将返回 DNSKEY RRset 的 RRSIG。 用ZSK公钥验证所请求 RRset 的 RRSIG。 用KSK公钥验证 DNSKEY RRset 的 RRSIG。 区域签名密钥（ZSK）是一种短期密钥，它用于定期计算DNS记录的签名。每个DNS区域通常都有自己的一组ZSK，这些密钥会定期更换，以提高安全性。通过使用ZSK对DNS记录进行签名，DNSSEC能够确保这些记录在传输过程中未被篡改。密钥签名密钥（KSK）则是一种长期密钥，用于对区域签名密钥（ZSK）上的签名进行计算。也就是说，KSK实际上是对ZSK进行签名的密钥，这形成了一个签名链，增强了DNSSEC的安全性。KSK的更换频率通常低于ZSK，这是因为频繁更换KSK可能会对DNS系统的稳定性造成影响。 委派签名者记录（DS）DNSSEC 引入了委派签名者（Delegation signer，DS）记录，以允许将信任从父区域转移到子区域建立起一个信任链模型。区域操作员对包含公共 KSK 的 DNSKEY 记录进行哈希处理，并将其提供给父区域以作为 DS 记录发布。 每次将解析器引用到子区域时，父区域也会提供 DS 记录。此 DS 记录是解析器获知子区域启用 DNSSEC 的方式。为了检查子区域的公共 KSK 的有效性，解析器对其进行哈希处理并将其与父区域的 DS 记录进行比较。如果两者匹配，则解析器可以假定公共 KSK 未被篡改，这意味着它可以信任子区域中的所有记录。这就是在 DNSSEC 中建立信任链的方式。 请注意，KSK 的任何变更都需要更改父区域的 DS 记录。更改 DS 记录是一个多步骤的过程，如果执行不正确，最终可能会破坏该区域。首先，父级需要添加新的 DS 记录，然后需要等到原始 DS 记录的 TTL 过期后将其删除。这就是为什么换掉区域签名密钥比密钥签名密钥要容易得多。 NSEC和NSEC3Next Secure（NSEC）记录可用于确定特定区域中是否存在某个名称。它的出现主要是为了解决记录不存在于某个区域的问题（即“拒绝存在”认证问题）。攻击者可以利用这个漏洞，伪造网站主机名的NXDOMAIN响应使网站无法访问。 DNSSEC解决了这个问题，当查询收到一个不存在的名称时，通过将域名按字母顺序排列，它可以提供一条NSEC记录来代表区域中的下一个记录是真实存在的。 举例来说，如果“example.com”区域经过排序，让“beta.example.com”成为第一条记录，那么针对“alpha.example.com”的查询将导致NXDOMAIN，并产生一条指向“beta.example.com”的NSEC记录。NSEC记录与其他任何记录一样，都由ZSK签名，具备对应的RRSIG。因此对NXDOMAIN的响应需要具备经过认证的RRSIG NSEC记录才算有效。 NSEC3的诞生就是为了解决NSEC记录被用于列出区域中所有有效记录而造成的问题。NSEC3在行为上与NSEC完全相同，不过区域中的Next secure名称会显示为哈希而非明文。这有助于保护信息并防止区域遍历 信任链现在，在区域内建立信任并将其连接到父区域的方法已经有了，但是我们如何信任 DS 记录呢？DS 记录就像其他任何 RRset 一样签署，这意味着它在父级中具有相应的 RRSIG。整个验证过程不断重复，直到获得父级的公共 KSK。为了验证父级的公共 KSK，我们需要转到父级的 DS 记录，以此类推，沿着信任链上行。但是，当我们最终到达根 DNS 区域时，又有一个问题：没有父 DS 记录可用于验证。在这里，我们可以看到全球互联网非常人性的一面：在“根区域签名仪式”上，来自世界各地的特定几人以公开且经严格审核的方式签署根 DNSKEY RRset。这次仪式会产生一个 RRSIG 记录，该记录可用于验证根名称服务器的公共 KSK 和 ZSK。我们不会由于父级的 DS 记录而信任公共 KSK，而是因为信任访问私有 KSK 所涉的安全性过程而假定其有效 总结区域文件中会包含ZSK公钥和KSK公钥两条DNSKEY记录，用于验证签名，父区域DS记录包含子区域KSK的哈希用于建立信任 数据结构","link":"/2024/06/08/other/DNSSEC%E8%AF%A6%E8%A7%A3/"},{"title":"dig命令","text":"dig是一个网络管理命令行工具，用于查询域名系统（DNS）。dig是域名服务器软件套件BIND的组成部分。 dig命令dig是一个网络管理命令行工具，用于查询域名系统（DNS）。dig是域名服务器软件套件BIND的组成部分。 windows安装dig命令windows下dig安装教程 注意：现在对windows最高支持到9.16.30版本，9.18.4版本已经没有windows下载选项了 使用查询域名信息：dig baidu.com 常用参数 @：指定进行域名解析的域名服务器 +trace：输出迭代查询的过程 查询NS记录：dig baidu.com NS（查询某个记录直接加上记录名） 输出内容 dig 命令的版本和输入的参数。 服务返回的一些技术详情，比较重要的是 status。如果 status 的值为 NOERROR 则说明本次查询成功结束。 “QUESTION SECTION”：显示我们要查询的域名以及要查询的记录，默认查询A记录。 “ANSWER SECTION”：是查询到的结果。 “AUTHORITY SECTION”：权威部分，查询域名的权威服务器，当无法给出答案时会给出下一步查询的服务器，详解在后。 “ADDITIONAL SECTION”：附加信息，通常是AUTHORITY SECTION中域名对应的IP，也称作GLUE RECORD 本次查询的一些统计信息，比如用了多长时间，查询了哪个 DNS 服务器，在什么时间进行的查询等等。 +trace递归解析示例 首先从本地DNS服务器172.19.2.1查询了根域名服务器的信息，然后从l.root-servers.net查询到了定义域名服务器的信息，然后从a.gtld-servers.net查询到了baidu.com的权威服务器，然后从ns4.baidu.com查到了baidu.com的A记录 AUTHORITY SECTION参考文章 AUTHORITY SECTION取决于查询使用的名称服务器。如果您没有使用@标志指定任何一个，它将使用本地递归的方式为您提供最终答案。这个答案可能是由递归名称服务器在得到答案之前查询许多不同的权威名称服务器计算出来的，因此在这个场景中可能没有权威名称服务器。 示例： 使用DNS服务器9.9.9.9查询serverfault.com结果中没有AUTHORITY SECTION，因为递归解析器不具有权威性，所以只返回了ANSWER 我们使用根权威服务器查询serverfault.com，因为根服务器不知道serverfault.com记录所以结果中没有ANSWER，但是根服务器知道需要去com顶级域名服务器查询该域名，所以在AUTHORITY中给出了顶级域名com的权威服务器地址 继续使用com服务器查询该域名，同样无法直接获得该域名的A记录，ANSWER为空，但是在AUTHORITY中给出了serverfault.com的NS记录，即该域名的权威服务器地址 使用该域名的权威服务器查询到了该域名的A记录，此时没有AUTHORITY，因为你根本不需要它，这是一种优化。","link":"/2024/05/18/other/dig%E5%91%BD%E4%BB%A4/"},{"title":"DNS记录","text":"DNS记录DNS 记录（又名区域文件）是位于 DNS 服务器中的指令，提供一个域的相关信息，包括哪些 IP 地址与该域关联，以及如何处理对该域的请求。这些记录由一系列以所谓的 DNS 语法编写的文本文件组成。DNS 语法是用作命令的字符串，这些命令告诉 DNS 服务器执行什么操作。此外，所有 DNS 记录都有一个 “TTL”，其代表生存时间，指示 DNS 服务器多久刷新一次该记录。 A记录 保存域的IP地址的记录 “A”代表“地址”，这是最基础的 DNS 记录类型：它用来指定给定域名的 IP 地址。 A 记录只保存 IPv4 地址。如果一个网站拥有 IPv6 地址，它将改用“AAAA”记录。 A记录示例 example.com record type value TTL @ A 192.0.2.1 14400 其中@表示example.com域名本身没有任何前缀 绝大多数网站只有一个 A 记录，但也可以有多个。一些高知名度网站可能有数个不同的 A 记录，将请求流量分配到多个 IP 地址中的一个，实现负载均衡 AAAA记录 包含域的 IPv6 地址的记录（与 A 记录相反，A 记录列出的是 IPv4 地址） DNS AAAA 记录将域名与 IPv6 地址进行匹配。DNS AAAA 记录与 DNS A 记录完全一样，只是它们存储域的 IPv6 地址，而非 IPv4 地址。 AAAA记录示例： example.com record type value TTL @ AAAA 2001:0db8:85a3:0000:0000:8a2e:0370:7334 14400 CNAME记录 将一个域或子域转发到另一个域，不提供 IP 地址。 一个”canonical name”（CNAME）记录从一个别名域指向一个”规范名称”域，当一个域或子域是另一个域的别名时，CNAME记录被用来代替A记录(一个域名不能同时设置A记录和CNAME记录)。所有CNAME记录都必须指向一个域名，而不是指向一个IP地址。想象一下，在一个寻宝游戏中，每条线索都指向另一条线索，而最后的线索则指向宝藏。 一个有CNAME记录的域名就像一条线索，可以把你指向另一条线索（另一个有CNAME记录的域名）或宝藏（一个有A记录的域名） 例如，假设 blog.example.com 的 CNAME 记录的值为“example.com”（没有“blog”）。这意味着当 DNS 服务器点击 blog.example.com 的 DNS 记录时，它实际上会触发另一个对 example.com 的 DNS 查找，并通过其 A 记录返回 example.com 的 IP 地址。在这种情况下，我们会说 example.com 是 blog.example.com 的规范名称（或真实名称）。 一个常见的误解是 CNAME 记录必须始终解析为其指向的域所在的网站，但事实并非如此。CNAME 记录仅将客户端指向与根域相同的 IP 地址。客户端访问该 IP 地址后，Web 服务器仍将相应地处理 URL。例如，blog.example.com 可能有一个 CNAME 指向 example.com，从而将客户端定向到 example.com 的 IP 地址。但是，当客户端实际连接到该 IP 地址时，Web 服务器将查看 URL，发现它是 blog.example.com，并且提供博客页面而不是主页。 CNAME记录示例： blog.example.com record type value TTL @ CNAME is an alias of example.com 32600 一个CNAME记录可以指向另一个CNAME记录吗?将 CNAME 记录指向另一个 CNAME 记录十分低效，因为它需要在加载域之前进行多次 DNS 查找——这会降低用户体验，不过这个过程是可以实现的。例如，blog.example.com 可以有一个 CNAME 记录指向 www.example.com 的 CNAME 记录，然后后者指向 example.com 的 A 记录。blog.example.com 的 CNAME： blog.example.com record type value TTL @ CNAME is an alias of www.example.com 32600 它指向 www.example.com 的 CNAME： www.example.com record type value TTL @ CNAME is an alias of example.com 32600 CNAME记录的限制MX 和 NS 记录不能指向 CNAME 记录，它们必须指向 A 记录（对于 IPv4）或 AAAA 记录（对于 IPv6）（即该记录指向的域名设置的记录不能为CNAME）。MX 记录是邮件交换记录，将电子邮件指向一个邮件服务器。NS 记录是“名称服务器”记录，表明哪个 DNS 服务器是该域的权威。 MX记录 将邮件定向到电子邮件服务器。 DNS“邮件交换”(MX) 记录将电子邮件定向到邮件服务器。MX 记录指示如何根据简单邮件传输协议（SMTP，所有电子邮件的标准协议）路由电子邮件。与 CNAME 记录类似，MX 记录必须始终指向另一个域。 MX 记录示例： example.com record type 优先级 value TTL @ MX 10 mailhost1.example.com 45000 @ MX 20 mailhost2.example.com 45000 这些 MX 记录的域前面的“优先级”数字表示优先权，较低的“优先级”值是首选。服务器将始终先尝试mailhost1，因为 10 小于 20。当消息发送失败时，服务器将默认使用 mailhost2。 查询MX记录的过程邮件传输代理 (MTA) 软件负责查询 MX 记录。当用户发送电子邮件时，MTA 会发送一个 DNS 查询，以确定电子邮件收件人的邮件服务器。MTA 与这些邮件服务器建立 SMTP 连接，从优先级高的域开始（在上面的第一个示例中，即为 mailhost1）。 MX 记录必须直接指向服务器的 A 记录或 AAAA 记录。定义 MX 记录运作原理的 RFC 文档禁止 MX 记录指向 CNAME TXT 记录 可让管理员在记录中存储文本注释。这些记录通常用于电子邮件安全。 DNS“文本”(TXT) 记录允许域管理员将文本输入到域名系统 (DNS) 中。TXT 记录最初的目的是用作存放人类可读笔记的地方。但是，现在也可以将一些机器可读的数据放入 TXT 记录中。一个域可以有许多 TXT 记录。 TXT 记录示例： example.com record type value TTL @ TXT This is an awesome domain! Definitely not spammy. 32600 如今，DNS TXT 记录的两个最重要用途是防止垃圾邮件和域名所有权验证，尽管 TXT 记录最初并非为这些用途而设计。 TXT 记录如何帮助防止垃圾邮件？ 垃圾邮件发送者经常试图伪造或假冒他们发送电子邮件的域。TXT 记录是几种不同的电子邮件验证方法的关键组成部分，它可帮助电子邮件服务器确定邮件是否来自可信的来源。 常见的电子邮件身份验证方法包括域密钥识别邮件 (DKIM)、发送方策略框架 (SPF) 以及基于域的邮件身份验证、报告和一致性 (DMARC)。通过配置这些记录，域运营商可以使垃圾邮件发送者更难伪造他们的域，并且可以跟踪此类尝试。 SPF 记录：SPF TXT 记录列出了所有被授权从一个域发送电子邮件的服务器。 DKIM 记录：DKIM 的工作原理是使用一个公钥-私钥对，对每封电子邮件进行数字签名。这有助于验证电子邮件确实来自它所声称的域。公钥被存放在与域关联的 TXT 记录中。（了解有关公钥加密的更多信息）。 DMARC 记录：DMARC TXT 记录引用域的 SPF 和 DKIM 政策。它应该存储在标题 _marc.example.com 下，“example.com”用实际域名代替。记录的“值”是域的 DMARC 政策 TXT 记录如何帮助验证域所有权？ 虽然域所有权验证最初不是 TXT 记录的一个功能，但这种方法已经被一些网站管理员工具和云提供商采用。 管理员可以通过上传包含特定信息的新 TXT 记录，或编辑当前的 TXT 记录，来证明他们控制着该域。工具或云提供商可以检查 TXT 记录，并看到它已按要求进行了更改。这有点像用户通过打开并点击发送到该电子邮件的链接来确认其电子邮件地址，证明他们拥有该地址 NS记录 存储 DNS 条目的域名服务器。 NS 代表“域名服务器”，域名服务器记录指示哪个 DNS 服务器对该域具有权威性（即，哪个服务器包含实际 DNS 记录）。基本上，NS 记录告诉互联网可从哪里找到域的 IP 地址。一个域通常会有多个 NS 记录，这些记录可指示该域的主要和辅助域名服务器。倘若没有正确配置的 NS 记录，用户将无法加载网站或应用程序。 NS 记录示例： example.com record type value TTL @ NS ns1.exampleserver.com 21600 请注意，NS 记录永远不能指向规范名称（CNAME）记录。 什么是域名服务器 域名服务器是一种 DNS 服务器，上面存储了域的所有 DNS 记录，包括 A 记录、MX 记录或 CNAME 记录。 几乎所有域都依靠多个域名服务器来提高可靠性：如果一个域名服务器出现故障或不可用，DNS 查询可以转到另一个域名服务器。通常有一个主要域名服务器和几个次要域名服务器，后者包含只读的区域文件副本，这意味着它们不能被修改。它们不是从本地文件中获取信息，而是在称为“区域传输”的通信过程中从主服务器接收相关信息。 使用多个域名服务器时（大多数情况下），NS 记录应列出不止一个服务器。 SOA记录 存储域的管理信息。 DNS ‘start of authority’ (SOA) 记录存储了关于域名和区域的重要信息，如管理员的电子邮件地址、域名上次更新的时间，以及服务器在刷新之间应等待的时长。 所有 DNS 区域都需要一个 SOA 记录，以符合 IETF 标准。SOA 记录对区域传输也很重要。 SOA 记录示例： name example.com record type SOA MNAME ns.primaryserver.com RNAME admin.example.com SERIAL 1111111111 REFRESH 86400 RETRY 7200 EXPIRE 4000000 TTL 11200 RNAME：管理员的电子邮件地址，这可能会造成混淆，因为它缺少“@”符号；但在 SOA 记录中，admin.example.com 等效于 admin@example.com。 SERIAL：区域序列号，表示SOA记录的版本号，当区域文件中的序列号发生更改时，这会提醒辅助名称服务器，它们应当通过区域传输更新其区域文件的副本。 MNAME：这是区域的主要名称服务器的名称。维护该区域 DNS 记录副本的辅助服务器会从该主要服务器接收对该区域的更新 REFRESH：辅助服务器在向主要服务器询问 SOA 记录以查看其是否已更新之前应等待的时间长度（秒）。 RETRY：服务器再次向无响应的主要名称服务器请求更新前应等待的时间长度。 EXPIRE：如果辅助服务器在该时间段内没有得到主要服务器的响应，则应该停止响应对该区域的查询。 什么是DNS区域？DNS 被分成许多不同的区域。这些区域可区分在 DNS 命名空间中以不同方式管理的区域。DNS 区域是 DNS 命名空间的一部分，由特定组织或管理员加以管理。DNS 区域是一个管理空间，其可实现对权威性域名服务器等 DNS 组件的更精细控制，DNS 区域可包含多个子域，并且多个区域可存在于同一服务器上。例如，想象一下 cloudflare.com 域及其以下三个子域：support.cloudflare.com、community.cloudflare.com 和 blog.cloudflare.com。假设blog是一个强健的独立站点，该站点需要单独管理，但是support和community与cloudflare.com 更紧密地关联，并且可在与主域相同的区域中加以管理。在这种情况下，cloudflare.com 以及support站点和community站点都将在一个区域中，而blog.cloudflare.com将存在于其自己的区域中。 什么是区域传输？DNS 区域传输是将 DNS 记录数据从一个主要名称服务器发送到一个辅助名称服务器的过程。SOA 记录将首先被传输。序列号将告知辅助服务器其版本是否需要更新。区域传输通过 TCP 协议进行。 PTR记录 DNS 指针记录（简称 PTR）提供与 IP 地址关联的域名。DNS PTR 记录与“A”记录完全相反，它提供与域名关联的 IP 地址 相关术语胶水记录胶水记录介绍死循环问题胶水记录（Glue Record）是DNS（域名系统）中的一个重要概念，尤其是在自建DNS环境中。其英文名为Glue Record，中文也有不同的称呼，比如一些运营商可能称之为“自定义DNS Host”或“注册DNS服务器”。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# dig @202.12.27.33 jd.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &lt;&lt;&gt;&gt; @202.12.27.33 jd.com; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 29264;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 13, ADDITIONAL: 27;; WARNING: recursion requested but not available;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;jd.com. IN A;; AUTHORITY SECTION:com. 172800 IN NS d.gtld-servers.net.com. 172800 IN NS f.gtld-servers.net.com. 172800 IN NS e.gtld-servers.net.com. 172800 IN NS g.gtld-servers.net.com. 172800 IN NS k.gtld-servers.net.com. 172800 IN NS a.gtld-servers.net.com. 172800 IN NS c.gtld-servers.net.com. 172800 IN NS j.gtld-servers.net.com. 172800 IN NS l.gtld-servers.net.com. 172800 IN NS b.gtld-servers.net.com. 172800 IN NS m.gtld-servers.net.com. 172800 IN NS i.gtld-servers.net.com. 172800 IN NS h.gtld-servers.net.;; ADDITIONAL SECTION:a.gtld-servers.net. 172800 IN A 192.5.6.30b.gtld-servers.net. 172800 IN A 192.33.14.30c.gtld-servers.net. 172800 IN A 192.26.92.30d.gtld-servers.net. 172800 IN A 192.31.80.30e.gtld-servers.net. 172800 IN A 192.12.94.30f.gtld-servers.net. 172800 IN A 192.35.51.30g.gtld-servers.net. 172800 IN A 192.42.93.30h.gtld-servers.net. 172800 IN A 192.54.112.30i.gtld-servers.net. 172800 IN A 192.43.172.30j.gtld-servers.net. 172800 IN A 192.48.79.30k.gtld-servers.net. 172800 IN A 192.52.178.30l.gtld-servers.net. 172800 IN A 192.41.162.30m.gtld-servers.net. 172800 IN A 192.55.83.30a.gtld-servers.net. 172800 IN AAAA 2001:503:a83e::2:30b.gtld-servers.net. 172800 IN AAAA 2001:503:231d::2:30c.gtld-servers.net. 172800 IN AAAA 2001:503:83eb::30d.gtld-servers.net. 172800 IN AAAA 2001:500:856e::30e.gtld-servers.net. 172800 IN AAAA 2001:502:1ca1::30f.gtld-servers.net. 172800 IN AAAA 2001:503:d414::30g.gtld-servers.net. 172800 IN AAAA 2001:503:eea3::30h.gtld-servers.net. 172800 IN AAAA 2001:502:8cc::30i.gtld-servers.net. 172800 IN AAAA 2001:503:39c1::30j.gtld-servers.net. 172800 IN AAAA 2001:502:7094::30k.gtld-servers.net. 172800 IN AAAA 2001:503:d2d::30l.gtld-servers.net. 172800 IN AAAA 2001:500:d937::30m.gtld-servers.net. 172800 IN AAAA 2001:501:b1f9::30;; Query time: 211 msec;; SERVER: 202.12.27.33#53(202.12.27.33);; WHEN: Thu Aug 01 18:13:03 CST 2019;; MSG SIZE rcvd: 831 这是根服务器返回的.com服务器的信息，其中ADDITIONAL SECTION就是胶水记录 普通DNS记录保存在权威服务器上，胶水记录保存在域名注册局的DNS服务器上 胶水记录可以看作是和DNS查询结果一起顺便返回的一组域名和IP地址的映射 作用： 减少递归查询次数，加快DNS递归查询，在向根域名和顶级域名服务器查询时他们通常返回的是下一级要查询的服务器的域名，此时胶水记录会同时附带要查询的域名的IP地址，如果没有胶水记录则会重新启动一次新的查询去查询该域名，因此胶水记录可以减少递归查询次数，加快 DNS 递归查询。 如果域名的NS服务器是子域名那么解析过程可能会陷入死循环。以一个简单的例子来说明：假设我们有一个域名b.com，并希望指定b.com的NS地址是a.b.com（无法直接指定ip地址）。在这种情况下，我们就必须指定a.b.com的A记录，否则在解析a.b.com时，系统又会去解析b.com，导致循环而无法得出结果。这就需要我们添加一条胶水记录去解析a.b.com 缓存投毒一次出人意料而名留青史的DNS投毒攻击攻击者通过精心构造DNS报文，在LDNS查询某个域名时，冒充真正的权威DNS做出回应，使得LDNS得到一个虚假响应。如果LDNS接受了这个虚假响应并写入缓存，LDNS就会中毒。","link":"/2024/04/08/other/DNS%E8%AE%B0%E5%BD%95/"},{"title":"go mod 依赖管理","text":"本文介绍了 Go 语言的依赖管理工具 go mod，它通过模块化的方式来管理项目的依赖关系。文章详细阐述了 go mod 的基本概念、如何启用模块化、go.mod 文件的结构以及常用命令。此外，还介绍了 go.sum 文件的作用、Go 模块版本控制、Go 模块代理的配置方法，以及一个简单的 Go 模块项目的工作流程示例。最后，总结了 go mod 的主要功能和特点，包括初始化模块、下载更新依赖包、清理未使用的依赖等，并强调了 go.mod 和 go.sum 文件在依赖管理中的重要性。 go mod 是 Go 1.11 引入的依赖管理工具，它通过模块化的方式来管理项目的依赖关系，使得 Go 项目不再依赖于 GOPATH 目录，可以在任意位置管理项目及其依赖。模块系统解决了之前版本中依赖包管理的复杂性问题，并且支持依赖版本控制。 1. 什么是 Go 模块 (go mod)？Go 模块（Go Modules）是一种项目和依赖包管理的方式。它通过定义一个 go.mod 文件，来管理你的项目及其所依赖的其他模块。每个模块包含了一个版本化的 Go 包集合，支持对包的版本管理和依赖解析。 模块：Go 模块是一个版本化的依赖管理单元，可以是一个仓库中的所有包，也可以是某个包的子目录。 go.mod 文件：这是模块的配置文件，描述了当前项目的模块路径和依赖信息（模块的版本号等）。 go.sum 文件：这个文件包含了所有依赖模块的校验和信息，用于验证依赖的正确性和完整性。 2. 启用模块化Go 模块化管理默认开启，你可以在任何地方使用 go mod，而不必把项目放到 GOPATH/src 目录中。 启用 Go 模块： 当你在一个新的项目中使用 Go 模块时，首先需要在项目根目录下初始化一个模块，生成 go.mod 文件： 1go mod init &lt;module-path&gt; 例如： 1go mod init github.com/username/myproject 这会生成一个 go.mod 文件，它包含了模块的名称（路径）和当前使用的 Go 版本。 123module github.com/username/myprojectgo 1.21 3. go.mod 文件结构go.mod 文件定义了当前项目的模块路径和依赖的版本。其典型结构如下： 12345678module github.com/username/myprojectgo 1.21require ( github.com/pkg/errors v0.9.1 golang.org/x/net v0.0.0-20211012123533-c345ae6c3143) module: 指定模块的路径(通常是代码库的 URL)。 go: 指定使用的 Go 版本。 require: 列出了项目依赖的模块及其版本。 4. go.mod 常用命令 go mod init初始化一个新的 Go 模块，生成 go.mod 文件。命令格式：go mod init &lt;module-path&gt; go get用于获取并安装依赖包或者更新依赖包的版本。常见用法： 添加新的依赖：go get github.com/pkg/errors 升级到某个特定版本：go get github.com/pkg/errors@v0.9.1 获取最新的次要版本或补丁版本：go get github.com/pkg/errors@latestgo get 命令会自动更新 go.mod 和 go.sum 文件。 go mod tidy清理 go.mod 和 go.sum 文件，移除未使用的依赖项，并下载所需的依赖。运行这个命令有助于保持模块依赖文件的整洁：go mod tidy go mod vendor将所有依赖包下载到本地项目的 vendor/ 目录中。使用 vendor 可以确保在构建时项目不依赖外部网络，所有依赖都在本地:go mod vendor go mod verify验证模块的依赖包是否与 go.sum 中的校验和一致，确保依赖包没有被篡改或损坏：go mod verify go mod graph列出当前项目的模块依赖关系图，帮助分析依赖的层次结构：go mod graph go mod edit手动编辑 go.mod 文件，用于添加、删除或更改模块依赖。例如，修改模块的 require 字段：go mod edit -require=github.com/pkg/errors@v0.9.1 go list -m all列出所有模块依赖及其版本信息。可以用来查看项目当前使用的所有依赖包：go list -m all 5. go.sum 文件当你下载模块时，Go 会生成或更新 go.sum 文件，记录每个模块版本的哈希值和其所有依赖包的版本。这是为了确保依赖的模块没有被篡改，go.sum 文件帮助验证模块的完整性。 6. Go 模块版本控制在 Go 模块中，版本号遵循 语义化版本控制（SemVer）规范，格式为 vX.Y.Z，其中： X：主版本号（大版本），进行不兼容的 API 修改时增加。 Y：次版本号，向下兼容的新功能增加时增加。 Z：修订号，仅做向下兼容的问题修复时增加。 使用 go get 时，可以指定依赖的版本，或者让 Go 自动处理版本升级： 升级到指定版本：go get github.com/pkg/errors@v0.9.1 升级到最新稳定版：go get github.com/pkg/errors@latest 7. Go 模块代理为了加快模块下载速度，Go 允许使用模块代理（Module Proxy）。Go 的默认代理是 proxy.golang.org，如果你的网络环境访问 Golang 官方模块仓库比较慢或被限制，你可以选择配置代理，如 goproxy.cn（适用于中国用户）。 配置代理的方法：go env -w GOPROXY=https://goproxy.cn,direct这将显著加快模块下载速度。 8. 示例流程下面是一个简单的 Go 模块项目的工作流程示例： 初始化项目： 123mkdir myprojectcd myprojectgo mod init github.com/username/myproject 添加依赖：在代码中引入第三方依赖，例如： 1import &quot;github.com/pkg/errors&quot; 然后运行： 1go get github.com/pkg/errors 编译项目： 1go build 清理依赖： 1go mod tidy 查看依赖关系： 1go mod graph 9. 依赖管理目录Go 在模块化模式下（go mod），依赖包下载路径与传统的 GOPATH 模式不同，它下载依赖到一个全局的缓存目录，而不是直接放到项目目录中。 在 Go 模块化管理中，依赖包会被下载到本地的模块缓存目录，而不是 GOPATH/src 目录下。默认情况下，依赖包下载到以下路径：$GOPATH/pkg/mod 如果你希望将所有依赖包下载到项目的 vendor 目录下，可以使用 go mod vendor 命令，它会将所有依赖拷贝到本地项目的 vendor/ 目录。这样在构建项目时，Go 会优先使用本地的 vendor/ 目录而不是全局缓存。 总结 go mod init：初始化模块，生成 go.mod 文件。 go get：下载、更新和管理依赖包。 go mod tidy：清理未使用的依赖。 go.mod 文件记录项目依赖，go.sum 文件记录模块校验和，确保模块一致性。","link":"/2024/10/13/other/go-mod-%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"},{"title":"令牌桶和漏桶","text":"点击阅读更多查看文章内容 令牌桶1. 令牌桶算法的定义令牌桶（Token Bucket）是一种流量控制算法，用于限制请求的速率，避免系统因流量突增而崩溃。它的核心思想是： 系统维护一个“令牌桶”，按照固定的速率向桶中添加令牌，当请求到达时，需要消耗桶中的令牌才能被处理。如果桶中没有令牌，请求会被丢弃或限流。 2. 令牌桶算法的工作流程 令牌按照固定速率 r（如每秒 10 个）加入桶中。 桶最多可以容纳b 个令牌，如果桶满了，新来的令牌就会被丢弃。 处理请求时，每个请求需要消耗 1 个令牌。 如果桶中有足够的令牌，请求就被放行（即正常处理）。 如果桶中没有足够的令牌，请求会被拒绝（限流）或排队等待。 3. 适用场景 API 限流（如限制用户访问频率） 流量控制（如保护数据库、Redis、Kafka 等后端服务） 带宽管理（如 QoS 处理） 总结 令牌桶允许短暂的突发流量，比漏桶更灵活。 速率可控，适用于 API 限流、服务保护等场景。 实现简单，性能高，广泛用于分布式系统。 漏桶1. 漏桶算法的定义漏桶（Leaky Bucket）是一种流量整形（Traffic Shaping）和速率限制（Rate Limiting）算法，主要用于平滑流量，防止突发请求对系统造成冲击。 核心思想：请求进入一个“漏桶”，桶中的请求以固定速率流出，如果桶满了，新请求将被丢弃。 2. 漏桶算法的工作流程 请求进入桶中，如果桶未满，数据进入队列等待处理。 以固定速率处理请求，不管流量有多大，处理速率始终不变（如每秒处理 5 个请求）。 如果桶满了，新请求会被丢弃，防止系统过载。 保证流量平滑，避免瞬时高并发压垮系统。 3. 适用场景 网络流量控制：避免突发流量导致带宽拥塞。 API 调用限流：控制 API 每秒的调用量，防止服务过载。 消息队列限流：保证消费者按固定速率消费消息，避免系统崩溃。 总结 漏桶算法平滑流量，即使流量突增，也会以固定速率处理请求，防止系统崩溃。 不允许突发流量，严格控制请求流出速率，适用于流量整形、网络流量控制等场景。 令牌桶 vs 漏桶令牌桶和漏桶都是流量控制（Rate Limiting）算法，主要用于限制请求速率，防止流量过载 对比项 令牌桶（Token Bucket） 漏桶（Leaky Bucket） 核心思想 令牌按照固定速率生成，只有拿到令牌的请求才能通过 请求进入桶后按固定速率流出，超出桶容量的请求被丢弃 流量控制 限制请求速率，但允许突发流量 严格控制请求流出速率，不允许突发流量 速率特点 允许短时间突发，但平均速率受控 速率恒定，保证稳定流量输出 流量超出处理 桶中无令牌时，新请求被限流 桶满时，新请求被丢弃 适用场景 API 限流、带宽管理、流量控制 流量整形、带宽控制、网络流量管理 典型应用 限制 QPS（请求数）、防止突发流量冲击后端 控制请求流量，防止系统瞬间超载 ✅ 如果希望允许短时间的流量突发：用令牌桶✅ 如果希望严格控制请求流出速率，使流量平稳：用漏桶","link":"/2025/03/03/other/%E4%BB%A4%E7%89%8C%E6%A1%B6&%E6%BC%8F%E6%A1%B6/"},{"title":"环境变量优先级","text":"点击阅读更多查看文章内容 关于环境变量的优先级问题问题描述使用 curl.exe -LO &quot;https://dl.k8s.io/release/v1.18.0/bin/windows/amd64/kubectl.exe&quot; 安装1.18.0版本的kubectl 将安装路径添加到环境变量的用户变量path中 在命令行查看版本信息却一直是1.30.5 问题原因使用where kubectl发现环境变量中有两个kubectl.exe，其中一个是之前安装的docker目录下kubectl，而且这个docker的目录优先级在k8s之上，这样在执行kubectl命令时就会优先执行docker中的命令 解决方法将k8s的路径添加到系统变量的path中，并将其启动到docker路径之前 重启命令行，此时查看环境变量中的kubectl就会发现k8s的优先级更高 查看版本就是1.18.0 环境变量优先级详解普通变量针对用户变量和系统变量中重名的变量，用户变量的优先级是大于系统变量的 这里我们在用户变量和系统变量中都定义了一个test变量 随后我们在命令行中打印test变量输出的是用户变量的值 PATH变量windows对于Path变量的处理方式是，将用户变量的Path添加到系统变量Path后面。windows在查找某一指令的时候，是按Path中的路径从前往后找，直至在某个路径中找到了该指令，所以说，如果系统变量Path中有对应指令的话，windows就不会再去用户变量Path中查找。","link":"/2025/03/03/other/%E5%85%B3%E4%BA%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%9A%84%E4%BC%98%E5%85%88%E7%BA%A7%E9%97%AE%E9%A2%98/"},{"title":"分布式锁","text":"点击阅读更多查看文章内容 为什么需要锁？并发场景下的超卖问题：两个goroutine同时进行库存减1的操作，g1查询库存为100，在g1还没有扣减库存的情况下，g2也查询到了库存为100，此时g1扣减库存更新后为99，g2同样更新的值也是99，此时卖出两件商品，但实际的库存只减了1 此时就需要对goroutine加锁，通过在 var m sync.Mutex 全局声明一把互斥锁，在查询库存前通过 m.lock 获取锁，此时其他的goroutine要想获取锁就会阻塞，在更新完数据库后执行 m.unlock 释放锁，此时其他的goroutine可以继续获取锁查询更新数据库。 为什么需要分布式锁？库存服务可能会部署在多台服务器上但是共享同一个数据库，此时一个服务器上的多个goutine使用一把锁，但是不同服务器上的goroutine之间没有锁请求同一个数据库时仍会存在超卖问题。 此时需要在库存服务1和库存服务2之外设置一个第三方的分布式锁，这两个服务首先请求分布式锁，如果库存服务1中的任何一个goroutine拿到了分布式锁，那么库存服务2中的任何一个goroutine就需要等待。 分布式锁的实现方案基于mysql实现悲观锁与乐观锁是人们定义出来的概念，你可以理解为一种思想，是处理并发资源的常用手段。不要把他们与mysql中提供的锁机制(表锁，行锁，排他锁，共享锁)混为一谈。 悲观锁 顾名思义，就是对于数据的处理持悲观态度，总认为会发生并发冲突，获取和修改数据时，别人会修改数据。所以在整个数据处理过程中，需要将数据锁定。（前面的sync.Mutex就是悲观锁） 悲观锁的实现，通常依靠数据库提供的锁机制实现，比如mysql的排他锁，在mysql查询时使用for update可以锁住记录，使用该方法时需要关闭autocommit（set autocommit=0） 首先执行select * from inventory where goods=421 for update ，对记录加锁，随后再执行相同的语句则会一直等待直到锁释放，释放锁只需要执行 commit 即可 注意，当有索引时（goods设置为索引） for update 加的锁是行锁，只会将符合条件的记录（goods=421）锁住，如果在执行select * from inventory where goods=422 for update 针对422的查询那么可以正常查询不会阻塞。 如果没有索引时，行锁会升级为表锁，整个表都会被锁住，针对任何记录的查询都会阻塞 锁只是锁住要更新的语句 select * from inventory where goods=422，普通的select可以正常执行（读写锁） 乐观锁 顾名思义，就是对数据的处理持乐观态度，乐观的认为数据一般情况下不会发生冲突，只有提交数据更新时，才会对数据是否冲突进行检测。如果发现冲突了，则返回错误信息给用户，让用户自已决定如何操作。 乐观锁的实现不依靠数据库提供的锁机制，需要我们自已实现，实现方式一般是记录数据版本，一种是通过版本号，一种是通过时间戳。 给表加一个版本号或时间戳的字段，读取数据时，将版本号一同读出，数据更新时，将版本号加1。当我们提交数据更新时，更新与第一次读取出来的版本号相等的记录。此时如果有另一个goroutine更新了数据库，那么记录的版本号会改变，查询不到最初的记录，就无法更新数据了，此时更新失败需要重新读取最新数据再执行一遍业务逻辑。 乐观锁没有对数据库加锁，并且不会出现数据不一致的问题 基于redis的分布式锁https://github.com/go-redsync/redsync 使用redsync实现 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( goredislib &quot;github.com/redis/go-redis/v9&quot; &quot;github.com/go-redsync/redsync/v4&quot; &quot;github.com/go-redsync/redsync/v4/redis/goredis/v9&quot;)func main() { // Create a pool with go-redis (or redigo) which is the pool redisync will // use while communicating with Redis. This can also be any pool that // implements the `redis.Pool` interface. client := goredislib.NewClient(&amp;goredislib.Options{ Addr: &quot;localhost:6379&quot;, }) pool := goredis.NewPool(client) // or, pool := redigo.NewPool(...) // Create an instance of redisync to be used to obtain a mutual exclusion // lock. rs := redsync.New(pool) // Obtain a new mutex by using the same name for all instances wanting the // same lock. mutexname := &quot;my-global-mutex&quot; mutex := rs.NewMutex(mutexname) // Obtain a lock for our given mutex. After this is successful, no one else // can obtain the same lock (the same mutex name) until we unlock it. if err := mutex.Lock(); err != nil { panic(err) } // Do your work that requires the lock. // Release the lock so other processes or threads can obtain a lock. if ok, err := mutex.Unlock(); !ok || err != nil { panic(&quot;unlock failed&quot;) }} 源码解析 - setnx的作用 使用redis实现锁只需要对要加锁的记录在redis中添加一个记录（例如key为加锁记录id，value为随机数），在操作完成后删除key。如果有其他线程想要操作该记录则先在redis中查询是否有对应的key，如果有则代表正有线程在操作该记录。 但是这里获取和设置值的操作需要满足原子性，如果先获取key再设置value，那么在高并发场景中，可能有线程发现redis没有key之后设置value之前又有其它线程也发现redis没有key，这样多个线程就会同时操作单个资源。 setnx：如果key不存在则设置value，如果key已存在则不会设置 —— 将获取和设置值变成原子性的操作； 过期时间和延长锁过期时间如果线程请求到锁之后服务挂掉了，就无法执行删除key的逻辑，此时其他的线程都在等待key的释放无法执行 设置过期时间 如果你设置了过期时间，那么如果过期时间到了我的业务逻辑没有执行完怎么办？ 在过期之前刷新一下，需要自己去启动协程完成延时的工作 为什么不自动延时？延时的接口可能会带来负面影响 - 如果其中某一个服务hung住了， 2s就能执行完，但是你hung住那么你就会一直去申请延长锁，导致别人永远获取不到锁，这个很要命 延长过期时间，这里的操作是基于lua脚本完成的，保证原子性 如何防止锁被其他的goroutine删除设置的value随机生成 当时设置的value值是多少只有当时的g才能知道 在删除的时取出redis中的值和当前自己保存下来的值对比一下 删除锁： redlockredis的分布式锁在集群环境之下容易出现的问题 在向主redis写入数据后由于宕机或网络故障等原因没有及时同步到从redis，此时其它的服务在从redis上没有查询到锁，会继续业务逻辑的执行，此时两个库存服务就会冲突 redlock向每个redis服务器都加锁这样就避免了同步问题 Redlock 算法概述 Redlock 是在多个独立的 Redis 实例上实现分布式锁的一种方法，适用于需要确保互斥访问共享资源的场景。这个算法的设计目标是，即使在网络分区、Redis 实例宕机或其他故障的情况下，也能保证锁的可靠性。 工作原理 初始化锁的获取：Redlock 假设有 N 个独立的 Redis 实例（一般推荐是 5 个）。客户端向这些实例发送加锁请求。 尝试加锁： 客户端向每个 Redis 实例尝试获取锁，使用一个唯一的随机值（如 UUID）作为锁的值。 每次请求加锁时，会设置一个过期时间（通常是一个合理的时间，例如 10 秒），确保锁在一定时间后自动释放，防止死锁。 加锁成功的条件： 客户端需要在大多数 Redis 实例中成功获取锁。例如，假设有 5 个 Redis 实例，客户端至少需要在 3 个实例上成功获取锁。 如果成功获取锁的 Redis 实例数达到大多数（如 3 个或更多），则客户端认为获取锁成功。 加锁失败： 如果客户端在大多数 Redis 实例上未能成功获取锁，则认为加锁失败，释放所有已获取的锁。 释放锁： 客户端持有锁时，需要定期向所有 Redis 实例发送释放锁的请求。 锁的释放也是通过检查唯一的随机值来进行的，确保不会误释放其他客户端的锁。 什么是时钟漂移 如果redis服务器的机器时钟发生了向前跳跃，就会导致这个key过早超时失效，比如说客户端1拿到锁后，key的过期时间是12:02分，但redis服务器本身的时钟比客户端快了2分钟，导致key在12:00的时候就失效了，这时候，如果客户端1还没有释放锁的话，就可能导致多个客户端同时持有同一把锁的问题。","link":"/2025/03/03/other/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"title":"博客搭建（hexo+github）","text":"简介搭建完成网站的如下所示https://polarday.top/ 使用github托管博客，完全免费不需要购买服务器博客框架：hexohexo主题：ICARUS图床：github+PicGo编辑：vscode 为什么使用hexo框架？因为hexo是静态框架，我们使用github托管博客的页面只能使用静态的框架，不支持像wordpress等需要请求数据库的动态框架，这类框架必须具有自己的服务器 搭建步骤 搭建hexo框架发布到github 更换ICARUS主题 配置vscode的markdown环境 连接图床 搭建hexo框架发布到github先安装node.js和git参考教程hexo官方文档 1.github创建个人仓库点击GitHub中的New repository创建新仓库，仓库名应该为：用户名.github.io这个用户名使用你的GitHub帐号名称代替，这是固定写法，比如我的仓库名为: 2.安装hexoHexo就是我们的个人博客网站的框架， 这里需要自己在电脑常里创建一个文件夹,可以命名为Blog,进入文件夹中,使用npm命令安装Hexo，输入：npm install -g hexo-cli安装完成后，初始化我们的博客，输入：hexo init blog初始化完成后进入blog目录，输入以下三条命令检测网站是否安装成功： 生成一篇文章hexo new test_my_site 生成静态文件hexo generate 启动服务器，默认情况下，访问网址为： http://localhost:4000/hexo server 这里hexo server命令在执行之前不需要执行hexo g生成静态文件，执行该命令默认会从本地文件中启动而不是使用hexo generate生成的静态文件，使用hexo server -s 命令才会使用静态文件启动本地服务器 3.本地静态文件推送到github上面只是在本地预览，接下来要做的就是就是推送网站，可以通过github的域名访问blog目录下的_config.yml是网站的配置信息，包括网站标题等自定义内容可以参考hexo官方文档设置，在本地都调试完成后将其推送到github，在_config.yml的最后有deploy的配置，修改为如下配置，其中repo是你之前创建的仓库的路径 1234deploy: type: git repo: https://github.com/shnpd/shnpd.github.io.git branch: main 执行命令，就可以一键部署，具体命令细节可以参考hexo官方文档hexo cleanhexo ghexo d 然后访问shnpd.github.io就可以看到我们的博客了组成我们网站的文件是blog目录下的public目录，执行clean命令会清楚public目录，执行generate命令会生成public目录，部署命令也是将public目录部署到github上 4.域名绑定（可选）绑定域名是可选的，我们使用shnpd.github.io本身就可以访问博客了，如果有同学想绑定自己的域名可以参考本节 首先需要购买自己的域名，购买的途径有很多，像腾讯云、阿里云都可以，我使用的是腾讯云 在腾讯云控制台域名解析中添加两条记录 登录github之前创建的仓库，settings-pages-custom domain填入自己的域名，点击save保存 进入blog的source目录下新建txt，输入你的域名。如果带有www，那么以后访问的时候必须带有www完整的域名才可以访问，但如果不带有www，以后访问的时候带不带www都可以访问。所以建议不要带有www。保存命名为CNAME，无后缀名。 域名绑定完成，这里因为是基于github搭建的所以不需要对域名进行备案 更换hexo主题hexo的主题有很多，我们这里使用的是icarushexo-theme-icarus官方文档 1.主题安装在blog目录下执行如下命令：npm install -S hexo-theme-icarus hexo-renderer-inferno 在网站配置_config.yml文件中启用icarus主题：theme: icarus或使用hexo命令修改主题为Icarushexo config theme icarus 启动本次服务器测试是否成功：hexo server 2.主题配置icarus的具体主题配置都可以参考官方文档，细节配置可以参考文档自行定义，下面主要介绍几个关键的地方 图片我们在设置网站的logo或其他配置时可能会用到图片，这里图片的路径为/img/xxx.jpg，这是相对路径，相对blog目录的路径为：/node_modules/hexo-theme-icarus/source/img/xxx.jpg About页面about页面在初始化的时候是没有的，需要我们自己创建，创建命令为：hexo new page about 需要执行以下命令重新生成静态文件 12hexo cleanhexo g 创建其他页面时也按照这个步骤，新建的页面在source目录下 写文章新建文章使用hexo new &quot;第一篇文章&quot;命令，就可以在source/_posts目录下创建文章的markdown文件直接编辑即可文章分类和标签的设置参考hexo官方文档Front-matter文章在首页默认会显示全部内容，需要在文章中添加&lt;!– more –&gt;标签。 标签前面的文章内容会被标记为摘要，而其后的内容不会显示在文章列表上。 配置vscode markdown环境（可选 推荐）这里因为我们需要编辑markdown来写文章，这里我们推荐使用vscode，通过vscode打开blog目录，可以方便的查看目录结构，同时也可以直接在vscode中开启终端执行相关命令，使用vscode编写markdown非常方便，具体配置教程有很多，这里主要就是安装几个插件 Markdown All in One （基本语法） Markdown Preview Enhanced（预览） markdownlint（语法检查） 安装完成后就可以直接编写markdown了 配置图床（可选 推荐）我们文章中会存在大量的图片，直接将图片保存在网站的文件中会相当的臃肿，所以我们推荐使用图床将图片保存在其他位置并生成外链，在我们的文章中通过外链来引用图片即可。 可以用来充当图床的服务有很多，包括七牛云、阿里云OSS、腾讯云COS、GitHub等，其中七牛云需要备案域名、阿里云和腾讯云不是完全免费的，我们这里使用的是GitHub，但是GitHub本身存在访问较慢的问题，还是推荐大家使用七牛云、阿里云等。 1.新建github仓库新建github仓库作为图床用来保存我们的图片，仓库名字可以随便起我的名字是blog-pic，仓库需要设置为public 2.下载PicGoPicGo官方文档PicGo是一个用于快速上传图片并获取图片URL链接的工具，如果使用vscode的话可以直接安装PicGo的扩展，安装完成后配置github图床 配置名：随意起仓库名：新建仓库的名称分支名：设置为main即可Token：需要在github中申请；settings——Developer Settings——Personal access tokens——tokens——Generate new token vscode的扩展也是相同的配置方法，这里主要说一下vscode中的使用 复制自动生成链接通过使用Upload image from clipboard就可以从粘贴板上传图片，这里的快捷键我们设置为ctrl+alt+e比较方便，当我们复制了一张图片后，使用该快捷键就可以自动将图片上传并生成链接插入到对应的位置 自定义图片的输出格式这里定义了前一步插入的格式，考虑到通用性我们设置为html的格式，同时添加了width=”50%”默认对每张图片缩放50%","link":"/2024/04/05/other/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%EF%BC%88hexo-github%EF%BC%89/"},{"title":"文献总结","text":"完整性验证完整性验证的本质用户首先对数据进行预处理，保存一些私有验证元数据，然后将文件发送给服务器存储。在验证完整性时用户向服务器发送挑战，服务器根据挑战返回给用户证明，用户验证证明的正确性。验证证明时通常是判断某两个值是否相等，其中一个值是根据服务器返回的证明构造的，另一个值是用户根据私有的验证元信息构造的，这里通常使用的技术有双线性映射、同态验证标签等。 基于密钥哈希的方案不推荐该方案 在存储文件 F 之前，验证者计算并存储哈希值 r = hκ(F) 以及秘密随机密钥 κ。为了检查证明者是否拥有 F，验证者向证明者出示 κ 并要求证明者计算并返回 r。这个简单的协议就提供了证明者知道 F 的有力证明。通过在不同的密钥上存储多个哈希值，验证者可以发起多个独立的检查。 注意：这里使用基于密钥的哈希而不能使用单独的哈希，因为证明者可能只保存文件的哈希而不保存原始文件，使用密钥哈希这样证明者返回的证明值需要根据用户提供的密钥计算，每次都不同，所以必须保存原始文件 缺点：资源成本高，要求验证者存储与其要执行的检查数量成线性关系的多个哈希值。并且每次调用都要求证明者处理整个文件F，对于大的 F ，即使是像散列这样的轻量级计算操作也可能非常繁重。 PDP方案（同态可验证标签） ATENIESE G, BURNS R, CURTMOLA R, 等. Provable data possession at untrusted stores[C/OL] 基于同态可验证标签 同态特性可以将多个标签组合成单个标签，可以实现常量大小且比实际文件小得多的证明 本方案对文件进行分块处理，在验证时会抽样验证文件块的子集，减少通信开销，实验证明验证的成功率也比较高。 PDP方案包括四个算法 KeyGen(1^k^)→(pk,sk)：客户端执行，生成密钥对 TagBlock(pk,sk,m)→Tm：客户端执行，生成验证元数据。m是文件 GenProof(pk,F,chal,Σ)→V：服务器运行，生成所有权证明。F是文件块集合、chal是挑战 、Σ是F中对应块的验证元数据集合。 CheckProof(pk,sk,chal,v)→{“success”,“failure”}：客户端执行，验证所有权证明 具体算法: 个人理解，这里同态特性体现在将多个标签T相乘后得到的黄色部分，随后在计算ρ的时候也得到了对应的部分，这样在验证的时候可以相互抵消。即一次可以验证任意个标签，证明的大小始终是相乘后的结果为一个常量。 这里aj的作用是：由于aj​ 是随机生成的，服务器无法预测哪些 aj​ 将被用于下一个证明。因此，服务器不能只存储数据块的总和或任何其他简化形式的数据表示，因为这样做将无法满足 aj​ 系数的特定组合。 另一种方案是去掉aj：去掉aj可以减少计算量，但是只能保证服务器具有m的总和，而不一定拥有每个文件块 POR方案（随机哨兵） JUELS A, KALISKI B S. Pors: proofs of retrievability for large files[C/OL] 简而言之，我们的 POR 协议对 F 进行加密并随机嵌入一组称为哨兵的随机值校验块。这里使用加密使得哨兵与其他文件块无法区分。验证者通过指定哨兵集合的位置并要求证明者返回相关的哨兵值来挑战证明者。如果证明者修改或删除了 F 的很大一部分，那么它也很有可能删除了一些哨兵。因此它不太可能正确响应验证者。为了防止 F 的一小部分的证明者损坏，我们还使用了纠错码。F ̃表示证明者存储的完整文件 本方案的两种情况： 假设证明者在接收到编码文件F ̃后，破坏了三个随机选择的位：β1、β2、β3。这些位不太可能驻留在哨兵中，哨兵只构成F ̃的一小部分。因此，验证器可能不会通过 POR 执行检测到损坏。然而，由于 F 中存在错误纠正，验证者可以完整地恢复原始文件 F。 相反，假设证明者损坏了 F 中的许多块，例如文件的 20%。在这种情况下（没有非常严重的错误编码），验证者不太可能恢复原始文件 F 。另一方面，验证者在 POR 中请求的每个哨兵将以大约 1/5 的概率检测到损坏。通过请求数百个哨兵，验证者可以以压倒性的概率检测到损坏。 前面提到的PDP方案依赖于文件的模幂运算，属于计算密集型的运算 过程细节： 用户只在本地存储哨兵的值作为验证元数据 密钥生成 文件编码：将文件分成多个块并使用纠错码以恢复原始数据；加密文件，生成随机的哨兵值，并将其嵌入到加密文件的随机位置中。并使用伪随机排列对加密文件的数据块进行重新排列，以隐藏哨兵的位置。 挑战生成：根据预先排列的策略，验证者选择一组哨兵，将该组哨兵的位置作为挑战发送给证明者 证明生成：证明者将该位置上的内容返回给验证者 验证：验证证明者返回的值是否与本地存储的哨兵值相匹配 基于Merkle树的方案 YUE D, LI R, ZHANG Y, 等. Blockchain-based verification framework for data integrity in edge-cloud storage[J/OL] 准备阶段 客户端将数据分成多个分片，并使用这些分片构建哈希 Merkle 树。 客户端将该哈希树的根存储在区块链上，表示为root1。 客户端将其数据和公共 Merkle 树上传到 ECS 验证阶段 客户端向ECS节点发送挑战数si，ECS节点选择分片i进行验证。 ECS根据si和分片i，使用哈希函数计算哈希摘要i‘。（si+i -&gt; i’） ECS将摘要i’和相应的辅助信息发送给BC。 区块链上的智能合约计算一个新的哈希根，记为root2，并将root1与root2进行比较。如果相等，则保证数据完整性；否则，数据完整性将被破坏。 BC将验证结果返回给客户端。 Merkle树的结构： Merkle树分为公共和私有两部分，私有部分的底层由分片和挑战数组成。私有部分的第二层包含摘要，Digesti=H(si+shardi)。公共部分的Leafmn是第m层的第n个节点，树的根记为R。 Merkle树的公共部分需要上传到ECS节点，以协助验证每个数据分片。私有部分的数据分片shardi也会上传到ECS节点。至于随机挑战数si，只有当客户端需要验证相应的数据分片时才可以发送给ECS节点。因此，si是由客户端保存在本地的。 辅助信息：假设原始数据分为12个分片，分支数为4，创建如下merkle 树，假设验证shard0，我们需要D1,D2,D3,D13,D14，这些就是验证shard0需要的辅助信息。 TODO:如何保证区块链收到的摘要和辅助信息就是对应的客户端发送的挑战的文件块呢？这里感觉客户端在发送挑战的时候应该将文件块摘要发给区块链，然后由区块链根据辅助信息验证（也不行那样的话ECS可以只保存摘要而不保存原始数据，ECS仍需发送摘要，ECS发送摘要可以证明它保存了原始数据，因为s是客户端私有的，只有ECS收到了s后才能结合本地保存的原始数据计算摘要，但是这只能使用一次，因为下一次ECS就可以只保存摘要而不保存原始数据，这在该场景下不可行，但是在我们跨链的场景下应该是可行的，因为我们只需要在接收数据时验证一次正确性即可。）（区块链需要能够验证数据摘要确实是用户发起挑战对应的数据，用户同步将挑战发给区块链，区块链进行比对！但是用户没有原始数据！用户只有随机数s）","link":"/2024/05/17/other/%E6%96%87%E7%8C%AE%E6%80%BB%E7%BB%93/"},{"title":"拜占庭将军问题（实用拜占庭容错）","text":"拜占庭将军问题是一个分布式系统中的协议问题，描述了当部分参与者（如将军）可能是恶意或叛徒时，如何保证所有参与者达成一致决策。此问题由莱斯利·兰伯特提出，是点对点通信中的基本问题，用于模拟在存在消息丢失的不可靠信道上通过消息传递达成一致性的困难。拜占庭将军问题提供了一个模型，反映了在硬件错误、网络阻塞或恶意攻击下，计算机和网络可能表现出不可预测的行为。拜占庭容错算法（BFT）旨在解决这类问题，确保在节点出错或行为恶意时，系统仍能正常运作。这种容错性表现在即使部分节点出现问题，系统也能继续执行大多数节点的共同决定。拜占庭容错机制是区块链、分布式系统等领域的重要组成部分，它确保了系统的安全性和活性。拜占庭容错算法通常要求系统中节点数量和身份预先确定，并需要在每次节点变化时对网络进行初始化。因此，它们不适用于像工作量证明（PoW）这样的开放网络。然而，基于BFT的权益证明（PoS）共识算法是一个例外，它结合了BFT和公有链的特性。 拜占庭将军问题Lamport在其论文中描述了如下问题：一组拜占庭将军分别各率领一支军队共同围困一座城市。为了简化问题，将各支军队的行动策略限定为进攻或撤离两种。因为部分军队进攻部分军队撤离可能会造成灾难性后果，因此各位将军必须通过投票来达成一致策略，即所有军队一起进攻或所有军队一起撤离。将军之间通过信使互相联系。在投票过程中每位将军都将自己投票给进攻还是撤退的信息通过信使分别通知其他所有将军，这样每位将军根据自己收到的投票结果选择多数票进行进攻或撤退。 二忠一叛难题假设有三位拜占庭将军，分别为 A、B、C。三位将军要决定的只有一件事情：「明天是进攻还是撤退」。为此将军们需要依据「少数服从多数」的原则投票表决，只要两个人意见达成一致就可以了。举例一个投票情况：A、B 投票进攻，C 投票撤退。 那么 A 的信使传递给 B 和 C 的消息都是进攻。 B 的信使传递给 A 和 C 的消息都是进攻。 C 信使传递给 A 和 B 的消息都是撤退。 如此一来，三位将军就都知道进攻方和撤退方二者的占比是 2:1 了。显而易见，按照少数服从多数原则，C 也会进攻，最终三位将军同时进攻，战争获得胜利。 叛徒的目标是破坏忠诚将军们之间的一致性达成，让拜占庭军队收到损失。譬如将军 A 向将军 B、C 分别发送撤退的消息，将军 B 向将军 A、C 分别发送进攻的消息。如果将军 C 是叛徒，那么我们思考 C 该做什么才能让两位忠诚的将军做出相反的决定？ 目前看来 撤退：进攻 = 1：1，无论 C 投哪一方，都会变成 2:1，这时候还是会形成一个一致性的作战方案。可是，作为叛徒，将军 C 肯定不会按常理出牌，于是将军 C 让信使告诉将军 A 要进攻，让另一个信使告诉将军 B 要撤退。至此： 将军 A 看到的投票结果是 进攻方：撤退方 = 2:1 将军 B 看到的投票结果是 进攻方：撤退方 = 1:2 按照少数服从多数的原则，忠诚的将军 A 单独冲向战场，结果当然是将军 A 寡不敌众，败给了敌人。截止目前，我们是否发现：明明大多数将军都是忠诚的（2/3），却被少数的叛徒（1/3）耍得团团转？实质上，拜占庭将军问题恰恰在此：一致性的达成过程中，叛徒将军（恶意节点）甚至不需要超过半数，就可以破坏占据多数正常节点一致性的达成，这也是我们常说的二忠一叛难题。 Lamport 在论文中也给出了一个更加普适的结论：如果存在 m 个叛将，那么至少需要 3m+1个 将军，才能最终达到一致的行动方案 解决方案口信消息型解决方案首先，对于口信消息（Oral message）的定义如下： 任何已经发送的消息都将被正确传达。 消息的接收者知道是谁发送了消息。 消息的缺席可以被检测。 基于口信消息的定义，我们可以知道，口信消息不能被篡改但是可以被伪造。在口信消息型解决方案中，首先发送消息的将军称为指挥官，其余将军称为副官。对于 3 忠 1 叛的场景需要进行两轮作战信息协商，如果没有收到作战信息那么默认撤退。 第一轮 指挥官向 3 位副官发送了进攻的消息。 第二轮 三位副官再次进行作战信息协商，由于将军 A、B 为忠将，因此他们根据指挥官的消息向另外两位副官发送了进攻的消息，而将军 C 为叛将，为了扰乱作战计划，他向另外两位副官发送了撤退的消息。最终指挥官、将军 A 和 B 达成了一致的进攻计划，可以取得胜利。 指挥官为叛将的场景 在第一轮作战信息协商中，指挥官向将军 A、B 发送了撤退的消息，但是为了扰乱将军 C 的决定向其发送了进攻的消息。 在第二轮中，由于所有副官均为忠将，因此都将来自指挥官的消息正确地发送给其余两位副官。最终所有忠将都能达成一致撤退的计划。 这个解决方法，其实就是 Lamport 在论文中提到的口信消息型拜占庭将军问题之解（A Solution with Oral Message）：如果叛将人数为 m，将军人数不少于 3m+1，那么最终能达成一致的行动计划。值的注意的是，在这个算法中，叛将人数 m 是已知的，且叛将人数 m 决定了递归的次数，即叛将数 m 决定了进行作战信息协商的轮数，如果存在 m 个叛将，则需要进行 m+1 轮作战信息协商。这也是上述存在 1 个叛将时需要进行两轮作战信息协商的原因。 假设有n个节点其中有f个恶意节点，在此场景下达成一致的前提是n&gt;3f证明：一共n个节点，其中f个恶意节点，n-f个正常节点，节点必须在收到n-f个消息后做出决定（因为f个恶意节点可能全都选择不回复）节点收到的n-f个消息中可能有f个是假的，也就是说有n-f-f个真的，要想达成一致需要真实的消息大于虚假的消息，因此得出n-2f&gt;f n&gt;3f 实用拜占庭容错PBFT","link":"/2024/06/24/other/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98%EF%BC%88%E5%AE%9E%E7%94%A8%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%AE%B9%E9%94%99%EF%BC%89/"},{"title":"限制访问外网的基本原理","text":"点击阅读更多查看文章内容 本文转载自：文章来源目前在国内基本访问不了google站点和android的站点，下载个gradle都要等很久。所以如果不翻墙很多工作都没办法正常做。所以在学习翻墙的同时也顺便了解了下目前限制网络访问的一些基本知识。 网络限制和监控应该说大家都有体会。比如很多公司都会限制一些网站的访问，比如网盘、视屏网站。有时也会对你访问的内容进行监控。还有一些公共WIFI，可能限制你只能访问80端口。在比如在国内无法访问google，facebook，android等网站。要想绕过这些限制，必须先知道他们是如何限制的。 本文主要是从技术角度来了解的网络限制方式和应对方式。并不做任何翻墙方式的推荐和指导。对于网络的知识，还是停留在上过网络课 的水平，文章内容也都是自己了解后总结的。可能会有错误和遗漏。会定期更新。 DNS污染和劫持以下解释来自百度百科：某些网络运营商为了某些目的，对DNS进行了某些操作，导致使用ISP的正常上网设置无法通过域名取得正确的IP地址。某些国家或地区出于某些目的为了防止某网站被访问，而且其又掌握部分国际DNS根目录服务器或镜像，也会利用此方法进行屏蔽。 目前我们访问网站主要都是通过域名进行访问，而真正访问这个网站前需要通过DNS服务器把域名解析为IP地址。而普通的DNS服务使用UDP协议，没有任何的认证机制。DNS劫持是指返回给你一个伪造页面的IP地址，DNS污染是返回给你一个不存在的页面的IP地址。 比如你使用电信、联通、移动的宽带，默认你是不需要设置任何DNS服务器的。这些DNS服务器由他们提供。一旦检测到你访问的网页是不允许的访问的，就会返回一个不存在的网页。而很多运营商也会使用DNS劫持来投放一些广告。 解决办法： 使用OpenDNS（208.67.222.222）或GoogleDNS（8.8.8.8）（现在不太好用，被封锁，速度慢） 使用一些第三方的DNS服务器 自己用VPS搭建DNS服务器 修改机器host文件，直接IP访问 封锁IP通过上面一些方式，可以绕过DNS污染，通过IP地址访问无法访问的网页。但是目前针对IP进行大范围的封锁。虽然google这种大公司有很多镜像IP地址，但是目前基本全部被封锁掉，有漏网的可能也坚持不了多久。而且很多小公司的服务是部署在一些第三方的主机上，所以封锁IP有时会误伤，封锁一个IP导致主机上本来可以使用的页面也无法访问了。 不过目前不可能把所有国外的IP全部封锁掉，所以我们采用机会从国内连接到国外的VPS，进行翻墙。 解决办法： 使用VPS搭建代理 使用IPV6 （IPV6地址巨大，采用封地址不现实，但是目前国内只有部分高校部署了IPV6） 封锁HTTP代理对于没有办法搭建VPS的人来说，最好的办法就是使用HTTP代理。客户端不在直接请求目标服务器，而是请求代理服务器，代理服务器在去请求目标服务器。然后返回结果。对于HTTP代理来说，封锁起来非常简单。因为HTTP协议是明文，Request Message中就带有要请求的URL或IP地址，这样很容易就被检测到。对于HTTPS来说，虽然通信是进行加密了，但是在建连之前会给代理服务器发送CONNECT方法，这里也会带上要访问的远端服务器地址。如果代理服务器在国外，在出去前就会被检测到。 如果代理服务器在国内，呵呵，你也出不去啊。 对于HTTP代理，因为是明文，所以很容易被服务器了解你的一些数据。所以不要随便使用第三方的HTTP代理访问HTTP网站，而HTTPS虽然不知道你的数据，但是可以知道你去了那里。 解决办法： 使用VPS搭建VPN 使用第三方VPN 封锁VPN虚拟专用网（英语：Virtual Private Network，简称VPN），是一种常用于连接中、大型企业或团体与团体间的私人网络的通讯方法。虚拟私人网络的讯息透过公用的网络架构（例如：互联网）来传送内联网的网络讯息。它利用已加密的通道协议（Tunneling Protocol）来达到保密、发送端认证、消息准确性等私人消息安全效果。正常网络通信时，所有网络请求都是通过我们的物理网卡直接发送出去。而VPN是客户端使用相应的VPN协议先与VPN服务器进行通信，成功连接后就在操作系统内建立一个虚拟网卡，一般来说默认PC上所有网络通信都从这虚拟网卡上进出，经过VPN服务器中转之后再到达目的地。通常VPN协议都会对数据流进行强加密处理，从而使得第三方无法知道数据内容，这样就实现了翻墙。翻墙时VPN服务器知道你干的所有事情（HTTP，对于HTTPS，它知道你去了哪)。 VPN有多种协议：OPENVPN、PPTP、L2TP/IPSec、SSLVPN、IKEv2 VPN，Cisco VPN等。其中的PPTP和L2TP是明文传输协议。只负责传输，不负责加密。分别利用了MPPE和IPSec进行加密。 对于VPN和其他一些加密的传输的协议来说，没有办法直接获取明文的请求信息，所以没有办法直接封锁，而是使用了监控的方式： 暴力破解对于一些使用弱加密方式的协议来说，直接使用暴力破解检查传输内容。比如PPTP使用MPPE加密，但是MPPE是基于RC4，对于强大的防火墙背后的超级计算机集群，破解就是几秒钟的事情。 破解后明文中一旦包含了违禁内容，请求就会被封。而对应的IP可能会进入重点关怀列表。 特征检测要想成功翻墙都必须与对应的远程服务器建立连接，然后再用对应的协议进行数据处理并传输。而问题就出在这里：翻墙工具和远程服务器建立连接时，如果表现的很独特，在一大堆流量里很显眼，就会轻易被GFW识别出从而直接阻断连接，而VPN（尤其是OPENVPN）和SSH这方面的问题尤其严重。 流量监控当一个VPN地址被大量人请求，并保持长时间连接时，就很容易引起关注。SSH接口有大量数据请求。一般会结合其他特征。 深度包检测深度数据包检测（英语：Deep packet inspection，缩写为 DPI），又称完全数据包探测（complete packet inspection）或信息萃取（Information eXtraction，IX），是一种电脑网络数据包过滤技术，用来检查通过检测点之数据包的数据部分（亦可能包含其标头），以搜索不匹配规范之协议、病毒、垃圾邮件、入侵，或以预定之准则来决定数据包是否可通过或需被路由至其他不同目的地，亦或是为了收集统计数据之目的。 比如我们用HTTPS来访问一个网站，TLS/SSL协议在建连过程如下：很明显的会发送“client hello”和“server hello” 这种特诊很明显的信息。（当然不会根据这个就封掉，否则https没法用了）。而后续会有服务端证书发送，验证，客户端密钥协商等过程。有明显的协议特征。 下面是网上找的两张图：提醒大家最好不要随便用不安全的VPN来访问不合适的网页，开开android没啥问题。 Socks代理Socks代理/SSH SocksSOCKS是一种网络传输协议，主要用于客户端与外网服务器之间通讯的中间传递。SOCKS是”SOCKetS”的缩写。当防火墙后的客户端要访问外部的服务器时，就跟SOCKS代理服务器连接。这个代理服务器控制客户端访问外网的资格，允许的话，就将客户端的请求发往外部的服务器。这个协议最初由David Koblas开发，而后由NEC的Ying-Da Lee将其扩展到版本4。最新协议是版本5，与前一版本相比，增加支持UDP、验证，以及IPv6。根据OSI模型，SOCKS是会话层的协议，位于表示层与传输层之间 与HTTP代理的对比SOCKS工作在比HTTP代理更低的层次：SOCKS使用握手协议来通知代理软件其客户端试图进行的连接SOCKS，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头（例如，使用另一种底层协议，例如FTP；然而，HTTP代理只是将HTTP请求转发到所需的HTTP服务器）。虽然HTTP代理有不同的使用模式，CONNECT方法允许转发TCP连接；然而，SOCKS代理还可以转发UDP流量和反向代理，而HTTP代理不能。HTTP代理通常更了解HTTP协议，执行更高层次的过滤（虽然通常只用于GET和POST方法，而不用于CONNECT方法） Socks代理本身协议是明文传输，虽然相对HTTP有一些优势，但是明文也导致Socks代理很容易被封。所以可以考虑对Socks进行加密。所以出现了SSH Socks，对于MAC和Linux来说，不需要Client就可以进行访问。详细可以看：SSH隧道技术简介：端口转发&amp;SOCKS代理 但是网上看有些地区好像会对一些VPS的SSH进行端口干扰。我在武汉好像SSH到我的VPS一会就会断。在上海一直没这问题。而且SSH一般是小流量数据，如果数据量特别大，也会被认为是翻墙，进入特别关怀列表。 Shadowsocks认准官网：https://shadowsocks.org/en/index.html （.com那个是卖账号的） 12A secure socks5 proxy,designed to protect your Internet traffic. Shadowsocks 目前不容易被封杀主要是因为： 建立在socks5协议之上，socks5是运用很广泛的协议，所以没办法直接封杀socks5协议 使用socks5协议建立连接，而没有使用VPN中的服务端身份验证和密钥协商过程。而是在服务端和客户端直接写死密钥和加密算法。所以防火墙很难找到明显的特征，因为这就是个普通的socks5协议。 Shadowsock搭建也比较简单，所以很多人自己架设VPS搭建，个人使用流量也很小，没法通过流量监控方式封杀。 自定义加密方式和密钥。因为加密主要主要是防止被检测，所以要选择安全系数高的加密方式。之前RC4会很容易被破解，而导致被封杀。所以现在推荐使用AES加密。而在客户端和服务端自定义密钥，泄露的风险相对较小。 所以如果是自己搭建的Shadosocks被封的概率很小，但是如果是第三方的Shadeowsocks，密码是server定的，你的数据很可能遭受到中间人攻击。顺便说一下，Shadowssocks是天朝的clowwindy大神写的。不过Shadowsocks项目源码已经从github上删除了并停止维护了，但是release中还有源码可以下载。https://github.com/shadowsocks/shadowsocks Shadowsocks-rss前面认为Shadowssocks特征并不是很明细，但是了解协议工作原理后会发现，SS协议本身还有有漏洞，可以被利用来检测特征，具体讨论看：ShadowSocks协议的弱点分析和改进。 里面中间那些撕逼就不用看了，我总结了下大致意思是：协议过于简单，并且格式固定，很容易被发起中间人攻击。先看看协议结构 12345+--------------+---------------------+------------------+----------+| Address Type | Destination Address | Destination Port | Data |+--------------+---------------------+------------------+----------+| 1 | Variable | 2 | Variable |+--------------+---------------------+------------------+----------+ Possible values of address type are 1 (IPv4), 4 (IPv6), 3 (hostname). For IPv4 address, it’s packed as a 32-bit (4-byte) big-endian integer. For IPv6 address, a compact representation (16-byte array) is used. For hostname, the first byte of destination address indicates the length, which limits the length of hostname to 255. The destination port is also a big-endian integer. The request is encrypted using the specified cipher with a random IV and the pre-shared key, it then becomes so-called payload. 结构很简单，上面解释也很清楚。Client每一个请求都是这种格式，然后进行加密。Server端解密然后解析。看起来没什么问题，没有密钥你无法模拟中间人攻击，也没什么明显特征。但是看看Server处理逻辑会发现存在一些问题： Client数据在加密目前用的最多的是AES系列，加密后在协议数据前会有16位的IV。而Server段解析后，首先判断请求是否有效，而这个判断很简单： 判断的依据就是Address Type的那个字节，看它是不是在那三个可能取值，如果不是，立即断开连接，如果是，就尝试解析后面的地址和端口进行连接。 如果能发起中间人攻击，模拟Client请求，这个就是一个很明显的特征，如果把Address Type穷举各种情况，其中只有3种情况会连接成功。那么很可能就是一个Shadowsocks 服务器。 所以只需要先劫持一条socks5的请求，因为AES加密后Address Type位置是固定的（第17位），篡改这一位，穷举256种情况（AES-256），然后发送给服务器。如果服务器在3种情况没有关闭连接，就说明这个很可能是Shadowsock服务。你这个IP很快就进入关怀列表了。 这里的关键就是AES加密明文和密文对应关系。密码学不是太懂，贴帖子里面一个回复： 1234567891011121314151617举个例子，现在有一个协议包，共7个字节0x01, 0x08, 0x08, 0x08, 0x08, 0x00, 0x50对照socks5协议，很明显这是一个IPv4包(第一个字节是0x01)，目的地是8.8.8.8的80端口被shadowsocks加密了以后（密码abc，加密方式aes-256-cfb），数据包就变成了这样0xbb, 0x59, 0x1c, 0x4a, 0xb9, 0x0a, 0x91, 0xdc, 0x07, 0xef, 0x72, 0x05, 0x90, 0x42, 0xca, 0x0d, 0x4c, 0x3b, 0x87, 0x8e, 0xca, 0xab, 0x32前16个字节，从0xbb到0x0d，都是iv，根据issue中提到的弱点和之前的总结，只需要修改0x4c，即真正密文中的第一个字节，就可要起到修改明文中的第一个字节的效果。那就把0x4c修改成0x4d吧，解密以后的结果是0x00, 0x08, 0x08, 0x08, 0x08, 0x00, 0x50的确只有第一个字节被改掉了，根据breakwa11的理论，不难推出其他情况，其中合法的是0x4e =&gt; 0x03 (Domain Name)0x49 =&gt; 0x04 (IPv6) 所以目前Shadowsocks应该是比较容易被检测出来。但是为什么没有被封掉，呵呵，就不知道了。所以这个项目目的就是在SS基础上进行一些混淆。因为原有实现确实有漏洞。 不过目前这个项目好像也停止更新了。并且木有开源。 当然如果是自己用完全可以自己修改一个私有协议，这样就没法被检测到了。但是需要同时修改Server段，MAC Client，Windows Client， Android Client。 – -！ GoAgent和GoProxyGoogle App Engine是一个开发、托管网络应用程序的平台，使用Google管理的数据中心 GoAgent的运行原理与其他代理工具基本相同，使用特定的中转服务器完成数据传输。它使用Google App Engine的服务器作为中传，将数据包后发送至Google服务器，再由Google服务器转发至目的服务器，接收数据时方法也类似。由于服务器端软件基本相同，该中转服务器既可以是用户自行架设的服务器，也可以是由其他人架设的开放服务器。 GoAgent其实也是利用GAE作为代理，但是因为他是连接到google的服务器，因为在国内现在google大量被封，所以GoAgent也基本很难使用。目前github上源码也已经删除。 但是GoAgent本身不依赖于GAE，而且使用Python编写，完全可以部署到VPS上进行代理。GoProxy是GoAgent的后续项目 https://github.com/phuslu/goproxy还有一个XX-NET：https://github.com/XX-net/XX-Net 有兴趣都可以去了解下。 TorTor（The Onion Router，洋葱路由器）是实现匿名通信的自由软件。Tor是第二代洋葱路由的一种实现，用户通过Tor可以在因特网上进行匿名交流。 Tor:Overview The Tor network is a group of volunteer-operated servers that allows people to improve their privacy and security on the Internet. Tor’s users employ this network by connecting through a series of virtual tunnels rather than making a direct connection, thus allowing both organizations and individuals to share information over public networks without compromising their privacy. Along the same line, Tor is an effective censorship circumvention tool, allowing its users to reach otherwise blocked destinations or content. Tor can also be used as a building block for software developers to create new communication tools with built-in privacy features. 而关于Tor的漏洞和检测看这里：Tor真的十分安全么其原理以及漏洞详解目前有结合Tor+Shadowsocks前置代理使用的。","link":"/2025/03/03/other/%E9%99%90%E5%88%B6%E8%AE%BF%E9%97%AE%E5%A4%96%E7%BD%91%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"},{"title":"1、硬件结构","text":"点击阅读更多查看文章内容 CPU是如何执行程序的？冯诺依曼模型冯诺依曼模型：运算器、控制器、存储器、输入设备、输出设备 运算器、控制器是在中央处理器里的，存储器就是我们常见的内存，输入输出设备则是计算机外接的设备。 存储单元和输入/输出设备要与中央处理器打交道就需要总线。 内存 我们的程序和数据都是存储在内存，存储的区域是线性的。 在计算机数据存储中，存储数据的基本单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。 内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1，这种结构好似我们程序里的数组，所以内存的读写任何一个数据的速度都是一样的。 中央处理器中央处理器也就是我们常说的 CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据： 32 位 CPU 一次可以计算 4 个字节； 64 位 CPU 一次可以计算 8 个字节； 这里的 32 位和 64 位，通常称为 CPU 的位宽，代表的是 CPU 一次可以计算（运算）的数据量。 之所以 CPU 要这样设计，是为了能计算更大的数值，如果是 8 位的 CPU，那么一次只能计算 1 个字节 0~255 范围内的数值，这样就无法一次完成计算 10000 * 500 ，于是为了能一次计算大数的运算，CPU 需要支持多个 byte 一起计算，所以 CPU 位宽越大，可以计算的数值就越大，比如说 32 位 CPU 能计算的最大整数是 4294967295。 CPU 内部还有一些组件，常见的有寄存器、控制单元和逻辑运算单元等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而寄存器可以分为多种类，每种寄存器的功能又不尽相同。 CPU 中的寄存器主要作用是存储计算时的数据，你可能好奇为什么有了内存还需要寄存器？原因很简单，因为内存离 CPU 太远了，而寄存器就在 CPU 里，还紧挨着控制单元和逻辑运算单元，自然计算时速度会很快 常见的寄存器种类： 通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。 程序计数器，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。 指令寄存器，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里 总线总线是用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种： 地址总线，用于指定 CPU 将要操作的内存地址； 数据总线，用于读写内存的数据； 控制总线，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线； 当 CPU 要读写内存数据的时候，一般需要通过下面这三个总线： 首先要通过「地址总线」来指定内存的地址； 然后通过「控制总线」控制是读或写命令； 最后通过「数据总线」来传输数据； 输入、输出设备输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。期间，如果输入设备是键盘，按下按键时是需要和 CPU 进行交互的，这时就需要用到控制总线了。 程序执行的基本过程 第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。 第二步，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4； 第三步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行； 简单总结一下就是，一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。 CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 CPU 的指令周期 存储器存储器的级别： 如何写出让CPU跑的更快的代码提高cpu缓存的命中率： 假设要遍历二维数组，有以下两种形式，虽然代码执行结果是一样，但你觉得哪种形式效率最高呢？为什么高呢？ 经过测试，形式一 array[i][j] 执行时间比形式二 array[j][i] 快好几倍。 之所以有这么大的差距，是因为二维数组 array 所占用的内存是连续的，比如长度 N 的值是 2 的话，那么内存中的数组元素的布局顺序是这样的： 形式一用 array[i][j] 访问数组元素的顺序，正是和内存中数组元素存放的顺序一致。当 CPU 访问 array[0][0] 时，由于该数据不在 Cache 中，于是会「顺序」把跟随其后的 3 个元素从内存中加载到 CPU Cache，这样当 CPU 访问后面的 3 个数组元素时，就能在 CPU Cache 中成功地找到数据，这意味着缓存命中率很高，缓存命中的数据不需要访问内存，这便大大提高了代码的性能 而如果用形式二的 array[j][i] 来访问，则访问的顺序就是： 你可以看到，访问的方式跳跃式的，而不是顺序的，那么如果 N 的数值很大，那么操作 array[j][i] 时，是没办法把 array[j+1][i] 也读入到 CPU Cache 中的，既然 array[j+1][i] 没有读取到 CPU Cache，那么就需要从内存读取该数据元素了。很明显，这种不连续性、跳跃式访问数据元素的方式，可能不能充分利用到了 CPU Cache 的特性，从而代码的性能不高。 那访问 array[0][0] 元素时，CPU 具体会一次从内存中加载多少元素到 CPU Cache 呢？这个问题，在前面我们也提到过，这跟 CPU Cache Line 有关，它表示 CPU Cache 一次性能加载数据的大小，可以在 Linux 里通过 coherency_line_size 配置查看 它的大小，通常是 64 个字节 也就是说，当 CPU 访问内存数据时，如果数据不在 CPU Cache 中，则会一次性会连续加载 64 字节大小的数据到 CPU Cache，那么当访问 array[0][0] 时，由于该元素不足 64 字节，于是就会往后顺序读取 array[0][0]~array[0][15] 到 CPU Cache 中。顺序访问的 array[i][j] 因为利用了这一特点，所以就会比跳跃式访问的 array[j][i] 要快。 因此，遇到这种遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处，这样我们代码的性能就会得到很大的提升 CPU缓存一致性那么如果数据写入 Cache 之后，内存与 Cache 相对应的数据将会不同，这种情况下 Cache 和内存数据都不一致了，于是我们肯定是要把 Cache 中的数据同步到内存里的。 问题来了，那在什么时机才把 Cache 中的数据写回到内存呢？ 为了应对这个问题，下面介绍两种针对写入数据的方法： 写直达（Write Through） 写回（Write Back） 写直达保持内存与 Cache 一致性最简单的方式是，把数据同时写入内存和 Cache 中，这种方法称为写直达（Write Through） 缺点：无论数据在不在 Cache 里面，每次写操作都会写回到内存，这样写操作将会花费大量的时间，无疑性能会受到很大的影响 写回当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率，这样便可以提高系统的性能。 如果当发生写操作时，数据已经在 CPU Cache 里的话，则把数据更新到 CPU Cache 里，同时标记 CPU Cache 里的这个 Cache Block 为脏（Dirty）的，这个脏的标记代表这个时候，我们 CPU Cache 里面的这个 Cache Block 的数据和内存是不一致的，这种情况是不用把数据写到内存里的； 如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的： 如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里（注意，这一步不是没用的，具体为什么要这一步，可以看这个「回答 (opens new window)」），然后再把当前要写入的数据写入到 Cache Block，最后也把它标记为脏的； 如果不是脏的话，把当前要写入的数据先从内存读入到 Cache Block 里，接着将数据写入到这个 Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。 多核缓存一致性问题当今 CPU 都是多核的，每个核心都有各自独立的 L1/L2 Cache，只有 L3 Cache 是多个核心之间共享的。所以，我们要确保多核缓存是一致性的，否则会出现错误的结果。 要想实现缓存一致性，关键是要满足 2 点： 第一点是写传播，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心； 第二点是事务的串行化，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的； （加锁） 基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。 MESI 协议，是已修改、独占、共享、已失效这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心 什么是软中断在计算机中，中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程转去处理更高优先级的任务，然后调用内核中的中断处理程序来响应请求。 中断是一种异步的事件处理机制，可以提高系统的并发处理能力。 操作系统收到了中断请求，会打断其他进程的运行，所以中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。 而且，中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说中断有可能会丢失，所以中断处理程序要短且快。 Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。 上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。 下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。 网卡收到网络包后，通过 DMA 方式将接收到的数据写入内存，接着会通过硬件中断通知内核有新的数据到了，于是内核就会调用对应的中断处理程序来处理该事件，这个事件的处理也是会分成上半部和下半部。 上部分要做的事情很少，会先禁止网卡中断，避免频繁硬中断，而降低内核的工作效率。接着，内核会触发一个软中断，把一些处理比较耗时且复杂的事情，交给「软中断处理程序」去做，也就是中断的下半部，其主要是需要从内存中找到网络数据，再按照网络协议栈，对网络数据进行逐层解析和处理，最后把数据送给应用程序。 所以，中断处理程序的上部分和下半部可以理解为： 上半部直接处理硬件请求，也就是硬中断，主要是负责耗时短的工作，特点是快速执行； 下半部是由内核触发，也就说软中断，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行； 为什么0.1+0.2 不等于 0.3为什么负数要用补码表示？ 使用原码存在的问题：需要特殊处理判断数字是否为负，如果是负数就要把加法变为减法才能得到正确结果 负数之所以用补码的方式来表示，主要是为了统一和正数的加减法操作一样，毕竟数字的加减法是很常用的一个操作，就不要搞特殊化，尽量以统一的方式来运算。 十进制小数怎么转成二进制？ 十进制整数转二进制使用的是「除 2 取余法」，十进制小数使用的是「乘 2 取整法」。 计算机是怎么存小数的？ 计算机是以浮点数的形式存储小数的，大多数计算机都是 IEEE 754 标准定义的浮点数格式，包含三个部分： 符号位：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数； 指数位：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大； 尾数位：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度； 用 32 位来表示的浮点数，则称为单精度浮点数，也就是我们编程语言中的 float 变量，而用 64 位来表示的浮点数，称为双精度浮点数，也就是 double 变量。 0.1 + 0.2 == 0.3 吗？ 不是的，0.1 和 0.2 这两个数字用二进制表达会是一个一直循环的二进制数，比如 0.1 的二进制表示为 0.0 0011 0011 0011… （0011 无限循环)，对于计算机而言，0.1 无法精确表达，这是浮点数计算造成精度损失的根源。 因此，IEEE 754 标准定义的浮点数只能根据精度舍入，然后用「近似值」来表示该二进制，那么意味着计算机存放的小数可能不是一个真实值。 0.1 + 0.2 并不等于完整的 0.3，这主要是因为这两个小数无法用「完整」的二进制来表示，只能根据精度舍入，所以计算机里只能采用近似数的方式来保存，那两个近似数相加，得到的必然也是一个近似数。 为什么8位有符号数的取值范围是-128 ~127为什么8位有符号数的取值范围是-128 ~127-CSDN博客 8位有符号数的取值范围下限为什么是-128？ - 知乎 第一位为符号位，正数为0，负数为1，负数使用补码表示（负数的补码 = 其绝对值的二进制表示按位取反 + 1。**） 正数最大值：0111 1111 即127 最小值是：1111 1111吗？，计算机存储的是补码，1111 1111的补码为 1000 0001，可以发现这个补码还能再减1，最终得到补码1000 0000表示-128；同时可以检验-128的补码为 1000 0000（绝对值的二进制）-&gt; 0111 1111（按位取反）-&gt; 1000 0000 (加一) 负数最小值：1000 0000 为-128（可以认为是-0） 内核什么是内核呢？ 计算机是由各种外部硬件设备组成的，比如内存、cpu、硬盘等，如果每个应用都要和这些硬件设备对接通信协议，那这样太累了，所以这个中间人就由内核来负责，让内核作为应用连接硬件设备的桥梁，应用程序只需关心与内核交互，不用关心硬件的细节。 内核有哪些能力呢？ 现代操作系统，内核一般会提供 4 个基本能力： 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。 内核是怎么工作的？ 内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件，而应用程序具有的权限很小，因此大多数操作系统，把内存分成了两个区域： 内核空间，这个内存空间只有内核程序可以访问； 用户空间，这个内存空间专门给应用程序使用； 用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。因此，当程序使用用户空间时，我们常说该程序在用户态执行，而当程序使内核空间时，程序则在内核态执行。 应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程： 内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。 宏内核 vs 微内核宏内核是一种将所有核心功能集成在一个内核空间运行的操作系统架构。所有操作系统核心组件（如进程管理、内存管理、文件系统、设备驱动等）都运行在内核模式，并共享同一个地址空间。 特点 高性能：所有服务运行在内核态，调用开销低。 紧密集成：所有功能紧密耦合，代码量大。 稳定性较差：一个模块崩溃可能导致整个系统崩溃。 扩展性差：修改或增加功能需要重新编译整个内核。 代表操作系统 Linux Windows（混合内核，但接近宏内核） Unix（早期版本） BSD 系 微内核是一种将操作系统的核心功能精简到最小，仅保留基本功能（如进程管理、内存管理、IPC），而将文件系统、设备驱动、网络协议等非核心功能移到用户空间，通过消息传递（IPC）进行通信。 特点 高安全性：由于驱动、文件系统等运行在用户空间，内核崩溃不会影响整个系统。 可扩展性强：可以动态加载或更换组件，无需重启内核。 性能较低：用户态与内核态之间的频繁通信增加了开销。 实现复杂：设计 IPC 机制和模块间通信较困难。 代表操作系统 鸿蒙 macOS（XNU 混合内核，部分微内核特性） 混合类型内核，它的架构有点像微内核，内核里面会有一个最小版本的内核，然后其他模块会在这个基础上搭建，然后实现的时候会跟宏内核类似，也就是把整个内核做成一个完整的程序，大部分服务都在内核中，这就像是宏内核的方式包裹着一个微内核","link":"/2025/03/03/interview/OS/1%E3%80%81%E7%A1%AC%E4%BB%B6%E7%BB%93%E6%9E%84/"},{"title":"2、内存管理","text":"点击阅读更多查看文章内容 虚拟内存单片机的 CPU 是直接操作内存的「物理地址」。在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。 我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「虚拟地址」，互不干涉。但是有个前提每个进程都不能访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的。 我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address） 实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address） 进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示： 操作系统是如何管理虚拟地址与物理地址之间的关系？主要有两种方式，分别是内存分段和内存分页 内存分段程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。 分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。 段选择因子就保存在段寄存器里面。段选择因子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。 段表：分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。 分段存在两个问题： 第一个就是内存碎片的问题。 第二个就是内存交换的效率低的问题。 我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中： 游戏占用了 512MB 内存 浏览器占用了 128MB 内存 音乐占用了 256 MB 内存。 这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。 如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。 内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以不会出现内部内存碎片。 但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以会出现外部内存碎片的问题。 解决「外部内存碎片」的问题就是内存交换。 可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。 这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。 为什么效率低？ 对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。 因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。 所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。 为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。 内存分页分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。 虚拟地址与物理地址之间通过页表来映射，如下图： 采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。 但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。 如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。 更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。 在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。 多级页表 在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。 这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。 那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了 要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决方案。 在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。 我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示： 你可能会问，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？ 每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存 如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？ 我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。 对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是： 全局页目录项 PGD（Page Global Directory）； 上层页目录项 PUD（Page Upper Directory）； 中间页目录项 PMD（Page Middle Directory）； 页表项 PTE（Page Table Entry）； TLB基于程序访问的局部性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。 在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。 有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。 TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个 段页式内存管理先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页； 这样，地址结构就由段号、段内页号和页内位移三部分组成。 用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示： 段页式地址变换中要得到物理地址须经过三次内存访问： 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址 传统LRU是如何管理数据的当访问的页在内存里，就直接把该页对应的 LRU 链表节点移动到链表的头部。 当访问的页不在内存里，除了要把该页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的页。 比如下图，假设 LRU 链表长度为 5，LRU 链表从左到右有编号为 1，2，3，4，5 的页。 如果访问了 3 号页，因为 3 号页已经在内存了，所以把 3 号页移动到链表头部即可，表示最近被访问了。 而如果接下来，访问了 8 号页，因为 8 号页不在内存里，且 LRU 链表长度为 5，所以必须要淘汰数据，以腾出内存空间来缓存 8 号页，于是就会淘汰末尾的 5 号页，然后再将 8 号页加入到头部。 传统的 LRU 算法并没有被 Linux 和 MySQL 使用，因为传统的 LRU 算法无法避免下面这两个问题： 预读失效导致缓存命中率下降； 缓存污染导致缓存命中率下降 预读失效Linux 操作系统为基于 Page Cache 的读缓存机制提供预读机制 一个例子是： 应用程序只想读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。 但是操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page； 下图代表了操作系统的预读机制： 预读机制带来的好处就是减少了 磁盘 I/O 次数，提高系统磁盘 I/O 吞吐量。 MySQL Innodb 存储引擎的 Buffer Pool 也有类似的预读机制，MySQL 从磁盘加载页时，会提前把它相邻的页一并加载进来，目的是为了减少磁盘 IO。 如果这些被提前加载进来的页，并没有被访问，相当于这个预读工作是白做了，这个就是预读失效。 如果使用传统的 LRU 算法，就会把「预读页」放到 LRU 链表头部，而当内存空间不够的时候，还需要把末尾的页淘汰掉。 如果这些「预读页」如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是热点数据，这样就大大降低了缓存命中率 预读失效解决方案Linux 操作系统和 MySQL Innodb 通过改进传统 LRU 链表来避免预读失效带来的影响，具体的改进分别如下： Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）； MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。 这两个改进方式，设计思想都是类似的，都是将数据分为了冷数据和热数据，然后分别进行 LRU 算法。不再像传统的 LRU 算法那样，所有数据都只用一个 LRU 算法管理。 inux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）。 active list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页； inactive list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页； 有了这两个 LRU 链表后，预读页就只需要加入到 inactive list 区域的头部，当页被真正访问的时候，才将页插入 active list 的头部。如果预读的页一直没有被访问，就会从 inactive list 移除，这样就不会影响 active list 中的热点数据。（active中淘汰数据会加入inactive的head，再淘汰inactive的tail） MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域，young 区域 和 old 区域。 young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，这两个区域都有各自的头和尾节点，如下图，young 区域与 old 区域在 LRU 链表中的占比关系并不是一比一的关系，而是 63:37（默认比例）的关系。 划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。 缓存污染当我们在批量读取数据的时候，由于数据被访问了一次，这些大量数据都会被加入到「活跃 LRU 链表」里，然后之前缓存在活跃 LRU 链表（或者 young 区域）里的热点数据全部都被淘汰了，如果这些大量的数据在很长一段时间都不会被访问的话，那么整个活跃 LRU 链表（或者 young 区域）就被污染了。 缓存污染带来的影响就是很致命的，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 I/O，系统性能就会急剧下降。 缓存污染解决方案前面的 LRU 算法只要数据被访问一次，就将数据加入活跃 LRU 链表（或者 young 区域），这种 LRU 算法进入活跃 LRU 链表的门槛太低了！正式因为门槛太低，才导致在发生缓存污染的时候，很容就将原本在活跃 LRU 链表里的热点数据淘汰了。 所以，只要我们提高进入到活跃 LRU 链表（或者 young 区域）的门槛，就能有效地保证活跃 LRU 链表（或者 young 区域）里的热点数据不会被轻易替换掉。 Linux 操作系统和 MySQL Innodb 存储引擎分别是这样提高门槛的： Linux 操作系统：在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。 MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断： 如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域； 如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域； 提高了进入活跃 LRU 链表（或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。 在批量读取数据时候，如果这些大量数据只会被访问一次，那么它们就不会进入到活跃 LRU 链表（或者 young 区域），也就不会把热点数据淘汰，只会待在非活跃 LRU 链表（或者 old 区域）中，后续很快也会被淘汰。","link":"/2025/03/03/interview/OS/2%E3%80%81%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"title":"4、调度算法","text":"点击阅读更多查看文章内容 进程调度算法进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。 当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。 什么时候会发生 CPU 调度呢？通常有以下情况： 当进程从运行状态转到等待状态； 当进程从运行状态转到就绪状态； 当进程从等待状态转到就绪状态； 当进程从运行状态转到终止状态； 其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。 非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。 而抢占式调度，顾名思义就是进程正在运行时，可以被打断，使其把 CPU 让给其他进程。 那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。 你可能会好奇为什么第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。 那第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。 调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。 先来先服务调度算法 最短作业优先调度算法 高响应比优先调度算法 时间片轮转调度算法 最高优先级调度算法 多级反馈队列调度算法 内存页面置换算法在了解内存页面置换算法前，我们得先谈一下缺页异常（缺页中断）。 当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于： 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。 我们来看一下缺页中断的处理流程，如下图： 页面置换算法的功能是，当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。 那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种： 最佳页面置换算法（OPT） ：置换在「未来」最长时间不访问的页面。实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。 所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的 先进先出置换算法（FIFO） ：选择在内存驻留时间很长的页面进行中置换 最近最久未使用的置换算法（LRU） ：选择最长时间没有被访问的页面进行置换，虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。 困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。 时钟页面置换算法（Lock） ：把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。 当发生缺页中断时，算法首先检查表针指向的页面： 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置； 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止； 最不常用置换算法（LFU）：当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。 磁盘调度算法 常见的机械磁盘是上图左边的样子，中间圆的部分是磁盘的盘片，一般会有多个盘片，每个盘面都有自己的磁头。右边的图就是一个盘片的结构，盘片中的每一层分为多个磁道，每个磁道分多个扇区，每个扇区是 512 字节。那么，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面，如上图里中间的样子。 磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。 寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。 假设有下面一个请求序列，每个数字代表磁道的位置： 98，183，37，122，14，124，65，67 初始磁头当前的位置是在第 53 磁道。 接下来，分别对以上的序列，作为每个调度算法的例子，那常见的磁盘调度算法有： 先来先服务算法 最短寻道时间优先算法：优先选择从当前磁头位置所需寻道时间最短的请求 扫描算法 ：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（Scan）算法。中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。 循环扫描算法：循环扫描（Circular Scan, CSCAN ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。 LOOK 与 C-LOOK 算法：我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。 那这其实是可以优化的，优化的思路就是磁头在移动到「最远的请求」位置，然后立即反向移动。 LOOK：针对 SCAN 算法的优化，磁头在移动到「最远的请求」位置，然后立即反向移动 C-LOOK：针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。","link":"/2025/03/03/interview/OS/4%E3%80%81%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/"},{"title":"3、进程管理","text":"点击阅读更多查看文章内容 进程我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」（Process）。 现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利用率是非常低的。所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运行这个进程。 这种多个程序、交替执行的思想，就有 CPU 管理多个进程的初步想法。 对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。 虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。 并发vs并行 进程的状态在上面，我们知道了进程有着「运行 - 暂停 - 运行」的活动规律。一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。 它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。 所以，在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。 上图中各个状态的意义： 运行状态（Running）：该时刻进程占用 CPU； 就绪状态（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行； 阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行； 当然，进程还有另外两个基本状态： 创建状态（new）：进程正在被创建时的状态； 结束状态（Exit）：进程正在从系统中消失时的状态 如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间。 所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。 那么，就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。 另外，挂起状态可以分为两种： 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行； 进程的上下文切换各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。 在详细说进程上下文切换前，我们先来看看 CPU 上下文切换 大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。 任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。 所以，操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。 CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。 再来，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。 所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。 既然知道了什么是 CPU 上下文，那理解 CPU 上下文切换就不难了。 CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。 系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。 上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换 进程是由内核管理和调度的，所以进程的切换只能发生在内核态。 所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。 通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示： 发生进程上下文切换有哪些场景？ 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行； 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行； 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度； 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行； 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序； 线程在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面，计算机科学家们又提出了更小的能独立运行的基本单位，也就是线程。 为什么使用线程？我们举个例子，假设你要编写一个视频播放器软件，那么该软件功能的核心模块有三个： 从视频文件当中读取数据； 对读取的数据进行解压缩； 把解压缩后的视频数据播放出来； 对于单进程的实现方式，我想大家都会是以下这个方式： 对于单进程的这种方式，存在以下问题： 播放出来的画面和声音会不连贯，因为当 CPU 能力不够强的时候，Read 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放； 各个函数之间不是并发执行，影响资源的使用效率； 、 那改进成多进程的方式： 对于多进程的这种方式，依然会存在问题： 进程之间如何通信，共享数据？ 维护进程的系统开销较大，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息； 那到底如何解决呢？需要有一种新的实体，满足以下特性： 实体之间可以并发运行； 实体之间共享相同的地址空间； 这个新的实体，就是线程( Thread )，线程之间可以并发运行且共享相同的地址空间。 什么是线程？线程是进程当中的一条执行流程。 同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。 线程的优点： 一个进程中可以同时存在多个线程； 各个线程之间可以并发执行； 各个线程之间可以共享地址空间和文件等资源； 线程的缺点： 当进程中的一个线程崩溃时，可能会导致其所属进程的所有线程崩溃。 举个例子，对于游戏的用户设计，则不应该使用多线程的方式，否则一个用户挂了，会影响其他同个进程的线程 线程与进程的比较如下： 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位； 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈； 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系； 线程能减少并发执行的时间和空间开销； 对于，线程相比进程能减少开销，体现在： 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们； 线 程的终止时间比进程快，因为线程释放的资源相比进程少很多； 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的； 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了； 所以，不管是时间效率，还是空间效率线程比进程都要高 线程的上下文切换线程是CPU调度的基本单位，所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样； 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据； 所以，线程的上下文切换相比进程，开销要小很多 线程的实现用户线程通常需要依赖内核线程来与操作系统交互，用户线程与内核线程的对应关系： 多对一模型（Many-to-One Model）：多个用户线程映射到一个内核线程。 优点： 创建和销毁线程的开销较小。 上下文切换在用户空间完成，速度快。 缺点： 无法利用多核 CPU。 一个线程的阻塞会影响整个进程。 一对一模型（One-to-One Model）：每个用户线程直接映射到一个内核线程。 优点： 可以直接利用多核 CPU。 一个线程的阻塞不会影响其他线程。 缺点： 创建和销毁线程的开销较大。 上下文切换涉及用户态和内核态的切换，开销较大。 多对多模型（Many-to-Many Model）：多个用户线程映射到多个内核线程。（goroutine就是这种模型） 优点： 结合了一对一和多对一模型的优点。 可以利用多核 CPU。 一个线程的阻塞不会影响其他线程。 缺点： 实现复杂，需要用户空间的线程库和内核的协同工作。 主要有三种线程的实现方式： 用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理； 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程； 轻量级进程（LightWeight Process）：在内核中来支持用户线程； 用户线程是基于用户态的线程管理库来实现的，那么线程控制块（Thread Control Block, TCB） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。用户级线程的模型，也就类似前面提到的多对一的关系，即多个用户线程对应同一个内核线程，如下图所示： 用户线程的优点： 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统； 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快； 用户线程的缺点： 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢； 内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。 内核线程的模型，也就类似前面提到的一对一的关系，即一个用户线程对应一个内核线程，如下图所示： 内核线程的优点： 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行； 分配给线程，多线程的进程获得更多的 CPU 运行时间； 内核线程的缺点： 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB； 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大； 轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。 在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。 1 : 1 模式一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4，属于此模型。 优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP； 缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。 N : 1 模式 多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。 优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高； 缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。 M : N 模式 根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。 优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源 进程调度算法 先来先服务 最短作业优先 高响应比优先 时间片轮转 最高优先级调度 多级反馈队列 多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。 顾名思义： 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列； 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行 进程间通信每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。 管道1$ ps auxf | grep mysql 上面命令行里的「|」竖线就是一个管道，它的功能是将前一个命令（ps auxf）的输出，作为后一个命令（grep mysql）的输入，从这功能描述，可以看出管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。 同时，我们得知上面这种管道是没有名字，所以「|」表示的管道称为匿名管道，用完了就销毁。 管道还有另外一个类型是命名管道，也被叫做 FIFO，因为数据是先进先出的传输方式。 在使用命名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字： 1$ mkfifo myPipe myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思： 12$ ls -lprw-r--r--. 1 root root 0 Jul 17 02:45 myPipe 接下来，我们往 myPipe 这个管道写入数据： 12$ echo &quot;hello&quot; &gt; myPipe // 将数据写进管道 // 停住了... 你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。 于是，我们执行另外一个命令来读取这个管道里的数据： 12$ cat &lt; myPipe // 读取管道里的数据hello 可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。 我们可以看出，管道这种通信方式效率低，不适合进程间频繁地交换数据。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。 所谓的管道，就是内核里面的一串缓存。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。 消息队列前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。 对于这个问题，消息队列的通信模式就可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。 再来，消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。 消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。 消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。 共享内存消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。 现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。 共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。 信号量 用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。 为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。 正好，信号量就实现了这一保护机制。 信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。 信号量表示资源的数量，控制信号量的方式有两种原子操作： 一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行。 另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程； P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。 接下来，举个例子，如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 1。 也可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 0。 如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待； 接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B； 最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了 信号上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用「信号」的方式来通知进程 在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 kill -l 命令，查看所有的信号： 1234567891011121314$ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX 运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如 Ctrl+C 产生 SIGINT 信号，表示终止该进程； Ctrl+Z 产生 SIGTSTP 信号，表示停止该进程，但还未结束； 如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如： kill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程； 所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。 信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。 执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。 捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。 忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。 Socket前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了 针对tcp协议的socket编程模型： 服务端和客户端初始化 socket，得到文件描述符； 服务端调用 bind，将绑定在 IP 地址和端口; 服务端调用 listen，进行监听； 服务端调用 accept，等待客户端连接； 客户端调用 connect，向服务器端的地址和端口发起连接请求； 服务端 accept 返回用于传输的 socket 的文件描述符； 客户端调用 write 写入数据； 服务端调用 read 读取数据； 客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。 这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。 所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。 成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。 针对 UDP 协议通信的 socket 编程模型： UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。 对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。 另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。 针对本地进程间通信的 socket 编程模型: 本地 socket 被用于在同一台主机上进程间通信的场景： 本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议； 本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现； 对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。 对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。 本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。 多线程冲突了怎么办互斥： 当多线程相互竞争操作共享变量时，可能会得到错误的结果，输出的结果存在不确定性（indeterminate）。 由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。 我们希望这段代码是互斥（mutualexclusion）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区，说白了，就是这段代码执行过程中，最多只能出现一个线程。 同步： 所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。 同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等； 互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」； 互斥与同步的实现为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种： 锁：加锁、解锁操作； 信号量：P、V 操作； 这两个都可以方便地实现进程/线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程/线程同步 怎么避免死锁在多线程编程中，我们为了防止多线程竞争共享资源而导致数据错乱，都会在操作共享资源之前加上互斥锁，只有成功获得到锁的线程，才能操作共享资源，获取不到锁的线程就只能等待，直到锁被释放。 那么，当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了死锁。 死锁只有同时满足以下四个条件才会发生： 互斥条件； 持有并等待条件； 不可剥夺条件； 环路等待条件； 互斥条件互斥条件是指多个线程不能同时使用同一个资源。 比如下图，如果线程 A 已经持有的资源，不能再同时被线程 B 持有，如果线程 B 请求获取线程 A 已经占用的资源，那线程 B 只能等待，直到线程 A 释放了资源。 持有并等待条件持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。 不可剥夺条件不可剥夺条件是指，当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。 环路等待条件环路等待条件指的是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。 比如，线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经获取了资源 1，而想请求资源 2，这就形成资源请求等待的环形图。 那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。 那什么是资源有序分配法呢？ 线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。 我们使用资源有序分配法的方式来修改前面发生死锁的代码，我们可以不改动线程 A 的代码。 我们先要清楚线程 A 获取资源的顺序，它是先获取互斥锁 A，然后获取互斥锁 B。 所以我们只需将线程 B 改成以相同顺序的获取资源，就可以打破死锁了。 互斥锁与自旋锁互斥锁 互斥锁加锁失败后，线程会释放 CPU ，给其他线程； 互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。 对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。如下图： 所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。 那这个开销成本是什么呢？ 会有两次线程上下文切换的成本： 当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行； 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。 上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。 所以，如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁 自旋锁 自旋锁加锁失败后，线程会忙等待，直到它拿到锁； 自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。 一般加锁的过程，包含两个步骤： 第一步，查看锁的状态，如果锁是空闲的，则执行第二步； 第二步，将锁设置为当前线程持有； CAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。（将获取到锁作为一个操作，不会出现没有拿到锁而阻塞情况） 自旋锁与互斥锁的不同之处在于，它不会使线程进入阻塞状态，而是让线程在获取锁时反复“自旋”检查锁的状态。如果锁没有被占用，线程会立即获取到锁；如果锁已经被占用，线程会一直忙等待（即自旋）直到锁可用。 自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。 自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。 自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对。 它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现 读写锁读写锁的工作原理是： 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。 但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。 所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。 知道了读写锁的工作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。 另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。 读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。如下图： 「写优先锁」是优先服务写线程，其工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取写锁。如下图： 乐观锁与悲观锁前面提到的互斥锁、自旋锁、读写锁，都是属于悲观锁。 悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。 那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。 乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。 放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。 可见，乐观锁的心态是，不管三七二十一，先改了资源再说。另外，你会发现乐观锁全程并没有加锁，所以它也叫无锁编程。 这里举一个场景例子：在线文档。 我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。 那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。 怎么样才算发生冲突？这里举个例子，比如用户 A 先在浏览器编辑文档，之后用户 B 在浏览器也打开了相同的文档进行编辑，但是用户 B 比用户 A 提交早，这一过程用户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并行修改的地方就会发生冲突。 服务端要怎么验证是否冲突了呢？通常方案如下： 由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号； 当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。 实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。 乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。 乐观锁的优点： 减少锁竞争，提升性能 避免了死锁问题 提高并发性，降低锁的开销 适应无锁编程模式，减少锁的使用 简化设计，避免显式锁管理 乐观锁的缺点： 冲突回滚的开销 复杂的冲突处理逻辑 无效的重复操作 不适用于长时间运行的事务","link":"/2025/03/03/interview/OS/3%E3%80%81%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"title":"5、文件系统","text":"点击阅读更多查看文章内容 文件系统的组成Linux 最经典的一句话是：「一切皆文件」，不仅普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的。 Linux 文件系统会为每个文件分配两个数据结构：索引节点（index node）和目录项（directory entry），它们主要用来记录文件的元信息和目录层次结构。 索引节点，也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。 目录项，也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。 由于索引节点唯一标识一个文件，而目录项记录着文件的名字，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别名。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。 注意，目录也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件 软链接和硬链接有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过硬链接（Hard Link） 和软链接（Symbolic Link） 的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的。 硬链接是多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。 软链接相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。","link":"/2025/03/03/interview/OS/5%E3%80%81%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"title":"6、设备管理","text":"点击阅读更多查看文章内容 设备控制器我们的电脑设备可以接非常多的输入输出设备，比如键盘、鼠标、显示器、网卡、硬盘、打印机、音响等等，每个设备的用法和功能都不同，那操作系统是如何把这些输入输出设备统一管理的呢? 为了屏蔽设备之间的差异，每个设备都有一个叫设备控制器（Device Control） 的组件，比如硬盘有硬盘控制器、显示器有视频控制器等。 I/O控制方式在前面我知道，每种设备都有一个设备控制器，控制器相当于一个小 CPU，它可以自己处理一些事情，但有个问题是，当 CPU 给设备发送了一个指令，让设备控制器去读设备的数据，它读完的时候，要怎么通知 CPU 呢？ 控制器的寄存器一般会有状态标记位，用来标识输入或输出操作是否完成。于是，我们想到第一种轮询等待的方法，让 CPU 一直查寄存器的状态，直到状态标记为完成，很明显，这种方式非常的傻瓜，它会占用 CPU 的全部时间。 那我们就想到第二种方法 —— 中断，通知操作系统数据已经准备好了。我们一般会有一个硬件的中断控制器，当设备完成任务后触发中断到中断控制器，中断控制器就通知 CPU，一个中断产生了，CPU 需要停下当前手里的事情来处理中断。 DMA另外，中断有两种，一种软中断，例如代码调用 INT 指令触发，一种是硬件中断，就是硬件通过中断控制器触发的。 但中断的方式对于频繁读写数据的磁盘，并不友好，这样 CPU 容易经常被打断，会占用 CPU 大量的时间。对于这一类设备的问题的解决方法是使用 DMA（Direct Memory Access） 功能，它可以使得设备在 CPU 不参与的情况下，能够自行完成把设备 I/O 数据放入到内存。那要实现 DMA 功能要有 「DMA 控制器」硬件的支持。 DMA 的工作方式如下： CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了； 接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存； 当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出一个确认成功的信号到 DMA 控制器； DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接用内存里面现成的数据了； 可以看到， CPU 当要读取磁盘数据的时候，只需给 DMA 控制器发送指令，然后返回去做其他事情，当磁盘数据拷贝到内存后，DMA 控制机器通过中断的方式，告诉 CPU 数据已经准备好了，可以从内存读数据了。仅仅在传送开始和结束时需要 CPU 干预 设备驱动程序虽然设备控制器屏蔽了设备的众多细节，但每种设备的控制器的寄存器、缓冲区等使用模式都是不同的，所以为了屏蔽「设备控制器」的差异，引入了设备驱动程序。 设备控制器不属于操作系统范畴，它是属于硬件，而设备驱动程序属于操作系统的一部分，操作系统的内核代码可以像本地调用代码一样使用设备驱动程序的接口，而设备驱动程序是面向设备控制器的代码，它发出操控设备控制器的指令后，才可以操作设备控制器。 不同的设备控制器虽然功能不同，但是设备驱动程序会提供统一的接口给操作系统，这样不同的设备驱动程序，就可以以相同的方式接入操作系统。如下图： 前面提到了不少关于中断的事情，设备完成了事情，则会发送中断来通知操作系统。那操作系统就需要有一个地方来处理这个中断，这个地方也就是在设备驱动程序里，它会及时响应控制器发来的中断请求，并根据这个中断的类型调用响应的中断处理程序进行处理。 通常，设备驱动程序初始化的时候，要先注册一个该设备的中断处理函数。 我们来看看，中断处理程序的处理流程： 在 I/O 时，设备控制器如果已经准备好数据，则会通过中断控制器向 CPU 发送中断请求； 保护被中断进程的 CPU 上下文； 转入相应的设备中断处理函数； 进行中断处理； 恢复被中断进程的上下文 通用块层对于块设备，为了减少不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理不同的块设备。 通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能： 第一个功能，向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序； 第二功能，通用层还会给文件系统和应用程序发来的 I/O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I/O 调度，主要目的是为了提高磁盘读写的效率。 存储系统I/O软件分层 键盘敲入字母时，期间发生了什么？看完前面的内容，相信你对输入输出设备的管理有了一定的认识，那接下来就从操作系统的角度回答开头的问题「键盘敲入字母时，操作系统期间发生了什么？」 我们先来看看 CPU 的硬件架构图： CPU 里面的内存接口，直接和系统总线通信，然后系统总线再接入一个 I/O 桥接器，这个 I/O 桥接器，另一边接入了内存总线，使得 CPU 和内存通信。再另一边，又接入了一个 I/O 总线，用来连接 I/O 设备，比如键盘、显示器等。 当用户输入了键盘字符，键盘控制器就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送中断请求。 CPU 收到中断请求后，操作系统会保存被中断进程的 CPU 上下文，然后调用键盘的中断处理程序。 键盘的中断处理程序是在键盘驱动程序初始化时注册的，那键盘中断处理函数的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。 得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。 显示出结果后，恢复被中断进程的上下文","link":"/2025/03/03/interview/OS/6%E3%80%81%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86/"},{"title":"8、linux常用命令","text":"点击阅读更多查看文章内容 1. 查看日志文件cat/tac cat /var/log/syslog # 查看完整日志 tac /var/log/syslog # 逆序查看日志（最新日志在前） less/more less /var/log/syslog # 分页查看日志，支持上下滚动 more /var/log/syslog # 逐页查看（只能向下翻页） head/tail head -n 50 /var/log/syslog # 查看日志的前50行 tail -n 50 /var/log/syslog # 查看日志的最后50行 tail -f /var/log/syslog # 实时跟踪日志变化（常用于监控） 2. 搜索日志grep grep &quot;error&quot; /var/log/syslog # 查找包含”error”的日志 grep -i &quot;failed&quot; /var/log/auth.log # 忽略大小写搜索”failed” grep -E &quot;error|fail|warning&quot; /var/log/syslog # 搜索多个关键字 grep -A 5 &quot;error&quot; /var/log/syslog # 显示”error”及其后5行日志 grep -B 5 &quot;error&quot; /var/log/syslog # 显示”error”及其前5行日志 grep -C 5 &quot;error&quot; /var/log/syslog # 显示”error”及其前后5行日志 awk awk '{print $1, $2, $5}' /var/log/syslog # 只显示日志的前两列时间和进程 awk '/error/ {print $0}' /var/log/syslog # 只显示包含”error”的日志 sed sed -n '/error/p' /var/log/syslog # 只打印包含”error”的行 sed -n '50,100p' /var/log/syslog # 只显示50到100行的日志 3. 统计分析日志统计某个关键字出现的次数 grep -c &quot;error&quot; /var/log/syslog # 统计”error”出现的次数 grep &quot;error&quot; /var/log/syslog | wc -l # 另一种统计方法","link":"/2025/03/03/interview/OS/8%E3%80%81linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"title":"7、网络系统","text":"点击阅读更多查看文章内容 什么是零拷贝？磁盘可以说是计算机系统最慢的硬件之一，读写速度相差内存 10 倍以上，所以针对优化磁盘的技术非常的多，比如零拷贝、直接 I/O、异步 I/O 等等，这些优化的目的就是为了提高系统的吞吐量，另外操作系统内核中的磁盘高速缓存区，可以有效的减少磁盘的访问次数。 为什么要有DMA技术？在没有 DMA 技术前，I/O 的过程是这样的： CPU 发出对应的指令给磁盘控制器，然后返回； 磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断； CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。 可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。 DMA 技术，也就是直接内存访问（Direct Memory Access） 技术，在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。 传统文件传输的问题如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。 传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。 首先，期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。 上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。 其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程： 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的 所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。 先来看看，如何减少「用户态与内核态的上下文切换」的次数呢？ 读取磁盘数据的时候，之所以要发生上下文切换，这是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候，就需要使用操作系统提供的系统调用函数。 而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。 所以，要想减少上下文切换到次数，就要减少系统调用的次数。 再来看看，如何减少「数据拷贝」的次数？ 在前面我们知道了，传统的文件传输方式会历经 4 次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。 因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的。 如何实现零拷贝零拷贝技术实现的方式通常有 2 种： mmap + write sendfile 下面就谈一谈，它们是如何减少「上下文切换」和「数据拷贝」的次数。 mmap + write 在前面我们知道，read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。buf = mmap(file, len); write(sockfd, buf, len);mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。 具体过程如下： 应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区； 应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据； 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。 我们可以得知，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。 但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。 sendfile 在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 sendfile()，函数形式如下： 12#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。 其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图： 但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。 从 Linux 内核 2.4 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， sendfile() 系统调用的过程发生了点变化，具体过程如下： 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里； 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝； 所以，这个过程之中，只进行了 2 次数据拷贝，如下图： 这就是所谓的零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。 零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。 所以，总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。 使用零拷贝技术的项目 kafka、nginx 线程池线程是运行在进程中的一个“逻辑流”，单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下文切换时不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据，因此同一个进程下的线程上下文切换的开销要比进程小得多。 当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。 如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。 那么，我们可以使用线程池的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。 需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。 上面基于进程或者线程模型的，其实还是有问题的。 新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K （C 是 Client 单词首字母缩写，C10K 就是单机同时处理 1 万个请求的问题。），意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程/线程，操作系统就算死扛也是扛不住的。 I/O多路复用既然为每个请求分配一个进程/线程的方式不合适，那有没有可能只使用一个进程来维护多个 Socket 呢？答案是有的，那就是 I/O 多路复用技术。 一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。 elect、poll 和 epoll 是 Linux 系统中用于 I/O 多路复用的机制，它们允许一个进程同时监控多个文件描述符（如套接字、管道等），并在这些文件描述符中的任何一个变得可读、可写或出现异常时通知进程。这些机制在网络编程中非常有用，尤其是在需要处理大量并发连接时。 select/poll/epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。 select/poll/epoll 这是三个多路复用接口，都能实现 C10K 吗？接下来，我们分别说说它们。 selectselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。 pollpoll 与 select 不同，poll 使用一个数组来存储文件描述符，因此没有文件描述符数量的限制（仅受系统资源限制）。每次调用 poll 时，仍然需要将文件描述符集合从用户空间拷贝到内核空间。内核仍然需要遍历所有文件描述符来检查状态。 poll 的工作流程 初始化：将需要监控的文件描述符列表传递给 poll()。 调用 poll()： 内核遍历所有文件描述符，检查是否有事件（如可读、可写）就绪。 返回就绪的文件描述符数量，并标记哪些文件描述符就绪。 应用程序遍历所有文件描述符，找到就绪的进行处理。 重复步骤 1~3，每次调用 poll() 都需要重新传递所有文件描述符。 缺点： 文件描述符数量多时，遍历开销大（时间复杂度 O(n)）。 每次调用需要全量传递文件描述符列表，内存拷贝开销大 epollepoll 是 Linux 2.6 引入的 I/O 多路复用机制，旨在解决 select 和 poll 的性能问题。 epoll 使用一个红黑树来存储需要监控的文件描述符，因此添加、删除和查找文件描述符的效率很高。 epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。 epoll 的工作流程 初始化： 调用 epoll_create() 创建一个 epoll 实例。 调用 epoll_ctl() 向 epoll 实例注册需要监控的文件描述符和事件。 调用 epoll_wait()： 内核直接返回已就绪的文件描述符列表（无需遍历所有文件描述符）。 应用程序遍历就绪列表，处理就绪的文件描述符。 重复步骤 2~3，无需重新注册文件描述符。 优点： 时间复杂度为 O(1)，仅处理就绪的文件描述符。 内核通过红黑树管理文件描述符，高效查找和更新。 触发模式 水平触发（LT, Level-Triggered）： 当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取； 适用场景：适合编程简单的场景，确保数据能完全处理。 示例：poll 仅支持 LT 模式，epoll 默认也是 LT 模式。 边缘触发（ET, Edge-Triggered）： 当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完； 适用场景：需要高性能的场景，但应用程序必须一次性处理完所有数据，否则可能丢失事件。 示例：epoll 支持 ET 模式。 水平触发（LT）的行为 核心特点： 只要 socket 的某个状态（如可读、可写）持续存在，每次调用 epoll_wait 都会报告该事件，直到状态被处理完毕。 事件通知是“宽容”的，允许应用程序分多次处理一个状态下的多个事件。 示例场景： 场景：socket 接收缓冲区中有 2KB 数据未读取。 **第一次调用 epoll_wait**：报告该 socket 可读。 处理：应用程序读取 1KB 数据，还剩 1KB。 **第二次调用 epoll_wait**：仍然会报告该 socket 可读，因为缓冲区中还有数据。 处理：应用程序继续读取剩余的 1KB，缓冲区清空。 **第三次调用 epoll_wait**：不再报告该 socket 可读。 总结： LT 模式下，未处理完的事件会持续通知，适合需要分批次处理数据的场景。 边缘触发（ET）的行为 核心特点： 仅在 socket 状态从无到有发生变化时通知一次。 如果应用程序未完全处理所有事件（例如未读完所有数据），剩余事件不会触发新的通知，即使状态仍然存在。 示例场景： 场景：socket 接收缓冲区中有 2KB 数据未读取。 **第一次调用 epoll_wait**：报告该 socket 可读（状态从“不可读”变为“可读”）。 处理：应用程序读取 1KB 数据，还剩 1KB。 第二次调用 epoll_wait：不会报告该 socket 可读，因为状态未发生新的变化（缓冲区仍有数据，但未再次从空变为非空）。 剩余数据：剩下的 1KB 数据会一直滞留在缓冲区中，直到有新数据到达（再次触发状态变化）。 关键问题： 必须一次性处理所有事件：在 ET 模式下，应用程序必须循环读取数据，直到返回 EAGAIN 或 EWOULDBLOCK，确保缓冲区被完全清空。 总结最基础的 TCP 的 Socket 编程，它是阻塞 I/O 模型，基本上只能一对一通信，那为了服务更多的客户端，我们需要改进网络 I/O 模型。 比较传统的方式是使用多进程/线程模型，每来一个客户端连接，就分配一个进程/线程，然后后续的读写都在对应的进程/线程，这种方式处理 100 个客户端没问题，但是当客户端增大到 10000 个时，10000 个进程/线程的调度、上下文切换以及它们占用的内存，都会成为瓶颈。 为了解决上面这个问题，就出现了 I/O 的多路复用，可以只在一个进程里处理多个文件的 I/O，Linux 下有三种提供 I/O 多路复用的 API，分别是：select、poll、epoll。 select 和 poll 并没有本质区别，它们内部都是使用「线性结构」来存储进程关注的 Socket 集合。 在使用的时候，首先需要把关注的 Socket 集合通过 select/poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 Socket 集合找到可读/可写的 Socket，然后对其处理。 很明显发现，select 和 poll 的缺陷在于，当客户端越多，也就是 Socket 集合越大，Socket 集合的遍历和拷贝会带来很大的开销，因此也很难应对 C10K。 epoll 是解决 C10K 问题的利器，通过两个方面解决了 select/poll 的问题。 epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。 epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。 而且，epoll 支持边缘触发和水平触发的方式，而 select/poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高。 一致性哈希如何分配请求？引入一个中间的负载均衡层，让它将外界的请求「轮流」的转发给内部的集群。比如集群有 3 个节点，外界请求有 3 个，那么每个节点都会处理 1 个请求，达到了分配请求的目的 考虑到每个节点的硬件配置有所区别，我们可以引入权重值，将硬件配置更好的节点的权重值设高，然后根据各个节点的权重值，按照一定比重分配在不同的节点上，让硬件配置更好的节点承担更多的请求，这种算法叫做加权轮询。 加权轮询算法使用场景是建立在每个节点存储的数据都是相同的前提。所以，每次读数据的请求，访问任意一个节点都能得到结果。 但是，加权轮询算法是无法应对「分布式系统（数据分片的系统）」的，因为分布式系统中，每个节点存储的数据是不同的。 当我们想提高系统的容量，就会将数据水平切分到不同的节点来存储，也就是将数据分布到了不同的节点。 比如一个分布式 KV（key-valu） 缓存系统，某个 key 应该到哪个或者哪些节点上获得，应该是确定的，不是说任意访问一个节点都可以得到缓存结果的。 因此，我们要想一个能应对分布式系统的负载均衡算法 普通哈希的问题有的同学可能很快就想到了：哈希算法。因为对同一个关键字进行哈希计算，每次计算都是相同的值，这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求。 哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 hash(key) % 3 公式对数据进行了映射。 如果客户端要获取指定 key 的数据，通过下面的公式可以定位节点：hash(key) % 3 如果经过上面这个公式计算后得到的值是 0，就说明该 key 需要去第一个节点获取。 但是有一个很致命的问题，如果节点数量发生了变化，也就是在对系统做扩容或者缩容后，取模的值发生了改变，数据对应的服务器也发生了改变。必须迁移改变了映射关系的数据，否则会出现查询不到数据的问题。 假设总数据条数为 M，哈希算法在面对节点数量变化时，最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)，这样数据的迁移成本太高了。 所以，我们应该要重新想一个新的算法，来避免分布式系统在扩容或者缩容时，发生过多的数据迁移。 一致性哈希一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值。 我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为哈希环，如下图： 一致性哈希要进行两步哈希： 第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希； 第二步：当对数据进行存储或访问时，对数据进行哈希映射； 所以，一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。 问题来了，对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？ 答案是，映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点。 举个例子，有 3 个节点经过哈希计算，映射到了如下图的位置： 接着，对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。 比如，下图中的 key-01 映射的位置，往顺时针的方向找到第一个节点就是节点 A。 所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址： 首先，对 key 进行哈希计算，确定此 key 在环上的位置； 然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。 知道了一致哈希寻址的方式，我们来看看，如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？ 假设节点数量从 3 增加到了 4，新的节点 D 经过哈希计算后映射到了下图中的位置： 你可以看到，key-01、key-03 都不受影响，只有 key-02 需要被迁移节点 D。 假设节点数量从 3 减少到了 2，比如将节点 A 移除 你可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。 因此，在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。 上面这些图中 3 个节点映射在哈希环还是比较分散的，所以看起来请求都会「均衡」到每个节点。 但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上。 比如，下图中 3 个节点的映射位置都在哈希环的右半边： 这时候有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中的节点 A 上， 另外，在这种节点分布不均匀的情况下，进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。 比如，上图中如果节点 A 被移除了，当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样，节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。 所以，一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。 要想解决节点能在哈希环上分配不均匀的问题，就是要有大量的节点，节点数越多，哈希环上的节点分布的就越均匀。 但问题是，实际中我们没有那么多节点。所以这个时候我们就加入虚拟节点，也就是对一个真实节点做多个副本。 具体做法是，不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。 比如对每个节点分别设置 3 个虚拟节点： 对节点 A 加上编号来作为虚拟节点：A-01、A-02、A-03 对节点 B 加上编号来作为虚拟节点：B-01、B-02、B-03 对节点 C 加上编号来作为虚拟节点：C-01、C-02、C-03 引入虚拟节点后，原本哈希环上只有 3 个节点的情况，就会变成有 9 个虚拟节点映射到哈希环上，哈希环上的节点数量多了 3 倍。 你可以看到，节点数量多了后，节点在哈希环上的分布就相对均匀了。这时候，如果有访问请求寻址到「A-01」这个虚拟节点，接着再通过「A-01」虚拟节点找到真实节点 A，这样请求就能访问到真实节点 A 了。 另外，虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高。 比如，当某个节点被移除时，对应该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了节点变化导致的压力。 而且，有了虚拟节点后，还可以为硬件配置更好的节点增加权重，比如对权重更高的节点增加更多的虚拟机节点即可。 因此，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。","link":"/2025/03/03/interview/OS/7%E3%80%81%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F/"},{"title":"1、mysql基础","text":"点击阅读更多查看文章内容 执行select语句的过程MySQL 的架构共分为两层：Server 层和存储引擎层 Server 层负责建立连接、分析和执行 SQL。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。 存储引擎层负责数据的存储和提取。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 。 第一步：连接器连接的过程需要先经过 TCP 三次握手，因为 MySQL 是基于 TCP 协议进行传输的。 当然不是了，MySQL 定义了空闲连接的最大空闲时长，由 wait_timeout 参数控制的，默认值是 8 小时（28880秒），如果空闲连接超过了这个时间，连接器就会自动将它断开。 MySQL 的连接也跟 HTTP 一样，有短连接和长连接的概念，它们的区别如下： 1234567891011// 短连接 连接 mysql 服务（TCP 三次握手） 执行sql 断开 mysql 服务（TCP 四次挥手） // 长连接 连接 mysql 服务（TCP 三次握手） 执行sql 执行sql 执行sql .... 断开 mysql 服务（TCP 四次挥手） 可以看到，使用长连接的好处就是可以减少建立连接和断开连接的过程，所以一般是推荐使用长连接。 但是，使用长连接后可能会占用内存增多，因为 MySQL 在执行查询过程中临时使用内存管理连接对象，这些连接对象资源只有在连接断开时才会释放。如果长连接累计很多，将导致 MySQL 服务占用内存太大，有可能会被系统强制杀掉，这样会发生 MySQL 服务异常重启的现象。 有两种解决方式。 第一种，定期断开长连接。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接。 第二种，客户端主动重置连接。MySQL 5.7 版本实现了 mysql_reset_connection() 函数的接口，注意这是接口函数不是命令，那么当客户端执行了一个很大的操作后，在代码里调用 mysql_reset_connection 函数来重置连接，达到释放内存的效果。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 第二步：查询缓存连接器工作完成后，客户端就可以向 MySQL 服务发送 SQL 语句了，MySQL 服务收到 SQL 语句后，就会解析出 SQL 语句的第一个字段，看看是什么类型的语句。 如果 SQL 是查询语句（select 语句），MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。 如果查询的语句命中查询缓存，那么就会直接返回 value 给客户端。如果查询的语句没有命中查询缓存中，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中。 这么看，查询缓存还挺有用，但是其实查询缓存挺鸡肋的。 对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。 所以，MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。 对于 MySQL 8.0 之前的版本，如果想关闭查询缓存，我们可以通过将参数 query_cache_type 设置成 DEMAND。 第三步：解析SQL解析器 解析器会做如下两件事情。 第一件事情，词法分析。MySQL 会根据你输入的字符串识别出关键字出来，例如，SQL语句 select username from userinfo，在分析之后，会得到4个Token，其中有2个Keyword，分别为select和from 第二件事情，语法分析。根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法，如果没问题就会构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。 第四步：执行SQL经过解析器后，接着就要进入执行 SQL 查询语句的流程了，每条SELECT 查询语句流程主要可以分为下面这三个阶段： prepare 阶段，也就是预处理阶段； 检查 SQL 查询语句中的表或者字段是否存在； 将 select * 中的 * 符号，扩展为表上的所有列； optimize 阶段，也就是优化阶段； 优化器主要负责将 SQL 查询语句的执行方案确定下来，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。 要想知道优化器选择了哪个索引，我们可以在查询语句最前面加个 explain 命令，这样就会输出这条 SQL 语句的执行计划，然后执行计划中的 key 就表示执行过程中使用了哪个索引。 execute 阶段，也就是执行阶段 经历完优化器后，就确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的。 主键索引查询 1select * from product where id = 1; 这条查询语句的查询条件用到了主键索引，而且是等值查询，同时主键 id 是唯一，不会有 id 相同的记录，所以优化器决定选用访问类型为 const 进行查询，也就是使用主键索引查询一条记录，那么执行器与存储引擎的执行流程是这样的： 执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为 InnoDB 引擎索引查询的接口，把条件 id = 1 交给存储引擎，让存储引擎定位符合条件的第一条记录。 存储引擎通过主键索引的 B+ 树结构定位到 id = 1的第一条记录，如果记录是不存在的，就会向执行器上报记录找不到的错误，然后查询结束。如果记录是存在的，就会将记录返回给执行器； 执行器从存储引擎读到记录后，接着判断记录是否符合查询条件，如果符合则发送给客户端，如果不符合则跳过该记录。 执行器查询的过程是一个 while 循环，所以还会再查一次，但是这次因为不是第一次查询了，所以会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为一个永远返回 - 1 的函数，所以当调用该函数的时候，执行器就退出循环，也就是结束查询了。 全表扫描 1select * from product where name = 'iphone'; 这条查询语句的查询条件没有用到索引，所以优化器决定选用访问类型为 ALL 进行查询，也就是全表扫描的方式查询，那么这时执行器与存储引擎的执行流程是这样的： 执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 all，这个函数指针被指向为 InnoDB 引擎全扫描的接口，让存储引擎读取表中的第一条记录； 执行器会判断读到的这条记录的 name 是不是 iphone，如果不是则跳过；如果是则将记录发给客户的（是的没错，Server 层每从存储引擎读到一条记录就会发送给客户端，之所以客户端显示的时候是直接显示所有记录的，是因为客户端是等查询语句查询完成后，才会显示出所有的记录）。 执行器查询的过程是一个 while 循环，所以还会再查一次，会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 all，read_record 函数指针指向的还是 InnoDB 引擎全扫描的接口，所以接着向存储引擎层要求继续读刚才那条记录的下一条记录，存储引擎把下一条记录取出后就将其返回给执行器（Server层），执行器继续判断条件，不符合查询条件即跳过该记录，否则发送到客户端； 一直重复上述过程，直到存储引擎把表中的所有记录读完，然后向执行器（Server层） 返回了读取完毕的信息； 执行器收到存储引擎报告的查询完毕的信息，退出循环，停止查询。 索引下推 索引下推能够减少二级索引在查询时的回表操作，提高查询的效率，因为它将 Server 层部分负责的事情，交给存储引擎层去处理了。 1select * from t_user where age &gt; 20 and reward = 100000; 联合索引当遇到范围查询 (&gt;、&lt;) 就会停止匹配，也就是 age 字段能用到联合索引，但是 reward 字段则无法利用到索引 那么，不使用索引下推（MySQL 5.6 之前的版本）时，执行器与存储引擎的执行流程是这样的： Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录； 存储引擎根据二级索引的 B+ 树快速定位到这条记录后，获取主键值，然后进行回表操作，将完整的记录返回给 Server 层； Server 层在判断该记录的 reward 是否等于 100000，如果成立则将其发送给客户端；否则跳过该记录； 接着，继续向存储引擎索要下一条记录，存储引擎在二级索引定位到记录后，获取主键值，然后回表操作，将完整的记录返回给 Server 层； 如此往复，直到存储引擎把表中的所有记录读完。 可以看到，没有索引下推的时候，每查询到一条二级索引记录，都要进行回表操作，然后将记录返回给 Server，接着 Server 再判断该记录的 reward 是否等于 100000。 而使用索引下推后，判断记录的 reward 是否等于 100000 的工作交给了存储引擎层，过程如下 ： Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录； 存储引擎定位到二级索引后，先不执行回表操作，而是先判断一下该索引中包含的列（reward列）的条件（reward 是否等于 100000）是否成立。如果条件不成立，则直接跳过该二级索引。如果成立，则执行回表操作，将完成记录返回给 Server 层。 Server 层在判断其他的查询条件（本次查询没有其他条件）是否成立，如果成立则将其发送给客户端；否则跳过该记录，然后向存储引擎索要下一条记录。 如此往复，直到存储引擎把表中的所有记录读完。 可以看到，使用了索引下推后，虽然 reward 列无法使用到联合索引，但是因为它包含在联合索引（age，reward）里，所以直接在存储引擎过滤出满足 reward = 100000 的记录后，才去执行回表操作获取整个记录。相比于没有使用索引下推，节省了很多回表操作。 mysql一行记录是如何存储的我们每创建一个 database（数据库） 都会在 /var/lib/mysql/ 目录里面创建一个以 database 为名的目录，然后保存表结构和表数据的文件都会存放在这个目录里。 比如，我这里有一个名为 my_test 的 database，该 database 里有一张名为 t_order 数据库表。 此时数据库目录下共有三个文件，这三个文件分别代表着： db.opt，用来存储当前数据库的默认字符集和字符校验规则。 t_order.frm ，t_order 的表结构会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。 t_order.ibd，t_order 的表数据会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .ibd 文件。 好了，现在我们知道了一张数据库表的数据是保存在「 表名字.ibd 」的文件里的，这个文件也称为独占表空间文件。 表空间文件的结构表空间由段（segment）、区（extent）、页（page）、行（row）组成，InnoDB存储引擎的逻辑存储结构大致如下图： 1、行（row） 数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。 后面我们详细介绍 InnoDB 存储引擎的行格式，也是本文重点介绍的内容。 2、页（page，数据库存储的基本单位）：记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。 因此，InnoDB 的数据是按「页」为单位来读写的，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。 默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间。 页是 InnoDB 存储引擎磁盘管理的最小单元，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。 页的类型有很多，常见的有数据页、undo 日志页、溢出页等等。 3、区（extent，数据库分配空间的基本单位） 我们知道 InnoDB 存储引擎是用 B+ 树来组织数据的。 B+ 树中每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I/O，随机 I/O 是非常慢的。 解决这个问题也很简单，就是让链表中相邻的页的物理位置也相邻，这样就可以使用顺序 I/O 了，那么在范围查询（扫描叶子节点）的时候性能就会很高。 那具体怎么解决呢？ 在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。 4、段（segment） 表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。 索引段：存放 B + 树的非叶子节点的区的集合； 数据段：存放 B + 树的叶子节点的区的集合； 回滚段：存放的是回滚数据的区的集合，之前讲事务隔离 (opens new window)的时候就介绍到了 MVCC 利用了回滚段实现了多版本查询数据。 Innodb行格式有哪些InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。 Redundant 是很古老的行格式了， MySQL 5.0 版本之前用的行格式，现在基本没人用了。 由于 Redundant 不是一种紧凑的行格式，所以 MySQL 5.0 之后引入了 Compact 行记录存储方式 Compact 是一种紧凑的行格式，设计的初衷就是为了让一个数据页中可以存放更多的行记录，从 MySQL 5.1 版本之后，行格式默认设置成 Compact。 Dynamic 和 Compressed 两个都是紧凑的行格式，它们的行格式都和 Compact 差不多，因为都是基于 Compact 改进一点东西。 从 MySQL5.7 版本之后，默认使用 Dynamic 行格式。 Redundant 行格式我这里就不讲了，因为现在基本没人用了，这次重点介绍 Compact 行格式，因为 Dynamic 和 Compressed 这两个行格式跟 Compact 非常像。 所以，弄懂了 Compact 行格式，之后你们在去了解其他行格式，很快也能看懂。 Compact行格式 记录的额外信息： 变长字段长度列表：varchar(n) 和 char(n) 的区别是什么，相信大家都非常清楚，char 是定长的，varchar 是变长的，变长字段实际存储的数据的长度（大小）不固定的。 所以，在存储数据的时候，也要把数据占用的大小存起来，存到「变长字段长度列表」里面，读取数据的时候才能根据这个「变长字段长度列表」去读取对应长度的数据。变长字段的真实数据占用的字节数会按照列的顺序逆序存放 「记录头信息」中指向下一个记录的指针，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。 「变长字段长度列表」中的信息之所以要逆序存放，是因为这样可以使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率。 同样的道理， NULL 值列表的信息也需要逆序存放。 NULL值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。 如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。 二进制位的值为1时，代表该列的值为NULL。 二进制位的值为0时，代表该列的值不为NULL。 另外，NULL 值列表必须用整数个字节的位表示（1字节8位），如果使用的二进制位个数不足整数个字节，则在字节的高位补 0。 记录头信息：记录头信息中包含的内容很多，我就不一一列举了，这里说几个比较重要的： delete_mask ：标识此条数据是否被删除。从这里可以知道，我们执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1。 next_record：下一条记录的位置。从这里可以知道，记录与记录之间是通过链表组织的。在前面我也提到了，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。 record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录 记录的真实数据： row_id 如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。 trx_id 事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。 roll_pointer 这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。","link":"/2025/03/03/interview/mysql/1%E3%80%81%E5%9F%BA%E7%A1%80/"},{"title":"2、mysql索引","text":"点击阅读更多查看文章内容 什么是索引？索引的定义就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是索引是数据的目录。 所谓的存储引擎，说白了就是如何存储数据、如何为存储的数据建立索引和如何更新、查询数据等技术的实现方法。MySQL 存储引擎有 MyISAM 、InnoDB、Memory，其中 InnoDB 是在 MySQL 5.5 之后成为默认的存储引擎。 索引底层数据结构选型Hash 表 哈希表是键值对的集合，通过键(key)即可快速取出对应的值(value)，因此哈希表可以快速检索数据（接近 O(1)）。 不适合作为索引的原因： Hash 索引不支持顺序和范围查询。假如我们要对表中的数据进行排序或者进行范围查询，那 Hash索引可就不行了。 Hash 索引每次 IO 只能取一个。 BST 二叉查找树（Binary Search Tree）具有以下特点： 1、左子树所有节点的值均小于根节点的值。 2、右子树所有节点的值均大于根节点的值。 3、左右子树也分别为二叉查找树。 不适合作为索引的原因： 二叉查找树的性能非常依赖于它的平衡程度。在最坏情况下（有序插入节点），树会退化成线性链表（也被称为斜树），导致查询效率急剧下降，时间复杂退化为 O(N) AVL树 保证任何节点的左右子树高度之差不超过 1，因此也被称为高度平衡二叉树， 不适合作为索引的原因： AVL 树需要频繁地进行旋转操作来保持平衡，计算开销大，降低数据库写操作的性能。 在使用 AVL 树时，每个树节点仅存储一个数据，每次进行磁盘 IO 时只能读取一个节点的数据，如果需要查询的数据分布在多个节点上，那么就需要进行多次磁盘 IO。 （磁盘 IO 是一项耗时的操作，在设计数据库索引时，我们需要优先考虑如何最大限度地减少磁盘 IO 操作的次数。） 红黑树 红黑树是一种自平衡二叉查找树，通过在插入和删除节点时进行颜色变换和旋转操作，使得树始终保持平衡状态。树的高度始终维持在 O(log n) 级别，避免普通二叉搜索树（BST）可能退化为链表的问题。 特点： 每个节点非红即黑； 根节点总是黑色的； 每个叶子节点都是黑色的空节点（NIL 节点）； 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）； 从任意节点到它的叶子节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。 不适合作为索引的原因： 红黑树的查询效率稍有下降：红黑树并不追求严格的平衡，而是大致的平衡。 一些数据需要进行多次磁盘 IO 操作才能查询到。因为平衡性相对较弱，可能会导致树的高度较高。 B 树&amp; B+ 树 B 树也称 B- 树，全称为 多路平衡查找树，B+ 树是 B 树的一种变体。B 树和 B+ 树中的 B 是 Balanced（平衡）的意思。 目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。 B 树&amp; B+ 树两者有何异同呢？ B 树的所有节点既存放键(key)也存放数据(data)，而 B+ 树只有叶子节点存放 key 和 data，其他内节点只存放 key。 B 树的叶子节点都是独立的；B+ 树的叶子节点有一条引用链指向与它相邻的叶子节点。 B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+ 树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。 在 B 树中进行范围查询时，首先找到要查找的下限，然后对 B 树进行中序遍历，直到找到查找的上限；而 B+ 树的范围查询，只需要对链表进行遍历即可。 综上，B+ 树与 B 树相比，具备更少的 IO 次数、更稳定的查询效率和更适于范围查询这些优势。 索引的分类 按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。 按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。 按「字段个数」分类：单列索引、联合索引。 按数据结构分类从数据结构的角度来看，MySQL 常见索引有 B+Tree 索引、HASH 索引、Full-Text 索引。 每一种存储引擎支持的索引类型不一定相同，我在表中总结了 MySQL 常见的存储引擎 InnoDB、MyISAM 和 Memory 分别支持的索引类型。 在创建表时，InnoDB 存储引擎会根据不同的场景选择不同的列作为主键索引： 如果有主键，默认会使用主键作为聚簇索引的索引键（key）； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）； 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）； 除了主键索引外其他创建的索引都属于辅助索引（Secondary Index），也被称为二级索引或非聚簇索引。创建的主键索引和二级索引默认使用的是 B+Tree 索引。 B+Tree的实现可参考：二叉搜索树、B-树、B+树_二叉树 b树 b-树 b+树-CSDN博客 假设目前有如下表数据，其中id为主键 主键索引的 B+Tree 如图所示（图中叶子节点之间画了单向链表，但是实际上是双向链表） 通过主键查询商品数据的过程 比如，我们执行了下面这条查询语句： select * from product where id= 5; 这条语句使用了主键索引查询 id 号为 5 的商品。查询过程是这样的 B+Tree 会自顶向下逐层进行查找： 将 5 与根节点的索引数据 (1，10，20) 比较，5 在 1 和 10 之间，所以根据 B+Tree的搜索逻辑，找到第二层的索引数据 (1，4，7)； 在第二层的索引数据 (1，4，7)中进行查找，因为 5 在 4 和 7 之间，所以找到第三层的索引数据（4，5，6）； 在叶子节点的索引数据（4，5，6）中进行查找，然后我们找到了索引值为 5 的行数据。 数据库的索引和数据都是存储在硬盘的，我们可以把读取一个节点当作一次磁盘 I/O 操作。那么上面的整个查询过程一共经历了 3 个节点，也就是进行了 3 次 I/O 操作。 B+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，这意味着从千万级的表查询目标数据最多需要 3-4 次磁盘 I/O，所以B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次 通过二级索引查询商品数据的过程 主键索引的 B+Tree 和二级索引的 B+Tree 区别如下： 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里； 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。 我这里将前面的商品表中的 product_no （商品编码）字段设置为二级索引，那么二级索引的 B+Tree 如下图（补成双向链表就行）。 回表如果我用 product_no 二级索引查询商品，如下查询语句： select * from product where product_no = '0002'; 会先检二级索引中的 B+Tree 的索引值（商品编码，product_no），找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据。如下图： 覆盖索引覆盖索引指的是索引本身包含了查询所需要的所有数据（字段），因此不需要回表（即不需要查询原始数据表），直接从索引中就能获取结果，比如下面这条查询语句： select id from product where product_no = ‘0002’; 这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据。 按照物理存储分类从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引（辅助索引）。 这两个区别在前面也提到了： 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里； 聚簇索引（Clustered Index） 是一种特殊的索引结构，其核心特点是：索引的顺序直接决定了表中数据的物理存储顺序。数据行实际存储在索引树的叶子节点中，而非独立于索引之外。在数据库中，聚簇索引和数据的物理存储方式紧密相关，因此一个表只能有一个聚簇索引。 数据与索引绑定 物理存储有序 主键默认是聚簇索引 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。 所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表 按字段特性分类从字段特性的角度来看，索引分为主键索引、唯一索引、普通索引、前缀索引。 主键索引 主键索引就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。 唯一索引 建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。 普通索引 普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。 前缀索引 前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。 使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率 按字段个数分类从字段个数的角度来看，索引分为单列索引、联合索引（复合索引）。 建立在单列上的索引称为单列索引，比如主键索引； 建立在多列上的索引称为联合索引； 联合索引 通过将多个字段组合成一个索引，该索引就被称为联合索引。 比如，将商品表中的 product_no 和 name 字段组合成联合索引(product_no, name)，创建联合索引的方式如下： CREATE INDEX index_product_no_name ON product(product_no, name); 联合索引(product_no, name) 的 B+Tree 示意图如下 可以看到，联合索引的非叶子节点用两个字段的值作为 B+Tree 的 key 值。当在联合索引查询数据时，先按 product_no 字段比较，在 product_no 相同的情况下再按 name 字段比较。 也就是说，联合索引查询的 B+Tree 是先按 product_no 进行排序，然后再 product_no 相同的情况再按 name 字段排序。 因此，使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。 比如，如果创建了一个 (a, b, c) 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引： where a=1； where a=1 and b=2 and c=3； where a=1 and b=2； 需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效: where b=2； where c=3； where b=2 and c=3； 上面这些查询条件之所以会失效，是因为(a, b, c) 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，b 和 c 是全局无序，局部相对有序的，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。 我这里举联合索引（a，b）的例子，该联合索引的 B+ Tree 如下 可以看到，a 是全局有序的（1, 2, 2, 3, 4, 5, 6, 7 ,8），而 b 是全局是无序的（12，7，8，2，3，8，10，5，2）。因此，直接执行where b = 2这种查询条件没有办法利用联合索引的，利用索引的前提是索引里的 key 是有序的。 只有在 a 相同的情况才，b 才是有序的，比如 a 等于 2 的时候，b 的值为（7，8），这时就是有序的，这个有序状态是局部的，因此，执行where a = 2 and b = 7是 a 和 b 字段能用到联合索引的，也就是联合索引生效了。 联合索引范围查询联合索引有一些特殊情况，并不是查询过程使用了联合索引查询，就代表联合索引中的所有字段都用到了联合索引进行索引查询，也就是可能存在部分字段用到联合索引的 B+Tree，部分字段没有用到联合索引的 B+Tree 的情况。 这种特殊情况就发生在范围查询。联合索引的最左匹配原则会一直向右匹配直到遇到「范围查询」就会停止匹配。也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。 范围查询有很多种，那到底是哪些范围查询会导致联合索引的最左匹配原则会停止匹配呢？ Q1: select * from t_table where a &gt; 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ 由于联合索引（二级索引）是先按照 a 字段的值排序的，所以符合 a &gt; 1 条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合 a &gt; 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a &gt; 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询。 但是在符合 a &gt; 1 条件的二级索引记录的范围里，b 字段的值是无序的。因此，我们不能根据查询条件 b = 2 来进一步减少需要扫描的记录数量（b 字段无法利用联合索引进行索引查询的意思）。 所以在执行 Q1 这条查询语句的时候，对应的扫描区间是 (2, + ∞)，形成该扫描区间的边界条件是 a &gt; 1，与 b = 2 无关。 因此，Q1 这条查询语句只有 a 字段用到了联合索引进行索引查询，而 b 字段并没有使用到联合索引。 通过 Q1 查询语句我们可以知道，a 字段使用了 &gt; 进行范围查询，联合索引的最左匹配原则在遇到 a 字段的范围查询（ &gt;）后就停止匹配了，因此 b 字段并没有使用到联合索引。 Q2: select * from t_table where a &gt;= 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ Q2 和 Q1 的查询语句很像，唯一的区别就是 a 字段的查询条件「大于等于」。 由于联合索引（二级索引）是先按照 a 字段的值排序的，所以符合 &gt;= 1 条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合 &gt;= 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a&gt;= 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询。 虽然在符合 a&gt;= 1 条件的二级索引记录的范围里，b 字段的值是「无序」的，但是对于符合 a = 1 的二级索引记录的范围里，b 字段的值是「有序」的（因为对于联合索引，是先按照 a 字段的值排序，然后在 a 字段的值相同的情况下，再按照 b 字段的值进行排序）。 于是，在确定需要扫描的二级索引的范围时，当二级索引记录的 a 字段值为 1 时，可以通过 b = 2 条件减少需要扫描的二级索引记录范围（b 字段可以利用联合索引进行索引查询的意思）。也就是说，从符合 a = 1 and b = 2 条件的第一条记录开始扫描，而不需要从第一个 a 字段值为 1 的记录开始扫描。 所以，Q2 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 Q3: SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ Q3 查询条件中 a BETWEEN 2 AND 8 的意思是查询 a 字段的值在 2 和 8 之间的记录。不同的数据库对 BETWEEN … AND 处理方式是有差异的。在 MySQL 中，BETWEEN 包含了 value1 和 value2 边界值，类似于 **&gt;= and =&lt;**。而有的数据库则不包含 value1 和 value2 边界值（类似于 &gt; and &lt;）。 这里我们只讨论 MySQL。由于 MySQL 的 BETWEEN 包含 value1 和 value2 边界值，所以类似于 Q2 查询语句，因此 Q3 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 Q4: SELECT * FROM t_user WHERE name like ‘j%’ and age = 22，联合索引（name, age）哪一个字段用到了联合索引的 B+Tree？ 由于联合索引（二级索引）是先按照 name 字段的值排序的，所以前缀为 ‘j’ 的 name 字段的二级索引记录都是相邻的， 于是在进行索引扫描的时候，可以定位到符合前缀为 ‘j’ 的 name 字段的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录的 name 前缀不为 ‘j’ 为止。 所以 a 字段可以在联合索引的 B+Tree 中进行索引查询，形成的扫描区间是[‘j’,’k’)。注意， j 是闭区间。如下图： 虽然在符合前缀为 ‘j’ 的 name 字段的二级索引记录的范围里，age 字段的值是「无序」的，但是对于符合 name = j 的二级索引记录的范围里，age字段的值是「有序」的（因为对于联合索引，是先按照 name 字段的值排序，然后在 name 字段的值相同的情况下，再按照 age 字段的值进行排序）。 于是，在确定需要扫描的二级索引的范围时，当二级索引记录的 name 字段值为 ‘j’ 时，可以通过 age = 22 条件减少需要扫描的二级索引记录范围（age 字段可以利用联合索引进行索引查询的意思）。也就是说，从符合 name = ‘j’ and age = 22 条件的第一条记录时开始扫描，而不需要从第一个 name 为 j 的记录开始扫描 。如下图的右边： 所以，Q4 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。 综上所示，联合索引的最左匹配原则，在遇到范围查询（如 &gt;、&lt;）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 &gt;=、&lt;=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配，前面我也用了四个例子说明了 索引下推索引下推是指数据库在使用索引扫描时，将查询条件的部分计算任务“下推”到索引扫描阶段，而不是等到扫描完整个数据表后再进行计算。 现在我们知道，对于联合索引（a, b），在执行 select * from table where a &gt; 1 and b = 2 语句的时候，只有 a 字段能用到索引，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后，还需要判断其他条件是否满足（看 b 是否等于 2），那是在联合索引里判断？还是回主键索引去判断呢？ 在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 当你的查询语句的执行计划里，出现了 Extra 为 Using index condition，那么说明使用了索引下推的优化。 索引区分度另外，建立联合索引时的字段顺序，对索引效率也有很大影响。越靠前的字段被用于索引过滤的概率越高，实际开发工作中建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到。 区分度就是某个字段 column 不同值的个数「除以」表的总行数，计算公式如下： 比如，性别的区分度就很小，不适合建立索引或不适合排在联合索引列的靠前的位置，而 UUID 这类字段就比较适合做索引或排在联合索引列的靠前的位置。 因为如果索引的区分度很小，假设字段的值分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比（惯用的百分比界线是”30%”）很高的时候，它一般会忽略索引，进行全表扫描。 联合索引进行排序联合索引进行排序 这里出一个题目，针对针对下面这条 SQL，你怎么通过索引来提高查询效率呢？select * from order where status = 1 order by create_time asc 有的同学会认为，单独给 status 建立一个索引就可以了。 但是更好的方式给 status 和 create_time 列建立一个联合索引，因为这样可以避免 MySQL 数据库发生文件排序。 因为在查询时，如果只用到 status 的索引，但是这条语句还要对 create_time 排序，这时就要用文件排序 filesort，也就是在 SQL 执行计划中，Extra 列会出现 Using filesort。 所以，要利用索引的有序性，在 status 和 create_time 列建立联合索引，这样根据 status 筛选后的数据就是按照 create_time 排好序的，避免在文件排序，提高了查询效率。 什么时候需要创建索引索引最大的好处是提高查询速度，但是索引也是有缺点的，比如： 需要占用物理空间，数量越大，占用空间越大； 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大； 会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。 所以，索引不是万能钥匙，它也是根据场景来使用的。 什么时候适用索引？ 字段有唯一性限制的，比如商品编码； 不为 NULL 的字段：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0、1、true、false 这样语义较为清晰的短值或短字符作为替代 被频繁查询的字段：我们创建索引的字段应该是查询操作非常频繁的字段。 被作为条件查询的字段：被作为 WHERE 条件查询的字段，应该被考虑建立索引。 频繁需要排序的字段：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。 什么时候不需要创建索引？ WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。 表数据太少的时候，不需要创建索引； 经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。 尽可能的考虑建立联合索引而不是单列索引 因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗 B+ 树。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。 索引优化方法 前缀索引优化； 覆盖索引优化； 主键索引最好是自增的； 防止索引失效； 前缀索引优化前缀索引顾名思义就是使用某个字段中字符串的前几个字符建立索引，那我们为什么需要使用前缀来建立索引呢？ 使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。 不过，前缀索引有一定的局限性，例如： order by 就无法使用前缀索引； 无法把前缀索引用作覆盖索引； 覆盖索引优化覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。 假设我们只需要查询商品的名称、价格，有什么方式可以避免回表呢？ 我们可以建立一个联合索引，即「商品ID、名称、价格」作为一个联合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表。 所以，使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。 主键索引最好是自增的我们在建表的时候，都会默认将主键索引设置为自增的，具体为什么要这样做呢？又什么好处？ InnoDB 创建主键索引默认为聚簇索引，数据被存放在了 B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的，因此，每当有一条新的数据插入时，数据库会根据主键将其插入到对应的叶子节点中。 如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。 如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率 索引最好设置为 NOT NULL为了更好的利用索引，索引列要设置为 NOT NULL 约束。有两个原因： 第一原因：索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。 第二个原因：NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题，因为 InnoDB 存储记录的时候，如果表中存在允许为 NULL 的字段，那么行格式 (opens new window)中至少会用 1 字节空间存储 NULL 值列表，如下图的紫色部分： 防止索引失效用上了索引并不意味着查询的时候会使用到索引，所以我们心里要清楚有哪些情况会导致索引失效，从而避免写出索引失效的查询语句，否则这样的查询效率是很低的，发生索引失效的情况： 当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效； 当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效； 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。 对于执行计划，参数有： possible_keys 字段表示可能用到的索引； key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引； key_len 表示索引的长度； rows 表示扫描的数据行数。 type 表示数据扫描类型，我们需要重点看这个。 type 字段就是描述了找到所需数据时使用的扫描方式是什么，常见扫描类型的执行效率从低到高的顺序为： All（全表扫描）； index（全索引扫描）； range（索引范围扫描）； ref（非唯一索引扫描）； eq_ref（唯一索引扫描）； const（结果只有一条的主键或唯一索引扫描）。 在这些情况里 all 是最坏的情况，因为采用了全表扫描的方式。 index 和 all 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。所以，要尽量避免全表扫描和全索引扫描。 range 表示采用了索引范围扫描，一般在 where 子句中使用 &lt; 、&gt;、in、between 等关键词，只检索给定范围的行，属于范围查找。从这一级别开始，索引的作用会越来越明显，因此我们需要尽量让 SQL 查询可以使用到 range 这一级别及以上的 type 访问方式。 ref 类型表示采用了非唯一索引，或者是唯一索引的非唯一性前缀，返回数据返回可能是多条。因为虽然使用了索引，但该索引列的值并不唯一，有重复。这样即使使用索引快速查找到了第一条数据，仍然不能停止，要进行目标值附近的小范围扫描。但它的好处是它并不需要扫全表，因为索引是有序的，即便有重复值，也是在一个非常小的范围内扫描。 eq_ref 类型是使用主键或唯一索引时产生的访问方式，通常使用在多表联查中。比如，对两张表进行联查，关联条件是两张表的 user_id 相等，且 user_id 是唯一索引，那么使用 EXPLAIN 进行执行计划查看的时候，type 就会显示 eq_ref。 const 类型表示使用了主键或者唯一索引与常量值进行比较，比如 select name from product where id=1。 需要说明的是 const 类型和 eq_ref 都使用了主键或唯一索引，不过这两个类型有所区别，const 是与常量进行比较，查询效率会更快，而 eq_ref 通常用于多表联查中 B+Tree的优点B+Tree vs B Tree 单点查询 B 树进行单个索引查询时，最快可以在 O(1) 的时间代价内就查到，而从平均时间代价来看，会比 B+ 树稍快一些。 但是 B 树的查询波动会比较大，因为每个节点即存索引又存记录，所以有时候访问到了非叶子节点就可以找到索引，而有时需要访问到叶子节点才能找到索引。 B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少 插入和删除效率 B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快，B 树则不同，B 树没有冗余节点，删除节点的时候非常复杂。 范围查询 B 树和 B+ 树等值查询原理基本一致，先从根节点查找，然后对比目标数据的范围，最后递归的进入子节点查找。因为 B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助，比如说我们想知道 12 月 1 日和 12 月 12 日之间的订单，这个时候可以先查找到 12 月 1 日所在的叶子节点，然后利用链表向右遍历，直到找到 12 月12 日的节点，这样就不需要从根节点查询了，进一步节省查询需要的时间。 而 B 树没有将所有叶子节点用链表串联起来的结构，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。 因此，存在大量范围检索的场景，适合使用 B+树，比如数据库。而对于大量的单个索引查询的场景，可以考虑 B 树，比如 nosql 的MongoDB。 B+Tree vs Hash Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。 但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因 索引失效有哪些？对索引使用左或者左右模糊匹配当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx% 这两种方式都会造成索引失效。 因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。 对索引使用函数有时候我们会用一些 MySQL 自带的函数来得到我们想要的结果，这时候要注意了，如果查询条件中对索引字段使用函数，就会导致索引失效 因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了。 不过，从 MySQL 8.0 开始，索引特性增加了函数索引，即可以针对函数计算后的值建立一个索引，也就是说该索引的值是函数计算后的值，所以就可以通过扫描索引来查询数据。 举个例子，我通过下面这条语句，对 length(name) 的计算结果建立一个名为 idx_name_length 的索引。 alter table t_user add key idx_name_length ((length(name))); 然后我再用下面这条查询语句，这时候就会走索引了。 对索引进行表达式计算在查询条件中对索引进行表达式计算，也是无法走索引的。 比如，下面这条查询语句 explain select * from t_user where id + 1 = 10; 但是，如果把查询语句的条件改成 where id = 10 - 1，这样就不是在索引字段进行表达式计算了，于是就可以走索引查询了。 原因跟对索引使用函数差不多。 因为索引保存的是索引字段的原始值，而不是 id + 1 表达式计算后的值，所以无法走索引，只能通过把索引字段的取值都取出来，然后依次进行表达式的计算来进行条件判断，因此采用的就是全表扫描的方式。 有的同学可能会说，这种对索引进行简单的表达式计算，在代码特殊处理下，应该是可以做到索引扫描的，比方将 id + 1 = 10 变成 id = 10 - 1。 是的，是能够实现，但是 MySQL 还是偷了这个懒，没有实现。 对索引隐式类型转换如果索引字段是字符串类型，但是在条件查询中，如果索引是字符串输入是整型类型的话，你会在执行计划的结果发现这条语句会走全表扫描。但是如果索引字段是整型类型，查询条件中的输入参数即使字符串，是不会导致索引失效，还是可以走索引扫描。 这是因为 MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果索引是字符串那么在比较时会将其转为数字也就是对索引使用了函数！而前面我们也说了，对索引使用函数是会导致索引失效的。 联合索引非最左匹配对主键字段建立的索引叫做聚簇索引，对普通字段建立的索引叫做二级索引。 那么多个普通字段组合在一起创建的索引就叫做联合索引，也叫组合索引。 创建联合索引时，我们需要注意创建时的顺序问题，因为联合索引 (a, b, c) 和 (c, b, a) 在使用的时候会存在差别。 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配。 比如，如果创建了一个 (a, b, c) 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引： where a=1； where a=1 and b=2 and c=3； where a=1 and b=2； 需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。 但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效: where b=2； where c=3； where b=2 and c=3； 有一个比较特殊的查询条件：where a = 1 and c = 3 ，符合最左匹配吗？ 这种其实严格意义上来说是属于索引截断，不同版本处理方式也不一样。 MySQL 5.5 的话，前面 a 会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行，Server 层从存储引擎层获取到数据行后，然后在 Server 层再比对 c 字段的值。 从 MySQL 5.6 之后，有一个索引下推功能，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。索引下推的大概原理是：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为 c 字段的值是在 (a, b, c) 联合索引里的），然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。 为什么联合索引不遵循最左匹配原则就会失效？ 原因是，在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。 也就是说，如果我们想使用联合索引中尽可能多的列，查询条件中的各个列必须是联合索引中从最左边开始连续的列。如果我们仅仅按照第二列搜索，肯定无法走索引 WHERE 子句中的 OR在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。这是因为 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描。要使用索引需要对OR前后的条件都设置索引。 count() count() 是什么？ count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个。 假设 count() 函数的参数是字段名，如下： select count(name) from t_order; 这条语句是统计「 t_order 表中，name 字段不为 NULL 的记录」有多少个。也就是说，如果某一条记录中的 name 字段的值为 NULL，则就不会被统计进去。 再来假设 count() 函数的参数是数字 1 这个表达式，如下： select count(1) from t_order; 这条语句是统计「 t_order 表中，1 这个表达式不为 NULL 的记录」有多少个。 1 这个表达式就是单纯数字，它永远都不是 NULL，所以上面这条语句，其实是在统计 t_order 表中有多少个记录 **count(主键字段) ** 在通过 count 函数统计有多少个记录时，MySQL 的 server 层会维护一个名叫 count 的变量。 server 层会循环向 InnoDB 读取一条记录，如果 count 函数指定的参数不为 NULL，那么就会将变量 count 加 1，直到符合查询的全部记录被读完，就退出循环。最后将 count 变量的值发送给客户端。 InnoDB 是通过 B+ 树来保存记录的，根据索引的类型又分为聚簇索引和二级索引，它们区别在于，聚簇索引的叶子节点存放的是实际数据，而二级索引的叶子节点存放的是主键值，而不是实际数据。 如果表里只有主键索引，没有二级索引时，那么，InnoDB 循环遍历聚簇索引，将读取到的记录返回给 server 层，然后读取记录中的 id 值，就会 id 值判断是否为 NULL，如果不为 NULL，就将 count 变量加 1。 但是，如果表里有二级索引时，InnoDB 循环遍历的对象就不是聚簇索引，而是二级索引。 这是因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I/O 成本比遍历聚簇索引的 I/O 成本小，因此「优化器」优先选择的是二级索引 **count(1) ** 如果表里只有主键索引，没有二级索引时。InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，但是不会读取记录中的任何字段的值，因为 count 函数的参数是 1，不是字段，所以不需要读取记录中的字段值。参数 1 很明显并不是 NULL，因此 server 层每从 InnoDB 读取到一条记录，就将 count 变量加 1。 可以看到，count(1) 相比 count(主键字段) 少一个步骤，就是不需要读取记录中的字段值，所以通常会说 count(1) 执行效率会比 count(主键字段) 高一点。但是，如果表里有二级索引时，InnoDB 循环遍历的对象就二级索引了。 *count() ** 看到 * 这个字符的时候，是不是大家觉得是读取记录中的所有字段值？ 对于 selete * 这条语句来说是这个意思，但是在 count() 中并不是这个意思。 count(*) 其实等于 count(0)，也就是说，当你使用 count() 时，MySQL 会将 * 参数转化为参数 0 来处理。 所以，count() 执行过程跟 count(1) 执行过程基本一样的，性能没有什么差异。 在 MySQL 5.7 的官方手册中有这么一句话：InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference. 而且 MySQL 会对 count() 和 count(1) 有个优化，如果有多个二级索引的时候，优化器会使用key_len 最小的二级索引进行扫描。 只有当没有二级索引的时候，才会采用主键索引来进行统计 count(字段) count(字段) 的执行效率相比前面的 count(1)、 count(*)、 count(主键字段) 执行效率是最差的。 对于这个查询来说，会采用全表扫描的方式来计数，所以它的执行效率是比较差的。 如何优化count(*)如果对一张大表经常用 count() 来做统计，其实是很不好的。 比如下面我这个案例，表 t_order 共有 1200+ 万条记录，我也创建了二级索引，但是执行一次 select count() from t_order 要花费差不多 5 秒！ 第一种，近似值 如果你的业务对于统计个数不需要很精确，比如搜索引擎在搜索关键词的时候，给出的搜索结果条数是一个大概值。 这时，我们就可以使用 show table status 或者 explain 命令来表进行估算。 执行 explain 命令效率是很高的，因为它并不会真正的去查询，下图中的 rows 字段值就是 explain 命令对表 t_order 记录的估算值。 第二种，额外表保存计数值 如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。 当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新增和删除操作时，我们需要额外维护这个计数表。","link":"/2025/03/03/interview/mysql/2%E3%80%81%E7%B4%A2%E5%BC%95/"},{"title":"3、mysql事务","text":"点击阅读更多查看文章内容 事务特性事务是由 MySQL 的引擎来实现的，我们常见的 InnoDB 引擎它是支持事务的。 不过并不是所有的引擎都能支持事务，比如 MySQL 原生的 MyISAM 引擎就不支持事务，也正是这样，所以大多数 MySQL 的引擎都是用 InnoDB。 事务看起来感觉简单，但是要实现事务必须要遵守 4 个特性，分别如下： 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成 一致性（Consistency）：一致性确保事务执行前后，数据库从一个有效状态转换到另一个有效状态。在转账操作中，事务执行后，两个账户的总金额应保持不变，即100元从一个账户转移到另一个账户，不会凭空增加或减少资金。 隔离性（Isolation）：隔离性确保并发执行的多个事务彼此独立，互不干扰。 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！ InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？ 持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性是通过约束检查来保证的 并行事务会引发什么问题？MySQL 服务端是允许多个客户端连接的，这意味着 MySQL 会出现同时处理多个事务的情况。 那么在同时处理多个事务的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题。 接下来，通过举例子给大家说明，这些问题是如何发生的。 脏读如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。 举个栗子。 假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后再执行更新操作，如果此时事务 A 还没有提交事务，而此时正好事务 B 也从数据库中读取小林的余额数据，那么事务 B 读取到的余额数据是刚才事务 A 更新后的数据，即使没有提交事务。 因为事务 A 是还没提交事务的，也就是它随时可能发生回滚操作，如果在上面这种情况事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据，这种现象就被称为脏读。 不可重复读在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。 涉及范围：只影响单行或多行的特定记录。 变化类型：通常是更新（UPDATE）操作引起的改变。 举个栗子。 假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后继续执行代码逻辑处理，在这过程中如果事务 B 更新了这条数据，并提交了事务，那么当事务 A 再次读取该数据时，就会发现前后两次读到的数据是不一致的，这种现象就被称为不可重复读。 幻读在一个事务内，两次执行相同的查询语句时，得到的结果集不同，就意味着发生了「幻读」现象。 这种情况通常是由于另一个事务在这段时间内插入或删除了一些符合条件的记录 涉及范围：影响一组记录的整体集合，而不是单个记录。 变化类型：通常是插入（INSERT）或删除（DELETE）操作引起的改变。 举个栗子。 假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库查询账户余额大于 100 万的记录，发现共有 5 条，然后事务 B 也按相同的搜索条件也是查询出了 5 条记录。接下来，事务 A 插入了一条余额超过 100 万的账号，并提交了事务，此时数据库超过 100 万余额的账号个数就变为 6。 然后事务 B 再次查询账户余额大于 100 万的记录，此时查询到的记录数量有 6 条，发现和前一次读到的记录数量不一样了，就感觉发生了幻觉一样，这种现象就被称为幻读。 事务的隔离级别有哪些？前面我们提到，当多个事务并发执行时可能会遇到「脏读、不可重复读、幻读」的现象，这些现象会对事务的一致性产生不同程序的影响。 脏读：读到其他事务未提交的数据； 不可重复读：前后读取的数据不一致； 幻读：前后读取的记录数量不一致。 这三个现象的严重性排序如下： SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下： 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到； 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到； 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别； 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行； 按隔离水平高低排序如下： 针对不同的隔离级别，并发事务时可能发生的现象也会不同。 MySQL 在「可重复读」隔离级别下，可以很大程度上避免幻读现象的发生（注意是很大程度避免，并不是彻底避免），所以 MySQL 并不会使用「串行化」隔离级别来避免幻读现象的发生，因为使用「串行化」隔离级别会影响性能，解决的方案有两种： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 接下来，举个具体的例子来说明这四种隔离级别，有一张账户余额表，里面有一条账户余额为 100 万的记录。然后有两个并发的事务，事务 A 只负责查询余额，事务 B 则会将我的余额改成 200 万，下面是按照时间顺序执行两个事务的行为： 在不同隔离级别下，事务 A 执行过程中查询到的余额可能会不同： 在「读未提交」隔离级别下，事务 B 修改余额后，虽然没有提交事务，但是此时的余额已经可以被事务 A 看见了，于是事务 A 中余额 V1 查询的值是 200 万，余额 V2、V3 自然也是 200 万了； 在「读提交」隔离级别下，事务 B 修改余额后，因为没有提交事务，所以事务 A 中余额 V1 的值还是 100 万，等事务 B 提交完后，最新的余额数据才能被事务 A 看见，因此额 V2、V3 都是 200 万； 在「可重复读」隔离级别下，事务 A 只能看见启动事务时的数据，所以余额 V1、余额 V2 的值都是 100 万，当事务 A 提交事务后，就能看见最新的余额数据了，所以余额 V3 的值是 200 万； 在「串行化」隔离级别下，事务 B 在执行将余额 100 万修改为 200 万时，由于此前事务 A 执行了读操作，这样就发生了读写冲突，于是就会被锁住，直到事务 A 提交后，事务 B 才可以继续执行，所以从 A 的角度看，余额 V1、V2 的值是 100 万，余额 V3 的值是 200万。 这四种隔离级别具体是如何实现的呢？ 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了； 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问； 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每次select执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「执行第一个select」生成一个 Read View，然后整个事务期间都在用这个 Read View。 MVCC 如何工作？MVCC（多版本并发控制，Multi-Version Concurrency Control）通过数据的多个版本，让不同事务看到数据库表的不同状态，从而避免加锁带来的性能损耗。在 MVCC 机制下，每条数据在数据库中可能会存在多个版本，不同的事务根据自己的快照时间来读取符合自己可见性规则的版本，而不是直接读取最新的数据。 ReadView 定义了一个事务能看到的数据版本范围，使得同一事务中的多个查询都能看到一致的数据状态，而不会被其他事务的修改影响。 当事务执行 SELECT 语句时，InnoDB 会创建一个 ReadView，它主要包含以下几个关键字段： m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。 min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。 任何小于这个 ID 的事务都已提交，对当前事务可见。（大于这个ID的事务也可能提交，需要判断其是否在m_ids中） max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1； 任何大于等于这个 ID 的事务都尚未开始，对当前事务不可见。 creator_trx_id ：指的是创建该 Read View 的事务的事务 id。 知道了 Read View 的字段，我们还需要了解聚簇索引记录中的两个隐藏列。 假设在账户余额表插入一条小林余额为 100 万的记录，然后我把这两个隐藏列也画出来，该记录的整个示意图如下： 对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列： trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里 roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。 在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况： 一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况： 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。 如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中： 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。 注意，执行「开始事务」命令，并不意味着启动了事务。在 MySQL 有两种开启事务的命令，分别是： 第一种：begin/start transaction 命令； 执行了 begin/start transaction 命令后，并不代表事务启动了。只有在执行这个命令后，执行了第一条 select 语句，才是事务真正启动的时机 第二种：start transaction with consistent snapshot 命令； 执行了 start transaction with consistent snapshot 命令，就会马上启动事务。 RC 和 RR 隔离级别下 MVCC 的差异在事务隔离级别 RC 和 RR （InnoDB 存储引擎的默认事务隔离级别）下，InnoDB 存储引擎使用 MVCC（非锁定一致性读），但它们生成 Read View 的时机却不同 在 RC 隔离级别下的 每次select 查询前都生成一个Read View (m_ids 列表) 在 RR 隔离级别下只在事务开始后 第一次select 数据前生成一个Read View（m_ids 列表） MVCC➕Next-key-Lock 防止幻读InnoDB存储引擎在 RR 级别下通过 MVCC和 Next-key Lock 来解决幻读问题： 1、执行普通 select，此时会以 MVCC 快照读的方式读取数据 在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，并使用至事务提交。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读” 2、执行 select…for update/lock in share mode、insert、update、delete 等当前读 在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Next-key Lock 来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读 可重复读是如何工作的？可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。 假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，那这两个事务创建的 Read View 如下： 事务 A 和 事务 B 的 Read View 具体内容如下： 在事务 A 的 Read View 中，它的事务 id 是 51，由于它是第一个启动的事务，所以此时活跃事务的事务 id 列表就只有 51，活跃事务的事务 id 列表中最小的事务 id 是事务 A 本身，下一个事务 id 则是 52。 在事务 B 的 Read View 中，它的事务 id 是 52，由于事务 A 是活跃的，所以此时活跃事务的事务 id 列表是 51 和 52，活跃的事务 id 中最小的事务 id 是事务 A，下一个事务 id 应该是 53。 接着，在可重复读隔离级别下，事务 A 和事务 B 按顺序执行了以下操作： 事务 B 读取小林的账户余额记录，读到余额是 100 万； 事务 A 将小林的账户余额记录修改成 200 万，并没有提交事务； 事务 B 读取小林的账户余额记录，读到余额还是 100 万； 事务 A 提交事务； 事务 B 读取小林的账户余额记录，读到余额依然还是 100 万； 接下来，跟大家具体分析下。 事务 B 第一次读小林的账户余额记录，在找到记录后，它会先看这条记录的 trx_id，此时发现 trx_id 为 50，比事务 B 的 Read View 中的 min_trx_id 值（51）还小，这意味着修改这条记录的事务早就在事务 B 启动前提交过了，所以该版本的记录对事务 B 可见的，也就是事务 B 可以获取到这条记录。接着，事务 A 通过 update 语句将这条记录修改了（还未提交事务），将小林的余额改成 200 万，这时 MySQL 会记录相应的 undo log，并以链表的方式串联起来，形成版本链，如下图： 然后事务 B 第二次去读取该记录，发现这条记录的 trx_id 值为 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。 最后，当事物 A 提交事务后，由于隔离级别时「可重复读」，所以事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。所以，即使事物 A 将小林余额修改为 200 万并提交了事务， 事务 B 第三次读取记录时，读到的记录都是小林余额是 100 万的这条记录。 读提交是如何工作的？读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View。 也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。 那读提交隔离级别是怎么工作呢？我们还是以前面的例子来聊聊。 假设事务 A （事务 id 为51）启动后，紧接着事务 B （事务 id 为52）也启动了，接着按顺序执行了以下操作： 事务 B 读取数据（创建 Read View），小林的账户余额为 100 万； 事务 A 修改数据（还没提交事务），将小林的账户余额从 100 万修改成了 200 万； 事务 B 读取数据（创建 Read View），小林的账户余额为 100 万； 事务 A 提交事务； 事务 B 读取数据（创建 Read View），小林的账户余额为 200 万； 那具体怎么做到的呢？我们重点看事务 B 每次读取数据时创建的 Read View。前两次 事务 B 读取数据时创建的 Read View 如下图： 我们来分析下为什么事务 B 第二次读数据时，读不到事务 A （还未提交事务）修改的数据？ 事务 B 在找到小林这条记录时，会看这条记录的 trx_id 是 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，接下来需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。而是，沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。 在事务 A 提交后，由于隔离级别是「读提交」，所以事务 B 在每次读数据的时候，会重新创建 Read View，此时事务 B 第三次读取数据时创建的 Read View 如下： 正是因为在读提交隔离级别下，事务每次读数据时都重新创建 Read View，那么在事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。 MySQL 可重复读隔离级别，完全解决幻读了吗?MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 这两个解决方案是很大程度上解决了幻读现象，但是还是有个别的情况造成的幻读现象是无法解决的。 这次，就跟大家好好聊这个问题。 当前读是如何避免幻读的？ MySQL 里除了普通查询是快照读，其他都是当前读，比如 update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。 这很好理解，假设你要 update 一个记录，另一个事务已经 delete 这条记录并且提交事务了，这样不是会产生冲突吗，所以 update 的时候肯定要知道最新的数据。 另外，select … for update 这种查询语句是当前读，每次执行的时候都是读取最新的数据。 接下来，我们假设select … for update当前读是不会加锁的（实际上是会加锁的），在做一遍实验。 这时候，事务 B 插入的记录，就会被事务 A 的第二条查询语句查询到（因为是当前读），这样就会出现前后两次查询的结果集合不一样，这就出现了幻读。 所以，Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了间隙锁。 假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生。 举个具体例子，场景如下： 事务 A 执行了这面这条锁定读语句后，就在对表中的记录加上 id 范围为 (2, +∞] 的 next-key lock（next-key lock 是间隙锁+记录锁的组合）。 然后，事务 B 在执行插入语句的时候，判断到插入的位置被事务 A 加了 next-key lock，于是事物 B 会生成一个插入意向锁，同时进入等待状态，直到事务 A 提交了事务。这就避免了由于事务 B 插入新记录而导致事务 A 发生幻读的现象。 幻读被完全解决了吗？ 可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读。 我举例一个可重复读隔离级别发生幻读现象的场景。 第一个发生幻读现象的场景 还是以这张表作为例子： 事务 A 执行查询 id = 5 的记录，此时表中是没有该记录的，所以查询不出来。 123456事务 A mysql&gt; begin; Query OK, 0 rows affected (0.00 sec) mysql&gt; select * from t_stu where id = 5; Empty set (0.01 sec) 然后事务 B 插入一条 id = 5 的记录，并且提交了事务。 1234567事务 B mysql&gt; begin;Query OK, 0 rows affected (0.00 sec) mysql&gt; insert into t_stu values(5, '小美', 18); Query OK, 1 row affected (0.00 sec) mysql&gt; commit; Query OK, 0 rows affected (0.00 sec) 此时，事务 A 更新 id = 5 这条记录，对没错，事务 A 看不到 id = 5 这条记录，但是他去更新了这条记录，这场景确实很违和，然后再次查询 id = 5 的记录，事务 A 就能看到事务 B 插入的纪录了，幻读就是发生在这种违和的场景。 123456789101112# 事务 Amysql&gt; update t_stu set name = '小林coding' where id = 5;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select * from t_stu where id = 5;+----+--------------+------+| id | name | age |+----+--------------+------+| 5 | 小林coding | 18 |+----+--------------+------+1 row in set (0.00 sec) 整个发生幻读的时序图如下： 在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id = 5 的记录并提交。接着，事务 A 对 id = 5 这条记录进行了更新操作，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。 因为这种特殊现象的存在，所以我们认为 MySQL Innodb 中的 MVCC 并不能完全避免幻读现象 第二个发生幻读现象的场景 除了上面这一种场景会发生幻读现象之外，还有下面这个场景也会发生幻读现象。 T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id &gt; 100 得到了 3 条记录。 T2 时刻：事务 B 往插入一个 id= 200 的记录并提交； T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id &gt; 100 for update 就会得到 4 条记录，此时也发生了幻读现象。 要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select … for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。","link":"/2025/03/03/interview/mysql/3%E3%80%81%E4%BA%8B%E5%8A%A1/"},{"title":"4、mysql锁","text":"点击阅读更多查看文章内容 全局锁要使用全局锁，则要执行这条命令：flush tables with read lock执行后，整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞： 对数据的增删改操作，比如 insert、delete、update等语句；对表结构的更改操作，比如 alter table、drop table 等语句。如果要释放全局锁，则要执行这条命令：unlock tables当然，当会话断开了，全局锁会被自动释放。 全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。 加上全局锁，意味着整个数据库都是只读状态，不能更新数据，这样会造成业务停滞。 既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免？ 有的，如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。 因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。 表级锁MySQL 里面表级别的锁有这几种： 表锁； 元数据锁（MDL）; 意向锁； AUTO-INC 锁； 表锁先来说说表锁。 如果我们想对学生表（t_student）加表锁，可以使用下面的命令： 1234567//表级别的共享锁，也就是读锁；//允许当前会话读取被锁定的表，但阻止其他会话对这些表进行写操作。lock tables t_student read;//表级别的独占锁，也就是写锁；//允许当前会话对表进行读写操作，但阻止其他会话对这些表进行任何操作（读或写）。lock tables t_stuent write; 需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。 举个例子， 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句（t1加读锁，t2加写锁）则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。 元数据锁再来说说元数据锁（MDL）。 我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL： 对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁； MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。 当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。 反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。 MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景： 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁； 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突； 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞， 那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。 为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？这是因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。 所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。 意向锁接着，说说意向锁。 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」； 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」； 也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。 而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。不过，select 也是可以对记录加共享锁和独占锁的，具体方式如下： 12345//先在表上加上意向共享锁，然后对读取的记录加共享锁select ... lock in share mode;//先表上加上意向独占锁，然后对读取的记录加独占锁select ... for update; 意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables … read）和独占表锁（lock tables … write）发生冲突。 表锁和行锁是满足读读共享、读写互斥、写写互斥的。 如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。 所以，意向锁的目的是为了快速判断表里是否有记录被加锁 AUTO-INC 锁表里的主键通常都会设置成自增的，这是通过对主键字段声明 AUTO_INCREMENT 属性实现的。 之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 AUTO-INC 锁实现的。AUTO-INC 锁是特殊的表锁机制，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。 在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。 那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 AUTO_INCREMENT 修饰的字段的值是连续递增的。 但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。 因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种轻量级的锁来实现自增。一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。 行级锁InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。 加锁的对象是索引，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的，next-key lock 是前开后闭区间，而间隙锁是前开后开区间。在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock 就会退化成记录锁或间隙锁。 前面也提到，普通的 select 语句是不会对记录加锁的，因为它属于快照读。如果要在查询时对记录加行锁，可以使用下面这两个方式，这种查询会加锁的语句称为锁定读。 12345//对读取的记录加共享锁select ... lock in share mode;//对读取的记录加独占锁select ... for update; 上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0。 共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥 行级锁的类型主要有三类： Record Lock，记录锁，也就是仅仅把一条记录锁上； Gap Lock，间隙锁，锁定一个范围，而不是具体的行。 Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身 Record LockRecord Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的： 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）; 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。 Gap Lock间隙锁锁定的是一个索引区间，而不是具体的行。这意味着即使在这个区间内没有实际的数据行存在，这个区间仍然会被锁定。这可以阻止其他事务在这个区间内插入新的数据行。 假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生。 间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。 Next-Key Lock 通过 next-key 锁（记录锁和间隙锁的组合）来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录，从而避免了幻读现象。 Next-Key Lock 称为临键锁，是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 假设，表中有一个范围 id 为（3，5] 的 next-key lock，那么其他事务即不能插入 id = 4 记录，也不能修改 id = 5 这条记录。 所以，next-key lock 即能保护该记录，又能阻止其他事务将新纪录插入到被保护记录前面的间隙中。 next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。 比如，一个事务持有了范围为 (1, 10] 的 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，就会被阻塞。 虽然相同范围的间隙锁是多个事务相互兼容的，但对于记录锁，我们是要考虑 X 型与 S 型关系，X 型的记录锁与 X 型的记录锁是冲突的 插入意向锁一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。 如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。 举个例子，假设事务 A 已经对表加了一个范围 id 为（3，5）间隙锁。 当事务 A 还没提交的时候，事务 B 向该表插入一条 id = 4 的新记录，这时会判断到插入的位置已经被事务 A 加了间隙锁，于是事物 B 会生成一个插入意向锁，然后将锁的状态设置为等待状态（PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁），此时事务 B 就会发生阻塞，直到事务 A 提交了事务。 插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁，属于行级别锁。 如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。 插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。 update 没加索引会锁全表？InnoDB 存储引擎的默认事务隔离级别是「可重复读」，但是在这个隔离级别下，在多个事务并发的时候，会出现幻读的问题，所谓的幻读是指在同一事务下，连续执行两次同样的查询语句，第二次的查询语句可能会返回之前不存在的行。 因此 InnoDB 存储引擎自己实现了行锁，通过 next-key 锁（记录锁和间隙锁的组合）来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录，从而避免了幻读现象。 当我们执行 update 语句时，实际上是会对记录加独占锁（X 锁）的，如果其他事务对持有独占锁的记录进行修改时是会被阻塞的。另外，这个锁并不是执行完 update 语句就会释放的，而是会等事务结束时才会释放。 在 InnoDB 事务中，对记录加锁带基本单位是 next-key 锁，但是会因为一些条件会退化成间隙锁，或者记录锁。加锁的位置准确的说，锁是加在索引上的而非行上。 比如，在 update 语句的 where 条件使用了唯一索引，那么 next-key 锁会退化成记录锁，也就是只会给一行记录加锁。 这里举个例子，这里有一张数据库表，其中 id 为主键索引。 假设有两个事务的执行顺序如下： 可以看到，事务 A 的 update 语句中 where 是等值查询，并且 id 是唯一索引，所以只会对 id = 1 这条记录加锁，因此，事务 B 的更新操作并不会阻塞。 但是，在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了。 假设有两个事务的执行顺序如下： 可以看到，这次事务 B 的 update 语句被阻塞了。 这是因为事务 A的 update 语句中 where 条件没有索引列，触发了全表扫描，在扫描过程中会对索引加锁，所以全表扫描的场景下，所有记录都会被加锁，也就是这条 update 语句产生了 4 个记录锁和 5 个间隙锁，相当于锁住了全表 因此，当在数据量非常大的数据库表执行 update 语句时，如果没有使用索引，就会给全表的加上 next-key 锁， 那么锁就会持续很长一段时间，直到事务结束，而这期间除了 select … from语句，其他语句都会被锁住不能执行，业务会因此停滞。 那 update 语句的 where 带上索引就能避免全表记录加锁了吗？ 并不是。 关键还得看这条语句在执行过程种，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了。 如何避免这种事故的发生？ 我们可以将 MySQL 里的 sql_safe_updates 参数设置为 1，开启安全更新模式。 大致的意思是，当 sql_safe_updates 设置为 1 时。 update 语句必须满足如下条件之一才能执行成功： 使用 where，并且 where 条件中必须有索引列； 使用 limit； 同时使用 where 和 limit，此时 where 条件中可以没有索引列； delete 语句必须满足以下条件能执行成功： 同时使用 where 和 limit，此时 where 条件中可以没有索引列； 如果 where 条件带上了索引列，但是优化器最终扫描选择的是全表，而不是索引的话，我们可以使用 force index([index_name]) 可以告诉优化器使用哪个索引，以此避免有几率锁全表带来的隐患。 MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？实验验证实验环境：MySQL 8.0 版本，可重复读隔离级。 现在有一张用户表（t_user），表里只有一个主键索引，表里有以下行数据： 现在有一个 A 事务执行了一条查询语句，查询到年龄大于 20 岁的用户共有 6 条行记录。 然后， B 事务执行了一条删除 id = 2 的语句： 此时，B 事务的删除语句就陷入了等待状态，说明是无法进行删除的。 因此，MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读问题。 加锁分析问题来了，A 事务在执行 select … for update 语句时，具体加了什么锁呢？ 我们可以通过 select * from performance_schema.data_locks\\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。 输出的内容很多，共有 11 行信息，我删减了一些不重要的信息： 从上面输出的信息可以看到，共加了两种不同粒度的锁，分别是： 表锁（LOCK_TYPE: TABLE）：X 类型的意向锁； 行锁（LOCK_TYPE: RECORD）：X 类型的 next-key 锁； 这里我们重点关注「行锁」，图中 LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思： 如果 LOCK_MODE 为 X，说明是 next-key 锁； 如果 LOCK_MODE 为 X, REC_NOT_GAP，说明是记录锁； 如果 LOCK_MODE 为 X, GAP，说明是间隙锁； 然后通过 LOCK_DATA 信息，可以确认 next-key 锁的范围，具体怎么确定呢？ 根据我的经验，如果 LOCK_MODE 是 next-key 锁或者间隙锁，那么 LOCK_DATA 就表示锁的范围最右值，而锁范围的最左值为 LOCK_DATA 的上一条记录的值。 因此，此时事务 A 在主键索引（INDEX_NAME : PRIMARY）上加了 10 个 next-key 锁，如下： X 型的 next-key 锁，范围：(-∞, 1] X 型的 next-key 锁，范围：(1, 2] X 型的 next-key 锁，范围：(2, 3] X 型的 next-key 锁，范围：(3, 4] X 型的 next-key 锁，范围：(4, 5] X 型的 next-key 锁，范围：(5, 6] X 型的 next-key 锁，范围：(6, 7] X 型的 next-key 锁，范围：(7, 8] X 型的 next-key 锁，范围：(8, 9] X 型的 next-key 锁，范围：(9, +∞] 这相当于把整个表给锁住了，其他事务在对该表进行增、删、改操作的时候都会被阻塞。 只有在事务 A 提交了事务，事务 A 执行过程中产生的锁才会被释放。 为什么只是查询年龄 20 岁以上行记录，而把整个表给锁住了呢？ 这是因为事务 A 的这条查询语句是全表扫描，锁是在遍历索引的时候加上的，并不是针对输出的结果加锁。 因此，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。 如果对 age 建立索引，事务 A 这条查询会加什么锁呢？ 接下来，我对 age 字段建立索引，然后再执行这条查询语句： 接下来，继续通过 select * from performance_schema.data_locks\\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。 具体的信息，我就不打印了，我直接说结论吧。 因为表中有两个索引，分别是主键索引和 age 索引，所以会分别对这两个索引加锁。 主键索引会加如下的锁： X 型的记录锁，锁住 id = 2 的记录； X 型的记录锁，锁住 id = 3 的记录； X 型的记录锁，锁住 id = 5 的记录； X 型的记录锁，锁住 id = 6 的记录； X 型的记录锁，锁住 id = 7 的记录； X 型的记录锁，锁住 id = 8 的记录； 分析 age 索引加锁的范围时，要先对 age 字段进行排序。 age 索引加的锁： X 型的 next-key lock，锁住 age 范围 (19, 21] 的记录； X 型的 next-key lock，锁住 age 范围 (21, 21] 的记录； X 型的 next-key lock，锁住 age 范围 (21, 23] 的记录； X 型的 next-key lock，锁住 age 范围 (23, 23] 的记录； X 型的 next-key lock，锁住 age 范围 (23, 39] 的记录； X 型的 next-key lock，锁住 age 范围 (39, 43] 的记录； X 型的 next-key lock，锁住 age 范围 (43, +∞] 的记录； 化简一下，age 索引 next-key 锁的范围是 (19, +∞]。 可以看到，对 age 字段建立了索引后，查询语句是索引查询，并不会全表扫描，因此不会把整张表给锁住。 死锁死锁的发生本次案例使用存储引擎 Innodb，隔离级别为可重复读（RR）。 接下来，我用实战的方式来带大家看看死锁是怎么发生的。 我建了一张订单表，其中 id 字段为主键索引，order_no 字段普通索引，也就是非唯一索引： 然后，先 t_order 表里现在已经有了 6 条记录：假设这时有两事务，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，因为需要对订单做幂等性校验，所以两个事务先要查询该订单是否存在，不存在才插入记录，过程如下： 可以看到，两个事务都陷入了等待状态（前提没有打开死锁检测），也就是发生了死锁，因为都在相互等待对方释放锁。 这里在查询记录是否存在的时候，使用了 select … for update 语句，目的为了防止事务执行的过程中，有其他事务插入了记录，而出现幻读的问题。 事务 A 在执行下面这条语句的时候： select id from t_order where order_no = 1007 for update; 我们可以通过 select * from performance_schema.data_locks\\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。 从上图可以看到，共加了两个锁，分别是： 表锁：X 类型的意向锁； 行锁：X 类型的间隙锁； 这里我们重点关注行锁，图中 LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思，通过 LOCK_MODE 可以确认是 next-key 锁，还是间隙锁，还是记录锁： 如果 LOCK_MODE 为 X，说明是 X 型的 next-key 锁； 如果 LOCK_MODE 为 X, REC_NOT_GAP，说明是 X 型的记录锁； 如果 LOCK_MODE 为 X, GAP，说明是 X 型的间隙锁； 因此，此时事务 A 在二级索引（INDEX_NAME : index_order）上加的是 X 型的 next-key 锁，锁范围是(1006, +∞]。 next-key 锁的范围 (1006, +∞]，是怎么确定的？ 根据我的经验，如果 LOCK_MODE 是 next-key 锁或者间隙锁，那么 LOCK_DATA 就表示锁的范围最右值，此次的事务 A 的 LOCK_DATA 是 supremum pseudo-record，表示的是 +∞。然后锁范围的最左值是 t_order 表中最后一个记录的 index_order 的值，也就是 1006。因此，next-key 锁的范围 (1006, +∞]。 当事务 B 往事务 A next-key 锁的范围 (1006, +∞] 里插入 id = 1008 的记录就会被锁住： Insert into t_order (order_no, create_date) values (1008, now()); 因为当我们执行以下插入语句时，会在插入间隙上获取插入意向锁，而插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。 而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 select ... for update 语句并不会相互影响。 案例中的事务 A 和事务 B 在执行完后 select ... for update 语句后都持有范围为(1006,+∞]的next-key 锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。 如何避免死锁？死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。 在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态： 设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。 上面这个两种策略是「当有死锁发生时」的避免方式。 我们可以回归业务的角度来预防死锁，对订单做幂等性校验的目的是为了保证不会出现重复的订单，那我们可以直接将 order_no 字段设置为唯一索引列，利用它的唯一性来保证订单表不会出现重复的订单，不过有一点不好的地方就是在我们插入一个已经存在的订单记录时就会抛出异常。 死锁问题分析 先创建一张 t_student 表，假设除了 id 字段，其他字段都是普通字段。然后，插入相关的数据后，t_student 表中的记录如下： 启动两个事务，按照题目的 SQL 执行顺序，过程如下表格： 可以看到，事务 A 和 事务 B 都在执行 insert 语句后，都陷入了等待状态（前提没有打开死锁检测），也就是发生了死锁，因为都在相互等待对方释放锁。 我们可以通过 select * from performance_schema.data_locks\\G; 这条语句，查看事务执行 SQL 过程中加了什么锁。 接下来，针对每一条 SQL 语句分析具体加了什么锁。 Time 1 阶段，事务 A 执行以下语句： 1234567# 事务 Amysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; update t_student set score = 100 where id = 25;Query OK, 0 rows affected (0.01 sec)Rows matched: 0 Changed: 0 Warnings: 0 然后执行 select * from performance_schema.data_locks\\G; 这条语句，查看事务 A 此时加了什么锁。 从上图可以看到，共加了两个锁，分别是： 表锁：X 类型的意向锁； 行锁：X 类型的间隙锁；此时事务 A 在主键索引（INDEX_NAME : PRIMARY）上加的是间隙锁，锁范围是(20, 30)。(因为id=25的数据不存在数据库在检索索引的时候只需要按顺序检索20,30就可以确定25不存在，所以检索的索引范围就是(20,30)) Time 2 阶段，事务 B 执行以下语句： 1234567# 事务 Bmysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; update t_student set score = 100 where id = 26;Query OK, 0 rows affected (0.01 sec)Rows matched: 0 Changed: 0 Warnings: 0 然后执行 select * from performance_schema.data_locks\\G; 这条语句，查看事务 B 此时加了什么锁。 从上图可以看到，行锁是 X 类型的间隙锁，间隙锁的范围是(20, 30)。 Time 3，事务 A 插入了一条记录： 123# Time 3 阶段，事务 A 插入了一条记录mysql&gt; insert into t_student(id, no, name, age,score) value (25, 'S0025', 'sony', 28, 90); /// 阻塞等待...... 此时，事务 A 就陷入了等待状态。 然后执行 select * from performance_schema.data_locks\\G; 这条语句，查看事务 A 在获取什么锁而导致被阻塞。 可以看到，事务 A 的状态为等待状态（LOCK_STATUS: WAITING），因为向事务 B 生成的间隙锁（范围 (20, 30)）中插入了一条记录，所以事务 A 的插入操作生成了一个插入意向锁（LOCK_MODE:INSERT_INTENTION）。 插入意向锁名字里虽然有意向锁这三个字，但是它并不是意向锁，它属于行级锁，是一种特殊的间隙锁。插入意向锁是一种特殊的间隙锁，但不同于间隙锁的是，该锁只用于并发插入操作。 如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。 插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。所以，插入意向锁和间隙锁之间是冲突的。 Time 4，事务 B 插入了一条记录： 123# Time 4 阶段，事务 B 插入了一条记录mysql&gt; insert into t_student(id, no, name, age,score) value (26, 'S0026', 'ace', 28, 90); /// 阻塞等待...... 此时，事务 B 就陷入了等待状态。 然后执行 select * from performance_schema.data_locks\\G; 这条语句，查看事务 B 在获取什么锁而导致被阻塞。 可以看到，事务 B 在生成插入意向锁时而导致被阻塞，这是因为事务 B 向事务 A 生成的范围为 (20, 30) 的间隙锁插入了一条记录，而插入意向锁和间隙锁是冲突的，所以事务 B 在获取插入意向锁时就陷入了等待状态。","link":"/2025/03/03/interview/mysql/4%E3%80%81%E9%94%81/"},{"title":"5、mysql日志","text":"点击阅读更多查看文章内容 三种日志更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、binlog （归档日志）这三种日志： undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。 redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复； binlog （归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制； undo log我们在执行执行一条“增删改”语句的时候，虽然没有输入 begin 开启事务和 commit 提交事务，但是 MySQL 会隐式开启事务来执行“增删改”语句的，执行完就自动提交事务的，这样就保证了执行完“增删改”语句后，我们可以及时在数据库表看到“增删改”的结果了。 执行一条语句是否自动提交事务，是由 autocommit 参数决定的，默认是开启。所以，执行一条 update 语句也是会使用事务的。 那么，考虑一个问题。一个事务在执行过程中，在还没有提交事务之前，如果 MySQL 发生了崩溃，要怎么回滚到事务之前的数据呢？ 如果我们每次在事务执行过程中，都记录下回滚时需要的信息到一个日志里，那么在事务执行中途发生了 MySQL 崩溃后，就不用担心无法回滚到事务之前的数据，我们可以通过这个日志回滚到事务之前的数据。 实现这一机制就是 undo log（回滚日志），它保证了事务的 ACID 特性 (opens new window)中的原子性（Atomicity）。 undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。如下图： 每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如： 在插入一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录删掉就好了； 在删除一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录插入到表中就好了； 在更新一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列更新为旧值就好了。 在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作 针对 delete 操作和 update 操作会有一些特殊的处理： delete操作实际上不会立即直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。 update分为两种情况：update的列是否是主键列。 如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。 如果是主键列，update分两部执行：先删除该行，再插入一行目标行。 不同的操作，需要记录的内容也是不同的，所以不同类型的操作（修改、删除、新增）产生的 undo log 的格式也是不同的，具体的每一个操作的 undo log 的格式我就不详细介绍了，感兴趣的可以自己去查查。 一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id： 通过 trx_id 可以知道该记录是被哪个事务修改的； 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链； 版本链如下图： undo log 两大作用： 实现事务回滚，保障事务的原子性。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。 实现 MVCC（多版本并发控制）关键因素之一。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。 Buffer PoolMySQL 的数据都是存在磁盘中的，那么我们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。那修改完这条记录是选择直接写回到磁盘，还是选择缓存起来呢？ 当然是缓存起来好，这样下次有查询语句命中了这条记录，直接读取缓存中的记录，就不需要从磁盘获取数据了。 为此，Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。 有了 Buffer Pool 后： 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。 Buffer Pool 缓存什么？ InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。 在 MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。 此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。 所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系。 Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等。 Undo 页是记录什么？ 开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。 查询一条记录，就只需要缓冲一条记录吗？ 不是的。 当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，将页加载到 Buffer Pool 后，再通过页里的「页目录」去定位到某条具体的记录。 redo log什么是redo log？redo log 是物理日志，记录了某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新，每当执行一个事务就会产生这样的一条或者多条物理日志。 在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。 当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。 Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。 为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，这个时候更新就算完成了。 后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 WAL （Write-Ahead Logging，预写日志）技术。 WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。 一些概念： Buffer Pool（缓冲池）。MySQL 中数据是以页为单位，查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。更新表数据的时候，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。 redo log buffer（重做日志缓存，存储在内存中）。事务执行更新时，最先把这一数据页的更新信息记录到重做日志缓存（ redo log buffer）里。 redo log（重做日志，存储在硬盘上）。用于持久化存储事务的物理修改记录，以保证 MySQL 事务的持久性（Durability, D）。 当事务执行COMMIT提交时： 把 redo log buffer 刷（盘）入 redo log 文件（磁盘文件），保证日志持久化。（redo log buffer–&gt; redo log）然后， Buffer Pool的数据页（更新后为脏页）本身稍后由后台线程写入磁盘（刷脏页），避免频繁IO影响性能。（buffer pool –&gt; 磁盘） InnoDB 存储引擎有一个后台线程，每隔 1 秒执行一次刷盘操作（redo log buffer –&gt; redo log）。这个刷盘指的是将 redo log buffer 的内容写入 文件系统缓存（page cache），然后调用 fsync把数据持久化到磁盘上的 redo log 文件。也就是说，一个没有提交事务的 redo log 记录，也可能会刷盘。 注意：InnoDB 的 redo log buffer 不是等事务提交才刷盘，而是 每 1 秒 被后台线程自动刷到文件系统缓存（page cache），然后 fsync 到磁盘的 redo log 文件中。即使事务没有提交，redolog 也可能被写入磁盘的 redo log 文件 被修改 Undo 页面，需要记录对应 redo log 吗？需要的。 开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。 不过，在内存修改该 Undo 页面后，也是需要记录对应的 redo log，因为undo log也要实现持久性的保护。 redo log 和 undo log 区别在哪？这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于： redo log 记录了此次事务「修改后」的数据状态，记录的是更新之后的值，主要用于事务崩溃恢复，保证事务的持久性。 undo log 记录了此次事务「修改前」的数据状态，记录的是更新之前的值，主要用于事务回滚，保证事务的原子性。 事务提交之前发生了崩溃（这里的崩溃不是宕机崩溃，而是事务执行错误，mysql 还是正常运行的。如果是宕机崩溃的话，其实就不需要通过 undo log 回滚了，因为事务没有提交，事务的数据并不会持久化，还是在内存中，宕机崩溃了数据就丢失了，反正事务都没有提交成功，所以数据本身就无意义的，丢失了就丢失了），重启后会通过 undo log 回滚事务。 事务提交之后发生了崩溃（这里的崩溃是宕机崩溃），重启后会通过 redo log 恢复事务，如下图： 所以有了 redo log，再通过 WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失，这个能力称为 crash-safe（崩溃恢复）。可以看出来， redo log 保证了事务四大特性中的持久性。 binlogredo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎。 而 binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层 前面介绍的 undo log 和 redo log 这两个日志都是 Innodb 存储引擎生成的。 MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写入 binlog 文件。 binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。 为什么有了 binlog， 还要有 redo log？ 这个问题跟 MySQL 的时间线有关系。 最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。 而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。 redo log 和 binlog 有什么区别？这两个日志有四个区别。 适用对象不同： binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；redo log 是 Innodb 存储引擎实现的日志； 文件格式不同： binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下： STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致； ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已； MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式； redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新； 写入方式不同： binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。 redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。 用途不同： binlog 用于备份恢复、主从复制； redo log 用于掉电等故障恢复。 如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？ 不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。 因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。 binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据 主从复制是怎么实现的？MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。 这个过程一般是异步的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。 MySQL 集群的主从复制过程梳理成 3 个阶段： 写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。 同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。 回放 Binlog：回放 binlog，并更新存储引擎中的数据。 具体详细过程如下： MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。 从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。 在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。 两阶段提交事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。 举个例子，假设 id = 1 这行数据的字段 name 的值原本是 ‘jay’，然后执行 UPDATE t_user SET name = ‘xiaolin’ WHERE id = 1; 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况： 如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id = 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性； 如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id = 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性； 可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。 MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。 两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。 在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了内部 XA 事务（是的，也有外部 XA 事务，跟本文不太相关，我就不介绍了），内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。 当客户端执行 commit 语句或者在自动提交的情况下，MySQL 内部开启一个 XA 事务，分两阶段来完成 XA 事务的提交，如下图： 从图中可看出，事务的提交过程有两个阶段，就是将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog，具体如下： prepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）； commit 阶段：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功； 异常重启会出现什么现象？ 我们来看看在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象？下图中有时刻 A 和时刻 B 都有可能发生崩溃： 不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，此时的 redo log 都处于 prepare 状态。 在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID： 如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务。对应时刻 A 崩溃恢复的情况。 如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。对应时刻 B 崩溃恢复的情况。 可以看到，对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。 所以说，两阶段提交是以 binlog 写成功为事务提交成功的标识，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。","link":"/2025/03/03/interview/mysql/5%E3%80%81%E6%97%A5%E5%BF%97/"},{"title":"6、mysql语句执行","text":"点击阅读更多查看文章内容 执行select语句的过程MySQL 的架构共分为两层：Server 层和存储引擎层 Server 层负责建立连接、分析和执行 SQL。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。 存储引擎层负责数据的存储和提取。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 。 第一步：连接器连接的过程需要先经过 TCP 三次握手，因为 MySQL 是基于 TCP 协议进行传输的。 当然不是了，MySQL 定义了空闲连接的最大空闲时长，由 wait_timeout 参数控制的，默认值是 8 小时（28880秒），如果空闲连接超过了这个时间，连接器就会自动将它断开。 MySQL 的连接也跟 HTTP 一样，有短连接和长连接的概念，它们的区别如下： 1234567891011// 短连接 连接 mysql 服务（TCP 三次握手） 执行sql 断开 mysql 服务（TCP 四次挥手） // 长连接 连接 mysql 服务（TCP 三次握手） 执行sql 执行sql 执行sql .... 断开 mysql 服务（TCP 四次挥手） 可以看到，使用长连接的好处就是可以减少建立连接和断开连接的过程，所以一般是推荐使用长连接。 但是，使用长连接后可能会占用内存增多，因为 MySQL 在执行查询过程中临时使用内存管理连接对象，这些连接对象资源只有在连接断开时才会释放。如果长连接累计很多，将导致 MySQL 服务占用内存太大，有可能会被系统强制杀掉，这样会发生 MySQL 服务异常重启的现象。 有两种解决方式。 第一种，定期断开长连接。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接。 第二种，客户端主动重置连接。MySQL 5.7 版本实现了 mysql_reset_connection() 函数的接口，注意这是接口函数不是命令，那么当客户端执行了一个很大的操作后，在代码里调用 mysql_reset_connection 函数来重置连接，达到释放内存的效果。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 第二步：查询缓存连接器工作完成后，客户端就可以向 MySQL 服务发送 SQL 语句了，MySQL 服务收到 SQL 语句后，就会解析出 SQL 语句的第一个字段，看看是什么类型的语句。 如果 SQL 是查询语句（select 语句），MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。 如果查询的语句命中查询缓存，那么就会直接返回 value 给客户端。如果查询的语句没有命中查询缓存中，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中。 这么看，查询缓存还挺有用，但是其实查询缓存挺鸡肋的。 对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，相当于缓存了个寂寞。 所以，MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。 对于 MySQL 8.0 之前的版本，如果想关闭查询缓存，我们可以通过将参数 query_cache_type 设置成 DEMAND。 第三步：解析SQL解析器 解析器会做如下两件事情。 第一件事情，词法分析。MySQL 会根据你输入的字符串识别出关键字出来，例如，SQL语句 select username from userinfo，在分析之后，会得到4个Token，其中有2个Keyword，分别为select和from 第二件事情，语法分析。根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法，如果没问题就会构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。 第四步：执行SQL经过解析器后，接着就要进入执行 SQL 查询语句的流程了，每条SELECT 查询语句流程主要可以分为下面这三个阶段： prepare 阶段，也就是预处理阶段； 检查 SQL 查询语句中的表或者字段是否存在； 将 select * 中的 * 符号，扩展为表上的所有列； optimize 阶段，也就是优化阶段； 优化器主要负责将 SQL 查询语句的执行方案确定下来，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。 要想知道优化器选择了哪个索引，我们可以在查询语句最前面加个 explain 命令，这样就会输出这条 SQL 语句的执行计划，然后执行计划中的 key 就表示执行过程中使用了哪个索引。 execute 阶段，也就是执行阶段 经历完优化器后，就确定了执行方案，接下来 MySQL 就真正开始执行语句了，这个工作是由「执行器」完成的。在执行的过程中，执行器就会和存储引擎交互了，交互是以记录为单位的。 主键索引查询 1select * from product where id = 1; 这条查询语句的查询条件用到了主键索引，而且是等值查询，同时主键 id 是唯一，不会有 id 相同的记录，所以优化器决定选用访问类型为 const 进行查询，也就是使用主键索引查询一条记录，那么执行器与存储引擎的执行流程是这样的： 执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为 InnoDB 引擎索引查询的接口，把条件 id = 1 交给存储引擎，让存储引擎定位符合条件的第一条记录。 存储引擎通过主键索引的 B+ 树结构定位到 id = 1的第一条记录，如果记录是不存在的，就会向执行器上报记录找不到的错误，然后查询结束。如果记录是存在的，就会将记录返回给执行器； 执行器从存储引擎读到记录后，接着判断记录是否符合查询条件，如果符合则发送给客户端，如果不符合则跳过该记录。 执行器查询的过程是一个 while 循环，所以还会再查一次，但是这次因为不是第一次查询了，所以会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 const，这个函数指针被指向为一个永远返回 - 1 的函数，所以当调用该函数的时候，执行器就退出循环，也就是结束查询了。 全表扫描 1select * from product where name = 'iphone'; 这条查询语句的查询条件没有用到索引，所以优化器决定选用访问类型为 ALL 进行查询，也就是全表扫描的方式查询，那么这时执行器与存储引擎的执行流程是这样的： 执行器第一次查询，会调用 read_first_record 函数指针指向的函数，因为优化器选择的访问类型为 all，这个函数指针被指向为 InnoDB 引擎全扫描的接口，让存储引擎读取表中的第一条记录； 执行器会判断读到的这条记录的 name 是不是 iphone，如果不是则跳过；如果是则将记录发给客户的（是的没错，Server 层每从存储引擎读到一条记录就会发送给客户端，之所以客户端显示的时候是直接显示所有记录的，是因为客户端是等查询语句查询完成后，才会显示出所有的记录）。 执行器查询的过程是一个 while 循环，所以还会再查一次，会调用 read_record 函数指针指向的函数，因为优化器选择的访问类型为 all，read_record 函数指针指向的还是 InnoDB 引擎全扫描的接口，所以接着向存储引擎层要求继续读刚才那条记录的下一条记录，存储引擎把下一条记录取出后就将其返回给执行器（Server层），执行器继续判断条件，不符合查询条件即跳过该记录，否则发送到客户端； 一直重复上述过程，直到存储引擎把表中的所有记录读完，然后向执行器（Server层） 返回了读取完毕的信息； 执行器收到存储引擎报告的查询完毕的信息，退出循环，停止查询。 索引下推 索引下推能够减少二级索引在查询时的回表操作，提高查询的效率，因为它将 Server 层部分负责的事情，交给存储引擎层去处理了。 1select * from t_user where age &gt; 20 and reward = 100000; 联合索引当遇到范围查询 (&gt;、&lt;) 就会停止匹配，也就是 age 字段能用到联合索引，但是 reward 字段则无法利用到索引 那么，不使用索引下推（MySQL 5.6 之前的版本）时，执行器与存储引擎的执行流程是这样的： Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录； 存储引擎根据二级索引的 B+ 树快速定位到这条记录后，获取主键值，然后进行回表操作，将完整的记录返回给 Server 层； Server 层在判断该记录的 reward 是否等于 100000，如果成立则将其发送给客户端；否则跳过该记录； 接着，继续向存储引擎索要下一条记录，存储引擎在二级索引定位到记录后，获取主键值，然后回表操作，将完整的记录返回给 Server 层； 如此往复，直到存储引擎把表中的所有记录读完。 可以看到，没有索引下推的时候，每查询到一条二级索引记录，都要进行回表操作，然后将记录返回给 Server，接着 Server 再判断该记录的 reward 是否等于 100000。 而使用索引下推后，判断记录的 reward 是否等于 100000 的工作交给了存储引擎层，过程如下 ： Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录； 存储引擎定位到二级索引后，先不执行回表操作，而是先判断一下该索引中包含的列（reward列）的条件（reward 是否等于 100000）是否成立。如果条件不成立，则直接跳过该二级索引。如果成立，则执行回表操作，将完成记录返回给 Server 层。 Server 层在判断其他的查询条件（本次查询没有其他条件）是否成立，如果成立则将其发送给客户端；否则跳过该记录，然后向存储引擎索要下一条记录。 如此往复，直到存储引擎把表中的所有记录读完。 可以看到，使用了索引下推后，虽然 reward 列无法使用到联合索引，但是因为它包含在联合索引（age，reward）里，所以直接在存储引擎过滤出满足 reward = 100000 的记录后，才去执行回表操作获取整个记录。相比于没有使用索引下推，节省了很多回表操作。 mysql一行记录是如何存储的我们每创建一个 database（数据库） 都会在 /var/lib/mysql/ 目录里面创建一个以 database 为名的目录，然后保存表结构和表数据的文件都会存放在这个目录里。 比如，我这里有一个名为 my_test 的 database，该 database 里有一张名为 t_order 数据库表。 此时数据库目录下共有三个文件，这三个文件分别代表着： db.opt，用来存储当前数据库的默认字符集和字符校验规则。 t_order.frm ，t_order 的表结构会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。 t_order.ibd，t_order 的表数据会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .ibd 文件。 好了，现在我们知道了一张数据库表的数据是保存在「 表名字.ibd 」的文件里的，这个文件也称为独占表空间文件。 表空间文件的结构表空间由段（segment）、区（extent）、页（page）、行（row）组成，InnoDB存储引擎的逻辑存储结构大致如下图： 1、行（row） 数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。 后面我们详细介绍 InnoDB 存储引擎的行格式，也是本文重点介绍的内容。 2、页（page，数据库存储的基本单位）：记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。 因此，InnoDB 的数据是按「页」为单位来读写的，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。 默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间。 页是 InnoDB 存储引擎磁盘管理的最小单元，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。 页的类型有很多，常见的有数据页、undo 日志页、溢出页等等。 3、区（extent，数据库分配空间的基本单位） 我们知道 InnoDB 存储引擎是用 B+ 树来组织数据的。 B+ 树中每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I/O，随机 I/O 是非常慢的。 解决这个问题也很简单，就是让链表中相邻的页的物理位置也相邻，这样就可以使用顺序 I/O 了，那么在范围查询（扫描叶子节点）的时候性能就会很高。 那具体怎么解决呢？ 在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。 4、段（segment） 表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。 索引段：存放 B + 树的非叶子节点的区的集合； 数据段：存放 B + 树的叶子节点的区的集合； 回滚段：存放的是回滚数据的区的集合，之前讲事务隔离 (opens new window)的时候就介绍到了 MVCC 利用了回滚段实现了多版本查询数据。 Innodb行格式有哪些InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。 Redundant 是很古老的行格式了， MySQL 5.0 版本之前用的行格式，现在基本没人用了。 由于 Redundant 不是一种紧凑的行格式，所以 MySQL 5.0 之后引入了 Compact 行记录存储方式 Compact 是一种紧凑的行格式，设计的初衷就是为了让一个数据页中可以存放更多的行记录，从 MySQL 5.1 版本之后，行格式默认设置成 Compact。 Dynamic 和 Compressed 两个都是紧凑的行格式，它们的行格式都和 Compact 差不多，因为都是基于 Compact 改进一点东西。 从 MySQL5.7 版本之后，默认使用 Dynamic 行格式。 Redundant 行格式我这里就不讲了，因为现在基本没人用了，这次重点介绍 Compact 行格式，因为 Dynamic 和 Compressed 这两个行格式跟 Compact 非常像。 所以，弄懂了 Compact 行格式，之后你们在去了解其他行格式，很快也能看懂。 Compact行格式 记录的额外信息： 变长字段长度列表：varchar(n) 和 char(n) 的区别是什么，相信大家都非常清楚，char 是定长的，varchar 是变长的，变长字段实际存储的数据的长度（大小）不固定的。 所以，在存储数据的时候，也要把数据占用的大小存起来，存到「变长字段长度列表」里面，读取数据的时候才能根据这个「变长字段长度列表」去读取对应长度的数据。变长字段的真实数据占用的字节数会按照列的顺序逆序存放 「记录头信息」中指向下一个记录的指针，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。 「变长字段长度列表」中的信息之所以要逆序存放，是因为这样可以使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率。 同样的道理， NULL 值列表的信息也需要逆序存放。 NULL值列表：表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。 如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。 二进制位的值为1时，代表该列的值为NULL。 二进制位的值为0时，代表该列的值不为NULL。 另外，NULL 值列表必须用整数个字节的位表示（1字节8位），如果使用的二进制位个数不足整数个字节，则在字节的高位补 0。 记录头信息：记录头信息中包含的内容很多，我就不一一列举了，这里说几个比较重要的： delete_mask ：标识此条数据是否被删除。从这里可以知道，我们执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1。 next_record：下一条记录的位置。从这里可以知道，记录与记录之间是通过链表组织的。在前面我也提到了，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。 record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录 记录的真实数据： row_id 如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。 trx_id 事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。 roll_pointer 这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。","link":"/2025/03/03/interview/mysql/6%E3%80%81%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C/"},{"title":"【Go】gin源码分析","text":"点击阅读更多查看文章内容 转载：https://zhuanlan.zhihu.com/p/611116090 Gin的优势 支持中间件操作（ handlersChain 机制 ） 更方便的使用（ gin.Context ） 更强大的路由解析能力（ radix tree 路由树 ） Gin与HTTP的关系Gin 是在 Golang HTTP 标准库 net/http 基础之上的再封装，两者的交互边界如下图： 在 net/http 的既定框架下，gin 所做的是提供了一个 gin.Engine 对象作为 Handler 注入net/http其中，从而实现路由注册/匹配、请求处理链路的优化. 使用示例： 1234567891011121314151617func myMiddleWare(c *gin.Context) { fmt.Println(&quot;middleware starting...&quot;)}func main() { // 创建一个 gin Engine，本质上是一个 http Handler mux := gin.Default() // 注册中间件 mux.Use(myMiddleWare) // 注册一个 path 为 /ping 的处理函数 mux.POST(&quot;/ping&quot;, func(c *gin.Context) { c.JSON(http.StatusOK, &quot;pone&quot;) }) // 运行 http 服务 if err := mux.Run(&quot;:8080&quot;); err != nil { panic(err) }} 核心数据结构gin.Engine：Engine 为 Gin 中构建的 HTTP Handler，其实现了 net/http 包下 Handler interface 的抽象方法： Handler.ServeHTTP 123type Handler interface { ServeHTTP(ResponseWriter, *Request)} 因此可以作为 Handler 注入到 net/http 的 Server 当中. 12345678910type Engine struct { // 路由组 RouterGroup // ... // context 对象池 pool sync.Pool // 方法路由树 trees methodTrees // ...} Engine包含的核心内容包括： 路由组 RouterGroup：第（2）部分展开 Context 对象池 pool：基于 sync.Pool 实现，作为复用 gin.Context 实例的缓冲池. gin.Context 的内容于本文第 5 章详解 路由树数组 trees：共有 9 棵路由树，对应于 9 种 http 方法. 路由树基于压缩前缀树实现，于本文第 4 章详解. RouteGroup123456type RouterGroup struct { Handlers HandlersChain basePath string engine *Engine root bool} RouterGroup 是路由组的概念，其中的配置将被从属于该路由组的所有路由复用： Handlers：路由组共同的 handler 处理函数链. 组下的节点将拼接 RouterGroup 的公用 handlers 和自己的 handlers，组成最终使用的 handlers 链 basePath：路由组的基础路径. 组下的节点将拼接 RouterGroup 的 basePath 和自己的 path，组成最终使用的 absolutePath engine：指向路由组从属的 Engine root：标识路由组是否位于 Engine 的根节点. 当用户基于 RouterGroup.Group 方法创建子路由组后，该标识为 false HandlersChain 1234type HandlersChain []HandlerFunctype HandlerFunc func(*Context) HandlersChain 是由多个路由处理函数 HandlerFunc 构成的处理函数链. 在使用的时候，会按照索引的先后顺序依次调用 HandlerFunc. handler注册流程下面以创建 gin.Engine 、注册 middleware 和注册 handler 作为主线，进行源码走读和原理解析： 1234567891011func main() { // 创建一个 gin Engine，本质上是一个 http Handler mux := gin.Default() // 注册中间件 mux.Use(myMiddleWare) // 注册一个 path 为 /ping 的处理函数 mux.POST(&quot;/ping&quot;, func(c *gin.Context) { c.JSON(http.StatusOK, &quot;pone&quot;) }) // ...} 初始化 Engine 方法调用：gin.Default -&gt; gin.New 创建一个 gin.Engine 实例 创建 Enging 的首个 RouterGroup，对应的处理函数链 Handlers 为 nil，基础路径 basePath 为 “/“，root 标识为 true 构造了 9 棵方法路由树，对应于 9 种 http 方法 创建了 gin.Context 的对象池 12345678910111213141516171819202122232425262728func Default() *Engine { engine := New() // ... return engine}func New() *Engine { // ... // 创建 gin Engine 实例 engine := &amp;Engine{ // 路由组实例 RouterGroup: RouterGroup{ Handlers: nil, basePath: &quot;/&quot;, root: true, }, // ... // 9 棵路由压缩前缀树，对应 9 种 http 方法 trees: make(methodTrees, 0, 9), // ... } engine.RouterGroup.engine = engine // gin.Context 对象池 engine.pool.New = func() any { return engine.allocateContext(engine.maxParams) } return engine} 注册 middleware 通过 Engine.Use 方法可以实现中间件的注册，会将注册的 middlewares 添加到 RouterGroup.Handlers 中. 后续 RouterGroup 下新注册的 handler 都会在前缀中拼上这部分 group 公共的 handlers 123456789func (engine *Engine) Use(middleware ...HandlerFunc) IRoutes { engine.RouterGroup.Use(middleware...) // ... return engine}func (group *RouterGroup) Use(middleware ...HandlerFunc) IRoutes { group.Handlers = append(group.Handlers, middleware...) return group.returnObj()} 注册 handler 以 http post 为例，注册 handler 方法调用顺序为 RouterGroup.POST-&gt; RouterGroup.handle，接下来会完成三个步骤： 拼接出待注册方法的完整路径 absolutePath 拼接出代注册方法的完整处理函数链 handlers 以 absolutePath 和 handlers 组成 kv 对添加到路由树中 12345678910func (group *RouterGroup) POST(relativePath string, handlers ...HandlerFunc) IRoutes { return group.handle(http.MethodPost, relativePath, handlers)}func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes { absolutePath := group.calculateAbsolutePath(relativePath) handlers = group.combineHandlers(handlers) group.engine.addRoute(httpMethod, absolutePath, handlers) return group.returnObj()} 服务端启动流程流程入口： 下面通过 Gin 框架运行 http 服务为主线，进行源码走读： 123456789func main() { // 创建一个 gin Engine，本质上是一个 http Handler mux := gin.Default() // 一键启动 http 服务 if err := mux.Run(); err != nil{ panic(err) }} 启动服务： 一键启动 Engine.Run 方法后，底层会将 gin.Engine 本身作为 net/http 包下 Handler interface 的实现类，并调用 http.ListenAndServe 方法启动服务.（ListenerAndServe 方法本身会基于主动轮询 + IO 多路复用的方式运行） 12345func (engine *Engine) Run(addr ...string) (err error) { // ... err = http.ListenAndServe(address, engine.Handler()) return} 处理请求 在服务端接收到 http 请求时，会通过 Handler.ServeHTTP 方法进行处理. 而此处的 Handler 正是 gin.Engine，其处理请求的核心步骤如下： 对于每笔 http 请求，会为其分配一个 gin.Context，在 handlers 链路中持续向下传递 调用 Engine.handleHTTPRequest 方法，从路由树中获取 handlers 链，然后遍历调用 处理完 http 请求后，会将 gin.Context 进行回收. 整个回收复用的流程基于对象池管理 12345678910111213141516func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { // 从对象池中获取一个 context c := engine.pool.Get().(*Context) // 重置/初始化 context c.writermem.reset(w) c.Request = req c.reset() // 处理 http 请求 engine.handleHTTPRequest(c) // 把 context 放回对象池 engine.pool.Put(c)} Engine.handleHTTPRequest 方法核心步骤分为三步： 根据 http method 取得对应的 methodTree 根据 path 从 methodTree 中找到对应的 handlers 链 将 handlers 链注入到 gin.Context 中，通过 Context.Next 方法按照顺序遍历调用 handler gin路由树 路由树是使用压缩前缀树实现的 （1）前缀树 前缀树又称 trie 树，是一种基于字符串公共前缀构建索引的树状结构，核心点包括： 除根节点之外，每个节点对应一个字符 从根节点到某一节点，路径上经过的字符串联起来，即为该节点对应的字符串 尽可能复用公共前缀，如无必要不分配新的节点 （2）压缩前缀树 压缩前缀树又称基数树或 radix 树，是对前缀树的改良版本，优化点主要在于空间的节省，核心策略体现在： 倘若某个子节点是其父节点的唯一孩子，则与父节点进行合并 在 gin 框架中，是用压缩前缀树 （3）为什么使用压缩前缀树 与压缩前缀树相对的就是使用 hashmap，以 path 为 key，handlers 为 value 进行映射关联，这里选择了前者的原因在于： path 匹配时不是完全精确匹配，比如末尾 ‘/’ 符号的增减（/ping与/ping/应该是同一个路径）、全匹配符号 ‘*’ 的处理等，map 无法胜任（模糊匹配部分的代码于本文中并未体现，大家可以深入源码中加以佐证） 路由的数量相对有限，对应数量级下 map 的性能优势体现不明显，在小数据量的前提下，map 性能甚至要弱于前缀树 path 串通常存在基于分组分类的公共前缀，适合使用前缀树进行管理，可以节省存储空间 （4）补偿策略 在 Gin 路由树中还使用一种补偿策略，在组装路由树时，会将注册路由句柄数量更多的 child node 摆放在 children 数组更靠前的位置. 这是因为某个链路注册的 handlers 句柄数量越多，一次匹配操作所需要话费的时间就越长，被匹配命中的概率就越大，因此应该被优先处理. Gin.Context gin.Context 的定位是对应于一次 http 请求，贯穿于整条 handlersChain 调用链路的上下文，其中包含了如下核心字段： Request/Writer：http 请求和响应的 reader、writer 入口 handlers：本次 http 请求对应的处理函数链 index：当前的处理进度，即处理链路处于函数链的索引位置 engine：Engine 的指针 mu：用于保护 map 的读写互斥锁 Keys：缓存 handlers 链上共享数据的 map 12345678910111213141516171819type Context struct { // ... // http 请求参数 Request *http.Request // http 响应 writer Writer ResponseWriter // ... // 处理函数链 handlers HandlersChain // 当前处于处理函数链的索引 index int8 engine *Engine // ... // 读写锁，保证并发安全 mu sync.RWMutex // key value 对存储 map Keys map[string]any // ..} 复用gin.Context 作为处理 http 请求的通用数据结构，不可避免地会被频繁创建和销毁. 为了缓解 GC 压力，gin 中采用对象池 sync.Pool 进行 Context 的缓存复用，处理流程如下： http 请求到达时，从 pool 中获取 Context，倘若池子已空，通过 pool.New 方法构造新的 Context 补上空缺 http 请求处理完成后，将 Context 放回 pool 中，用以后续复用 sync.Pool 并不是真正意义上的缓存，将其称为回收站或许更加合适，放入其中的数据在逻辑意义上都是已经被删除的，但在物理意义上数据是仍然存在的，这些数据可以存活两轮 GC 的时间，在此期间倘若有被获取的需求，则可以被重新复用. 12345678910111213141516type Engine struct { // context 对象池 pool sync.Pool}func New() *Engine { // ... engine.pool.New = func() any { return engine.allocateContext(engine.maxParams) } return engine}func (engine *Engine) allocateContext(maxParams uint16) *Context { v := make(Params, 0, maxParams) // ... return &amp;Context{engine: engine, params: &amp;v, skippedNodes: &amp;skippedNodes}} 分配与回收 gin.Context 分配与回收的时机是在 gin.Engine 处理 http 请求的前后，位于 Engine.ServeHTTP 方法当中： 从池中获取 Context 重置 Context 的内容，使其成为一个空白的上下文 调用 Engine.handleHTTPRequest 方法处理 http 请求 请求处理完成后，将 Context 放回池中 12345678910111213func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { // 从对象池中获取一个 context c := engine.pool.Get().(*Context) // 重置/初始化 context c.writermem.reset(w) c.Request = req c.reset() // 处理 http 请求 engine.handleHTTPRequest(c) // 把 context 放回对象池 engine.pool.Put(c)} 使用时机（1）handlesChain 入口 在 Engine.handleHTTPRequest 方法处理请求时，会通过 path 从 methodTree 中获取到对应的 handlers 链，然后将 handlers 注入到 Context.handlers 中，然后启动 Context.Next 方法开启 handlers 链的遍历调用流程. 123456789101112131415161718192021func (engine *Engine) handleHTTPRequest(c *Context) { // ... t := engine.trees for i, tl := 0, len(t); i &lt; tl; i++ { if t[i].method != httpMethod { continue } root := t[i].root value := root.getValue(rPath, c.params, c.skippedNodes, unescape) // ... if value.handlers != nil { c.handlers = value.handlers c.fullPath = value.fullPath c.Next() c.writermem.WriteHeaderNow() return } // ... } // ...} handlerschain遍历调用 推进 handlers 链调用进度的方法正是 Context.Next. 可以看到其中以 Context.index 为索引，通过 for 循环依次调用 handlers 链中的 handler.（调用next会顺序执行其后的每个handler） 1234567func (c *Context) Next() { c.index++ for c.index &lt; int8(len(c.handlers)) { c.handlers[c.index](c) c.index++ }} 由于 Context 本身会暴露于调用链路中，因此用户可以在某个 handler 中通过手动调用 Context.Next 的方式来打断当前 handler 的执行流程，提前进入下一个 handler 的处理中，此时本质上是一个方法压栈调用的行为，因此在后置位 handlers 链全部处理完成后，最终会回到压栈前的位置，执行当前 handler 剩余部分的代码逻辑. 结合下面的代码示例来说，用户可以在某个 handler 中，于调用 Context.Next 方法的前后分别声明前处理逻辑和后处理逻辑，这里的“前”和“后”相对的是后置位的所有 handler 而言. 1234567func myHandleFunc(c *gin.Context){ // 前处理 preHandle() c.Next() // 后处理 postHandle()} 此外，用户可以在某个 handler 中通过调用 Context.Abort 方法实现 handlers 链路的提前熔断. 其实现原理是将 Context.index 设置为一个过载值 63，导致 Next 流程直接终止. 这是因为 handlers 链的长度必须小于 63，否则在注册时就会直接 panic. 因此在 Context.Next 方法中，一旦 index 被设为 63，则必然大于整条 handlers 链的长度，for 循环便会提前终止. 123456const abortIndex int8 = 63func (c *Context) Abort() { c.index = abortIndex} 总结 gin 将 Engine 作为 http.Handler 的实现类进行注入，从而融入 Golang net/http 标准库的框架之内 gin 中基于 handler 链的方式实现中间件和处理函数的协调使用 gin 中基于压缩前缀树的方式作为路由树的数据结构，对应于 9 种 http 方法共有 9 棵树 gin 中基于 gin.Context 作为一次 http 请求贯穿整条 handler chain 的核心数据结构 gin.Context 是一种会被频繁创建销毁的资源对象，因此使用对象池 sync.Pool 进行缓存复用","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91gin%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"【Go】grpc+protobuf详解","text":"点击阅读更多查看文章内容 Protobuf详解官方地址： https://developers.google.com/protocol-buffers/docs/proto3 数据类型 .proto Type Notes Go Type double float64 float float32 int32 使用变长编码，对于负值的效率很低，如果你的域有可能有负值，请使用sint64替代 int32 uint32 使用变长编码 uint32 uint64 使用变长编码 uint64 sint32 使用变长编码，这些编码在负值时比int32高效的多 int32 sint64 使用变长编码，有符号的整型值。编码时比通常的int64高效。 int64 fixed32 总是4个字节，如果数值总是比总是比228大的话，这个类型会比uint32高效。 uint32 fixed64 总是8个字节，如果数值总是比总是比256大的话，这个类型会比uint64高效。 uint64 sfixed32 总是4个字节 int32 sfixed64 总是8个字节 int64 bool bool string 一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本。 string bytes 可能包含任意顺序的字节数据。 默认值当一个消息被解析的时候，如果被编码的信息不包含一个特定的singular元素，被解析的对象所对应的域被设置位一个默认值，对于不同类型指定如下： 对于strings，默认是一个空string 对于bytes，默认是一个空的bytes 对于bools，默认是false 对于数值类型，默认是0 对于枚举，默认是第一个定义的枚举值，必须为0; option go_package指明生成文件的目录以及包名，option go_package=“.;proto”，在当前目录下生成文件，文件package为proto，使用go_package后无需为proto文件再单独定义package 编号问题客户端定义 1234message Data{ string name = 1; string url = 2;} 服务端定义 1234message Data{ string name = 2; string url = 1;} 如果两个文件的序号不对应那么最终的结果是，客户端发送的name在服务端被解析为url，客户端发送的url在服务端被解析为name 假设name为tom，url为tom.com，那么实际传输的数据类似1(序号)3(长度)tom27tom.com import其它的proto文件 自定义文件在代码中使用时需要生成import的proto的代码（两个proto文件都在同一目录下直接import一个package即可） 内置文件需要import文件中的go_package empty.proto 嵌套的message对象message只放在需要它的message里面，避免公共message的爆炸式增长 12345678910message HelloReply { string message = 1; message Result { string name = 1; string url = 2; } repeated Result data = 2;} 生成代码调用时可以通过 proto.HelloReply_Result 对其进行实例化 枚举类型proto文件定义 1234enum Gender{ MALE = 0; FEMALE = 1;} 生成代码使用：proto_bak.Gender_MALE 生成的Gender是int32类型，对每个值都会生成对应的常量 map类型proto文件定义： 生成代码： 使用： 内置timestamp类型proto文件定义： grpc详解什么是rpc实现rpc调用主要解决三个问题： Call ID映射。我们怎么告诉远程机器我们要调用add，而不是sub或者Foo呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用add，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 &lt;–&gt; Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。 序列化和反序列化。客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。 网络传输。远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西。 rpc开发的四大要素RPC技术在架构设计上有四部分组成，分别是：客户端、客户端存根、服务端、服务端存根。 通过stub屏蔽掉网络通信的内容，使得在客户端调用远程的函数就跟调用本地函数一样 客户端(Client)：服务调用发起方，也称为服务消费者。 客户端存根(Client Stub)：该程序运行在客户端所在的计算机机器上，主要用来存储要调用的服务器的地址，另外，该程序还负责将客户端请求远端服务器程序的数据信息打包成数据包，通过网络发送给服务端Stub程序；其次，还要接收服务端Stub程序发送的调用结果数据包，并解析返回给客户端。 服务端(Server)：远端的计算机机器上运行的程序，其中有客户端要调用的方法。 服务端存根(Server Stub)：接收客户Stub程序通过网络发送的请求消息数据包，并调用服务端中真正的程序功能方法，完成功能调用；其次，将服务端执行调用的结果进行数据处理打包发送给客户端Stub程序。 了解完了RPC技术的组成结构我们来看一下具体是如何实现客户端到服务端的调用的。实际上，如果我们想要在网络中的任意两台计算机上实现远程调用过程，要解决很多问题，比如： 两台物理机器在网络中要建立稳定可靠的通信连接。 两台服务器的通信协议的定义问题，即两台服务器上的程序如何识别对方的请求和返回结果。也就是说两台计算机必须都能够识别对方发来的信息，并且能够识别出其中的请求含义和返回含义，然后才能进行处理。这其实就是通信协议所要完成的工作。 在上述图中，通过1-10的步骤图解的形式，说明了RPC每一步的调用过程。具体描述为： 1、客户端想要发起一个远程过程调用，首先通过调用本地客户端Stub程序的方式调用想要使用的功能方法名； 2、客户端Stub程序接收到了客户端的功能调用请求，将客户端请求调用的方法名，携带的参数等信息做序列化操作，并打包成数据包。 3、客户端Stub查找到远程服务器程序的IP地址，调用Socket通信协议，通过网络发送给服务端。 4、服务端Stub程序接收到客户端发送的数据包信息，并通过约定好的协议将数据进行反序列化，得到请求的方法名和请求参数等信息。 5、服务端Stub程序准备相关数据，调用本地Server对应的功能方法进行，并传入相应的参数，进行业务处理。 6、服务端程序根据已有业务逻辑执行调用过程，待业务执行结束，将执行结果返回给服务端Stub程序。 7、服务端Stub程序将程序调用结果按照约定的协议进行序列化，并通过网络发送回客户端Stub程序。 8、客户端Stub程序接收到服务端Stub发送的返回数据，对数据进行反序列化操作，并将调用返回的数据传递给客户端请求发起者。 9、客户端请求发起者得到调用结果，整个RPC调用过程结束。 grpcgRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java 和 Go 语言版本，分别是：grpc, grpc-java, grpc-go. 其中 C 版本支持 C, C++, Node.js, Python, Ruby, Objective-C, PHP 和 C# 支持. grpc项目地址 grpc的四种数据流 proto123456789101112131415161718192021222324syntax = &quot;proto3&quot;;//声明proto的版本 只能 是3，才支持 grpc//声明 包名option go_package=&quot;.;proto&quot;;//声明grpc服务service Greeter { /* 以下 分别是 服务端 推送流， 客户端 推送流 ，双向流。 */ rpc GetStream (StreamReqData) returns (stream StreamResData){} rpc PutStream (stream StreamReqData) returns (StreamResData){} rpc AllStream (stream StreamReqData) returns (stream StreamResData){}}//stream请求结构message StreamReqData { string data = 1;}//stream返回结构message StreamResData { string data = 1;} 服务端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package mainimport ( &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;log&quot; &quot;net&quot; &quot;start/new_stream/proto&quot; &quot;sync&quot; &quot;time&quot;)const PORT = &quot;:50052&quot;type server struct {}//服务端 单向流func (s *server)GetStream(req *proto.StreamReqData, res proto.Greeter_GetStreamServer) error{ i:= 0 for{ i++ res.Send(&amp;proto.StreamResData{Data:fmt.Sprintf(&quot;%v&quot;,time.Now().Unix())}) time.Sleep(1*time.Second) if i &gt;10 { break } } return nil}//客户端 单向流func (s *server) PutStream(cliStr proto.Greeter_PutStreamServer) error { for { if tem, err := cliStr.Recv(); err == nil { log.Println(tem) } else { log.Println(&quot;break, err :&quot;, err) break } } return nil}//客户端服务端 双向流func(s *server) AllStream(allStr proto.Greeter_AllStreamServer) error { wg := sync.WaitGroup{} wg.Add(2) go func() { for { data, _ := allStr.Recv() log.Println(data) } wg.Done() }() go func() { for { allStr.Send(&amp;proto.StreamResData{Data:&quot;ssss&quot;}) time.Sleep(time.Second) } wg.Done() }() wg.Wait() return nil}func main(){ //监听端口 lis,err := net.Listen(&quot;tcp&quot;,PORT) if err != nil{ panic(err) return } //创建一个grpc 服务器 s := grpc.NewServer() //注册事件 proto.RegisterGreeterServer(s,&amp;server{}) //处理链接 err = s.Serve(lis) if err != nil { panic(err) }} 客户端1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package mainimport ( &quot;google.golang.org/grpc&quot; &quot;context&quot; _ &quot;google.golang.org/grpc/balancer/grpclb&quot; &quot;log&quot; &quot;start/new_stream/proto&quot; &quot;time&quot;)const ( ADDRESS = &quot;localhost:50052&quot;)func main(){ //通过grpc 库 建立一个连接 conn ,err := grpc.Dial(ADDRESS,grpc.WithInsecure()) if err != nil{ return } defer conn.Close() //通过刚刚的连接 生成一个client对象。 c := proto.NewGreeterClient(conn) //调用服务端推送流 reqstreamData := &amp;proto.StreamReqData{Data:&quot;aaa&quot;} res,_ := c.GetStream(context.Background(),reqstreamData) for { aa,err := res.Recv() if err != nil { log.Println(err) break } log.Println(aa) } //客户端 推送 流 putRes, _ := c.PutStream(context.Background()) i := 1 for { i++ putRes.Send(&amp;proto.StreamReqData{Data:&quot;ss&quot;}) time.Sleep(time.Second) if i &gt; 10 { break } } //服务端 客户端 双向流 allStr,_ := c.AllStream(context.Background()) go func() { for { data,_ := allStr.Recv() log.Println(data) } }() go func() { for { allStr.Send(&amp;proto.StreamReqData{Data:&quot;ssss&quot;}) time.Sleep(time.Second) } }() select { }} grpc的metadata机制grpc中的metadata类似于http中的header，可以用来存放一些元信息（如token） gRPC让我们可以像本地调用一样实现远程调用，对于每一次的RPC调用中，都可能会有一些有用的数据，而这些数据就可以通过metadata来传递。metadata是以key-value的形式存储数据的，其中key是string类型，而value是[]string，即一个字符串数组类型。metadata使得client和server能够为对方提供关于本次调用的一些信息，metadata的生命周期就是一次RPC调用。 新建metadata MD 类型实际上是map，key是string，value是string类型的slice。 1type MD map[string][]string 创建的时候可以像创建普通的map类型一样使用new关键字进行创建： 12345678//第一种方式md := metadata.New(map[string]string{&quot;key1&quot;: &quot;val1&quot;, &quot;key2&quot;: &quot;val2&quot;})//第二种方式 key不区分大小写，会被统一转成小写。md := metadata.Pairs( &quot;key1&quot;, &quot;val1&quot;, &quot;key1&quot;, &quot;val1-2&quot;, // &quot;key1&quot; will have map value []string{&quot;val1&quot;, &quot;val1-2&quot;} &quot;key2&quot;, &quot;val2&quot;,) 发送metadata：将metadata添加到context中 1234567md := metadata.Pairs(&quot;key&quot;, &quot;val&quot;)// 新建一个有 metadata 的 contextctx := metadata.NewOutgoingContext(context.Background(), md)// 单向 RPCresponse, err := client.SomeRPC(ctx, someRequest) 接收metadata：从context中取出metadata 1234func (s *server) SomeRPC(ctx context.Context, in *pb.SomeRequest) (*pb.SomeResponse, err) { md, ok := metadata.FromIncomingContext(ctx) // do something with metadata} grpc拦截器gRPC 拦截器主要分为两种：客户端拦截器（ClientInterceptor），服务端拦截器（ServerInterceptor），顾名思义，分别于请求的两端执行相应的前拦截处理。 客户端拦截器 1、作用时机？ 请求被分发出去之前。 2、可以做什么？ a)、请求日志记录及监控 b)、添加请求头数据、以便代理转发使用 c)、请求或者结果重写 3、实现 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;time&quot; &quot;start/grpc_interceptor/proto&quot;)func interceptor(ctx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error { start := time.Now() err := invoker(ctx, method, req, reply, cc, opts...) fmt.Printf(&quot;method=%s req=%v rep=%v duration=%s error=%v\\n&quot;, method, req, reply, time.Since(start), err) return err}func main(){ //stream var opts []grpc.DialOption opts = append(opts, grpc.WithInsecure()) // 指定客户端interceptor opts = append(opts, grpc.WithUnaryInterceptor(interceptor)) conn, err := grpc.Dial(&quot;localhost:50051&quot;, opts...) if err != nil { panic(err) } defer conn.Close() c := proto.NewGreeterClient(conn) r, err := c.SayHello(context.Background(), &amp;proto.HelloRequest{Name:&quot;bobby&quot;}) if err != nil { panic(err) } fmt.Println(r.Message)} 服务端拦截器 1、作用时机？ 请求被具体的Handler相应前。 2、可以做什么？ a）访问认证 b）请求日志记录及监控 c）代理转发 3、实现 123456789101112131415161718192021222324252627282930313233type Server struct{}func (s *Server) SayHello(ctx context.Context, request *proto.HelloRequest) (*proto.HelloReply, error){ return &amp;proto.HelloReply{ Message: &quot;hello &quot;+request.Name, }, nil}func main(){ var interceptor grpc.UnaryServerInterceptor interceptor = func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) { // 继续处理请求 fmt.Println(&quot;接收到新请求&quot;) res, err := handler(ctx, req) fmt.Println(&quot;请求处理完成&quot;) return res, err } var opts []grpc.ServerOption opts = append(opts, grpc.UnaryInterceptor(interceptor)) g := grpc.NewServer(opts...) proto.RegisterGreeterServer(g, &amp;Server{}) lis, err := net.Listen(&quot;tcp&quot;, &quot;0.0.0.0:50051&quot;) if err != nil{ panic(&quot;failed to listen:&quot;+err.Error()) } err = g.Serve(lis) if err != nil{ panic(&quot;failed to start grpc:&quot;+err.Error()) }} 拦截器的应用场景：go-grpc-middleware 通过拦截器和metadata实现grpc的auth认证客户端： 1234567891011interceptor := func(ctx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error { start := time.Now() md := metadata.New(map[string]string{ &quot;appid&quot;:&quot;10101&quot;, &quot;appkey&quot;:&quot;i am key&quot;, }) ctx = metadata.NewOutgoingContext(context.Background(), md) err := invoker(ctx, method, req, reply, cc, opts...) fmt.Printf(&quot;耗时：%s\\n&quot;, time.Since(start)) return err} 服务端 1234567891011121314151617181920212223242526interceptor = func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) { md, ok := metadata.FromIncomingContext(ctx) if !ok { return resp, status.Errorf(codes.Unauthenticated, &quot;无Token认证信息&quot;) } var ( appid string appkey string ) if val, ok := md[&quot;appid&quot;]; ok { appid = val[0] } if val, ok := md[&quot;appkey&quot;]; ok { appkey = val[0] } if appid != &quot;imooc&quot; || appkey != &quot;bobby&quot; { return resp, status.Errorf(codes.Unauthenticated, &quot;Token认证信息无效: appid=%s, appkey=%s&quot;, appid, appkey) } // 继续处理请求 return handler(ctx, req)} grpc的验证器protoc-gen_validate，验证proto中定义的message是否符合某个规则 生成源码 1protoc -I . --go_out=plugins=grpc:. --validate_out=&quot;lang=go:.&quot; helloworld.proto 新建validate.proto文件内容从 https://github.com/envoyproxy/protoc-gen-validate/blob/master/validate/validate.proto 拷贝 新建helloworl.proto文件 1234567891011121314151617syntax = &quot;proto3&quot;;import &quot;validate.proto&quot;;option go_package=&quot;.;proto&quot;;service Greeter { rpc SayHello (Person) returns (Person);}message Person { uint64 id = 1 [(validate.rules).uint64.gt = 999]; string email = 2 [(validate.rules).string.email = true]; string name = 3 [(validate.rules).string = { pattern: &quot;^[^[0-9]A-Za-z]+( [^[0-9]A-Za-z]+)*$&quot;,max_bytes: 256,}];} 客户端： 12345678910111213141516171819202122232425262728293031323334package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;google.golang.org/grpc&quot; &quot;start/pgv_test/proto&quot;)type customCredential struct{}func main() { var opts []grpc.DialOption //opts = append(opts, grpc.WithUnaryInterceptor(interceptor)) opts = append(opts, grpc.WithInsecure()) conn, err := grpc.Dial(&quot;localhost:50051&quot;, opts...) if err != nil { panic(err) } defer conn.Close() c := proto.NewGreeterClient(conn) //rsp, _ := c.Search(context.Background(), &amp;empty.Empty{}) rsp, err := c.SayHello(context.Background(), &amp;proto.Person{ Email: &quot;bobby&quot;, }) if err != nil { panic(err) } fmt.Println(rsp.Id)} 服务端：通过validate方法就可以验证规则，不符合则返回error，直接定义一个包含validate方法的接口，validate方法实现在生成的validate文件中 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( &quot;context&quot; &quot;google.golang.org/grpc/codes&quot; &quot;google.golang.org/grpc/status&quot; &quot;net&quot; &quot;google.golang.org/grpc&quot; &quot;start/pgv_test/proto&quot;)type Server struct{}func (s *Server) SayHello(ctx context.Context, request *proto.Person) (*proto.Person, error){ return &amp;proto.Person{ Id: 32, }, nil}type Validator interface { Validate() error}func main(){ var interceptor grpc.UnaryServerInterceptor interceptor = func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) { // 继续处理请求 if r, ok := req.(Validator); ok { if err := r.Validate(); err != nil { return nil, status.Error(codes.InvalidArgument, err.Error()) } } return handler(ctx, req) } var opts []grpc.ServerOption opts = append(opts, grpc.UnaryInterceptor(interceptor)) g := grpc.NewServer(opts...) proto.RegisterGreeterServer(g, &amp;Server{}) lis, err := net.Listen(&quot;tcp&quot;, &quot;0.0.0.0:50051&quot;) if err != nil{ panic(&quot;failed to listen:&quot;+err.Error()) } err = g.Serve(lis) if err != nil{ panic(&quot;failed to start grpc:&quot;+err.Error()) }} grpc的状态码https://github.com/grpc/grpc/blob/master/doc/statuscodes.md grpc中的错误处理 服务端生成错误信息 1err := status.Errorf(codes.NotFound, &quot;记录未找到：%s&quot;, request.Name) 客户端获取错误中的状态信息 123456st, ok := status.FromError(err)if !ok { // Error was not a status error}st.Message()st.Code() grpc中的超时机制在客户端设置超时时间3s 服务端等待10s 此时，客户端在发出请求3s后会直接返回错误 protoc生成的go的源码里面有什么？proto文件： 1234567891011syntax = &quot;proto3&quot;;option go_package = &quot;.;proto&quot;;service Greeter { rpc SayHello (HelloRequest) returns (HelloReply);}message HelloRequest { string name = 1;}message HelloReply { string message = 1;} proto 中的 message 会生成 go 文件中的 struct 服务端： service 生成了 server 的接口 生成了注册方法 服务端调用时，实现对应的业务逻辑（SayHello）然后直接将实现业务逻辑的结构体注册即可 客户端： 生成了client接口（与服务端参数不同） 通过new方法（类似于其它语言中的构造函数）生成接口，new返回的是greeterClient进行了一层包装将cc包装进来 cc包装了调用的方法Invoke greeterClient通过cc.Invoke实现了SayHello方法的调用 cc就是我们在客户端调用时生成的conn","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91grpc+protobuf%E8%AF%A6%E8%A7%A3/"},{"title":"【Go】锁","text":"点击阅读更多查看文章内容 基本原语Go 语言在 sync 包中提供了用于同步的一些基本原语，包括常见的 sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Once 和 sync.Cond： 这些基本原语提供了较为基础的同步功能，但是它们是一种相对原始的同步机制，在多数情况下，我们都应该使用抽象层级更高的 Channel 实现同步。 MutexGo 语言的 sync.Mutex 由两个字段 state 和 sema 组成。其中 state 表示当前互斥锁的状态，而 sema 是用于控制锁状态的信号量。 1234type Mutex struct { state int32 sema uint32} 上述两个加起来只占 8 字节空间的结构体表示了 Go 语言中的互斥锁。 互斥锁的状态比较复杂，如下图所示，最低三位分别表示 mutexLocked、mutexWoken 和 mutexStarving，剩下的位置用来表示当前有多少个 Goroutine 在等待互斥锁的释放： 在默认情况下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态： mutexLocked — 表示互斥锁的锁定状态； mutexWoken — 表示从正常模式被从唤醒； mutexStarving — 当前的互斥锁进入饥饿状态； waitersCount — 当前互斥锁上等待的 Goroutine 个数； 正常模式和饥饿模式正常模式 竞争激烈时性能优先： 在正常模式下，锁的获取是非公平的，新到达的 goroutine 可能会直接获取锁，而不需要等待。 自旋等待： 当锁被占用时，新到达的 goroutine 会自旋等待一段时间，尝试直接获取锁，而不是立即进入休眠状态。 适用场景： 适用于竞争不激烈或锁持有时间较短的场景，可以最大化性能。 饥饿模式 公平性优先： 在饥饿模式下，锁的获取是公平的，等待时间最长的 goroutine 会优先获取锁。 防止长时间等待： 当某个 goroutine 等待锁的时间超过一定阈值（默认为 1 毫秒），锁会进入饥饿模式。 适用场景： 适用于竞争激烈或锁持有时间较长的场景，可以防止某些 goroutine 长时间等 在饥饿模式下，如果某个 goroutine 获取锁时发现没有其他 goroutine 在等待，Mutex 会从饥饿模式切换回正常模式。","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91Mutex/"},{"title":"【Go】代码规范","text":"点击阅读更多查看文章内容 代码规范命名规范包名：package 保持package的名字和目录保持一致，尽量采取有意义的包名，简短，有意义，尽量和标准库不要冲突。包名应该为小写单词，不要使用下划线或者混合大小写。 12package modelpackage main 文件名 尽量采取有意义的文件名，简短，有意义，应该为小写单词，使用下划线分隔各个单词。 1user_model.go 结构体命名 采用驼峰命名法，首字母根据访问控制大写或者小写 struct 申明和初始化格式采用多行，例如下面： 1234567891011// 多行申明type User struct{ Username string Email string} // 多行初始化u := User{ Username: &quot;bobby&quot;, Email: &quot;bobby@imooc.com&quot;,} 接口命名 命名规则基本和上面的结构体类型 单个函数的结构名以 “er” 作为后缀，例如 Reader , Writer 。 123type Reader interface { Read(p []byte) (n int, err error)} 变量命名 和结构体类似，变量名称一般遵循驼峰法，首字母根据访问控制原则大写或者小写，但遇到特有名词时，需要遵循以下规则： 如果变量为私有，且特有名词为首个单词，则使用小写，如 apiClient 其它情况都应当使用该名词原有的写法，如 APIClient、repoID、UserID 错误示例：UrlArray，应该写成 urlArray 或者 URLArray 若变量类型为 bool 类型，则名称应以 Has, Is, Can 或 Allow 开头 1234var isExist boolvar hasConflict boolvar canManage boolvar allowGitHook bool 常量命名 常量均需使用全部大写字母组成，并使用下划线分词 1const APP_VER = &quot;1.0&quot; 如果是枚举类型的常量，需要先创建相应类型： 123456type Scheme stringconst ( HTTP Scheme = &quot;http&quot; HTTPS Scheme = &quot;https&quot;) 注释 单行注释是最常见的注释形式，你可以在任何地方使用以 // 开头的单行注释 多行注释也叫块注释，均已以 /* 开头，并以 */ 结尾，且不可以嵌套使用，多行注释一般用于包的文档描述或注释成块的代码片段 go 语言自带的 godoc 工具可以根据注释生成文档，生成可以自动生成对应的网站（golang.org 就是使用 godoc 工具直接生成的），注释的质量决定了生成的文档的质量。每个包都应该有一个包注释，在package子句之前有一个块注释。对于多文件包，包注释只需要存在于一个文件中，任何一个都可以。包评论应该介绍包，并提供与整个包相关的信息。它将首先出现在godoc页面上，并应设置下面的详细文档。 包注释 每个包都应该有一个包注释，一个位于package子句之前的块注释或行注释。包如果有多个go文件，只需要出现在一个go文件中（一般是和包同名的文件）即可。 包注释应该包含下面基本信息(请严格按照这个顺序，简介，创建人，创建时间）： 包的基本简介（包名，简介） 创建者，格式： 创建人： rtx 名 创建时间，格式：创建时间： yyyyMMdd 123// util 包， 该包包含了项目共用的一些常量，封装了项目中一些共用函数。// 创建人： hanru// 创建时间： 20190419 结构（接口）注释 每个自定义的结构体或者接口都应该有注释说明，该注释对结构进行简要介绍，放在结构体定义的前一行，格式为： 结构体名， 结构体说明。同时结构体内的每个成员变量都要有说明，该说明放在成员变量的后面（注意对齐），实例如下： 12345// User ， 用户对象，定义了用户的基础信息type User struct{ Username string // 用户名 Email string // 邮箱} 函数（方法）注释 每个函数，或者方法（结构体或者接口下的函数称为方法）都应该有注释说明，函数的注释应该包括三个方面（严格按照此顺序撰写）： 简要说明，格式说明：以函数名开头，“，”分隔说明部分 参数列表：每行一个参数，参数名开头，“，”分隔说明部分 返回值： 每行一个返回值 1234567// NewtAttrModel ， 属性数据层操作类的工厂方法// 参数：// ctx ： 上下文信息// 返回值：// 属性操作类指针func NewAttrModel(ctx *common.Context) *AttrModel {} 代码逻辑注释 对于一些关键位置的代码逻辑，或者局部较为复杂的逻辑，需要有相应的逻辑说明，方便其他开发者阅读该段代码，实例如下： 1234// 从 Redis 中批量读取属性，对于没有读取到的 id ， 记录到一个数组里面，准备从 DB 中读取xxxxxxxxxxxxxxxxxxx 注释风格 统一使用中文注释，对于中英文字符之间严格使用空格分隔， 这个不仅仅是中文和英文之间，英文和中文标点之间也都要使用空格分隔，例如： 1// 从 Redis 中批量读取属性，对于没有读取到的 id ， 记录到一个数组里面，准备从 DB 中读取 上面 Redis 、 id 、 DB 和其他中文字符之间都是用了空格分隔。 建议全部使用单行注释 和代码的规范一样，单行注释不要过长，禁止超过 120 字符。 import规范import在多行的情况下，goimports会自动帮你格式化，但是我们这里还是规范一下import的一些规范，如果你在一个文件里面引入了一个package，还是建议采用如下格式： 123import ( &quot;fmt&quot;) 如果你的包引入了三种类型的包，标准库包，自己编写的项目包，第三方包，建议采用如下方式进行组织你的包： 1234567891011import ( &quot;encoding/json&quot; &quot;strings&quot; &quot;myproject/models&quot; &quot;myproject/controller&quot; &quot;myproject/utils&quot; &quot;github.com/astaxie/beego&quot; &quot;github.com/go-sql-driver/mysql&quot;) 有顺序的引入包，不同的类型采用空行分离，第一种是标准库，第二是项目包，第三是第三方包。 在项目中不要使用相对路径引入包： 12345// 这是不好的导入import “../net”// 这是正确的做法import “github.com/repo/proj/src/net” 但是如果是引入本项目中的其他包，最好使用相对路径，这样在拷贝到其它位置运行时不需要进行修改。 错误处理 错误处理的原则就是不能丢弃任何有返回err的调用，不要使用 _ 丢弃，必须全部处理。接收到错误，要么返回err，或者使用log记录下来 尽早return：一旦有错误发生，马上返回 尽量不要使用panic，除非你知道你在做什么 错误描述如果是英文必须为小写，不需要标点结尾 采用独立的错误流进行处理","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"},{"title":"【Go】常见问题","text":"点击阅读更多查看文章内容 协程与线程的区别协程：由 Go 语言 runtime 管理的轻量级并发执行单元，是用户态的线程，可以通过用户程序创建、删除。协程切换时不需要切换内核态。 线程：由操作系统内核管理的并发执行单元。 区别： 调度：线程是操作系统的概念，而协程是程序级的概念。线程由操作系统内核调度。而协程由Go runtime 负责调度，基于 G-M-P 模型。 性能：线程上下文切换涉及用户态和内核态切换，开销较大。而协程切换时不需要操作系统的介入，上下文切换完全在用户态完成，切换开销较小。 并发模型：协程基于 CSP 模型（Communicating Sequential Processes），通过 Channel 通信。通信更安全，避免数据竞争。线程基于共享内存，需要锁（如互斥锁）同步。容易引发数据竞争，需要开发者手动管理锁。 内存占用：协程初始栈大小 2KB，可动态扩容（最大 1GB）。线程默认栈大小 1MB（不同操作系统可能不同） new和make的区别var声明值类型的变量时，系统会默认为他分配内存空间，并赋该类型的零值如果是指针类型或者引用类型的变量，系统不会为它分配内存，默认是nil。 1.make 仅用来分配及初始化类型为 slice、map、chan 的数据。2.new 可分配任意类型的数据，根据传入的类型申请一块内存，返回指向这块内存的指针，即类型 *Type。3.make 返回引用，即 Type，new 分配的空间被清零， make 分配空间后，会进行初始。4.make函数返回的是slice、map、chan类型本身5.new函数返回一个指向该类型内存地址的指针 Golang的slice的实现原理slice不是线程安全的切片是基于数组实现的，底层是数组，可以理解为对底层数组的抽象 12345type slice struct{ array unsafe.Pointer len int cap int} slice占24个字节array：指向底层数组的指针，占用8个字节len: 切片的长度，占用8个字节cap：切片的容量，cap总是大于等于len，占用8个字节 初始化slice调用的是runtime.makeslice，makeslice函数的工作主要就是计算slice所需内存大小，然后调用mallocgc进行内存的分配 所需内存的大小=切片中元素大小*切片的容量 array和slice的区别 长度不同 数组初始化必须指定长度，并且长度就是固定的 切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大 变量类型不同 数组是值类型：将一个数组赋值给另一个数组时，传递的是一份深拷贝，函数传参操作都会复制整个数组数据，会占用额外的内存，函数内对数组元素值的修改，不会修改原数组内容。 切片是引用类型：切片是引用类型，将一个切片赋值给另一个切片时，传递的是一份浅拷贝，函数传参操作不会拷贝整个切片，只会复制len和cap，底层共用同一个数组，不会占用额外的内存，函数内对数组元素值的修改，会修改原数组内容。 底层实现 数组：数组是一个连续的内存块，存储固定数量的元素。 切片：是一个结构体，包含指向底层数组的指针、长度和容量。 性能/使用场景 数组更高效但灵活性差，适合固定大小的集合；存储在连续的内存中，访问速度快。 切片灵活但可能有性能开销，适合动态大小的集合；切片的底层数组可能需要在运行时动态分配和扩容，涉及额外的内存管理开销。 原子操作Go atomic包是最轻量级的锁（也称无锁结构），可以在不形成临界区和创建互斥量的情况下完成并发安全的值替换操作，不过这个包只支持int32/Int64/uint32/uint64/uintptr这几种数据类型的一些基础操作（增减、交换、载入、存储等） 原子操作仅会由一个独立的CPU指令代表和完成。原子操作是无锁的，常常直接通过CPU指令直接实现。事实上，其它同步技术的实现常常依赖于原子操作。 当我们想要对某个变量并发安全的修改，除了使用官方提供的 mutex，还可以使用sync/atomic包的原子操作，它能够保证对变量的读取或修改期间不被其他的协程所影响。atomic 包提供的原子操作能够确保任一时刻只有一个goroutine对变量进行操作，善用atomic能够避免程序中出现大量的锁操作。 1234func add(addr *int64， delta int64) {atomic.AddInt64(addr, delta)//加操作fmt.Println(&quot;add opts: &quot;,*addr)} 原子操作和锁的区别1.原子操作由底层硬件支持，而锁是基于原子操作+信号量完成的。若实现相同的功能，前者通常会更有效率2.原子操作是单个指令的互斥操作；互斥锁/读写锁是一种数据结构，可以完成临界区（多个指令）的互斥操作，扩大原子操作的范围3.原子操作是无锁操作，属于乐观锁；说起锁的时候，一般属于悲观锁4.原子操作存在于各个指令/语言层级，比如*机器指令层级的原子操作”，““汇编指令层级的原子操作”，“Go语言层级的原子操作”等。5.锁也存在于各个指令/语言层级中，比如“机器指令层级的锁”，“汇编指令层级的锁“Go语言层级的锁“等 Channel死锁场景1.非缓存channel只写不读2.非缓存channel读在写后面3.缓存channel写入超过缓冲区数量4.空读5.多个协程相互等待 Go的Struct能不能比较？1.相同struct类型的可以比较2.不同struct类型的不可以比较,编译都不过，类型不匹配 内存泄漏内存泄露（Memory Leak）是指程序在运行过程中分配的内存无法被垃圾回收器（GC）回收，导致内存占用持续增加，最终可能耗尽系统内存。Go 的垃圾回收机制虽然强大，但在某些场景下仍可能发生内存泄露。以下是内存泄露的常见原因、检测方法和预防措施： 全局变量或长生命周期对象的引用 全局变量或长生命周期对象（如缓存、单例）持有对某些对象的引用，导致这些对象无法被回收。 12345var cache = make(map[string]*BigObject)func addToCache(key string, obj *BigObject) { cache[key] = obj} 如果 cache 中的对象不再使用但没有删除，会导致内存泄露。 未关闭的资源 未关闭的文件、网络连接、数据库连接等资源会占用内存，导致泄露。 1234func readFile() { file, _ := os.Open(&quot;data.txt&quot;) // 未调用 file.Close()} Goroutine 泄露 Goroutine 未正确退出，导致其引用的资源无法被回收。 1234567func leakyFunc() { go func() { for { time.Sleep(time.Second) } }()} Channel 阻塞 Goroutine 因 Channel 阻塞而无法退出，导致泄露。 1234567func leakyChan() { ch := make(chan int) go func() { ch &lt;- 1 }() // 未读取 ch，导致 Goroutine 阻塞} 循环引用 12345678910type Node struct { next *Node}func createCycle() { a := &amp;Node{} b := &amp;Node{} a.next = b b.next = a // 循环引用} go 打印时 %v %+v %#v 的区别？%v 只输出所有的值；%+v 先输出字段名字，再输出该字段的值；%#v 先输出结构体名字值，再输出结构体（字段名字+字段的值）； 什么是 rune 类型？Go语言的字符有以下两种： 1.uint8 类型，或者叫 byte 型，代表了 ASCII 码的一个字符。2.rune 类型，代表一个 UTF-8 字符，当需要处理中文、日文或者其他复合字符时，则需要用到 rune 类型。rune 类型等价于 int32 类型。 单个字符为int32，字符串中取字符为uint8 123456func main() { var a = 'c' fmt.Println(reflect.TypeOf(a)) // int32 var b = &quot;abc&quot; fmt.Println(reflect.TypeOf(b[0])) // uint8} 在使用range遍历字符串时直接取得的字符为int32，下标取得的字符为uint8（range取得的v是t[i]的副本） 12345t := &quot;avc&quot;for i, v := range t { fmt.Println(reflect.TypeOf(t[i])) //uint8 fmt.Println(reflect.TypeOf(v)) //int32} 空 struct{} 占用空间么？用途是什么？空结构体 struct{} 实例不占据任何的内存空间。 用途： 1.将 map 作为集合(Set)使用时，可以将值类型定义为空结构体，仅作为占位符使用即可。 2.不发送数据的信道(channel)使用 channel 不需要发送任何的数据，只用来通知子协程(goroutine)执行任务，或只用来控制协程并发度。 12345678910111213func worker(done chan struct{}) { fmt.Println(&quot;Working...&quot;) time.Sleep(time.Second) fmt.Println(&quot;Done&quot;) done &lt;- struct{}{} // 发送完成信号}func main() { done := make(chan struct{}) go worker(done) &lt;-done // 等待任务完成 fmt.Println(&quot;Worker finished&quot;)} 3.结构体只包含方法，不包含任何的字段 golang值接收者和指针接收者的区别golang函数与方法的区别是，方法有一个接收者。 如果方法的接收者是指针类型，无论调用者是对象还是对象指针，修改的都是对象本身，会影响调用者 如果方法的接收者是值类型，无论调用者是对象还是对象指针，修改的都是对象的副本，不影响调用者 通常我们使用指针类型作为方法的接收者的理由： 使用指针类型能够修改调用者的值 使用指针类型可以避免在每次调用方法时复制该值，在值的类型为大型结构体时，这样做更加高效 引用传递和值传递什么是引用传递?将实参的地址传递给形参，函数内对形参值内容的修改，将会影响实参的值内容。Go语言是没有引用传递的，向函数传参时都会传递变量的副本，不过有的变量是引用类型它的值本身是就是一个指针因此即使传递副本他们内部的指针还是一样的。Go的值类型(int、struct等）、引用类型（指针、slice、map、 channel) defer关键字 延迟执行defer 语句会将函数调用压入一个栈中，在当前函数返回之前按照 ​后进先出（LIFO）​​ 的顺序执行。 参数预计算defer 语句中的函数参数会在 defer 语句执行时立即计算，而不是在延迟调用时计算。 12345678func main() { i := 1 defer fmt.Println(&quot;Deferred call:&quot;, i) i++ fmt.Println(&quot;Main function:&quot;, i)}// Main function: 2// Deferred call: 1 作用域defer 语句的作用域是当前函数，函数返回时才会执行 defer 语句。 如果函数中有多个 defer 语句，它们会按照 ​后进先出（LIFO）​​ 的顺序执行。 panic后的defer不会被执行，panic之前的defer会被执行（遇到panic，如果没有捕获错误，函数会立刻终止） panic没有被recover时，抛出的panic到当前goroutine最上层函数时，最上层程序直接异常终止 defer、return、返回值三者的执行逻辑应该是：return最先执行，return负责将结果写入返回值中；接着defer开始执行一些收尾工作；最后函数携带当前返回值退出 123456789101112func testd() int { i := 1 defer func() { i++ }() return i}func main() { fmt.Println(testd())}// 1 selectselect 是一种用于处理多 Channel 操作的机制，类似于 switch 语句，但专门用于 Channel 的读写操作。select 的主要作用是 监听多个 Channel 的操作，并在其中一个 Channel 就绪时执行对应的分支。以下是 select 的详细使用方法和底层原理。 12345678select {case &lt;-ch1: // ch1 可读时执行case ch2 &lt;- value: // ch2 可写时执行default: // 没有任何 Channel 就绪时执行} 使用场景 多 Channel 监听：同时监听多个 Channel 的读写操作。 超时控制：结合 time.After 实现超时机制。 非阻塞操作：使用 default 分支实现非阻塞的 Channel 操作。 selectgo 的执行流程 runtime.selectgo 的执行流程如下： 初始化： 遍历所有 case 分支，检查每个 Channel 的状态（是否可读或可写）。 将可操作的 Channel 加入一个随机顺序的列表中。 随机选择： 从可操作的 Channel 中随机选择一个执行。 如果没有任何 Channel 就绪，则执行 default 分支（如果存在）。 执行分支： 执行选中的 case 分支，完成对应的 Channel 操作。 返回结果： 返回选中的 case 分支的索引，以及是否成功执行 select 阻塞的实现细节 如果 select 的所有 case 分支都阻塞，并且没有 default 分支，select 会 阻塞，而不是自旋。 select 的阻塞行为是通过挂起当前 Goroutine 实现的，不会浪费 CPU 资源。 select 的底层实现依赖于 Go 的运行时机制，包括 Goroutine 的挂起和唤醒。 Goroutine 的挂起 当 select 阻塞时，当前 Goroutine 会被挂起，并加入到所有相关 Channel 的等待队列中。具体步骤如下： 检查 Channel 状态：遍历所有 case 分支，检查每个 Channel 是否可读或可写。 加入等待队列：如果没有任何 Channel 就绪，将当前 Goroutine 加入到所有相关 Channel 的等待队列中。 挂起 Goroutine：将 Goroutine 的状态设置为 Gwaiting，并释放 CPU 资源。 Goroutine 的唤醒 当任何一个 Channel 就绪时，Go 的运行时机制会唤醒等待的 Goroutine，并执行对应的 case 分支。具体步骤如下： Channel 就绪：某个 Channel 接收到数据或可以发送数据。 唤醒 Goroutine：从 Channel 的等待队列中取出 Goroutine，并将其状态设置为 Grunnable。 执行 case 分支：runtime.selectgo 函数返回对应的 case 分支索引，执行对应的代码。 服务发现是怎么做的？主要有两种服务发现机制：客户端发现和服务端发现 客户端发现：是指客户端应用程序主动扫描、获取和管理可用的服务实例列表。客户端通过向服务注册中心发送请求来获取服务实例列表，然后根据负载均衡算法选择其中一台实例进行服务调用。客户端负责维护可用实例列表，包括实例的添加、删除和更新等操作。客户端发现需要在客户端应用程序中集成相应的服务发现客户端，例如Netflix的Eureka客户端。 服务端发现：是指服务注册中心负责主动维护和管理可用的服务实例列表。服务实例在启动时向服务注册中心进行注册，注册中心负责记录和维护服务实例的信息，包括实例的网络地址、健康状态、负载情况等。当客户端需要调用服务时，向服务注册中心发送请求，注册中心根据负载均衡算法选择合适的实例返回给客户端。服务端发现通常需要使用专门的服务注册中心，例如Consul、ZooKeeper等。 HTTP和RPC对比RPC（Remote Produce Call）：远程过程调用，HTTP：网络传输协议 相同点： 都是基于TCP协议的应用层协议 都可以实现远程调用，服务调用服务 不同点： RPC主要用于在不同的进程或计算机之间进行函数调用和数据交换。HTTP主要用于数据传输和通信。 RPC协议通常采用二进制协议和高效的序列化方式，而HTTP通常采用文本协议和基于ASCII码的编码方式，数据传输效率较低 RPC通常需要使用专门的IDL文件来定义服务和消息类型，生成服务端和客户端的代码。而HTTP没有这个限制，可以使用套接字进行通信 gRPC和RPC对比gRPC是一种高性能，通用的远程过程调用（RPC）框架，采用基于HTTP/2的二进制传输协议实现可以实现双向流、头部压缩和多路复用等，使用Protocol Buffers作为默认的序列化协议 区别： 通信协议不同：gRPC是基于HTTP/2协议进行数据传输，而传统的RPC框架通常使用TCP和UDP等传输层协议 序列化方式不同：gRPC使用Protocol Buffers作为默认的序列化协议，而传统的RPC框架使用JSON、XML等格式。 支持多种语言：gRPC支持多种编程语言，包括C++、Java、Python、Go、Ruby等，而传统的RPC框架通常只支持少数几种语言 高性能：由于采用了HTTP/2协议和Protocol Buffers序列化协议，gRPC具有更高的性能和效率 自动生成代码：gRPC可以根据服务定义文件自动生成客户端和服务端的代码，大大简化了开发过程。 安全性：gRPC提供了TLS加密和认证等安全机制，保障通信的安全性。 Sync.Pool的使用在 Go 中，频繁地创建和销毁对象会导致以下问题： 内存分配开销：每次创建对象都需要分配内存，可能增加 GC（垃圾回收）的压力。 GC 性能下降：大量临时对象会增加 GC 的工作量，导致程序性能下降。 sync.Pool 通过缓存和复用对象，可以减少内存分配和 GC 的开销，从而提高程序性能 sync.Pool 的核心特性 对象复用：sync.Pool 缓存对象，供后续复用。 线程安全：sync.Pool 是并发安全的，多个 goroutine 可以安全地从中获取和放回对象。 自动清理：sync.Pool 中的对象可能会被 GC 清理，因此不能依赖它来长期保存对象。 1234567891011121314151617181920212223func main() { pool := &amp;sync.Pool{ New: func() interface{} { fmt.Println(&quot;Creating new object&quot;) return make([]byte, 1024) // 创建一个 1KB 的字节切片 }, } // 从池中获取对象 obj := pool.Get().([]byte) fmt.Println(&quot;Got object from pool&quot;, obj) // 使用对象 obj[0] = 1 // 将对象放回池中 pool.Put(obj) fmt.Println(&quot;Put object back to pool&quot;, obj) // 再次从池中获取对象（可能复用之前放回的对象） obj2 := pool.Get().([]byte) fmt.Println(&quot;Got object from pool again&quot;, obj2)} Gin框架1.支持中间件操作（handlersChain机制） 2.更方便的使用（gin.Context） 3.更强大的路由解析能力（radix tree路由树） 协程池协程已经很轻量了，为什么还要有协程池？ 限制协程的数量，不让协程无限制地增长 减少GC和协程创建的开销 golang中指针的作用 传递大对象 修改函数外部变量 动态分配内存 函数返回指针 for range在 Go 语言中，使用 for i, list := range lists 遍历切片时，变量 list 是切片元素的副本，lists[i]取得的才是切片中实际的元素。 在使用range遍历字符串时直接取得的字符为int32，下标取得的字符为uint8 12345t := &quot;avc&quot;for i, v := range t { fmt.Println(reflect.TypeOf(t[i])) //uint8 fmt.Println(reflect.TypeOf(v)) //int32}","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"title":"【Go】Mutex","text":"点击阅读更多查看文章内容 基本原语Go 语言在 sync 包中提供了用于同步的一些基本原语，包括常见的 sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Once 和 sync.Cond： 这些基本原语提供了较为基础的同步功能，但是它们是一种相对原始的同步机制，在多数情况下，我们都应该使用抽象层级更高的 Channel 实现同步。 MutexGo 语言的 sync.Mutex 由两个字段 state 和 sema 组成。其中 state 表示当前互斥锁的状态，而 sema 是用于控制锁状态的信号量。 1234type Mutex struct { state int32 sema uint32} 上述两个加起来只占 8 字节空间的结构体表示了 Go 语言中的互斥锁。 互斥锁的状态比较复杂，如下图所示，最低三位分别表示 mutexLocked、mutexWoken 和 mutexStarving，剩下的位置用来表示当前有多少个 Goroutine 在等待互斥锁的释放： 在默认情况下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态： mutexLocked — 表示互斥锁的锁定状态； mutexWoken — 表示从正常模式被从唤醒； mutexStarving — 当前的互斥锁进入饥饿状态； waitersCount — 当前互斥锁上等待的 Goroutine 个数； 正常模式和饥饿模式正常模式 竞争激烈时性能优先： 在正常模式下，锁的获取是非公平的，新到达的 goroutine 可能会直接获取锁，而不需要等待。 自旋等待： 当锁被占用时，新到达的 goroutine 会自旋等待一段时间，尝试直接获取锁，而不是立即进入休眠状态。 适用场景： 适用于竞争不激烈或锁持有时间较短的场景，可以最大化性能。 饥饿模式 公平性优先： 在饥饿模式下，锁的获取是公平的，等待时间最长的 goroutine 会优先获取锁。 防止长时间等待： 当某个 goroutine 等待锁的时间超过一定阈值（默认为 1 毫秒），锁会进入饥饿模式。 适用场景： 适用于竞争激烈或锁持有时间较长的场景，可以防止某些 goroutine 长时间等","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E9%94%81/"},{"title":"【Go】map的实现","text":"点击阅读更多查看文章内容 设计原理哈希函数实现哈希表的关键点在于哈希函数的选择，哈希函数的选择在很大程度上能够决定哈希表的读写性能。在理想情况下，哈希函数应该能够将不同键映射到不同的索引上，这要求哈希函数的输出范围大于输入范围，但是由于键的数量会远远大于映射的范围，所以在实际使用时，这个理想的效果是不可能实现的。 完美哈希函数： 比较实际的方式是让哈希函数的结果能够尽可能的均匀分布，然后通过工程上的手段解决哈希碰撞的问题。哈希函数映射的结果一定要尽可能均匀，结果不均匀的哈希函数会带来更多的哈希冲突以及更差的读写性能。 不均匀哈希函数： 如果使用结果分布较为均匀的哈希函数，那么哈希的增删改查的时间复杂度为 O(1)；但是如果哈希函数的结果分布不均匀，那么所有操作的时间复杂度可能会达到 O(n)。 冲突解决开放寻址法开放寻址法是一种在哈希表中解决哈希碰撞的方法，这种方法的核心思想是依次探测和比较数组中的元素以判断目标键值对是否存在于哈希表中，如果我们使用开放寻址法来实现哈希表，那么实现哈希表底层的数据结构就是数组，不过因为数组的长度有限，向哈希表写入 (author, draven) 这个键值对时会从如下的索引开始遍历： 1index := hash(&quot;author&quot;) % array.len 当我们向当前哈希表写入新的数据时，如果发生了冲突，就会将键值对写入到下一个索引不为空的位置： 如上图所示，当 Key3 与已经存入哈希表中的两个键值对 Key1 和 Key2 发生冲突时，Key3 会被写入 Key2 后面的空闲位置。当我们再去读取 Key3 对应的值时就会先获取键的哈希并取模，这会先帮助我们找到 Key1，找到 Key1 后发现它与 Key 3 不相等，所以会继续查找后面的元素，直到内存为空或者找到目标元素。 当需要查找某个键对应的值时，会从索引的位置开始线性探测数组，找到目标键值对或者空内存就意味着这一次查询操作的结束。 开放寻址法中对性能影响最大的是装载因子，它是数组中元素的数量与数组大小的比值。随着装载因子的增加，线性探测的平均用时就会逐渐增加，这会影响哈希表的读写性能。当装载率超过 70% 之后，哈希表的性能就会急剧下降，而一旦装载率达到 100%，整个哈希表就会完全失效，这时查找和插入任意元素的时间复杂度都是 O(n)的，这时需要遍历数组中的全部元素，所以在实现哈希表时一定要关注装载因子的变化。 拉链法与开放地址法相比，拉链法是哈希表最常见的实现方法，大多数的编程语言都用拉链法实现哈希表，它的实现比较开放地址法稍微复杂一些，但是平均查找的长度也比较短，各个用于存储节点的内存都是动态申请的，可以节省比较多的存储空间。 实现拉链法一般会使用数组加上链表，不过一些编程语言会在拉链法的哈希中引入红黑树以优化性能，拉链法会使用链表数组作为哈希底层的数据结构，我们可以将它看成可以扩展的二维数组： 如上图所示，当我们需要将一个键值对 (Key6, Value6) 写入哈希表时，键值对中的键 Key6 都会先经过一个哈希函数，哈希函数返回的哈希会帮助我们选择一个桶，和开放地址法一样，选择桶的方式是直接对哈希返回的结果取模： 1index := hash(&quot;Key6&quot;) % array.len 选择了 2 号桶后就可以遍历当前桶中的链表了，在遍历链表的过程中会遇到以下两种情况： 找到键相同的键值对 — 更新键对应的值； 没有找到键相同的键值对 — 在链表的末尾追加新的键值对； 如果要在哈希表中获取某个键对应的值，会经历如下的过程： Key11 展示了一个键在哈希表中不存在的例子，当哈希表发现它命中 4 号桶时，它会依次遍历桶中的链表，然而遍历到链表的末尾也没有找到期望的键，所以哈希表中没有该键对应的值。 在一个性能比较好的哈希表中，每一个桶中都应该有 01 个元素，有时会有 23 个，很少会超过这个数量。计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销，使用拉链法实现的哈希也有装载因子这一概念：装载因子:=元素数量÷桶数量 与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差。在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。 内存模型在源码中，表示 map 的结构体是 hmap，它是 hashmap 的“缩写”： 123456789101112131415161718192021// A header for a Go map.type hmap struct { // 元素个数，调用 len(map) 时，直接返回此值 count int flags uint8 // buckets 的对数 log_2 B uint8 // overflow 的 bucket 近似数 noverflow uint16 // 计算 key 的哈希的时候会传入哈希函数 hash0 uint32 // 指向 buckets 数组，大小为 2^B // 如果元素个数为0，就为 nil buckets unsafe.Pointer // 等量扩容的时候，buckets 长度和 oldbuckets 相等 // 双倍扩容的时候，buckets 长度会是 oldbuckets 的两倍 oldbuckets unsafe.Pointer // 指示扩容进度，小于此地址的 buckets 迁移完成 nevacuate uintptr extra *mapextra // optional fields} buckets：指向buckets数组的指针，数组大小为2^B，如果元素个数为0，它为nil. oldbuckets：如果发生扩容，oldbuckets是指向老的buckets数组的指针，老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为ni1. hash0 是哈希的种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入； oldbuckets 是哈希在扩容时用于保存之前 buckets 的字段，它的大小是当前 buckets 的一半； buckets 是一个指针，最终它指向的是一个结构体： 123type bmap struct { tophash [abi.MapBucketCount]uint8} 上面bmap结构是静态结构，在编译过程中runtime.bmap会拓展成以下结构体， 123456789type bmap struct{tophash [8]uint8keys [8]keytype// keytype由编译器编译时候确定values [8]elemtype// elemtype由编译器编译时候确定overflow uintptr//overflowi的下一个bmap，overflow是uintptr而不是*bmap类型，保证bmap完全不含指针，是为了减少gc，溢出桶存储到extra字段中} bmap 就是我们常说的“桶”，桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果是“一类”的。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有8个位置）。 当 map 的 key 和 value 都不是指针，并且 size 都小于 128 字节的情况下，会把 bmap 标记为不含指针，这样可以避免 gc 时扫描整个 hmap。但是，我们看 bmap 其实有一个 overflow 的字段，是指针类型的，破坏了 bmap 不含指针的设想，这时会把 overflow 移动到 extra 字段来。 12345678type mapextra struct { // overflow[0] contains overflow buckets for hmap.buckets. // overflow[1] contains overflow buckets for hmap.oldbuckets. overflow [2]*[]*bmap // nextOverflow 包含空闲的 overflow bucket，这是预分配的 bucket nextOverflow *bmap} bmap 是存放 k-v 的地方，我们把视角拉近，仔细看 bmap 的内部组成。 上图就是 bucket 的内存模型，HOB Hash 指的就是 top hash。 注意到key 和value是各自放在一起的，并不是 key/value/key/valuer …这样的形式，当key和alue类型不一样的时候，key和value占用掌节大小不一样，使用keylvalue这种形式可能会因为内存对齐导致内存空间浪费，所以Go采用key和value分开存储的设计，更节省内存空间 每个 bucket 设计成最多只能放 8 个 key-value 对，如果有第 9 个 key-value 落入当前的 bucket，那就需要再构建一个 bucket ，通过 overflow 指针连接起来。 创建map从语法层面上来说，创建 map 很简单： 123456ageMp := make(map[string]int)// 指定 map 长度ageMp := make(map[string]int, 8)// ageMp 为 nil，不能向其添加元素，会直接panicvar ageMp map[string]int 实际上底层调用的是 makemap 函数，主要做的工作就是初始化 hmap 结构体的各种字段，例如计算 B 的大小，设置哈希种子 hash0 等等。 1234567891011121314151617181920212223242526272829303132333435363738func makemap(t *maptype, hint int64, h *hmap, bucket unsafe.Pointer) *hmap { // 省略各种条件检查... // 找到一个 B，使得 map 的装载因子在正常范围内 B := uint8(0) for ; overLoadFactor(hint, B); B++ { } // 初始化 hash table // 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配 // 如果长度比较大，分配内存会花费长一点 buckets := bucket var extra *mapextra if B != 0 { var nextOverflow *bmap buckets, nextOverflow = makeBucketArray(t, B) if nextOverflow != nil { extra = new(mapextra) extra.nextOverflow = nextOverflow } } // 初始化 hamp if h == nil { h = (*hmap)(newobject(t.hmap)) } h.count = 0 h.B = B h.extra = extra h.flags = 0 h.hash0 = fastrand() h.buckets = buckets h.oldbuckets = nil h.nevacuate = 0 h.noverflow = 0 return h} 哈希函数map 的一个关键点在于，哈希函数的选择。在程序启动时，会检测 cpu 是否支持 aes，如果支持，则使用 aes hash，否则使用 memhash。这是在函数 alginit() 中完成，位于路径：src/runtime/alg.go 下。 key定位过程key 经过哈希计算后得到哈希值，共 64 个 bit 位（64位机，32位机就不讨论了，现在主流都是64位机），计算它到底要落在哪个桶时，只会用到最后 B 个 bit 位。还记得前面提到过的 B 吗？如果 B = 5，那么桶的数量，也就是 buckets 数组的长度是 2^5 = 32 例如，现在有一个 key 经过哈希函数计算后，得到的哈希结果是： 10010111 | 000011110110110010001111001010100010010110010101010 │ 01010 用最后的 5 个 bit 位，也就是 01010，值为 10，也就是 10 号桶。这个操作实际上就是取余操作，但是取余开销太大，所以代码实现上用的位操作代替。 再用哈希值的高 8 位，找到此 key 在 bucket 中的位置，这是在寻找已有的 key。最开始桶内还没有 key，新加入的 key 会找到第一个空位放入。 buckets 编号就是桶编号，当两个不同的 key 落在同一个桶中，也就是发生了哈希冲突。冲突的解决手段是用链表法：在 bucket 中，从前往后找到第一个空位。这样，在查找某个 key 时，先找到对应的桶，再去遍历 bucket 中的 key。 上图中，假定 B = 5，所以 bucket 总数就是 2^5 = 32。首先计算出待查找 key 的哈希，使用低 5 位 00110，找到对应的 6 号 bucket，使用高 8 位 10010111，对应十进制 151，在 6 号 bucket 中寻找 tophash 值（HOB hash）为 151 的 key，找到了 2 号槽位，这样整个查找过程就结束了。 如果在 bucket 中没找到，并且 overflow 不为空，还要继续去 overflow bucket 中寻找，直到找到或是所有的 key 槽位都找遍了，包括所有的 overflow bucket。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // …… // 如果 h 什么都没有，返回零值 if h == nil || h.count == 0 { return unsafe.Pointer(&amp;zeroVal[0]) } // 写和读冲突 if h.flags&amp;hashWriting != 0 { throw(&quot;concurrent map read and map write&quot;) } // 不同类型 key 使用的 hash 算法在编译期确定 alg := t.key.alg // 计算哈希值，并且加入 hash0 引入随机性 hash := alg.hash(key, uintptr(h.hash0)) // 比如 B=5，那 m 就是31，二进制是全 1 // 求 bucket num 时，将 hash 与 m 相与， // 达到 bucket num 由 hash 的低 8 位决定的效果 m := uintptr(1)&lt;&lt;h.B - 1 // b 就是 bucket 的地址 b := (*bmap)(add(h.buckets, (hash&amp;m)*uintptr(t.bucketsize))) // oldbuckets 不为 nil，说明发生了扩容 if c := h.oldbuckets; c != nil { // 如果不是同 size 扩容（看后面扩容的内容） // 对应条件 1 的解决方案 if !h.sameSizeGrow() { // 新 bucket 数量是老的 2 倍 m &gt;&gt;= 1 } // 求出 key 在老的 map 中的 bucket 位置 oldb := (*bmap)(add(c, (hash&amp;m)*uintptr(t.bucketsize))) // 如果 oldb 没有搬迁到新的 bucket // 那就在老的 bucket 中寻找 if !evacuated(oldb) { b = oldb } } // 计算出高 8 位的 hash // 相当于右移 56 位，只取高8位 top := uint8(hash &gt;&gt; (sys.PtrSize*8 - 8)) // 增加一个 minTopHash if top &lt; minTopHash { top += minTopHash } for { // 遍历 bucket 的 8 个位置 for i := uintptr(0); i &lt; bucketCnt; i++ { // tophash 不匹配，继续 if b.tophash[i] != top { continue } // tophash 匹配，定位到 key 的位置 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) // key 是指针 if t.indirectkey { // 解引用 k = *((*unsafe.Pointer)(k)) } // 如果 key 相等 if alg.equal(key, k) { // 定位到 value 的位置 v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) // value 解引用 if t.indirectvalue { v = *((*unsafe.Pointer)(v)) } return v } } // bucket 找完（还没找到），继续到 overflow bucket 里找 b = b.overflow(t) // overflow bucket 也找完了，说明没有目标 key // 返回零值 if b == nil { return unsafe.Pointer(&amp;zeroVal[0]) } }} 函数返回 h[key] 的指针，如果 h 中没有此 key，那就会返回一个 key 相应类型的零值，不会返回 nil。 代码整体比较直接，没什么难懂的地方。跟着上面的注释一步步理解就好了。 这里，说一下定位 key 和 value 的方法以及整个循环的写法。 12345// key 定位公式k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))// value 定位公式v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) b 是 bmap 的地址，这里 bmap 还是源码里定义的结构体，只包含一个 tophash 数组，经编译器扩充之后的结构体才包含 key，value，overflow 这些字段。dataOffset 是 key 相对于 bmap 起始地址的偏移： 因此 bucket 里 key 的起始地址就是 unsafe.Pointer(b)+dataOffset。第 i 个 key 的地址就要在此基础上跨过 i 个 key 的大小；而我们又知道，value 的地址是在所有 key 之后，因此第 i 个 value 的地址还需要加上所有 key 的偏移。理解了这些，上面 key 和 value 的定位公式就很好理解了。 再说整个大循环的写法，最外层是一个无限循环，通过 b = b.overflow(t) 遍历所有的 bucket，这相当于是一个 bucket 链表。 当定位到一个具体的 bucket 时，里层循环就是遍历这个 bucket 里所有的 cell，或者说所有的槽位，也就是 bucketCnt=8 个槽位。整个循环过程： 再说一下 minTopHash，当一个 cell 的 tophash 值小于 minTopHash 时，标志这个 cell 的迁移状态。因为这个状态值是放在 tophash 数组里，为了和正常的哈希值区分开，会给 key 计算出来的哈希值一个增量：minTopHash。这样就能区分正常的 top hash 值和表示状态的哈希值。 下面的这几种状态就表征了 bucket 的情况： 1234567891011// 空的 cell，也是初始时 bucket 的状态empty = 0// 空的 cell，表示 cell 已经被迁移到新的 bucketevacuatedEmpty = 1// key,value 已经搬迁完毕，但是 key 都在新 bucket 前半部分，// 后面扩容部分会再讲到。evacuatedX = 2// 同上，key 在后半部分evacuatedY = 3// tophash 的最小正常值minTopHash = 4 源码里判断这个 bucket 是否已经搬迁完毕，用到的函数： 1234func evacuated(b *bmap) bool { h := b.tophash[0] return h &gt; empty &amp;&amp; h &lt; minTopHash} 只取了 tophash 数组的第一个值，判断它是否在 0-4 之间。对比上面的常量，当 top hash 是 evacuatedEmpty、evacuatedX、evacuatedY 这三个值之一，说明此 bucket 中的 key 全部被搬迁到了新 bucket。 遍历过程本来 map 的遍历过程比较简单：遍历所有的 bucket 以及它后面挂的 overflow bucket，然后挨个遍历 bucket 中的所有 cell。每个 bucket 中包含 8 个 cell，从有 key 的 cell 中取出 key 和 value，这个过程就完成了。 但是，现实并没有这么简单。还记得前面讲过的扩容过程吗？扩容过程不是一个原子的操作，它每次最多只搬运 2 个 bucket，所以如果触发了扩容操作，那么在很长时间里，map 的状态都是处于一个中间态：有些 bucket 已经搬迁到新家，而有些 bucket 还待在老地方。 因此，遍历如果发生在扩容的过程中，就会涉及到遍历新老 bucket 的过程，这是难点所在。 假设我们有下图所示的一个 map，起始时 B = 1，有两个 bucket，后来触发了扩容（这里不要深究扩容条件，只是一个设定），B 变成 2。并且， 1 号 bucket 中的内容搬迁到了新的 bucket，1 号裂变成 1 号和 3 号；0 号 bucket 暂未搬迁。老的 bucket 挂在在 *oldbuckets 指针上面，新的 bucket 则挂在 *buckets 指针上面。 这时，我们对此 map 进行遍历。假设经过初始化后，startBucket = 3，offset = 2。于是，遍历的起点将是 3 号 bucket 的 2 号 cell，下面这张图就是开始遍历时的状态： 标红的表示起始位置，bucket 遍历顺序为：3 -&gt; 0 -&gt; 1 -&gt; 2。 因为 3 号 bucket 对应老的 1 号 bucket，因此先检查老 1 号 bucket 是否已经被搬迁过。判断方法就是： 1234func evacuated(b *bmap) bool { h := b.tophash[0] return h &gt; empty &amp;&amp; h &lt; minTopHash} 如果 b.tophash[0] 的值在标志值范围内，即在 (0,4) 区间里，说明已经被搬迁过了。 在本例中，老 1 号 bucket 已经被搬迁过了。所以它的 tophash[0] 值在 (0,4) 范围内，因此只用遍历新的 3 号 bucket。 依次遍历 3 号 bucket 的 cell，这时候会找到第一个非空的 key：元素 e。到这里，mapiternext 函数返回，这时我们的遍历结果仅有一个元素： 由于返回的 key 不为空，所以会继续调用 mapiternext 函数。 继续从上次遍历到的地方往后遍历，从新 3 号 overflow bucket 中找到了元素 f 和 元素 g。 遍历结果集也因此壮大： 新 3 号 bucket 遍历完之后，回到了新 0 号 bucket。0 号 bucket 对应老的 0 号 bucket，经检查，老 0 号 bucket 并未搬迁，因此对新 0 号 bucket 的遍历就改为遍历老 0 号 bucket。那是不是把老 0 号 bucket 中的所有 key 都取出来呢？ 并没有这么简单，回忆一下，老 0 号 bucket 在搬迁后将裂变成 2 个 bucket：新 0 号、新 2 号。而我们此时正在遍历的只是新 0 号 bucket（注意，遍历都是遍历的 *bucket 指针，也就是所谓的新 buckets）。所以，我们只会取出老 0 号 bucket 中那些在裂变之后，分配到新 0 号 bucket 中的那些 key。 因此，lowbits == 00 的将进入遍历结果集： 和之前的流程一样，继续遍历新 1 号 bucket，发现老 1 号 bucket 已经搬迁，只用遍历新 1 号 bucket 中现有的元素就可以了。结果集变成： 继续遍历新 2 号 bucket，它来自老 0 号 bucket，因此需要在老 0 号 bucket 中那些会裂变到新 2 号 bucket 中的 key，也就是 lowbit == 10 的那些 key。 这样，遍历结果集变成： 最后，继续遍历到新 3 号 bucket 时，发现所有的 bucket 都已经遍历完毕，整个迭代过程执行完毕。 map 遍历的核心在于理解 2 倍扩容时，老 bucket 会分裂到 2 个新 bucket 中去。而遍历操作，会按照新 bucket 的序号顺序进行，碰到老 bucket 未搬迁的情况时，要在老 bucket 中找到将来要搬迁到新 bucket 来的 key。 赋值过程向 map 中插入或者修改 key，最终调用的是 mapassign 函数。插入或修改 key 的语法是一样的，只不过前者操作的 key 在 map 中不存在，而后者操作的 key 存在 map 中。 整体来看，流程非常得简单：对 key 计算 hash 值，根据 hash 值按照之前的流程，找到要赋值的位置（可能是插入新 key，也可能是更新老 key），对相应位置进行赋值。 源码大体和之前讲的类似，核心还是一个双层循环，外层遍历 bucket 和它的 overflow bucket，内层遍历整个 bucket 的各个 cell。 数首先会检查 map 的标志位 flags。如果 flags 的写标志位此时被置 1 了，说明有其他协程在执行“写”操作，进而导致程序 panic。这也说明了 map 对协程是不安全的。 通过前文我们知道扩容是渐进式的，如果 map 处在扩容的过程中，那么当 key 定位到了某个 bucket 后，需要确保这个 bucket 对应的老 bucket 完成了迁移过程。即老 bucket 里的 key 都要迁移到新的 bucket 中来（分裂到 2 个新 bucket），才能在新的 bucket 中进行插入或者更新的操作。 现在到了定位 key 应该放置的位置了，所谓找准自己的位置很重要。准备两个指针，一个（inserti）指向 key 的 hash 值在 tophash 数组所处的位置，另一个(insertk)指向 cell 的位置（也就是 key 最终放置的地址），当然，对应 value 的位置就很容易定位出来了。这三者实际上都是关联的，在 tophash 数组中的索引位置决定了 key 在整个 bucket 中的位置（共 8 个 key），而 value 的位置需要“跨过” 8 个 key 的长度。 在循环的过程中，inserti 和 insertk 分别指向第一个找到的空闲的 cell。如果之后在 map 没有找到 key 的存在，也就是说原来 map 中没有此 key，这意味着插入新 key。那最终 key 的安置地址就是第一次发现的“空位”（tophash 是 empty）。 如果这个 bucket 的 8 个 key 都已经放置满了，那在跳出循环后，发现 inserti 和 insertk 都是空，这时候需要在 bucket 后面挂上 overflow bucket。当然，也有可能是在 overflow bucket 后面再挂上一个 overflow bucket。这就说明，太多 key hash 到了此 bucket。 在正式安置 key 之前，还要检查 map 的状态，看它是否需要进行扩容。如果满足扩容的条件，就主动触发一次扩容操作。 这之后，整个之前的查找定位 key 的过程，还得再重新走一次。因为扩容之后，key 的分布都发生了变化。 最后，会更新 map 相关的值，如果是插入新 key，map 的元素数量字段 count 值会加 1；在函数之初设置的 hashWriting 写标志出会清零。 删除过程删除操作底层的执行函数是 mapdelete： func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) 它首先会检查 h.flags 标志，如果发现写标位是 1，直接 panic，因为这表明有其他协程同时在进行写操作。 计算 key 的哈希，找到落入的 bucket。检查此 map 如果正在扩容的过程中，直接触发一次搬迁操作。 删除操作同样是两层循环，核心还是找到 key 的具体位置。寻找过程都是类似的，在 bucket 中挨个 cell 寻找。找到对应位置后，对 key 或者 value 进行“清零”操作： 12345678910111213// 对 key 清零if t.indirectkey { *(*unsafe.Pointer)(k) = nil} else { typedmemclr(t.key, k)}// 对 value 清零if t.indirectvalue { *(*unsafe.Pointer)(v) = nil} else { typedmemclr(t.elem, v)} 最后，将 count 值减 1，将对应位置的 tophash 值置成 Empty。 扩容过程使用哈希表的目的就是要快速查找到目标 key，然而，随着向 map 中添加的 key 越来越多，key 发生碰撞的概率也越来越大。bucket 中的 8 个 cell 会被逐渐塞满，查找、插入、删除 key 的效率也会越来越低。最理想的情况是一个 bucket 只装一个 key，这样，就能达到 O(1) 的效率，但这样空间消耗太大，用空间换时间的代价太高。 Go 语言采用一个 bucket 里装载 8 个 key，定位到某个 bucket 后，还需要再定位到具体的 key，这实际上又用了时间换空间。 当然，这样做，要有一个度，不然所有的 key 都落在了同一个 bucket 里，直接退化成了链表，各种操作的效率直接降为 O(n)，是不行的。 因此，需要有一个指标来衡量前面描述的情况，这就是装载因子。Go 源码里这样定义 装载因子：loadFactor := count / (2^B) count 就是 map 的元素个数，2^B 表示 bucket 数量。 再来说触发 map 扩容的时机：在向 map 插入新 key 的时候，会进行条件检测，符合下面这 2 个条件，就会触发扩容： 装载因子超过阈值，源码里定义的阈值是 6.5。 overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B &gt;= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15。 通过汇编语言可以找到赋值操作对应源码中的函数是 mapassign，对应扩容条件的源码如下： 12345678910111213141516171819// src/runtime/hashmap.go/mapassign// 触发扩容时机if !h.growing() &amp;&amp; (overLoadFactor(int64(h.count), h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) }// 装载因子超过 6.5func overLoadFactor(count int64, B uint8) bool { return count &gt;= bucketCnt &amp;&amp; float32(count) &gt;= loadFactor*float32((uint64(1)&lt;&lt;B))}// overflow buckets 太多func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { if B &lt; 16 { return noverflow &gt;= uint16(1)&lt;&lt;B } return noverflow &gt;= 1&lt;&lt;15} 第 1 点：我们知道，每个 bucket 有 8 个空位，在没有溢出，且所有的桶都装满了的情况下，装载因子算出来的结果是 8。因此当装载因子超过 6.5 时，表明很多 bucket 都快要装满了，查找效率和插入效率都变低了。在这个时候进行扩容是有必要的。 第 2 点：是对第 1 点的补充。就是说在装载因子比较小的情况下，这时候 map 的查找和插入效率也很低，而第 1 点识别不出来这种情况。表面现象就是计算装载因子的分子比较小，即 map 里元素总数少，但是 bucket 数量多（真实分配的 bucket 数量多，包括大量的 overflow bucket）。 不难想像造成这种情况的原因：不停地插入、删除元素。先插入很多元素，导致创建了很多 bucket，但是装载因子达不到第 1 点的临界值，未触发扩容来缓解这种情况。之后，删除元素降低元素总数量，再插入很多元素，导致创建很多的 overflow bucket，但就是不会触犯第 1 点的规定，你能拿我怎么办？overflow bucket 数量太多，导致 key 会很分散，查找插入效率低得吓人，因此出台第 2 点规定。这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。 对于命中条件 1，2 的限制，都会发生扩容。但是扩容的策略并不相同，毕竟两种条件应对的场景不同。 对于条件 1，元素太多，而 bucket 数量太少，很简单：将 B 加 1，bucket 最大数量（2^B）直接变成原来 bucket 数量的 2 倍。于是，就有新老 bucket 了。注意，这时候元素都在老 bucket 里，还没迁移到新的 bucket 来。而且，新 bucket 只是最大数量变为原来最大数量（2^B）的 2 倍（2^B * 2）。 对于条件 2，其实元素没那么多，但是 overflow bucket 数特别多，说明很多 bucket 都没装满。解决办法就是开辟一个新 bucket 空间，将老 bucket 中的元素移动到新 bucket，使得同一个 bucket 中的 key 排列地更紧密。这样，原来，在 overflow bucket 中的 key 可以移动到 bucket 中来。结果是节省空间，提高 bucket 利用率，map 的查找和插入效率自然就会提升。 再来看一下扩容具体是怎么做的。由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果有大量的 key/value 需要搬迁，会非常影响性能。因此 Go map 的扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。 上面说的 hashGrow() 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 growWork() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。 我们先看 hashGrow() 函数所做的工作，再来看具体的搬迁 buckets 是如何进行的。 12345678910111213141516171819202122232425262728293031func hashGrow(t *maptype, h *hmap) { // B+1 相当于是原来 2 倍的空间 bigger := uint8(1) // 对应条件 2 if !overLoadFactor(int64(h.count), h.B) { // 进行等量的内存扩容，所以 B 不变 bigger = 0 h.flags |= sameSizeGrow } // 将老 buckets 挂到 buckets 上 oldbuckets := h.buckets // 申请新的 buckets 空间 newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger) flags := h.flags &amp;^ (iterator | oldIterator) if h.flags&amp;iterator != 0 { flags |= oldIterator } // 提交 grow 的动作 h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets // 搬迁进度为 0 h.nevacuate = 0 // overflow buckets 数为 0 h.noverflow = 0 // ……} 主要是申请到了新的 buckets 空间，把相关的标志位都进行了处理：例如标志 nevacuate 被置为 0， 表示当前搬迁进度为 0。 再来看看真正执行搬迁工作的 growWork() 函数。 12345678910func growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的 bucket 对应正在使用的 bucket evacuate(t, h, bucket&amp;h.oldbucketmask()) // 再搬迁一个 bucket，以加快搬迁进程 if h.growing() { evacuate(t, h, h.nevacuate) }} 123func (h *hmap) growing() bool { return h.oldbuckets != nil} 如果 oldbuckets 不为空，说明还没有搬迁完毕，还得继续搬。 接下来，我们集中所有的精力在搬迁的关键函数 evacuate，搬迁过程详细说明。 搬迁的目的就是将老的 buckets 搬迁到新的 buckets。而通过前面的说明我们知道，应对条件 1，新的 buckets 数量是之前的一倍，应对条件 2，新的 buckets 数量和之前相等。 对于条件 2，从老的 buckets 搬迁到新的 buckets，由于 bucktes 数量不变，因此可以按序号来搬，比如原来在 0 号 bucktes，到新的地方后，仍然放在 0 号 buckets。 对于条件 1，就没这么简单了。要重新计算 key 的哈希，才能决定它到底落在哪个 bucket。例如，原来 B = 5，计算出 key 的哈希后，只用看它的低 5 位，就能决定它落在哪个 bucket。扩容后，B 变成了 6，因此需要多看一位，它的低 6 位决定 key 落在哪个 bucket。这称为 rehash。 因此，某个 key 在搬迁前后 bucket 序号可能和原来相等，也可能是相比原来加上 2^B（原来的 B 值），取决于 hash 值 第 6 bit 位是 0 还是 1。 再明确一个问题：如果扩容后，B 增加了 1，意味着 buckets 总数是原来的 2 倍，原来 1 号的桶“裂变”到两个桶。 例如，原始 B = 2，1号 bucket 中有 2 个 key 的哈希值低 3 位分别为：010，110。由于原来 B = 2，所以低 2 位 10 决定它们落在 2 号桶，现在 B 变成 3，所以 010、110 分别落入 2、6 号桶。 evacuate 函数每次只完成一个 bucket 的搬迁工作，因此要遍历完此 bucket 的所有的 cell，将有值的 cell copy 到新的地方。bucket 还会链接 overflow bucket，它们同样需要搬迁。因此会有 2 层循环，外层遍历 bucket 和 overflow bucket，内层遍历 bucket 的所有 cell。这样的循环在 map 的源码里到处都是，要理解透了。 源码里提到 X, Y part，其实就是我们说的如果是扩容到原来的 2 倍，桶的数量是原来的 2 倍，前一半桶被称为 X part，后一半桶被称为 Y part。一个 bucket 中的 key 可能会分裂落到 2 个桶，一个位于 X part，一个位于 Y part。所以在搬迁一个 cell 之前，需要知道这个 cell 中的 key 是落到哪个 Part。很简单，重新计算 cell 中 key 的 hash，并向前“多看”一位，决定落入哪个 Part，这个前面也说得很详细了。 确定了要搬迁到的目标 bucket 后，搬迁操作就比较好进行了。将源 key/value 值 copy 到目的地相应的位置。 设置 key 在原始 buckets 的 tophash 为 evacuatedX 或是 evacuatedY，表示已经搬迁到了新 map 的 x part 或是 y part。新 map 的 tophash 则正常取 key 哈希值的高 8 位。 下面通过图来宏观地看一下扩容前后的变化。 扩容前，B = 2，共有 4 个 buckets，lowbits 表示 hash 值的低位。假设我们不关注其他 buckets 情况，专注在 2 号 bucket。并且假设 overflow 太多，触发了等量扩容（对应于前面的条件 2）。 扩容完成后，overflow bucket 消失了，key 都集中到了一个 bucket，更为紧凑了，提高了查找的效率。 假设触发了 2 倍的扩容，那么扩容完成后，老 buckets 中的 key 分裂到了 2 个 新的 bucket。一个在 x part，一个在 y 的 part。依据是 hash 的 lowbits。新 map 中 0-3 称为 x part，4-7 称为 y part。 上面的两张图忽略了其他 buckets 的搬迁情况，表示所有的 bucket 都搬迁完毕后的情形。实际上，我们知道，搬迁是一个“渐进”的过程，并不会一下子就全部搬迁完毕。所以在搬迁过程中，oldbuckets 指针还会指向原来老的 []bmap，并且已经搬迁完毕的 key 的 tophash 值会是一个状态值，表示 key 的搬迁去向。 Golang的map为什么是无序的？使用range多次遍历map时输出的key和vabue 的顺序可能不同。这是Go语言的设计者们有意为之，旨在提示开发者们，Go底层实现并不保证map遍历顺序稳定，请大家不要依赖range遍历结果顺序 map在遍历时，并不是从固定的0号bucket开始遍历的，每次遍历，都会从一个随机值序号的bucket，再从其中随机的cell开始遍历 map遍历时，是按序遍历bucket，同时按需遍历bucket中和其overflow bucket中的cell。但是map在扩容后，会发生key的搬迁，这造成原来落在一个buket中的Key,搬迁后，有可能会落到其他bucket中了，从这个角度看，遍历map的结果就不可能是按照原来的顺序了 map本身是无序的，且遍历时顺序还会被随机化，如果想顺序遍历map，需要对 map key先排序，再按照key 的顺序遍历map。 sync.mapGo 语言原生 map 并不是线程安全的，对它进行并发读写操作的时候，需要加锁。而 sync.map 则是一种并发安全的 map，在 Go 1.9 引入。 sync.map 是线程安全的，读取，插入，删除也都保持着常数级的时间复杂度。sync.map 的零值是有效的，并且零值是一个空的 map。在第一次使用之后，不允许被拷贝。 一般情况下解决并发读写 map 的思路是加一把大锁，或者把一个 map 分成若干个小 map，对 key 进行哈希，只操作相应的小 map。前者锁的粒度比较大，影响效率；后者实现起来比较复杂，容易出错。 而使用 sync.map 之后，对 map 的读写，不需要加锁。并且它通过空间换时间的方式，使用 read 和 dirty 两个 map 来进行读写分离，降低锁时间来提高效率。 使用方式： 1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;fmt&quot; &quot;sync&quot;)func main() { var m sync.Map // 1. 写入 m.Store(&quot;qcrao&quot;, 18) m.Store(&quot;stefno&quot;, 20) // 2. 读取 age, _ := m.Load(&quot;qcrao&quot;) fmt.Println(age.(int)) // 3. 遍历 m.Range(func(key, value interface{}) bool { name := key.(string) age := value.(int) fmt.Println(name, age) return true }) // 4. 删除 m.Delete(&quot;qcrao&quot;) age, ok := m.Load(&quot;qcrao&quot;) fmt.Println(age, ok) // 5. 读取或写入 m.LoadOrStore(&quot;stefno&quot;, 100) age, _ = m.Load(&quot;stefno&quot;) fmt.Println(age)} sync.map 适用于读多写少的场景。对于写多的场景，会导致 read map 缓存失效，需要加锁，导致冲突变多；而且由于未命中 read map 次数过多，导致 dirty map 提升为 read map，这是一个 O(N) 的操作，会进一步降低性能。 数据结构123456type Map struct { mu Mutex read atomic.Value // readOnly dirty map[interface{}]*entry misses int} sync.Map 内部维护两个数据结构： **read**：原子操作的只读 map，支持无锁读操作。 **dirty**：可写的 map，存储最新数据，写操作需要加锁。 这种设计将高频的读操作（无锁）和低频的写操作（加锁）分离，减少锁竞争。 读操作优先访问 read，无需加锁。 若 read 中不存在目标键，则加锁访问 dirty，并记录未命中次数（misses），触发 dirty 到 read 的提升。 写操作： 读取 read 字段： 首先尝试从 read 中查找目标键。 检查 read 中是否存在目标键： 如果 read 中存在目标键，则尝试通过原子操作更新其值。 如果更新成功，写操作完成。 加锁并检查 dirty 字段： 如果 read 中不存在目标键，或者更新失败，则加锁（m.mu.Lock()）并检查 dirty 字段。 更新 dirty 字段： 如果 dirty 中存在目标键，则直接更新其值。 如果 dirty 中不存在目标键，则将键值对写入 dirty。 处理 misses 计数器： 如果 read 中未找到目标键，则增加 misses 计数器。 当 misses 达到一定阈值时，将 dirty 提升为新的 read，并清空 dirty。 解锁： 写操作完成后，释放锁（m.mu.Unlock()）。 关键机制解析 entry 的原子操作每个键值对存储在 entry 结构体中，通过原子操作 atomic.LoadPointer 和 atomic.StorePointer 保证线程安全。 dirty 的重建当 dirty 为 nil 时，新的写操作会触发 dirty 的重建：将 read 中的所有有效条目复制到 dirty。 misses 触发提升当读操作未命中 read 的次数（misses）超过 dirty 的长度时，dirty 会被提升为新的 read，此后读操作直接访问新 read","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91map%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"title":"2、TCP","text":"点击阅读更多查看文章内容 三次握手 一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态 客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态。 为什么不是两次、四次？避免历史连接 防止旧的重复连接初始化造成混乱，我们考虑一个场景，客户端先发送了 SYN（seq = 90）报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100）报文（注意！不是重传 SYN，重传的 SYN 的序列号是一样的） 一个「旧 SYN 报文」比「最新的 SYN」 报文早到达了服务端，那么此时服务端就会回一个 SYN + ACK 报文给客户端，此报文中的确认号是 91（90+1）。 客户端收到后，发现自己期望收到的确认号应该是 100 + 1，而不是 90 + 1，于是就会回 RST 报文。 服务端收到 RST 报文后，就会释放连接。 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。 上述中的「旧 SYN 报文」称为历史连接，TCP 使用三次握手建立连接的最主要原因就是防止「历史连接」初始化了连接。 在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费 同步双方初始序列号 序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。 四次握手可以合并成三次握手 避免资源浪费 由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 ACK 报文，所以服务端每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？ 如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。（历史连接问题） 为什么建立TCP连接的初始化序列号都要求不一样 为了防止历史报文被下一个相同四元组的连接接收（主要方面） 防止黑客伪造相同序列号的TCP报文被对方接受 假设每次建立连接，客户端和服务器的初始序列号都从0开始 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。 紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接； 在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱 既然IP层会分片为什么TCP层还需要MSS MTU：一个网络包的最大长度，以太网中一般为 1500 字节 MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度 假设有一份数据，在TCP层不分段，如果这份数据在发送的过程中出现丢包现象，TCP会发生重传，那么重传的就是这一大份数据（虽然IP层会把数据切分为MTU长度的N多个小包，但是TCP重传的单位却是那一大份数据）；如果TCP把这份数据，分段为N个小于等于MSS长度的数据包，到了IP层后加上IP头和TCP头，还是小于MTU，那么IP层也不会再进行分包。此时在传输路上发生了丢包，那么TCP重传的时候也只是重传那一小部分的MSS段。效率会比TCP不分段时更高。 IP层本身没有超时重传机制，超时重传都是由TCP负责的，而TCP的重传机制是基于字节流的，而不是IP数据包的大小。因此，当TCP发送大量数据时，即使在IP层数据已经被分割成多个小包（比如每个包的大小小于MTU），TCP依然是以完整的大块数据为单位来管理和重传的。（TCP将一整段数据交付给IP层，IP层分片发送，如果其中某个分片丢失，而接收的TCP并不知道该分片具体的序号也就无法针对该分片进行重传，只有在TCP层分段为每个数据段都设置对应的序号，接收方才能分别确认各个数据段，才能判断哪一个数据段没有收到进行重传） 丢失重传 第一次握手丢失： 客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且重传的 SYN 报文的序列号都是一样的。 第二次握手丢失： 第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是客户端就会触发超时重传机制，重传 SYN 报文。 因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。 那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是服务端这边会触发超时重传机制，重传 SYN-ACK 报文。 第三次握手丢失： 因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。 注意：ACK 报文时不会重传的，如果ACK丢失了，就由对方重传对应的报文 四次挥手 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。 为什么需要四次挥手？ 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，因此是需要四次挥手。 为什么TIME_WAIT等待的时间是2MSLMSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。MSL应该要大于等于TTL消耗为0的时间，以确保报文已被自然消亡。 TIME_WAIT 等待 2 倍的 MSL，是因为如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方。 一来一去正好 2 个 MSL。可以看到 2MSL时长 这其实是相当于至少允许报文丢失一次。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对 服务器出现大量TIME_WAIT状态的原因有哪些？HTTP没有使用长连接 在 HTTP/1.1 中默认是打开的，请求的 header 中：Connection: Keep-Alive，响应header中Connection: Keep-Alive 短连接每次请求响应都要创建关闭TCP连接，因此会有大量的TIME_WAIT状态，长连接只会创建一个TCP连接多次使用。 HTTP长连接超时 如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。如果有大量客户端建立完TCP连接后没有使用就会导致服务端主动关闭连接，产生大量TIME_WAIT。可以往网络问题排查，比如是否是因为网络问题，导致客户端发送的数据一直没有被服务端接收。 HTTP长连接的请求数量达到上限 Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。 比如 nginx 的 keepalive_requests 这个参数，这个参数是指一个 HTTP 长连接建立之后，nginx 就会为这个连接设置一个计数器，记录这个 HTTP 长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。 服务器出现大量CLOSE_WAIT状态的原因有哪些？CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。 所以，当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接。 SocketSocket是一个抽象的概念，它代表了网络中不同主机上的应用进程之间的双向通信的端点。每一个Socket都有一个唯一的标识符，这个标识符由IP地址和端口号组成。通过这种方式，不同的应用程序可以通过网络相互通信。 Socket是对TCP/IP协议族的一个抽象层，它隐藏了底层复杂的细节，提供了一组简单的接口供应用层调用以实现网络通信。实际上，Socket并不直接对应于某个具体的协议，而是作为一个中间层工具存在于应用层和传输层之间 服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接(close)，服务端会读取到EOF，待处理完数据后服务端调用close表示连接关闭 注意：服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。 所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。 成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。 accept发生在三次握手的哪一步？ 客户端调用close连接断开的流程 客户端调用 close，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态； 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，应用程序可以通过 read 调用来感知这个 FIN 包。这个 EOF 会被放在已排队等候的其他已接收的数据之后，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态； 接着，当处理完数据后，自然就会读到 EOF，于是也调用 close 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态； 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态； 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态； 客户端经过 2MSL 时间之后，也进入 CLOSE 状态； 重传、滑动窗口、流量控制、拥塞控制重传机制TCP 实现可靠传输的方式之一，是通过序列号与确认应答。 在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。 TCP针对数据包丢失的情况，会用重传机制解决。 超时重传 重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据，也就是我们常说的超时重传。 TCP 会在以下两种情况发生超时重传： 数据包丢失 确认应答丢失 超时时间计算：超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。 快速重传 TCP 还有另外一种快速重传（Fast Retransmit）机制，它不以时间为驱动，而是以数据驱动重传。 在上图，发送方发出了 1，2，3，4，5 份数据： 第一份 Seq1 先送到了，于是就 Ack 回 2； 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2； 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到； 发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。 最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。 快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，是重传一个，还是重传所有的问题。 举个例子，假设发送方发了 6 个数据，编号的顺序是 Seq1 ~ Seq6 ，但是 Seq2、Seq3 都丢失了，那么接收方在收到 Seq4、Seq5、Seq6 时，都是回复 ACK2 给发送方，但是发送方并不清楚这连续的 ACK2 是接收方收到哪个报文而回复的， 那是选择重传 Seq2 一个报文，还是重传 Seq2 之后已发送的所有报文呢（Seq2、Seq3、 Seq4、Seq5、 Seq6） 呢？ 如果只选择重传 Seq2 一个报文，那么重传的效率很低。因为对于丢失的 Seq3 报文，还得在后续收到三个重复的 ACK3 才能触发重传。 如果选择重传 Seq2 之后已发送的所有报文，虽然能同时重传已丢失的 Seq2 和 Seq3 报文，但是 Seq4、Seq5、Seq6 的报文是已经被接收过了，对于重传 Seq4 ～Seq6 折部分数据相当于做了一次无用功，浪费资源。 SACK方法 SACK（ Selective Acknowledgment）， 选择性确认。 这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将已收到的数据的信息发送给「发送方」，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。 如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 SACK 信息发现只有 200~299 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。 滑动窗口TCP 每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。 效率比较低的。 窗口：无需等待确认应答，可以继续发送数据的最大值。 窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。 假设窗口大小为 3 个 TCP 段，那么发送方就可以「连续发送」 3 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。如下图： 图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据「接收方」都收到了。这个模式就叫累计确认或者累计应答。 拥塞控制滑动窗口用于流量控制，避免发送方的数据填满接收方的缓存 拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。 我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。 拥塞窗口 cwnd 变化的规则： 只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少； 如果发送方没有在规定时间内接收到ACK应答报文，也就是发生了超时重传，就会认为网络出现了拥塞。 慢启动 TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？ 慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。 这里假定拥塞窗口 cwnd 和发送窗口 swnd 相等，下面举个栗子： 连接建立完成后，一开始初始化 cwnd = 1，表示可以传一个 MSS 大小的数据。 当收到一个 ACK 确认应答后，cwnd 增加 1，于是一次能够发送 2 个 当收到 2 个的 ACK 确认应答后， cwnd 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个 当这 4 个的 ACK 确认到来的时候，每个确认 cwnd 增加 1， 4 个确认 cwnd 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。 慢启动门限：当cwnd小于ssthresh时使用慢启动算法，当cwnd&gt;=ssthresh时使用拥塞避免算法 拥塞避免 一般来说 ssthresh 的大小是 65535 字节。 那么进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1/cwnd。 接上前面的慢启动的栗子，现假定 ssthresh 为 8：当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd 一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了线性增长。 拥塞发生 当网络出现拥塞时会发生数据包重传，重传有两种：超时重传和快速重传。 当发生了「超时重传」，则就会使用拥塞发生算法。 这个时候，ssthresh 和 cwnd 的值会发生变化 ssthresh 设为 cwnd/2 cwnd 重置为 1 （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1） 之后就重新开始慢启动 当发生快速重传时，TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 ssthresh 和 cwnd 变化如下： cwnd = cwnd/2 ，也就是设置为原来的一半; ssthresh = cwnd; 进入快速恢复算法 快速恢复 快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。 进入快速恢复之前，cwnd 和 ssthresh 已被更新了： cwnd = cwnd/2 ，也就是设置为原来的一半; ssthresh = cwnd; 然后，进入快速恢复算法如下： 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个重复数据包被收到了）； 重传丢失的数据包； 如果再收到重复的 ACK，那么 cwnd 增加 1； （收到重复ACK说明上一步重传的数据包尚未接收且网络仍具有一定的传输能力，可以增加cwnd大小提高发送效率尽快将数据包发送给目标） 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态； 半连接队列与全连接队列在 TCP 三次握手的时候，每一个socket执行listen时，内核都会自动创建一个半连接队列和全连接队列。 半连接队列，也称 SYN 队列； 全连接队列，也称 accept 队列； 服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。 不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。 如果 SYN 半连接队列已满，只能丢弃连接吗？ 并不是这样，开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接。 syncookies 的工作原理：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。 绕过三次握手 TCP Fast Open首次连接：需要三次握手，生成cookie 客户端发送普通SYN报文（不带数据）。 服务器生成一个加密的TFO Cookie（通常基于客户端IP等信息），通过SYN-ACK报文返回。 客户端完成三次握手后，保存该Cookie。 后续连接（绕过三次握手）： 客户端发送SYN报文时，携带已存储的Cookie和用户数据。 服务器验证Cookie合法性： 若合法：服务器直接处理SYN报文中的数据，并在SYN-ACK报文中返回响应数据。 若不合法：丢弃数据部分，退化为普通三次握手。 客户端收到SYN-ACK后，发送ACK确认服务器返回的SYN以及数据，整个过程仅需1个RTT即可完成数据传输。 通过cookie验证身份，传统的三次握手用于确保双方可达且序列号同步，而TFO通过加密的Cookie验证客户端身份。服务器通过验证Cookie的合法性，确认客户端是此前成功建立过连接的合法实体，从而允许跳过握手直接接受数据。客户端在发送SYN报文时即可携带数据（前提是Cookie有效），服务器在回复SYN-ACK时也可携带响应数据，无需等待ACK确认。 close和shutdown关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。 如果进程收到 RST 报文，就直接关闭连接了，不需要走四次挥手流程，是一个暴力关闭连接的方式。 安全关闭连接的方式必须通过四次挥手，它由进程调用 close 和 shutdown 函数发起 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。 调用 close 函数和 shutdown 函数有什么区别？ close 函数。意味着完全断开连接，完全断开不仅指无法传输数据，而且也不能发送数据。 shutdown 函数，它可以控制只关闭（读或写）一个方向的连接 如何TCP是面向理解字节流的协议当用户消息通过 UDP 协议传输时，操作系统不会对消息进行拆分，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是每个 UDP 报文就是一个用户消息的边界，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。 你可能会问，如果收到了两个 UDP 报文，操作系统是怎么区分开的？ 操作系统在收到 UDP 报文后，会将其插入到队列里，队列里的每一个元素就是一个 UDP 报文，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。 当用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个的 TCP 报文，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。 这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。 举个实际的例子来说明。 发送方准备发送 「Hi.」和「I am Xiaolin」这两个消息。 在发送端，当我们调用 send 函数完成数据“发送”以后，数据并没有被真正从网络上发送出去，只是从应用程序拷贝到了操作系统内核协议栈中。 至于什么时候真正被发送，取决于发送窗口、拥塞窗口以及当前发送缓冲区的大小等条件。也就是说，我们不能认为每次 send 调用发送的数据，都会作为一个整体完整地消息被发送出去。 如果我们考虑实际网络传输过程中的各种影响，假设发送端陆续调用 send 函数先后发送 「Hi.」和「I am Xiaolin」 报文，那么实际的发送很有可能有多种情况。 因此，我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议。 当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 TCP 粘包问题，这时接收方不知道消息的边界的话，是无法读出有效的消息。 要解决这个问题，要交给应用程序 固定长度消息 特殊字符边界 HTTP协议 自定义消息结构 数据长度+数据内容 已建立连接的TCP收到SYN会发生什么一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 Established 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理 端口号不同：建立新的连接，旧连接中如果客户端收到服务端的数据包会返回RST报文，如果服务端一直没收到客户端数据则超过一段时间后会启动TCP保活机制，服务端自动释放连接 端口号相同：处于 Established 状态的服务端，如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。 接着，客户端收到这个 Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。 TCP Keepalive注意与HTTP中的Keep-Alive不是一个东西，HTTP中的是启用长连接，是由应用程序实现的。 TCP 的 Keepalive 是 TCP 的保活机制，是由内核实现的。 如果两端的 TCP 连接一直没有数据交互，达到了触发 TCP 保活机制的条件，那么内核里的 TCP 协议栈就会发送探测报文。 如果对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。 如果对端主机宕机（注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。 所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，这个工作是在内核完成的。 TCP协议缺陷升级困难TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核。 而升级内核这个工作是很麻烦的事情，麻烦的事情不是说升级内核这个操作很麻烦，而是由于内核升级涉及到底层软件和运行库的更新，我们的服务程序就需要回归测试是否兼容新的内核版本，所以服务器的内核升级也比较保守和缓慢。 很多 TCP 协议的新特性，都是需要客户端和服务端同时支持才能生效的，比如 TCP Fast Open 这个特性，虽然在2013 年就被提出了，但是 Windows 很多系统版本依然不支持它，这是因为 PC 端的系统升级滞后很严重，W indows Xp 现在还有大量用户在使用，尽管它已经存在快 20 年。 所以，即使 TCP 有比较好的特性更新，也很难快速推广，用户往往要几年或者十年才能体验到 队头阻塞TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。如下图： 图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 packet #3 在网络中丢失了，即使 packet #4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet #3 重传后，接收方的应用层才可以从内核中读取到数据。 这就是 TCP 队头阻塞问题，但这也不能怪 TCP ，因为只有这样做才能保证数据的有序性。 网络迁移基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。 那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接。 而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的 TCP和UDP可以绑定同一个端口吗可以的。 在数据链路层中，通过 MAC 地址来寻找局域网中的主机。在网际层中，通过 IP 地址来寻找网络中互连的主机或路由器。在传输层中，需要通过端口进行寻址，来识别同一计算机中同时通信的不同应用程序。 所以，传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。 传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。 当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理 重启 TCP 服务进程时，为什么会有“Address in use”的报错信息？ 当我们重启 TCP 服务进程的时候，意味着通过服务器端发起了关闭连接操作，于是就会经过四次挥手，而对于主动关闭方，会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误。 而等 TIME_WAIT 状态的连接结束后，重启 TCP 服务进程就能成功。 客户端同一个端口可以绑定多个连接吗？ TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。所以如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。 只要客户端连接的服务器不同，端口资源可以重复使用 不使用listen可以建立TCP连接吗？可以的，客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接 我们知道执行 listen 方法时，会创建半连接队列和全连接队列。 三次握手的过程中会在这两个队列中暂存连接信息。 所以形成连接，前提是你得有个地方存放着，方便握手的时候能根据 IP + 端口等信息找到对应的 socket。 那么客户端会有半连接队列吗？ 显然没有，因为客户端没有执行listen，因为半连接队列和全连接队列都是在执行 listen 方法时，内核自动创建的。 但内核还有个全局 hash 表，可以用于存放 sock 连接的信息。 在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个全局 hash 表中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接。 TCP 同时打开的情况也类似，只不过从一个客户端变成了两个客户端而已。 没有accept，能建立TCP连接吗？一般情况下，如果启动服务器，会发现最后程序会阻塞在accept()里。 此时服务端就算ok了，就等客户端了。客户端比较简单，创建好socket之后，直接就发起connect方法。 此时回到服务端，会发现之前一直阻塞的accept方法，返回结果了。 这就算两端成功建立好了一条连接。之后就可以愉快的进行读写操作了。 那么，我们今天的问题是，如果没有这个accept方法，TCP连接还能建立起来 就算不执行accept()方法，三次握手照样进行，并顺利建立连接。 每一个socket执行listen时，内核都会自动创建一个半连接队列和全连接队列。 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。 accept方法只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎毫无关系。 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了哈希表，而全连接队列本质是链表。 全连接队列满了，再来第三次握手也会丢弃，此时如果tcp_abort_on_overflow=1，还会直接发RST给客户端。 半连接队列满了，可能是因为受到了SYN Flood攻击，可以设置tcp_syncookies，绕开半连接队列。 成一个cookies，这个cookies会跟着第二次握手，发回客户端。客户端在发第三次握手的时候带上这个cookies，服务端验证到它就是当初发出去的那个，就会建立连接并放入到全连接队列中。可以看出整个过程不再需要半连接队列的参与。 客户端没有半连接队列和全连接队列，但有一个全局hash，可以通过它实现自连接或TCP同时打开 数据包的发送流程为了发送数据包，两端首先会通过三次握手，建立TCP连接。 一个数据包，从聊天框里发出，消息会从聊天软件所在的用户空间拷贝到内核空间的发送缓冲区（send buffer），数据包就这样顺着传输层、网络层，进入到数据链路层，在这里数据包会经过流控（qdisc），再通过RingBuffer发到物理层的网卡。数据就这样顺着网卡发到了纷繁复杂的网络世界里。这里头数据会经过n多个路由器和交换机之间的跳转，最后到达目的机器的网卡处。 此时目的机器的网卡会通知DMA将数据包信息放到RingBuffer中，再触发一个硬中断给CPU，CPU触发软中断让ksoftirqd去RingBuffer收包，于是一个数据包就这样顺着物理层，数据链路层，网络层，传输层，最后从内核空间拷贝到用户空间里的聊天软件里。 TCP四次挥手，可以变成三次吗？粗暴关闭 vs 优雅关闭 前面介绍 TCP 四次挥手的时候，并没有详细介绍关闭连接的函数，其实关闭的连接的函数有两种函数： close 函数，同时 socket 关闭发送方向和读取方向，也就是 socket 不再有发送和接收数据的能力。如果有多进程/多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 FIN 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出 FIN 报文。 shutdown 函数，可以指定 socket 只关闭发送方向而不关闭读取方向，也就是 socket 不再有发送数据的能力，但是还是具有接收数据的能力。如果有多进程/多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用，然后发出 FIN 报文，如果有别的进程企图使用该 socket，将会受到影响。 如果客户端是用 close 函数来关闭连接，那么在 TCP 四次挥手过程中，如果收到了服务端发送的数据，由于客户端已经不再具有发送和接收数据的能力，所以客户端的内核会回 RST 报文给服务端，然后内核会释放连接，这时就不会经历完成的 TCP 四次挥手，所以我们常说，调用 close 是粗暴的关闭 相对的，shutdown 函数因为可以指定只关闭发送方向而不关闭读取方向，所以即使在 TCP 四次挥手过程中，如果收到了服务端发送的数据，客户端也是可以正常读取到该数据的，然后就会经历完整的 TCP 四次挥手，所以我们常说，调用 shutdown 是优雅的关闭。但是注意，shutdown 函数也可以指定「只关闭读取方向，而不关闭发送方向」，但是这时候内核是不会发送 FIN 报文的，因为发送 FIN 报文是意味着我方将不再发送任何数据，而 shutdown 如果指定「不关闭发送方向」，就意味着 socket 还有发送数据的能力，所以内核就不会发送 FIN。 什么情况会出现三次挥手？ 当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。 然后因为 TCP 延迟确认机制是默认开启的，所以导致我们抓包时，看见三次挥手的次数比四次挥手还多。 什么是 TCP 延迟确认机制？ 当发送没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。 为了解决 ACK 传输效率低问题，所以就衍生出了 TCP 延迟确认。 TCP 延迟确认的策略： 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK 序列号与确认号 序列号 = 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。 确认号 = 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。 序列号：在建立连接时由内核生成的随机数作为其初始值，通过 SYN 报文传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。 确认号：指下一次「期望」收到的数据的序列号，发送端收到接收方发来的 ACK 确认报文以后，就可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。 控制位：用来标识 TCP 报文是什么类型的报文，比如是 SYN 报文、数据报文、ACK 报文，FIN 报文等","link":"/2025/03/03/interview/network/2%E3%80%81TCP/"},{"title":"3、IP","text":"点击阅读更多查看文章内容 IP基本知识IP与MAC之间的区别和关系MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。在数据包传输的过程中，源IP地址和目的IP地址是不会变化的（前提是没有使用NAT），只有源MAC地址和目的MAC地址一直在变化。 地址分类 主机号全0：用于表示整个网络，称为 网络地址（Network Address）。用于路由表中表示某个子网。 主机号全1：代表该子网的所有主机，称为 广播地址（Broadcast Address）。用于发送广播数据包，让该子网内所有主机接收。 私有IP地址 IP分片与重组每种数据链路的最大传输单元 MTU 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。 每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。 其中，我们最常见数据链路是以太网，它的 MTU 是 1500 字节。 那么当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。 经过分片之后的 IP 数据报在被重组的时候，只能由目标主机进行，路由器是不会进行重组的。 假设发送方发送一个 4000 字节的大数据报，若要传输在以太网链路，则需要把数据报分片成 3 个小数据报进行传输，再交由接收方重组成大数据报。 在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废，所以 TCP 引入了 MSS 也就是在 TCP 层进行分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 MTU 的数据报文。 IP协议相关技术DNSDNS负责将域名网址自动转换为具体的IP地址。 ARP在传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道「下一跳」的 MAC 地址。 由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 ARP 协议，求得下一跳的 MAC 地址。 那么 ARP 又是如何知道对方 MAC 地址的呢？ 简单地说，ARP 是借助 ARP 请求与 ARP 响应两种类型的包确定 MAC 地址的。 主机会通过广播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 ARP 响应包返回给主机。 操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。 不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除。 DHCP 先说明一点，DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。 这 4 个步骤： 客户端首先发起 DHCP 发现报文（DHCP DISCOVER） 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 UDP 广播通信，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。 DHCP 服务器收到 DHCP 发现报文时，用 DHCP 提供报文（DHCP OFFER） 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 IP 地址租用期。 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 DHCP 请求报文（DHCP REQUEST进行响应，回显配置的参数。 最后，服务端用 DHCP ACK 报文对 DHCP 请求报文进行响应，应答所要求的参数。 一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。 如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文： 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。 可以发现，DHCP 交互中，全程都是使用 UDP 广播通信。 咦，用的是广播，那如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络都要配一个 DHCP 服务器？ 所以，为了解决这一问题，就出现了 DHCP 中继代理。有了 DHCP 中继代理以后，对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。 NATNAT网络地址转换，私有网络对外部通信时，将私有IP地址转换成公有IP地址 普通的NAT，N个私有地址就需要N个公有地址，没什么意义。 由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。 因此，可以把 IP 地址 + 端口号一起进行转换。 这样，就用一个全球 IP 地址就可以了，这种转换技术就叫网络地址与端口转换 NAPT。 很抽象？来，看下面的图解就能瞬间明白了。 图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进行通信，并且这两个客户端的本地端口都是 1025。 此时，两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。 于是，生成一个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。 这种转换表在 NAT 路由器上自动生成。例如，在 TCP 的情况下，建立 TCP 连接首次握手时的 SYN 包一经发出，就会生成这个表。而后又随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。 ICMPICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。 里面有个关键词 —— 控制，如何控制的呢？ 网络包在复杂的网络传输环境里，常常会遇到各种问题。 当遇到问题的时候，总不能死个不明不白，没头没脑的作风不是计算机网络的风格。所以需要传出消息，报告遇到了什么问题，这样才可以调整传输策略，以此来控制整个局面。 ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。 在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。 如上图例子，主机 A 向主机 B 发送了数据包，由于某种原因，途中的路由器 2 未能发现主机 B 的存在，这时，路由器 2 就会向主机 A 发送一个 ICMP 目标不可达数据包，说明发往主机 B 的包未能成功。 ICMP 的这种通知消息会使用 IP 进行发送 。 因此，从路由器 2 返回的 ICMP 包会按照往常的路由控制先经过路由器 1 再转发给主机 A 。收到该 ICMP 包的主机 A 则分解 ICMP 的首部和数据域以后得知具体发生问题的原因。 ICMP类型：一类用于诊断的查询消息，也就是查询报文类型；另一类用于通知出错原因的错误消息，也就是差错报文类型。 IGMP在前面我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有一组的主机能收到数据包，不在一组的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 IGMP 协议了。 IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间，如上图中的蓝色部分。 IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。 IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。 常规查询与响应工作机制 路由器会周期性发送目的地址为 224.0.0.1（表示同一网段内所有主机和路由器） IGMP 常规查询报文。 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10 秒，计时器超时后主机就会发送 IGMP 成员关系报告报文（源 IP 地址为自己主机的 IP 地址，目的 IP 地址为组播地址）。如果在定时器超时之前，收到同一个组内的其他主机发送的成员关系报告报文，则自己不再发送，这样可以减少网络中多余的 IGMP 报文数量。 路由器收到主机的成员关系报文后，就会在 IGMP 路由表中加入该组播组，后续网络中一旦该组播地址的数据到达路由器，它会把数据包转发出去。 离开组播组工作机制 一、网段中仍有该组播组 主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报文，报文的目的地址是 224.0.0.2（表示发向网段内的所有路由器） 路由器 收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个），以便确认该网络是否还有 224.1.1.1 组的其他成员。 主机 3 仍然是组 224.1.1.1 的成员，因此它立即响应这个特定组查询。路由器知道该网络中仍然存在该组播组的成员，于是继续向该网络转发 224.1.1.1 的组播数据包。 二、网段中没有该组播组 主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报文。 路由器收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个）。此时在该网段内，组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。 一定时间后，路由器认为该网段中已经没有 224.1.1.1 组播组成员了，将不会再向这个网段转发该组播地址的数据包 ping的工作原理ICMPping是基于ICMP协议的，ICMP主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。 ICMP报文是封装在IP包里面的，它工作在网络层 ICMP包头的类型字段，大致可以分为两类： 一类是用于诊断的查询消息，也就是「查询报文类型」 另一类是通知出错原因的错误消息，也就是「差错报文类型」 查询报文类型 回送消息 —— 类型 0 和 8 回送消息用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息，ping 命令就是利用这个消息实现的 可以向对端主机发送回送请求的消息（ICMP Echo Request Message，类型 8），也可以接收对端主机发回来的回送应答消息（ICMP Echo Reply Message，类型 0）。 相比原生的 ICMP，这里多了两个字段： 标识符：用以区分是哪个应用程序发 ICMP 包，比如用进程 PID 作为标识符； 序号：序列号从 0 开始，每发送一次新的回送请求就会加 1， 可以用来确认网络包是否有丢失。 在选项数据中，ping 还会存放发送请求的时间值，来计算往返时间，说明路程的长短 差错报文类型 目标不可达消息 —— 类型 为 3 原点抑制消息 —— 类型 4 重定向消息 —— 类型 5 超时消息 —— 类型 11 目标不可达消息（Destination Unreachable Message） —— 类型为 3 IP 路由器无法将 IP 数据包发送给目标地址时，会给发送端主机返回一个目标不可达的 ICMP 消息，并在这个消息中显示不可达的具体原因，原因记录在 ICMP 包头的代码字段。 由此，根据 ICMP 不可达的具体消息，发送端主机也就可以了解此次发送不可达的具体原因。 举例 6 种常见的目标不可达类型的代码 原点抑制消息（ICMP Source Quench Message） —— 类型 4 在使用低速广域线路的情况下，连接 WAN 的路由器可能会遇到网络拥堵的问题。 ICMP 原点抑制消息的目的就是为了缓和这种拥堵情况。 当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP 原点抑制消息。 收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而增大 IP 包的传输间隔，减少网络拥堵的情况。 然而，由于这种 ICMP 可能会引起不公平的网络通信，一般不被使用。 重定向消息（ICMP Redirect Message） —— 类型 5 如果路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个 ICMP 重定向消息给这个主机。 在这个消息中包含了最合适的路由信息和源数据。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的 ICMP 消息告知发送端，让它下次发给另外一个路由器。 好比，小林本可以过条马路就能到的地方，但小林不知道，所以绕了一圈才到，后面小林知道后，下次小林就不会那么傻再绕一圈了。 超时消息（ICMP Time Exceeded Message） —— 类型 11 IP 包中有一个字段叫做 TTL （Time To Live，生存周期），它的值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。 此时，路由器将会发送一个 ICMP 超时消息给发送端主机，并通知该包已被丢弃。 设置 IP 包生存周期的主要目的，是为了在路由控制遇到问题发生循环状况时，避免 IP 包无休止地在网络上被转发 ping —— 查询报文类型的使用接下来，我们重点来看 ping 的发送和接收过程。 同个子网下的主机 A 和 主机 B，主机 A 执行ping 主机 B 后，我们来看看其间发送了什么？ ping 命令执行的时候，源主机首先会构建一个 ICMP 回送请求消息数据包。 ICMP 数据包内包含多个字段，最重要的是两个： 第一个是类型，对于回送请求消息而言该字段为 8； 另外一个是序号，主要用于区分连续 ping 的时候发出的多个数据包。 每发出一个请求数据包，序号会自动加 1。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。 然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，协议字段设置为 1 表示是 ICMP 协议，再加上一些其他控制信息，构建一个 IP 数据包 接下来，需要加入 MAC 头。如果在本地 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。 主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。 接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。 主机 B 会构建一个 ICMP 回送响应消息数据包，回送响应数据包的类型字段为 0，序号为接收到的请求数据包中的序号，然后再发送出去给主机 A。 在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。 此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟 traceroute —— 差错报文类型的使用有一款充分利用 ICMP 差错报文类型的应用叫做 traceroute（在UNIX、MacOS中是这个命令，而在Windows中对等的命令叫做 tracert ）。 traceroute 作用一 traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。 traceroute 的参数指向某个目的 IP 地址：traceroute 192.168.1.100 它的原理就是利用 IP 包的生存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的一种方法。 比如，将 TTL 设置 为 1，则遇到第一个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。 接下来将 TTL 设置为 2，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。 这样的过程，traceroute 就可以拿到了所有的路由器 IP。 当然有的路由器根本就不会返回这个 ICMP，所以对于有的公网地址，是看不到中间经过的路由的。 发送方如何知道发出的 UDP 包是否到达了目的主机呢？ traceroute 在发送 UDP 包时，会填入一个不可能的端口号值作为 UDP 目标端口号：33434。然后对于每个下一个探针，它都会增加一个，这些端口都是通常认为不会被使用，不过，没有人知道当某些应用程序监听此类端口时会发生什么。 当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。 所以，当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。 traceroute 作用二 traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU。 这么做是为了什么？ 这样做的目的是为了路径MTU发现。 因为有的时候我们并不知道路由器的 MTU 大小，以太网的数据链路上的 MTU 通常是 1500 字节，但是非以太网的 MTU 值就不一样了，所以我们要知道 MTU 的大小，从而控制发送的包大小。 它的工作原理如下： 首先在发送端主机发送 IP 数据报时，将 IP 包首部的分片禁止标志位设置为 1。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。 随后，通过一个 ICMP 的不可达消息将数据链路上 MTU 的值一起给发送主机，不可达消息的类型为「需要进行分片但设置了不分片位」。 发送主机端每次收到 ICMP 差错报文时就减少包的大小，以此来定位一个合适的 MTU 值，以便能到达目标主机 断网还能ping通127.0.0.1吗有网的情况下，ping 最后是通过网卡将数据发送出去的。 那么断网的情况下，网卡已经不工作了，ping 回环地址却一切正常，我们可以看下这种情况下的工作原理。从应用层到传输层再到网络层。这段路径跟ping外网的时候是几乎是一样的。到了网络层，系统会根据目的IP，在路由表中获取对应的路由信息，而这其中就包含选择哪个网卡把消息发出。 当发现目标IP是外网IP时，会从”真网卡”发出。 当发现目标IP是回环地址时，就会选择本地网卡。 本地网卡，其实就是个”假网卡”，它不像”真网卡”那样有个ring buffer什么的，”假网卡”会把数据推到一个叫 input_pkt_queue 的 链表 中。这个链表，其实是所有网卡共享的，上面挂着发给本机的各种消息。消息被发送到这个链表后，会再触发一个软中断。 专门处理软中断的工具人”ksoftirqd” （这是个内核线程），它在收到软中断后就会立马去链表里把消息取出，然后顺着数据链路层、网络层等层层往上传递最后给到应用程序。 127.0.0.1、localhost、0.0.0.0、本机ip的区别127.0.0.1：表示本地回环地址，127开头的都属于回环地址。 localhost：域名，对应127.0.0.1，可以在本地文件中配置 本机ip：ipconfig命令查询的本机ip 0.0.0.0：代表本机的所有ip，当启动服务监听0.0.0.0的地址时，上面所有的地址都可以访问到服务","link":"/2025/03/03/interview/network/3%E3%80%81IP/"},{"title":"1、HTTP","text":"点击阅读更多查看文章内容 状态码 200 OK：成功 301 Moved Permanently：永久重定向，请求的资源已永久移动到新的 URL。浏览器会缓存重定向结果，后续请求直接访问新地址，不再请求旧地址。 302 Found：临时重定向，请求的资源临时移动到新的 URL。浏览器不会缓存重定向结果，后续请求仍会访问旧地址。（301和302都会在响应头里使用字段Location，指明后续要跳转的URL，浏览器会自动重定向新的URL） 304 Not Modified：主要用于 缓存优化，表示客户端缓存的资源仍然有效（资源未修改），可以直接使用，而无需服务器重新传输资源内容。 400 Bad Request：客户端发送的请求有语法错误，服务器无法理解。（请求参数、请求头或 URL 格式错误） 403 Forbidden：服务器理解请求，但拒绝执行。（权限不足、IP 黑名单、文件权限设置不正确） 404 Not Found：服务器未找到请求的资源。（URL 错误、资源被删除或移动、路由配置错误） 500 Internal Server Error：服务器内部错误（代码 bug、配置错误、数据库连接失败） 501 Not Implemented：未实现的功能（已经定义暂未实现） 502 Bad Gateway：服务器作为网关或代理时，从上游服务器接收到无效响应。 503 Service Unavailable：服务器暂时无法处理请求，通常是由于过载或维护。 常见字段Host：指定服务器的域名 Host: www.A.com Content-Length：表明响应的数据长度 Content-Length: 1000 Content-Encoding：说明服务器返回的数据的压缩方法 Content-Encoding: gzip，客户端请求时使用Accept-Encoding: gzip, deflate 说明自己可以接收哪些压缩方法 GET与POST 用途 GET：主要用于请求资源或获取数据。它用于从服务器获取数据，并且应当是“安全”的操作，不会对服务器上的资源进行修改。 POST：主要用于提交数据给服务器对指定的资源做出处理，例如表单提交或上传文件。它用于创建或更新服务器上的资源，通常会更改服务器的状态。 数据传输方式 GET：数据通过 URL 传递。参数附加在 URL 后面，格式为 ?key1=value1&amp;key2=value2 POST：数据通过请求体（body）传递，POST 请求的数据没有大小限制（不过有一些实际的服务器和客户端可能会有限制） 缓存针对重复性的HTTP请求，可以把这对 请求-响应 的数据都缓存在本地，通过缓存之前请求的资源，使后续请求可以直接使用缓存数据，而无需重新向服务器请求相同的内容。 HTTP的缓存有两种实现方式：强制缓存和协商缓存 强制缓存： 原理：在缓存有效期内，客户端直接使用本地缓存数据，而不与服务器通信。 实现：使用HTTP响应头的 Cache-Control 和 Expires 头部字段实现，Cache-Control的优先级高于Expires。 当浏览器第一次请求访问服务器资源时，服务器在返回这个资源的同时，会在response头部添加cache-control，设置过期时间大小 当浏览器再次请求该资源时，会比较请求字段的时间与cache-control中设置的过期时间判断是否过期，如果没过期则使用该缓存，否则重新请求服务器 服务器再次收到请求后，会再次更新response头部的cache-control 协商缓存： 原理：客户端请求资源时，服务器会检查缓存是否仍然有效，决定是否返回 304（Not Modified）响应，让客户端使用本地缓存（服务器无需返回所有数据）。 实现1：请求头的 If-None-Match 字段与响应头的 ETag 字段（推荐） ETag（实体标签）是服务器生成的一个资源唯一标识符，类似文件的哈希值。 客户端第一次请求资源时，服务器返回 ETag 头部。 客户端后续请求时，在请求头中带上 If-None-Match 头部（携带上次 ETag 值）。 服务器比较 ETag： 相同：返回 304 Not Modified，客户端继续使用缓存。 不同：返回新资源，并生成新的 ETag。 实现2：使用请求头的If-Modified-Since字段与响应头的Last-Modified字段 Last-Modified 记录资源的最后修改时间。 客户端第一次请求资源时，服务器返回 Last-Modified 头部。 客户端后续请求时，带上 If-Modified-Since 头部（上次的 Last-Modified 时间）。 服务器比较资源的修改时间： 未修改：返回 304 Not Modified。 已修改：返回新资源，并更新 Last-Modified 缓存策略选择： 强制缓存 优先，适用于静态资源（如 JS、CSS、图片）。 协商缓存 适用于可能变化的资源，减少带宽消耗。 缓存位置 浏览器缓存：存储在客户端本地，提高页面加载速度。 CDN 缓存：由内容分发网络（CDN）存储资源，减少服务器压力。 代理服务器缓存：如 Nginx 反向代理，可缓存服务器响应。 服务器缓存：如 Redis/Memcached，在后端减少数据库查询。 HTTP 1.1相比 HTTP/1.0，HTTP/1.1 进行了多个优化，包括持久连接（Keep-Alive）、管道化请求（Pipelining）、缓存控制、分块传输编码（Chunked Encoding）等，使得性能和灵活性大大提高 持久连接（Keep-Alive，默认开启） HTTP/1.0 问题：每次请求都会建立一个新的 TCP 连接，消耗大量资源。 HTTP/1.1 解决方案： 默认使用 持久连接，即多个 HTTP 请求可以复用同一个 TCP 连接，避免频繁建立和关闭连接。 服务器会在响应头中加入 Connection: keep-alive 管道化请求（Pipelining，已被 HTTP/2 替代） 问题：HTTP/1.0 需要等待前一个请求的响应才能发送下一个请求（队头阻塞）。 HTTP/1.1 解决方案： 支持 Pipelining，即客户端可以同时发送多个请求，服务器按顺序处理并返回响应。 但由于 服务器仍需按顺序返回响应，且存在队头阻塞问题（如果处理前面的请求耗时较长，那么后续的请求处理都会被阻塞），Pipelining 实际上很少被使用，HTTP/2 引入了多路复用彻底解决了这个问题。 无状态 服务器在处理每个 HTTP 请求时，不会自动保留之前的请求信息，每次请求都必须携带所需的全部信息。 好处：不需要管理每个客户端的状态，减少资源占用。 坏处：需要额外的机制来维护用户状态 Cookie + Session 服务器发送 Set-Cookie，客户端在每次请求时携带 Cookie 维持会话。服务器通过 Session ID 识别用户。 HTTPSHTTP中信息都是明文传输的缺乏安全性 HTTPS在TCP和HTTP之间加入了SSL/TLS协议，使得报文能够加密传输。 加密：防止数据被窃听（中间人攻击）。通过加密算法实现。 数据完整性：防止数据在传输过程中被篡改（MITM 攻击）。通过摘要算法实现。 身份认证：防止伪造网站（钓鱼攻击），确保访问的是正确的服务器。通过数字证书实现 混合加密： 通过非对称加密交换会话密钥，后续就不再使用非对称加密 基于会话密钥采用对称加密的方式加密明文数据 摘要+数字签名 发送方对内容计算出摘要同内容一起传输给对方，对方收到内容后也计算一个摘要并与发送方的摘要进行比较，如果相同则没有被篡改。 通过哈希算法可以确保内容不会被篡改，但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明。 数字签名：服务端使用自己的私钥加密摘要，客户端根据服务端的公钥解密进行认证，如果可以解密，则说明该消息是服务端发送的 数字证书 证明公钥确实属于对应的服务器，而不是其他人伪造的密钥对 通过权威机构CA将服务器公钥存放在数字证书中，只要证书是可信的，公钥就是可信的 HTTPS连接建立 SSL/TLS 协议基本流程： 客户端向服务器索要并验证服务器的公钥。 双方协商生产「会话秘钥」。 双方采用「会话秘钥」进行加密通信。 前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。 TLS 的「握手阶段」涉及四次通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：RSA 算法 (opens new window)和 ECDHE 算法 (opens new window)。 客户端（浏览器）发起 HTTPS 请求 浏览器请求 https://example.com 服务器响应，开始 TLS 握手 服务器返回 SSL 证书 证书由 CA（证书颁发机构）签发，包含公钥、域名、有效期等信息。 浏览器验证证书的合法性（检查是否被篡改、是否被信任）。 客户端和服务器协商加密方式 浏览器和服务器协商支持的 TLS 版本、加密算法。 客户端生成对称密钥 浏览器使用服务器的公钥加密对称密钥，然后发送给服务器。 服务器用私钥解密得到对称密钥。 使用对称加密通信 之后的 HTTP 请求和响应都使用这个对称密钥加密，保证数据安全。 HTTP/1.1、HTTP/2、HTTP/3HTTP/1.1HTTP/1.1 相比 HTTP/1.0 性能上的改进： 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。 但 HTTP/1.1 还是有性能瓶颈： 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分； 发送冗长的首部。每次互相发送相同的首部造成的浪费较多； 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞； 没有请求优先级控制； 请求只能从客户端开始，服务器只能被动响应 HTTP/2HTTP/2 协议是基于 HTTPS 的，保证了安全性 那 HTTP/2 相比 HTTP/1.1 性能上的改进： 头部压缩：HTTP/1.1 的 Header 信息较大，HTTP/2 采用 HPACK 进行压缩，减少带宽占用。在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。 二进制格式：HTTP/1.1 是文本协议，HTTP/2 使用二进制帧格式，解析更快，传输更高效。 并发传输：单个 TCP 连接可同时传输多个 HTTP 请求和响应，不受顺序影响，彻底解决队头阻塞（HTTP/1.1 的主要问题）。 将请求和响应分解为小的二进制帧（Frame），每个帧属于一个特定的流（Stream）。多个流的帧可以交错传输，接收端根据帧头中的流 ID 重新组装。流是 HTTP/2 中的一个逻辑概念，表示一个独立的请求-响应交互。 服务器主动推送资源：服务器可以主动推送资源到客户端缓存，减少后续请求等待时间。比如客户端在访问HTML时，服务器可以直接主动推送CSS文件，减少消息传递的次数。 缺点： 仍然基于 TCP，存在队头阻塞（HoL Blocking）：虽然 HTTP/2 解决了 HTTP 层的队头阻塞，但 TCP 层仍然有丢包重传的阻塞问题，影响整体吞吐量。TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。 HTTP/3HTTP/3 由 Google QUIC 协议演变而来，彻底抛弃 TCP，使用 UDP + QUIC 传输，提高连接速度和稳定性。 UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。但 UDP 是不可靠传输的，不过基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。 QUIC（Quick UDP Internet Connections）是一种基于 UDP 的传输层协议，最初由 Google 在 2012 年提出，并在 HTTP/3 中作为默认传输协议。它的目标是提高网络传输效率，减少延迟，并优化 HTTP/2 在 TCP 上的缺陷（如队头阻塞问题） 主要特点： 基于 UDP，减少连接建立时间 QUIC 不使用 TCP，而是基于 UDP 传输，并在应用层实现可靠性保证。 0-RTT 连接建立（如果之前通信过）： 传统的 TCP + TLS 需要 2~3 次 RTT来建立安全连接，而 QUIC 只需要 1 个 RTT，甚至可以做到 0-RTT（复用之前的加密信息）。 1-RTT 连接建立（首次连接）： 结合 QUIC + TLS 1.3，QUIC 在1 次 RTT 内完成握手，相比 TCP 快了一倍。 解决 TCP 的队头阻塞 HTTP/2 的多路复用仍受 TCP 队头阻塞影响： 如果一个数据包丢失，整个 TCP 连接都会等待重传。 QUIC 在 UDP 之上实现了自己的流控制： 每个 HTTP 请求/响应被视为独立的流，丢失的数据包只影响单个流，而不会影响整个连接。 连接迁移 TCP 连接依赖 IP + 端口，如果切换网络（如 Wi-Fi → 4G），连接会断开。 QUIC 连接基于 “Connection ID”，与 IP/端口无关。当用户切换网络时，QUIC 连接可以自动恢复，而不需要重新握手。 内置 TLS 加密 传统的 HTTPS 需要 TCP + TLS，而 QUIC 直接在协议层集成了 TLS 1.3，所有 QUIC 连接默认是加密的。 这不仅提高了安全性，还减少了握手延迟（因为 QUIC 和 TLS 1.3 可以同时握手）。 更好的流控 &amp; 拥塞控制 TCP 的丢包检测依赖超时（timeout），可能会导致不必要的延迟。 QUIC 基于 ACK 反馈机制，可以更快地调整数据传输速率，提高传输效率。 如何优化HTTP/1.1使用缓存 避免发送HTTP请求，对于一些有重复性的HTTP请求，可以把这对 [请求-响应] 缓存在本地，那么下次发送请求时可以直接读取本地缓存的响应而无需发送网络请求，缓存的实现可以参考前文。 减少HTTP请求次数 减少重定向请求次数：将重定向的工作在代理服务器上执行而无需客户端重新发送请求 更进一步如果代理服务器知晓了重定向规则后，可以进一步减少消息传递的次数，直接请求新地址 合并请求：把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着减少了重复发送的 HTTP 头部。 使用webpack等打包工具将多个 CSS 或 JavaScript 文件合并为一个文件，减少请求数。 使用 CSS Sprites：将多个小图标合并为一张大图，无需分别请求每个小图标。 延迟发送请求：一般 HTML 里会含有很多 HTTP 的 URL，当前不需要的资源，我们没必要也获取过来，于是可以通过「按需获取」的方式，来减少第一时间的 HTTP 请求次数。 请求网页的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的页面资源，当用户向下滑动页面的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果 减少HTTP响应的数据大小 无损压缩：对原始资源建立统计模型，利用这个统计模型，将常出现的数据用较短的二进制比特序列表示，将不常出现的数据用较长的二进制比特序列表示，生成二进制比特序列一般是「霍夫曼编码」算法。 gzip是常见的无损压缩算法，在http请求头中添加 Accept-Encoding: gzip, deflate, br 服务器收到后会选择一个服务器支持的压缩算法对响应资源进行压缩，通过响应头中的 Content-Encoding: gzip 字段告诉客户端 有损压缩：将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，常用于多媒体文件 关于图片压缩，目前压缩比最高的是WebP格式 既然有HTTP协议，为什么还要有RPC 性能需求： RPC 使用二进制协议，传输效率更高，适合对性能要求高的场景。 开发效率： RPC 提供类似本地方法调用的体验，减少开发工作量。 服务治理： RPC 框架通常内置服务发现、负载均衡、熔断等功能，适合微服务架构。 内部通信： 在内部服务之间，RPC 比 HTTP 更轻量、更高效 上面比较的 HTTP，其实特指的是现在主流使用的 HTTP/1.1，HTTP/2 在前者的基础上做了很多改进，所以性能可能比很多 RPC 协议还要好，甚至连 gRPC 底层都直接用的 HTTP/2。 那么问题又来了，为什么既然有了 HTTP/2，还要有 RPC 协议？ 这个是由于 HTTP/2 是 2015 年出来的。那时候很多公司内部的 RPC 协议都已经跑了好些年了，基于历史原因，一般也没必要去换了。 既然有HTTP协议，为什么还要有WebSocket怎么样才能在用户不做任何操作的情况下，网页能收到消息并发生变更。 最常见的解决方案是，网页的前端代码里不断定时发 HTTP 请求到服务器，服务器收到请求后给客户端响应消息。 这其实时一种「伪」服务器推的形式。 它其实并不是服务器主动发消息到客户端，而是客户端自己不断偷偷请求服务器，只是用户无感知而已。 用这种方式的场景也有很多，最常见的就是扫码登录。 比如，某信公众号平台，登录页面二维码出现之后，前端网页根本不知道用户扫没扫，于是不断去向后端服务器询问，看有没有人扫过这个码。而且是以大概 1 到 2 秒的间隔去不断发出请求，这样可以保证用户在扫码后能在 1 到 2 秒内得到及时的反馈，不至于等太久。 使用HTTP定时轮询会有两个比较明显的问题： 当你打开 F12 页面时，你会发现满屏的 HTTP 请求。虽然很小，但这其实也消耗带宽，同时也会增加下游服务器的负担。 最坏情况下，用户在扫码后，需要等个 12 秒，正好才触发下一次 HTTP 请求，然后才跳转页面，用户会感到明显的卡顿。 使用起来的体验就是，二维码出现后，手机扫一扫，然后在手机上点个确认，这时候卡顿等个 12 秒，页面才跳转 解决方案：长轮询 我们知道，HTTP 请求发出后，一般会给服务器留一定的时间做响应，比如 3 秒，规定时间内没返回，就认为是超时。 如果我们的 HTTP 请求将超时设置的很大，比如 30 秒，在这 30 秒内只要服务器收到了扫码请求，就立马返回给客户端网页。如果超时，那就立马发起下一次请求。 这样就减少了 HTTP 请求的个数，并且由于大部分情况下，用户都会在某个 30 秒的区间内做扫码操作，所以响应也是及时的。 像这种发起一个请求，在较长时间内等待服务器响应的机制，就是所谓的长轮询机制。我们常用的消息队列 RocketMQ 中，消费者去取数据时，也用到了这种方式。 不管是不断轮询还是长轮询，本质上还是客户端主动取数据，对于扫码这种场景还能使用，但是在网页游戏中，游戏一般会有大量的数据需要从服务器主动推送到客户端，这里就需要websocket。 websocket 我们知道 TCP 可以进行全双工通信。 而现在使用最广泛的HTTP/1.1，也是基于TCP协议的，却只支持半双工。 也就是说，好好的全双工 TCP，被 HTTP/1.1 用成了半双工。 为什么？ 这是由于 HTTP 协议设计之初，考虑的是看看网页文本的场景，能做到客户端发起请求再由服务器响应，就够了，根本就没考虑网页游戏这种，客户端和服务器之间都要互相主动发大量数据的场景。 所以，为了更好的支持这样的场景，我们需要另外一个基于TCP的新协议。 于是新的应用层协议WebSocket就被设计出来了。 建立websocket连接：使用http进行一次通信，带上特殊的header头 Upgrade: WebSocket，就会升级成websocket协议，websocket升级后与http就没有关系了，它是基于tcp的协议 使用场景：完成继承了TCP协议的全双工能力，适用于服务器与客户端频繁交互的大部分场景，比如网页/小程序游戏，网页聊天室等","link":"/2025/03/03/interview/network/1%E3%80%81HTTP/"},{"title":"【redis】常见问题","text":"点击阅读更多查看文章内容 认识RedisRedis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。 Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是原子性的，因为执行命令由单线程负责的，不存在并发竞争的问题。 除此之外，Redis 还支持事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制等等。 Redis 和 Memcached 有什么区别？很多人都说用 Redis 作为缓存，但是 Memcached 也是基于内存的数据库，为什么不选择它作为缓存呢？要解答这个问题，我们就要弄清楚 Redis 和 Memcached 的区别。 Redis 与 Memcached 共同点： 都是基于内存的数据库，一般都用来当做缓存使用。 都有过期策略。 两者的性能都非常高。 Redis 与 Memcached 区别： Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型； Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了； Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据； Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持； 为什么用 Redis 作为 MySQL 的缓存？主要是因为 Redis 具备「高性能」和「高并发」两种特性。 Redis 具备高性能 假如用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。 Redis 具备高并发 单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。 所以，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。 Redis 除了做缓存，还能做什么？ 分布式锁：通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁。关于 Redis 实现分布式锁的详细介绍，可以看我写的这篇文章：分布式锁详解。 限流：一般是通过 Redis + Lua 脚本的方式来实现限流。如果不想自己写 Lua 脚本的话，也可以直接利用 Redisson 中的 RRateLimiter 来实现分布式限流，其底层实现就是基于 Lua 代码+令牌桶算法。 消息队列：Redis 自带的 List 数据结构可以作为一个简单的队列使用。Redis 5.0 中增加的 Stream 类型的数据结构更加适合用来做消息队列。它比较类似于 Kafka，有主题和消费组的概念，支持消息持久化以及 ACK 机制。 延时队列：Redisson 内置了延时队列（基于 Sorted Set 实现的）。 分布式 Session：利用 String 或者 Hash 数据类型保存 Session 数据，所有的服务器都可以访问。 复杂业务场景：通过 Redis 以及 Redis 扩展（比如 Redisson）提供的数据结构，我们可以很方便地完成很多复杂的业务场景，比如通过 Bitmap 统计活跃用户、通过 Sorted Set 维护排行榜、通过 HyperLogLog 统计网站 UV 和 PV Redis数据结构Redis 数据类型以及使用场景分别是什么？Redis 提供了丰富的数据类型，常见的有五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合） 随着 Redis 版本的更新，后面又支持了四种数据类型： BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）。 Redis 五种数据类型的应用场景： String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。 List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。 Hash 类型：缓存对象、购物车等。 Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。 Zset 类型：排序场景，比如排行榜、电话和姓名排序等。 Redis 后续版本又支持四种数据类型，它们的应用场景如下： BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等； HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等； GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车； Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。 五种常见的 Redis 数据类型是怎么实现？ String 类型内部实现 String 类型的底层的数据结构实现主要是 SDS（简单动态字符串）。 SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串： SDS 不仅可以保存文本数据，还可以保存二进制数据。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。 SDS 获取字符串长度的时间复杂度是 O(1)。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。 Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。 List 类型内部实现 List 类型的底层数据结构是由双向链表或压缩列表实现的： 如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用压缩列表作为 List 类型的底层数据结构； 压缩列表的本质就是一个数组，只不过是增加了 “列表长度”、“尾部偏移量”、“列表元素个数” 以及 “列表结束标识”，这样的话就有利于快速的寻找列表的首、尾节点。压缩列表将表中每一项存放在前后连续的地址空间内，每一项因占用的空间不同，而采用变长编码。由于内存是连续分配的，所以遍历速度很快。 正向遍历：1.初始化指针：从 Ziplist 的头部（第一个节点）开始，指针指向第一个节点的起始位置。2.读取节点：读取当前节点的 encoding 和 data，获取节点的值。3.移动到下一个节点：根据当前节点的 encoding 和 data 的长度，计算下一个节点的起始位置。4.将指针移动到下一个节点的起始位置。 反向遍历：1.初始化指针：从 Ziplist 的尾部（最后一个节点）开始，指针指向最后一个节点的起始位置（通过 zltail 获取）。2.读取节点：读取当前节点的 encoding 和 data，获取节点的值。3.移动到前一个节点：读取当前节点的 prevlen，获取前一个节点的长度。根据 prevlen，计算前一个节点的起始位置。将指针移动到前一个节点的起始位置。 连锁更新问题：ziplist 在更新或者新增时候，如空间不够则需要对整个列表进行重新分配。当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降 属性 说明 “zlbytes” 表示压缩列表的长度（包括所有的字节） “zltail” 表示压缩列表尾部的指针（偏移量） “zllen” 表示压缩列表中节点（Entry）的个数 “entry” 存储区，可以包含多个节点，每个节点可以存放整数或者字符串 “zlend” 表示列表结束 如果列表的元素不满足元素个数小于 512 个，列表每个元素的值都小于 64 字节，Redis 会使用双向链表作为 List 类型的底层数据结构； LinkedList 是标准的双向链表，Node 节点包含 prev 和 next 指针，分别指向后继与前驱节点，因此从双向链表中的任意一个节点开始都可以很方便地访问其前驱与后继节点。 但是在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表。quickList，是ziplist和linkedlist二者的结合；quickList是一个ziplist组成的双向链表。每个节点使用ziplist来保存数据。本质上来说，quicklist里面保存着一个一个小的ziplist。结构如下： Hash 类型内部实现 Hash 类型的底层数据结构是由压缩列表或哈希表实现的： 如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构； 如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的底层数据结构。 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack紧凑列表 数据结构来实现了。 listpack 也叫紧凑列表，与压缩列表类似它的特点就是用一块连续的内存空间来紧凑地保存数据，但是在 listpack 中，因为每个列表项只记录自己的长度，而不会像 ziplist 中的列表项那样，会记录前一项的长度。所以，当在 listpack 中新增或修改元素时，实际上只会涉及每个列表项自己的操作，而不会影响后续列表项的长度变化，这就避免了连锁更新。 Set 类型内部实现 Set 类型的底层数据结构是由哈希表或整数集合实现的： 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用整数集合作为 Set 类型的底层数据结构； 如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。 ZSet 类型内部实现 Zset 类型的底层数据结构是由压缩列表或跳表实现的： 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构； 如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构； 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。 应用场景 String 类型的应用场景：缓存对象、常规计数、分布式锁、共享session信息等。 List 类型的应用场景：消息队列（有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。 Hash 类型：缓存对象、购物车等。 Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。 Zset 类型：排序场景，比如排行榜、电话和姓名排序等。 BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等； HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等； GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车； Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。 String 还是 Hash 存储对象数据更好呢？简单对比一下二者： 对象存储方式：String 存储的是序列化后的对象数据，存放的是整个对象，操作简单直接。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息，Hash 就非常适合。 内存消耗：Hash 通常比 String 更节省内存，特别是在字段较多且字段长度较短时。Redis 对小型 Hash 进行优化（如使用 ziplist 存储），进一步降低内存占用。 复杂对象存储：String 在处理多层嵌套或复杂结构的对象时更方便，因为无需处理每个字段的独立存储和操作。 性能：String 的操作通常具有 O(1) 的时间复杂度，因为它存储的是整个对象，操作简单直接，整体读写的性能较好。Hash 由于需要处理多个字段的增删改查操作，在字段较多且经常变动的情况下，可能会带来额外的性能开销。 总结： 在绝大多数情况下，String 更适合存储对象数据，尤其是当对象结构简单且整体读写是主要操作时。 如果你需要频繁操作对象的部分字段或节省内存，Hash 可能是更好的选择。 Redis 线程模型Redis是单线程吗？Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的，这也是我们常说 Redis 是单线程的原因。 但是，Redis 程序并不是单线程的，Redis 在启动的时候，是会启动后台线程（BIO）的： Redis 在 2.6 版本，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务； Redis 在 4.0 版本之后，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 Redis 主线程卡顿，我们应该使用 unlink 命令来异步删除大key。 之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。 后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可。 关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列： BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭； BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘， BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 free(obj) 释放对象 / free(dict) 删除数据库所有对象 / free(skiplist) 释放跳表对象； Redis 单线程模式是怎样的？Redis 6.0 版本之前的单线模式如下图： 图中的蓝色部分是一个事件循环，是由主线程负责的，可以看到网络 I/O 和命令处理都是单线程。 Redis 初始化的时候，会做下面这几件事情： 首先，调用 epoll_create() 创建一个 epoll 对象和调用 socket() 创建一个服务端 socket 然后，调用 bind() 绑定端口和调用 listen() 监听该 socket； 然后，将调用 epoll_ctl() 将 listen socket 加入到 epoll，同时注册「连接事件」处理函数。 初始化完后，主线程就进入到一个事件循环函数，主要会做以下事情： 首先，先调用处理发送队列函数，看是发送队列里是否有任务，如果有发送任务，则通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。 接着，调用 epoll_wait 函数等待事件的到来： 如果是连接事件到来，则会调用连接事件处理函数，该函数会做这些事情：调用 accpet 获取已连接的 socket -&gt; 调用 epoll_ctl 将已连接的 socket 加入到 epoll -&gt; 注册「读事件」处理函数； 如果是读事件到来，则会调用读事件处理函数，该函数会做这些事情：调用 read 获取客户端发送的数据 -&gt; 解析命令 -&gt; 处理命令 -&gt; 将客户端对象添加到发送队列 -&gt; 将执行结果写到发送缓存区等待发送； 如果是写事件到来，则会调用写事件处理函数，该函数会做这些事情：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。 Redis 采用单线程为什么还这么快？单线程的 Redis 吞吐量可以达到 10W/每秒 之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因： Redis 的大部分操作都在内存中完成，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了； Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。 Redis 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。 Redis6.0之前为什么使用单线程？ 单线程编程容易并且更容易维护； Redis 的性能瓶颈不在 CPU，主要在内存大小和网络I/O；（内存读写速度比磁盘快很多，因此CPU的利用率也远高于磁盘读写，而多线程的主要目的就是提高CPU的利用率，所以redis就不需要使用多线程。） 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能 Redis 6.0 之后为什么引入了多线程？Redis6.0 引入多线程主要是为了提高网络 IO 读写性能，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。 虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。 Redis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要设置 IO 线程数 &gt; 1，需要修改 redis 配置文件 redis.conf： Redis持久化Redis 如何实现数据不丢失？ Redis 的读写操作都是在内存中，所以 Redis 性能才会高，但是当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。 Redis 共有三种数据持久化的方式： AOF 日志（append-only file,）：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里； RDB 快照（snapshotting）：将某一时刻的内存数据，以二进制的方式写入磁盘； 混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RDB 的优点； AOF日志是如何实现的？Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到 AOF 缓冲区server.aof_buf 中，然后再写入到 AOF 文件中（此时还在系统内核缓存区未同步到磁盘），最后再根据持久化方式（ fsync策略）的配置来决定何时将系统内核缓存区的数据同步到硬盘中的。 我这里以「set name xiaolin」命令作为例子，Redis 执行了这条命令后，记录在 AOF 日志里的内容如下图： 「*3」表示当前命令有三个部分，每部分都是以「$+数字」开头，后面紧跟着具体的命令、键或值。然后，这里的「数字」表示这部分中的命令、键或值一共有多少字节。例如，「$3 set」表示这部分有 3 个字节，也就是「set」命令这个字符串的长度。 AOF 工作基本流程是怎样的？ AOF 持久化功能的实现可以简单分为 5 步： 命令追加（append）：所有的写命令会追加到 AOF 缓冲区中。 文件写入（write）：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用write函数（系统调用），write将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。 文件同步（fsync）：AOF 缓冲区根据对应的持久化方式（ fsync 策略）向硬盘做同步操作。这一步需要调用 fsync 函数（系统调用）， fsync 针对单个文件操作，对其进行强制硬盘同步，fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。 文件重写（rewrite）：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。 重启加载（load）：当 Redis 重启时，可以加载 AOF 文件进行数据恢复 为什么先执行命令，再把数据写入日志呢？ Reids 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。 避免额外的检查开销：AOF 记录日志不会对命令进行语法检查； 不会阻塞当前写操作命令的执行：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。 当然，这样做也会带来风险： 数据可能会丢失： 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。 可能阻塞其他操作： 因为 AOF 日志也是在主线程中执行，还是会阻塞后续的操作无法执行。 AOF 写回策略有几种？ Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填： appendfsync always：主线程调用 write 执行写操作后，后台线程（ aof_fsync 线程）立即会调用 fsync 函数同步 AOF 文件（刷盘），fsync 完成后线程返回，这样会严重降低 Redis 的性能（write + fsync）。 appendfsync everysec：主线程调用 write 执行写操作后立即返回，由后台线程（ aof_fsync 线程）每秒钟调用 fsync 函数（系统调用）同步一次 AOF 文件（write+fsync，fsync间隔为 1 秒） appendfsync no：主线程调用 write 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（write但不fsync，fsync 的时机由操作系统决定）。 AOF 重写机制 AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。 所以，Redis 为了避免 AOF 文件越写越大，提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。 AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。 举个例子，在没有使用重写机制前，假设前后执行了「set name xiaolin」和「set name xiaolincoding」这两个命令的话，就会将这两个命令记录到 AOF 文件。 但是在使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件，之前的第一个命令就没有必要记录了，因为它属于「历史」命令，没有作用了。这样一来，一个键值对在重写日志中只用一条命令就行了。 后台重写 Redis 的重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的，这么做可以达到两个好处： 子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程； 子进程带有主进程的数据副本（数据副本怎么产生的后面会说），这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能，而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。 主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。 这样一来，子进程就共享了父进程的物理内存数据了，这样能够节约物理内存资源，页表对应的页表项的属性会标记该物理内存的权限为只读。 不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发写保护中断，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为「写时复制(Copy On Write)」。 RDB快照是如何实现的？ AOF 文件的内容是操作命令； RDB 文件的内容是二进制数据。 因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，势必会造成 Redis 的恢复操作缓慢。 为了解决这个问题，Redis 增加了 RDB 快照。RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。 因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以。 RDB 做快照时会阻塞线程吗？ Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行： 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程； 执行了 bgsave 命令，会创建一个子进程（注意是进程！）来生成 RDB 文件，这样可以避免主线程的阻塞； RDB 的生成时机 Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置： 12345save 900 1 save 300 10 save 60 10000 别看选项名叫 save，实际上执行的是 bgsave 命令，也就是会创建子进程来生成 RDB 快照文件。 只要满足上面条件的任意一个，就会执行 bgsave，它们的意思分别是： 900 秒之内，对数据库进行了至少 1 次修改； 300 秒之内，对数据库进行了至少 10 次修改； 60 秒之内，对数据库进行了至少 10000 次修改。 这里提一点，Redis 的快照是全量快照，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。 RDB 在执行快照的时候，数据能修改吗？ 可以的，执行 bgsave 过程中，Redis 依然可以继续处理操作命令的，也就是数据是能被修改的，关键的技术就在于写时复制技术（Copy-On-Write, COW）。 执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。 如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。 AOF+RDB混合持久化RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。 AOF 优点是丢失数据少，但是数据恢复不快。 为了集成了两者的优点， Redis 4.0 提出了混合使用 AOF 日志和内存快照，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。 混合持久化工作在 AOF 日志重写过程 当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后RDB之后的增量操作命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。 也就是说，使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。 这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。 加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。 混合持久化优点： 混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。 混合持久化缺点： AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差； 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。 Redis集群Redis 如何实现服务高可用？ 要想设计一个高可用的 Redis 服务，一定要从 Redis 的多服务节点来考虑，比如 Redis 的主从复制、哨兵模式、切片集群。 主从复制主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。 主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。 也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。 注意，主从服务器之间的命令复制是异步进行的。 具体来说，在主从服务器命令传播阶段，主服务器收到新的写命令后，会发送给从服务器。但是，主服务器并不会等到从服务器实际执行完命令后，再把结果返回给客户端，而是主服务器自己在本地执行完命令后，就会向客户端返回结果了。如果从服务器还没有执行主服务器同步过来的命令，主从服务器间的数据就不一致了。 优点： 配置简单，易于实现。 实现数据冗余，提高数据可靠性。 读写分离，提高系统性能。 缺点： 主节点故障时，需要手动切换到从节点，故障恢复时间较长。 主节点承担所有写操作，可能成为性能瓶颈。 无法实现数据分片，受单节点内存限制。 主从复制模式适用于以下场景： 数据备份和容灾恢复：通过从节点备份主节点的数据，实现数据冗余。 读写分离：将读操作分发到从节点，减轻主节点压力，提高系统性能。 在线升级和扩展：在不影响主节点的情况下，通过增加从节点来扩展系统的读取能力。 哨兵模式哨兵模式是在主从复制基础上加入了哨兵节点，实现了自动故障转移。哨兵节点是一种特殊的Redis节点，它会监控主节点和从节点的运行状态。当主节点发生故障时，哨兵节点会自动从从节点中选举出一个新的主节点，并通知其他从节点和客户端，实现故障转移。 优点： 自动故障转移，提高系统的高可用性。 具有主从复制模式的所有优点，如数据冗余和读写分离。 缺点： 配置和管理相对复杂。 依然无法实现数据分片，受单节点内存限制。 哨兵模式适用于以下场景： 高可用性要求较高的场景：通过自动故障转移，确保服务的持续可用。 数据备份和容灾恢复：在主从复制的基础上，提供自动故障转移功能。 切片集群模式Cluster模式是Redis的一种高级集群模式，它通过数据分片和分布式存储实现了负载均衡和高可用性。在Cluster模式下，Redis将所有的键值对数据分散在多个节点上。每个节点负责一部分数据，称为槽位。通过对数据的分片，Cluster模式可以突破单节点的内存限制，实现更大规模的数据存储。 Redis Cluster将数据分为16384个槽位，每个节点负责管理一部分槽位。当客户端向Redis Cluster发送请求时，Cluster会根据键的哈希值将请求路由到相应的节点。具体来说，Redis Cluster使用CRC16算法计算键的哈希值，然后对16384取模，得到槽位编号。 接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案： 平均分配： 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。 手动分配： 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。 为了方便你的理解，我通过一张图来解释数据、哈希槽，以及节点三者的映射分布关系。 上图中的切片集群一共有 2 个节点，假设有 4 个哈希槽（Slot 0～Slot 3）时，我们就可以通过命令手动分配哈希槽，比如节点 1 保存哈希槽 0 和 1，节点 2 保存哈希槽 2 和 3。 12redis-cli -h 192.168.1.10 –p 6379 cluster addslots 0,1 redis-cli -h 192.168.1.11 –p 6379 cluster addslots 2,3 然后在集群运行的过程中，key1 和 key2 计算完 CRC16 值后，对哈希槽总个数 4 进行取模，再根据各自的模数结果，就可以被映射到哈希槽 1（对应节点1） 和 哈希槽 2（对应节点2）。 需要注意的是，在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。 优点： 数据分片，实现大规模数据存储。 负载均衡，提高系统性能。 自动故障转移，提高高可用性。 缺点： 配置和管理较复杂。 一些复杂的多键操作可能受到限制。 集群脑裂导致数据丢失怎么办？什么是脑裂？ 先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？ 那么在 Redis 中，集群脑裂产生数据丢失的现象是怎样的呢？ 在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。 这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— 脑裂出现了。 然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题。 总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。 解决方案 当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。 原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了。 等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。 Redis过期删除与内存淘汰Redis 使用的过期删除策略是什么？Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。 Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key（键），过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。 当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中： 如果不在，则正常读取键值； 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。 Redis 使用的过期删除策略是「惰性删除+定期删除」这两种策略配和使用。 惰性删除 不主动删除过期键，只在访问key的时候检查是否过期，过期则删除 惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。 惰性删除的流程图如下： 惰性删除策略的优点： 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。 惰性删除策略的缺点： 如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。 定期删除 定期删除策略的做法是，每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。并根据过期key所占的比例判断是否需要继续删除 Redis 的定期删除的流程： 从过期字典中随机抽取 20 个 key； 检查这 20 个 key 是否过期，并删除已过期的 key； 如果本轮检查的已过期 key 的数量，超过 5 个，也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。 可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。 定期删除的流程如下： 定期删除策略的优点： 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。 定期删除策略的缺点： 难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。 可以看到，惰性删除策略和定期删除策略都有各自的优点，所以 Redis 选择「惰性删除+定期删除」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。 Redis 持久化时，对过期键会如何处理的？Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键在这两种格式中的呈现状态。 RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。 RDB 文件生成阶段：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，过期的键「不会」被保存到新的 RDB 文件中，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。 RDB 加载阶段：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况： 如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中。所以过期键不会对载入 RDB 文件的主服务器造成影响； 如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。 AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。 AOF 文件写入阶段：当 Redis 以 AOF 模式持久化时，如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值。 AOF 重写阶段：执行 AOF 重写时，会对 Redis 中的键值对进行检查，已过期的键不会被保存到重写后的 AOF 文件中，因此不会对 AOF 重写造成任何影响。 Redis 主从模式对过期键会如何处理？当 Redis 运行在主从模式下时，从库不会进行过期扫描，从库对过期的处理是被动的。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。 从库的过期键处理依靠主服务器控制，主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。 Redis 内存淘汰策略？Redis 内存淘汰策略有哪些？Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。 不进行数据淘汰的策略 noeviction（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。 进行数据淘汰的策略，针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。 在设置了过期时间的数据中进行淘汰： volatile-random：随机淘汰设置了过期时间的任意键值； volatile-ttl：优先淘汰更早过期的键值。 volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值； volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值； 在所有数据范围内进行淘汰： allkeys-random：随机淘汰任意键值; allkeys-lru：淘汰整个键值中最久未使用的键值； allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。 LRU与LFU算法的区别LRU 全称是 Least Recently Used 翻译为最近最少使用，会选择淘汰最近最少使用的数据。 传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。 Redis 并没有使用这样的方式实现 LRU 算法，因为传统的 LRU 算法存在两个问题： 需要用链表管理所有的缓存数据，这会带来额外的空间开销； 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。 Redis 实现的是一种近似 LRU 算法，目的是为了更好的节约内存，它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。 当 Redis 进行内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。 Redis 实现的 LRU 算法的优点： 不用为所有的数据维护一个大链表，节省了空间占用； 不用在每次数据访问时都移动链表项，提升了缓存的性能； 但是 LRU 算法有一个问题，无法解决缓存污染问题，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。 因此，在 Redis 4.0 之后引入了 LFU 算法来解决这个问题。 LFU 全称是 Least Frequently Used 翻译为最近最不常用的，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。 所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。 Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。 在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。 在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，用来记录 key 的访问时间戳；低 8bit 存储 logc(Logistic Counter)，用来记录 key 的访问频次。 Redis性能优化使用批量操作减少网络传输一个 Redis 命令的执行可以简化为以下 4 步： 发送命令； 命令排队； 命令执行； 返回结果。 其中，第 1 步和第 4 步耗费时间之和称为 Round Trip Time（RTT，往返时间），也就是数据在网络上传输的时间。 使用批量操作可以减少网络传输次数，进而有效减小网络开销，大幅减少 RTT。 Redis 中有一些原生支持批量操作的命令，比如： MGET（获取一个或多个指定 key 的值）、MSET（设置一个或多个指定 key 的值）、 HMGET（获取指定哈希表中一个或者多个指定字段的值）、HMSET（同时将一个或多个 field-value 对设置到指定哈希表中）、 SADD（向指定集合添加一个或多个元素） …… 不过，在 Redis 官方提供的分片集群解决方案 Redis Cluster 下，使用这些原生批量操作命令可能会存在一些小问题需要解决。就比如说 MGET 无法保证所有的 key 都在同一个 hash slot（哈希槽） 上，MGET可能还是需要多次网络传输，原子操作也无法保证了。不过，相较于非批量操作，还是可以节省不少网络传输次数。 pipeline 对于不支持批量操作的命令，我们可以利用 pipeline（流水线） 将一批 Redis 命令封装成一组，这些 Redis 命令会被一次性提交到 Redis 服务器，只需要一次网络传输。不过，需要注意控制一次批量操作的 元素个数（例如 500 以内，实际也和元素字节数有关），避免网络传输的数据量过大。 与 MGET、MSET 等原生批量操作命令一样，pipeline 同样在 Redis Cluster 上使用会存在一些小问题。原因类似，无法保证所有的 key 都在同一个 hash slot（哈希槽） 上。如果想要使用的话，客户端需要自己维护 key 与 slot 的关系。 原生批量操作命令和 pipeline 的是有区别的，使用的时候需要注意： 原生批量操作命令是原子操作，pipeline 是非原子操作。 pipeline 可以打包不同的命令，原生批量操作命令不可以。 原生批量操作命令是 Redis 服务端支持实现的，而 pipeline 需要服务端和客户端的共同实现。 顺带补充一下 pipeline 和 Redis 事务的对比： 事务是原子操作，pipeline 是非原子操作。两个不同的事务不会同时运行，而 pipeline 可以同时以交错方式执行。 Redis 事务中每个命令都需要发送到服务端，而 Pipeline 只需要发送一次，请求次数更少 Lua 脚本 Lua 脚本同样支持批量操作多条命令。一段 Lua 脚本可以视作一条命令执行，可以看作是 原子操作。也就是说，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰，这是 pipeline 所不具备的。 并且，Lua 脚本中支持一些简单的逻辑处理比如使用命令读取值并在 Lua 脚本中进行处理，这同样是 pipeline 所不具备的。 不过， Lua 脚本依然存在下面这些缺陷： 如果 Lua 脚本运行时出错并中途结束，之后的操作不会进行，但是之前已经发生的写操作不会撤销，所以即使使用了 Lua 脚本，也不能实现类似数据库回滚的原子性。 Redis Cluster 下 Lua 脚本的原子操作也无法保证了，原因同样是无法保证所有的 key 都在同一个 hash slot（哈希槽） 上 Redis bigkey （大 key）什么是 Redis 大 key？ 大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。 一般而言，下面这两种情况被称为大 key： String 类型的值大于 10 KB； Hash、List、Set、ZSet 类型的元素的个数超过 5000个； 大 key 会带来以下四种影响： 客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。 引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。 阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。 内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。 如何找到大key 可以通过 redis-cli –bigkeys 命令查找大 key： redis-cli -h 127.0.0.1 -p6379 -a &quot;password&quot; -- bigkeys 使用的时候注意事项： 最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点； 如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。 该方式的不足之处： 这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey； 对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。 使用 SCAN 命令对数据库扫描，SCAN 命令可以按照一定的模式和数量返回匹配的 key。获取了 key 之后，可以利用 STRLEN、HLEN、LLEN 等命令返回其长度或成员数量 对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。 对于集合类型来说，有两种方法可以获得它占用的内存大小： 如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：LLEN 命令；Hash 类型：HLEN 命令；Set 类型：SCARD 命令；Sorted Set 类型：ZCARD 命令； 如果不能提前知道写入集合的元素大小，可以使用 MEMORY USAGE 命令（需要 Redis 4.0 及以上版本）查询一个键值对占用的内存空间。 使用 RdbTools 工具查找大 key 使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。 比如，下面这条命令，将大于 10 kb 的 key 输出到一个表格文件。 rdb dump.rdb -c memory --bytes 10240 -f redis.csv 如何处理 bigkey？ bigkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）： 分割 bigkey：将一个 bigkey 分割为多个小 key。例如，将一个含有上万字段数量的 Hash 按照一定策略（比如二次哈希）拆分为多个 Hash。 手动清理：Redis 4.0+ 可以使用 UNLINK 命令来异步删除一个或多个指定的 key。Redis 4.0 以下可以考虑使用 SCAN 命令结合 DEL 命令来分批次删除。 采用合适的数据结构：例如，文件二进制数据不使用 String 保存、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）。 开启 lazy-free（惰性删除/延迟释放）：lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。 Redis hotkey（热 Key）如果一个 key 的访问次数比较多且明显多于其他 key 的话，那这个 key 就可以看作是 hotkey（热 Key）。例如在 Redis 实例的每秒处理请求达到 5000 次，而其中某个 key 的每秒访问量就高达 2000 次，那这个 key 就可以看作是 hotkey。 hotkey 出现的原因主要是某个热点数据访问量暴增，如重大的热搜事件、参与秒杀的商品。 hotkey 有什么危害？ 处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理。此外，如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。 因此，hotkey 很可能成为系统性能的瓶颈点，需要单独对其进行优化，以确保系统的高可用性和稳定性 如何发现 hotkey？ 1、使用 Redis 自带的 --hotkeys 参数来查找。 Redis 4.0.3 版本中新增了 hotkeys 参数，该参数能够返回所有 key 的被访问次数。 使用该方案的前提条件是 Redis Server 的 maxmemory-policy 参数设置为 LFU 算法，不然就会报错 Redis 中有两种 LFU 算法： volatile-lfu（least frequently used）：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰。 allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key 需要注意的是，hotkeys 参数命令也会增加 Redis 实例的 CPU 和内存消耗（全局扫描），因此需要谨慎使用。 2、使用 MONITOR 命令。 MONITOR 命令是 Redis 提供的一种实时查看 Redis 的所有操作的方式，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。 由于该命令对 Redis 性能的影响比较大，因此禁止长时间开启 MONITOR（生产环境中建议谨慎使用该命令）。 在发生紧急情况时，我们可以选择在合适的时机短暂执行 MONITOR 命令并将输出重定向至文件，在关闭 MONITOR 命令后通过对文件中请求进行归类分析即可找出这段时间中的 hotkey。 3、借助开源项目。 京东零售的 hotkey 这个项目不光支持 hotkey 的发现，还支持 hotkey 的处理。 4、根据业务情况提前预估。 可以根据业务情况来预估一些 hotkey，比如参与秒杀活动的商品数据等。不过，我们无法预估所有 hotkey 的出现，比如突发的热点新闻事件等。 5、业务代码中记录分析。 在业务代码中添加相应的逻辑对 key 的访问情况进行记录分析。不过，这种方式会让业务代码的复杂性增加，一般也不会采用。 6、借助公有云的 Redis 分析服务。 如果你用的是公有云的 Redis 服务的话，可以看看其是否提供了 key 分析功能（一般都提供了）。 如何解决 hotkey？ hotkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）： 读写分离：主节点处理写请求，从节点处理读请求。 使用 Redis Cluster：将热点数据分散存储在多个 Redis 节点上。 二级缓存：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。 Redis缓存设计如何避免缓存雪崩？通常我们为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间，当缓存数据过期后，用户访问的数据如果不在缓存里，业务系统需要重新生成缓存，因此就会访问数据库，并将数据更新到 Redis 里，这样后续请求都可以直接命中缓存。 那么，当大量缓存数据在同一时间过期（失效）时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。 对于缓存雪崩问题，我们可以采用两种方案解决。 将缓存失效时间随机打散： 我们可以在原有的失效时间基础上增加一个随机值（比如 1 到 10 分钟）这样每个缓存的过期时间都不重复了，也就降低了缓存集体失效的概率。 提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间，比如秒杀场景下的数据在秒杀结束之前不过期。 设置缓存不过期： 我们可以通过后台服务来更新缓存数据，从而避免因为缓存失效造成的缓存雪崩，也可以在一定程度上避免缓存并发问题。 如何避免缓存击穿我们的业务通常会有几个数据会被频繁地访问，比如秒杀活动，这类被频地访问的数据被称为热点数据。 如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。 可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。 应对缓存击穿可以采取前面说到两种方案： 互斥锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），保证同一时间只有一个业务线程去数据库请求加载数据，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。 提前预热（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间； 如何避免缓存穿透？当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。 当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。 缓存穿透的发生一般有这两种情况： 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据； 黑客恶意攻击，故意大量访问某些读取不存在数据的业务； 应对缓存穿透的方案，常见的方案有三种。 非法请求的限制：在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。 设置空值或者默认值：针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。 使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。 缓存预热如何实现？常见的缓存预热方式有两种： 使用定时任务，比如 xxl-job，来定时触发缓存预热的逻辑，将数据库中的热点数据查询出来并存入缓存中。 使用消息队列，比如 Kafka，来异步地进行缓存预热，将数据库中的热点数据的主键或者 ID 发送到消息队列中，然后由缓存服务消费消息队列中的数据，根据主键或者 ID 查询数据库并更新缓存 如何设计一个缓存策略，可以动态缓存热点数据呢？由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而只是将其中一部分热点数据缓存起来，所以我们要设计一个热点数据动态缓存的策略。 热点数据动态缓存的策略总体思路：通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据。 以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下： 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前； 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中； 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。 在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。 常见的缓存更新策略 Cache Aside（旁路缓存）策略； Read/Write Through（读穿 / 写穿）策略； Write Back（写回）策略； 实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略应用不了。 Cache Aside（旁路缓存）策略 Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。 写策略的步骤： 先更新数据库中的数据，再删除缓存中的数据。 读策略的步骤： 如果读取的数据命中了缓存，则直接返回数据； 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。 注意，写策略的步骤的顺序不能倒过来，即不能先删除缓存再更新数据库，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。 举个例子，假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。 最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。 为什么「先更新数据库再删除缓存」不会有数据不一致的问题？ 继续用「读 + 写」请求的并发的场景来分析。 假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。 最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。 从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，但是在实际中，这个问题出现的概率并不高。 因为缓存的写入通常要远远快于数据库的写入，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。 针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「延迟双删」。 12345678#删除缓存redis.delKey(X)#更新数据库db.update(X)#睡眠Thread.sleep(N)#再删除缓存redis.delKey(X) 加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。 为什么是删除缓存，而不是更新缓存呢？ 删除一个数据，相比更新一个数据更加轻量级，出问题的概率更小。在实际业务中，缓存的数据可能不是直接来自数据库表，也许来自多张底层数据表的聚合。 比如商品详情信息，在底层可能会关联商品表、价格表、库存表等，如果更新了一个价格字段，那么就要更新整个数据库，还要关联的去查询和汇总各个周边业务系统的数据，这个操作会非常耗时。 从另外一个角度，不是所有的缓存数据都是频繁访问的，更新后的缓存可能会长时间不被访问，所以说，从计算资源和整体性能的考虑，更新的时候删除缓存，等到下次查询命中再填充缓存，是一个更好的方案。 系统设计中有一个思想叫 Lazy Loading，适用于那些加载代价大的操作，删除缓存而不是更新缓存，就是懒加载思想的一个应用。 旁路缓存策略适合读多写少的场景，不适合写多的场景，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。如果业务对缓存命中率有严格的要求，那么可以考虑两种解决方案： 一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响； 另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。 Read/Write Through（读穿 / 写穿）策略 Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。 1、Read Through 策略 先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。 2、Write Through 策略 当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在： 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。 如果缓存中数据不存在，直接更新数据库，然后返回； 下面是 Read Through/Write Through 策略的示意图： Write Back（写回）策略 Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。 实际上，Write Back（写回）策略也不能应用到我们常用的数据库和缓存的场景中，因为 Redis 并没有异步更新数据库的功能。Write Back 是计算机体系结构中的设计，比如 CPU 的缓存、操作系统中文件系统的缓存都采用了 Write Back（写回）策略。 Write Back 策略特别适合写多的场景，因为发生写操作的时候， 只需要更新缓存，就立马返回了。比如，写文件的时候，实际上是写入到文件系统的缓存就返回了，并不会写磁盘。 但是带来的问题是，数据不是强一致性的，而且会有数据丢失的风险，因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 Page Cache 还没有来得及刷盘造成的。 这里贴一张 CPU 缓存与内存使用 Write Back 策略的流程图 Redis实战Redis 如何实现延迟队列？延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种： 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消； 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单； 点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单； 在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。 使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。 Redis管道有什么用？管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。 普通命令模式，如下图所示： 管道模式，如下图所示： 使用管道技术可以解决多个命令执行时的网络等待，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。 但使用管道技术也要注意避免发送的命令过大，或管道内的数据太多而导致的网络阻塞。 要注意的是，管道技术本质上是客户端提供的功能，而非 Redis 服务器端的功能 Redis事务支持回滚吗？MySQL 在执行事务时，会提供回滚机制，当事务执行发生错误时，事务中的所有操作都会撤销，已经修改的数据也会被恢复到事务执行前的状态。 Redis 中并没有提供回滚机制，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。 事务执行过程中，如果命令入队时没报错，而事务提交后，实际执行时报错了，正确的命令依然可以正常执行，所以这可以看出 Redis 并不一定保证原子性（原子性：事务中的命令要不全部成功，要不全部失败）。 如何用Redis实现分布式锁 Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。 Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁： 如果 key 不存在，则显示插入成功，可以用来表示加锁成功； 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。 基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁； 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间； 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端； 满足这三个条件的分布式命令如下： SET lock_key unique_value NX PX 10000 lock_key 就是 key 键； unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作； NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作； PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。 而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。在分布式锁场景中，锁被其他线程误删是一个典型的 “超时释放后锁被抢占” 问题。以下是问题的本质分析和解决方案： 问题复现 线程 A 获取锁成功，锁的 value 为 A，TTL 为 30 秒。 线程 A 执行业务逻辑耗时过长（超过 30 秒），锁因 TTL 过期自动释放。 线程 B 抢占锁成功，设置 value 为 B，开始执行业务逻辑。 线程 A 业务逻辑完成后，尝试释放锁： 若释放锁的逻辑是简单的 DEL 操作（未验证 value），会直接删除锁。 若释放逻辑包含 GET + DEL（但非原子操作），可能在 GET 时获取到的是 线程A 的锁，但删除前过期被 线程B 抢占，导致误删 线程 B 的锁。 因此，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。 123456// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1])else return 0end 这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。 如何解决业务未执行完成而锁过期释放的问题呢？ 使用开源框架Redisson 只要线程一加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断的延长锁key的生存时间。因此，Redisson就是使用Redisson解决了锁过期释放，业务没执行完问题。 如何实现可重入锁？ 所谓可重入锁指的是在一个线程中可以多次获取同一把锁，比如一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法即可重入 ，而无需重新获得锁。 不可重入的分布式锁基本可以满足绝大部分业务场景了，一些特殊的场景可能会需要使用可重入的分布式锁。 可重入分布式锁的实现核心思路是线程在获取锁的时候判断是否为自己的锁，如果是的话，就不用再重新获取了。为此，我们可以为每个锁关联一个可重入计数器和一个占有它的线程。当可重入计数器大于 0 时，则锁被占有，需要判断占有该锁的线程和请求获取锁的线程是否为同一个。 实际项目中，我们不需要自己手动实现，推荐使用我们上面提到的 Redisson ，其内置了多种类型的锁比如可重入锁（Reentrant Lock）、自旋锁（Spin Lock）、公平锁（Fair Lock）、多重锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）。 著作权归JavaGuide(javaguide.cn)所有 基于MIT协议 原文链接：https://javaguide.cn/distributed-system/distributed-lock-implementations.html 基于 Redis 实现分布式锁有什么优缺点？ 基于 Redis 实现分布式锁的优点： 性能高效（这是选择缓存实现分布式锁最核心的出发点）。 实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。 避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。 基于 Redis 实现分布式锁的缺点： 超时时间不好设置。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。那么如何合理设置超时时间呢？ 我们可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。 Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性。如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。 Redis 如何解决集群情况下分布式锁的可靠性？ 为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。 它是基于多个 Redis 节点的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。 Redlock 算法的基本思路，是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。 这样一来，即使有某个 Redis 节点发生故障，因为锁的数据在其他节点上也有保存，所以客户端仍然可以正常地进行锁操作，锁的数据也不会丢失。 Redlock 算法加锁三个过程： 第一步是，客户端获取当前时间（t1）。 第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作： 加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。 如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。 第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。 可以看到，加锁成功要同时满足两个条件： 条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁； 条件二：客户端从大多数节点获取锁的总耗时（t2-t1）小于锁设置的过期时间。 加锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁最初设置的过期时间」减去「客户端从大多数节点获取锁的总耗时（t2-t1）」。如果计算的结果已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。 加锁失败后，客户端向所有 Redis 节点发起释放锁的操作，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了","link":"/2025/03/02/interview/redis/%E3%80%90redis%E3%80%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"},{"title":"【redis】简介","text":"点击阅读更多查看文章内容 什么是redisRedis诞生于2009年全称是Remote Dictionary Server，远程词典服务器，是一个基于内存的键值型NoSQL数据库。 特征： 键值型，value支持多种不同数据结构，功能丰富 单线程，redis处理命令请求是单线程的避免上下文切换 低延迟，速度快（基于内存、IO多路复用、良好的编码） 支持数据持久化（redis数据会落到磁盘持久化） 支持主从集群、分片集群 支持多语言客户端 安装redisInstall Redis on Windows | Docs windows下需要安装wsl，通过wsl进入linux子系统 通过redis-cli进入redis命令行客户端进行交互 redis常见命令数据结构介绍key一般是String类型，不过value类型多样，前五种为基本类型，后三种为特殊类型 命令帮助文档：Commands | Docs 通过命令行中 help @数据类型，也可以查看对应类型的文档 通用命令 keys：查看符合模板的所有key，pattern是redis的通配符，不建议在生产环境设备中使用，匹配时间较长单线程会阻塞 del：删除一个指定的key exists：判断key是否存在 expire：给一个key设置有效期，有效期到期时该key会被自动删除，节省内存空间（短期验证码） ttl：查看一个key的剩余有效期 String类型根据字符串的格式不同，又可以分为3类： string：普通字符串 int：整数类型，可以做自增、自减操作 float：浮点类型，可以做自增、自减操作 不管哪种格式，底层都是字节数组形式存储，只不过编码方式不同，字符串类型的最大空间不超过512m 常见命令： key的层级格式Redis没有类似MySQL中的Table的概念，我们该如何区分不同类型的key呢? 例如，需要存储用户、商品信息到redis,有一个用户id是1,有一个商品id恰好也是1 Redis的key允许有多个单词形成层级结构，多个单词之间用 ‘:’ 隔开，例如： 如果value是一个对象，则可以将对象序列化为json字符串后存储： Hash类型其value是一个无序字典，类似于哈希表 存储对象时使用JSON序列化修改不方便 hash可以将对象中的每个字段独立存储，针对单个字段做CRUD 常见命令： List类型list可以看做是一个双向链表的结构，既可以支持正向检索也可以支持反向检索 有序 元素可以重复 插入和删除快（直接修改节点指向） 查询速度一般（遍历） 常用来存储一个有序数据：朋友圈点赞列表、评论列表等 Set类型集合 无序 元素不可重复 查找快 支持交集、并集、差集等功能 常见命令： SortedSet类型SortedSet是一个可排序的set集合，SortedSet中的每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表加hash表 可排序 元素不重复 查询速度快 因为SortedSet的可排序特性，经常被用来实现排行榜这样的功能 go-redisredis/go-redis: Redis Go client 文档：Golang Redis客户端 安装：go get github.com/redis/go-redis/v9 建立连接： 12345rdb := redis.NewClient(&amp;redis.Options{ Addr: &quot;localhost:6379&quot;, Password: &quot;&quot;, // 没有密码，默认值 DB: 0, // 默认DB 0}) Set/Get： 123456789ctx := context.Background()err := rdb.Set(ctx, &quot;key&quot;, &quot;value&quot;, 10*time.Second).Err()if err != nil { panic(err)}val, err := rdb.Get(ctx, &quot;key&quot;).Result()if err != nil { panic(err)} 短信登陆基于session 集群的session共享问题：多台服务器并不共享session存储空间，当请求切换到不同的服务器时会导致数据丢失的问题。 session的替代方案应该满足： 数据共享 内存存储 key-value数据结构 基于Redis实现共享session登录 商户查询缓存什么是缓存？ 缓存就是数据交换的缓冲区（Cache），是存贮数据的临时地方，一般读写性能较高。它可以位于内存中，也可以位于 CPU、磁盘等位置。缓存的主要目的是减少访问 慢速存储（如磁盘或数据库）的时间，从而提高系统性能。 CPU内部具有一个缓存，通过缓存读写数据比内存或磁盘快得多。 web应用开发中缓存的使用场景： 作用： 降低后端负载 提高读写效率，降低响应时间 成本： 数据一致性成本 代码维护成本（解决一致性问题） 运维成本（缓存穿透、缓存雪崩、缓存击穿） 添加Redis缓存在查询商户时添加缓存 缓存更新策略 主动更新策略： 线程安全问题： 线程安全问题 是指在 多线程环境 中，多个线程同时访问共享资源时，如果没有采取适当的同步机制，可能导致程序的行为变得不确定，甚至出现错误的情况。 先删除缓存，再操作数据库：线程1删除缓存后，在更新数据库之前，线程2查询缓存未命中再查询数据库将旧的数据写入缓存。线程1更新数据库的操作是比较慢的，线程2查询的操作相对比较快，因此这种缓存与数据库不一致的现象发生的概率是比较高的。 先操作数据库，再操作缓存：线程1查询缓存未命中，查询数据库的数据，再将数据写入缓存之前，线程2更新了数据库并删除缓存了，此时线程1将更新前的数据写入缓存。线程1写缓存的速度是非常快的，在这期间内线程2要完成数据库更新以及缓存删除的操作，这种现象发生的概率是比较低的。 缓存穿透 缓存穿透：客户端请求的数据在缓存和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。 解决方案： 缓存空对象 实现简单，维护方便 额外的内存消耗；可能造成短期的不一致 布隆过滤 内存占用少，没有多余key 实现复杂，存在误判可能 使用缓存空对象解决缓存穿透问题： 除了以上两种被动解决方案（在发生缓存穿透之后的解决方案），还可以主动解决（在未发生缓存传统之前避免出现缓存传统）： 增强id的复杂度，避免被猜测id规律，做好数据的基础格式校验 在请求到达缓存层之前，先进行基本参数检查，避免无意义的查询。 加强用户权限校验 做好热点参数的限流 缓存雪崩缓存雪崩：在同一时段内大量的缓存key同时失效或者redis服务宕机，导致大量请求到达数据库，带来巨大压力 解决方案： 给不同的Key的TTL添加随机值 利用Redis集群提高服务的可用性 给缓存业务添加降级限流策略 给业务添加多级缓存 缓存击穿缓存击穿：缓存击穿问题也叫热点Key问题，就是一个高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。 解决方案： 互斥锁 效率较低：只有一个线程在重建数据，其它的所有线程等在等待 逻辑过期：一个线程重建，其它线程返回旧数据。不为key设置TTL，而是添加一个expire字段，如果数据过期则获取锁开启新线程执行数据重建，其它的线程都直接返回旧数据 基于互斥锁解决缓存击穿问题：（互斥锁可以用redis的setnx设置一个key，只有第一个设置才会生效，后续的设置因为已经存在不会生效） 基于逻辑过期解决缓存击穿问题： 缓存雪崩：大量key到期；缓存击穿：少量热点key到期；这两种问题的后果都是大量请求打到数据库","link":"/2025/03/03/interview/redis/%E3%80%90redis%E3%80%91%E7%AE%80%E4%BB%8B/"},{"title":"【Go】CSP模型","text":"点击阅读更多查看文章内容 CSP模型Go 语言中的 CSP 模型（Communicating Sequential Processes，通信顺序进程）是其并发编程的核心思想之一。CSP 模型由 Tony Hoare 在 1978 年提出，Go 语言通过 goroutine 和 channel 实现了这一模型。以下是关于 Go 中 CSP 模型的详细介绍： CSP 模型的核心思想 CSP 模型强调通过 通信 来共享内存，而不是通过 共享内存 来通信。具体来说： 进程（Process）： 在 Go 中，进程对应的是 goroutine，它是一种轻量级的线程，由 Go 运行时管理。 通信（Communication）： 进程之间通过 channel 进行通信，channel 是类型安全的管道，用于在 goroutine 之间传递数据。 CSP 模型的关键组件 Goroutine 轻量级线程： Goroutine 是 Go 并发的基本单元，比操作系统线程更轻量，创建和切换的开销更小。 创建方式： 使用 go 关键字启动一个 goroutine。 例如： 123go func() { fmt.Println(&quot;Hello from goroutine&quot;)}() Channel 通信管道： Channel 是 goroutine 之间通信的管道，用于发送和接收数据。 创建方式： 使用 make 函数创建 channel。 例如： 1ch := make(chan int) 发送和接收： 使用 &lt;- 操作符发送和接收数据。 例如： 12ch &lt;- 42 // 发送数据value := &lt;-ch // 接收数据 CSP 模型的特点 通过通信共享内存 避免竞态条件： 通过 channel 传递数据，避免了多个 goroutine 直接共享内存，从而减少了竞态条件的发生。 数据所有权转移： 数据通过 channel 传递时，所有权从一个 goroutine 转移到另一个 goroutine，确保数据的安全访问。 顺序进程 独立执行： 每个 goroutine 是独立的执行单元，按照自己的顺序执行。 同步通信： Channel 可以是同步的（无缓冲）或异步的（有缓冲），用于控制 goroutine 之间的同步。 CSP 模型的优势 简化并发编程 清晰的通信模式： 通过 channel 明确 goroutine 之间的通信关系，代码更易读和维护。 避免锁的复杂性： 不需要显式使用锁（如 sync.Mutex），减少了死锁和竞态条件的风险。 高效并发 轻量级 goroutine： Goroutine 的创建和切换开销小，适合高并发场景。 高效调度： Go 运行时调度器优化了 goroutine 的调度，充分利用多核 CPU。","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91CSP%E6%A8%A1%E5%9E%8B/"},{"title":"【Go】Channel","text":"点击阅读更多查看文章内容 ChannelGo 语言中的 channel 是一种用于在 goroutine 之间进行通信的机制，支持通过channel在不同的 goroutine 之间传递数据。通过 channel，Go 提供了类似消息队列的机制，使得并发编程变得更加直观与简单。 下面我将详细介绍 Go 语言中的 channel，包括其基本概念、使用方式、特性、和一些高级用法。 创建channel创建 channel 使用内置函数 make。有两种主要的 channel 类型： 无缓冲 channelch := make(chan int) 当发送者向无缓冲的 Channel 发送数据时，若没有接收者接收数据，则发送者会被阻塞，直到有接收者接收数据后才能继续执行。反之，当接收者从无缓冲的 Channel 中接收数据时，若没有发送者发送数据，则接收者会被阻塞，直到有发送者发送数据后才能继续执行。 无缓冲 Channel 的应用场景： 多个 Goroutine 之间需要进行严格的同步和协调； 希望确保发送和接收操作的顺序性； 希望避免数据竞争和死锁的情况 有缓冲 channelch := make(chan int, 3) // 创建一个大小为 3 的缓冲区 当发送者向有缓冲的 Channel 发送数据时，若缓冲区未满，则数据将被存储在缓冲区中。反之，若缓冲区已满，则发送者将被阻塞，直到有接收者从缓冲区中取出数据后才能继续执行。当接收者从有缓冲的 Channel 中接收数据时，若缓冲区不为空，则数据将被从缓冲区中取出并返回给接收者。反之，若缓冲区为空，则接收者将被阻塞，直到有发送者向缓冲区中发送数据后才能继续执行。 有缓冲 Channel 的应用场景： 多个 Goroutine 之间需要进行异步通信； 希望提高数据传输的效率和吞吐量； 程序中存在发送和接收的速度不匹配的情况。 示例： 12345678910func main() { ch := make(chan int) go func() { &lt;-ch }() ch &lt;- 1 fmt.Println(&quot;1&quot;) ch &lt;- 2 fmt.Println(&quot;2&quot;)} 以上代码的执行结果为： 121fatal error: all goroutines are asleep - deadlock! 首先创建了一个channel，随后启动了一个goroutine从channel中接收一个数据 然后执行 ch &lt;- 1 向channel中发送一个数据，此时主goroutine阻塞不再执行后面的代码，当子goroutine接收到channel中的数据后主goroutine继续向后执行又向channel中发送了一个数据然后阻塞，此时没有goroutine能够接收数据一直阻塞就发生了死锁。 我们将创建一个缓冲区为1的channel 12345678910111213func main() { ch := make(chan int, 1) go func() { time.Sleep(3 * time.Second) &lt;-ch }() ch &lt;- 1 fmt.Println(&quot;1&quot;) ch &lt;- 2 fmt.Println(&quot;2&quot;) ch &lt;- 3 fmt.Println(&quot;3&quot;)} 以上代码的执行结果为： 12312fatal error: all goroutines are asleep - deadlock! 首先输出1，等待3s后输出2，随后进入死锁。 因为缓冲区为1，所以最开始向channel发送了一个数据后并不会阻塞直接输出1，此时再向channel中发送数据2会阻塞，等待3s后1从channel中取出此时阻塞停止，将2发送到channel中并执行后面的代码，后面再向channel中发送3会阻塞，此时没有goroutine能从channel中取出数据，陷入死锁。 数据插入时机： 没有缓冲区时，发送操作 ch1 &lt;- 1 不会直接将数据插入 channel，而是会阻塞发送方的 goroutine，直到有其他 goroutine 准备好接收这个数据。这种机制的本质是 同步：发送和接收操作必须同时准备好，数据才会完成传递。 有缓冲区时，缓冲区未满数据会直接存入缓冲区，发送操作 立即完成，发送方 goroutine 不会阻塞。缓冲区已满满再向其中发送数据会阻塞， nil channelnil channel 是一个未分配内存的 channel，其值为 nil。可以通过以下方式创建一个 nil channel： go 1var ch chan int // ch 是一个 nil channel 此时，ch 的类型是 chan int，但它的值为 nil。 nil channel 在发送、接收和关闭操作中有以下行为： **发送操作 (ch &lt;- value)**：向 nil channel 发送数据会导致 永久阻塞，因为 nil channel 没有底层数据结构来存储数据。 **接收操作 (&lt;-ch)**：从 nil channel 接收数据会导致 永久阻塞，因为 nil channel 没有底层数据结构来提供数据。 **关闭操作 (close(ch))**：关闭 nil channel 会引发 panic，因为 nil channel 没有底层数据结构可以关闭。 nil channel 的用途 尽管 nil channel 在发送和接收时会阻塞，但它在某些场景下可以作为有效的工具，例如： **动态禁用 select 语句中的 case**：在 select 语句中，nil channel 的 case 永远不会被选中，因此可以用来动态禁用某些操作。 12345678910111213141516171819202122232425262728func main() { ch1 := make(chan int) var ch2 chan int // ch2 是一个 nil channel go func() { for i := 0; i &lt; 3; i++ { ch1 &lt;- i } close(ch1) }() for { select { case value, ok := &lt;-ch1: if !ok { ch1 = nil // 禁用 ch1 的 case fmt.Println(&quot;ch1 closed&quot;) continue } fmt.Println(&quot;Received from ch1:&quot;, value) case value := &lt;-ch2: fmt.Println(&quot;Received from ch2:&quot;, value) // 永远不会执行 default: fmt.Println(&quot;No data received&quot;) time.Sleep(500 * time.Millisecond) } }} 发送和接收数据发送数据：ch &lt;- 42 接收数据：value := &lt;- ch 关闭channel当发送者不再向 channel 发送数据时，可以关闭 channel。关闭 channel 可以通知接收者没有更多的数据可接收。 只能由发送方关闭 channel。 1close(ch) 关闭 channel 的底层操作主要包括以下步骤： 设置关闭标志： channel 的内部数据结构中有一个标志位（closed），用于标记 channel 是否已关闭。调用 close(ch) 会将这个标志位设置为 true。 唤醒等待的接收方： 如果有 goroutine 正在等待从 channel 中接收数据，关闭 channel 会唤醒这些 goroutine，让它们可以继续执行。 禁止发送操作： 关闭 channel 后，任何尝试向 channel 发送数据的操作都会引发 panic，因为 channel 已经关闭，不能再接收数据。 关闭 channel 后，接收者继续从中接收数据时，如果 channel 中的数据已经接收完，接收操作会返回零值，并且可以通过 ok 标志来判断 channel 是否已关闭，如果channel已关闭则ok为false。 注意：如果channel没关闭且channel没有元素那么读操作会阻塞，如果channel关闭即使channel没有元素那么读操作仍会读到0 当一个 channel 被关闭时，所有从该 channel 接收数据的 goroutine 都会立即收到一个零值（nil）。 关闭 channel 是一种广播机制，所有监听该 channel 的 goroutine 都会感知到关闭事件。 1234value, ok := &lt;-chif !ok { fmt.Println(&quot;Channel is closed and empty&quot;)} Select 语句select 语句类似于 switch，但是它用于 channel 操作。select 允许一个 goroutine 等待多个 channel 操作中的任意一个完成。它常用于并发控制和多路复用。 123456789101112131415161718192021222324252627282930package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() { ch1 := make(chan string) ch2 := make(chan string) go func() { time.Sleep(1 * time.Second) ch1 &lt;- &quot;Message from ch1&quot; }() go func() { time.Sleep(2 * time.Second) ch2 &lt;- &quot;Message from ch2&quot; }() // 等待两个 channel 中的一个返回 select { case msg1 := &lt;-ch1: fmt.Println(&quot;Received:&quot;, msg1) case msg2 := &lt;-ch2: fmt.Println(&quot;Received:&quot;, msg2) case &lt;-time.After(3 * time.Second): fmt.Println(&quot;Timeout!&quot;) }} 在这个例子中，select 会等待 ch1 或 ch2 中的消息返回，第一个完成的分支会执行。如果在 3 秒内没有接收到消息，time.After 会触发超时分支。 for range遍历channelfor range 用于遍历 channel 时，会一直等待，直到该 channel 关闭，并且 channel 中的数据被完全接收完为止。 具体来说，range 遍历 channel 会持续进行以下几个步骤： 如果 channel 中有数据，range 会接收并处理这些数据。 如果 channel 中没有数据，range 会阻塞，直到有数据发送到 channel。 12345678910111213141516171819func main() { ch := make(chan int, 3) // 启动一个 goroutine 发送数据到 channel go func() { for i := 1; i &lt;= 3; i++ { ch &lt;- i time.Sleep(1 * time.Second) // 模拟耗时操作 } time.Sleep(5 * time.Second) close(ch) // 发送完数据后关闭 channel }() // 使用 for range 遍历 channel for value := range ch { fmt.Println(value) // 输出 channel 中的数据 } fmt.Println(&quot;Channel is closed and all data read&quot;)} 执行结果：每隔1s输出1，2，3；输出3后等待5s输出 Channel is closed and all data read 1234123Channel is closed and all data read 实际应用以下是一个websocket的服务处理函数，主goroutine每隔200ms向连接发送一个数据，并启动了一个goroutine不断从连接中读取数据。 此时如果连接中断，子goroutine中的读取操作会返回错误表示连接中断，子goroutine需要将连接中断的消息发送给主goroutine结束连接。 done := make(chan struct{})定义一个channel，子goroutine中如果报错则向done中发送一个信号，主goroutine中通过select接收，如果200ms内没有收到done的内容则会收到time.After的返回，此时不执行select不执行任何操作直接发送后面的数据，如果在200ms内收到了done的信号，则会直接return。 channel的内容为struct{}，因为这里只用作通知消息，无需传输实际的值，因此使用空结构体不占用任何内存，（在仅传输信号的场景中一般都是用空结构体，表达的意图更清晰可以直接判断channel的用途）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func handleWebSocket(w http.ResponseWriter, r *http.Request) { // 升级到websocket u := &amp;websocket.Upgrader{ CheckOrigin: func(r *http.Request) bool { return true }, } c, err := u.Upgrade(w, r, nil) if err != nil { fmt.Printf(&quot;upgrade error: %v\\n&quot;, err) return } defer c.Close() done := make(chan struct{}) go func() { for { m := make(map[string]interface{}) err := c.ReadJSON(&amp;m) if err != nil { fmt.Printf(&quot;read error: %v\\n&quot;, err) // 如果不是正常错误则打印错误信息 if !websocket.IsCloseError(err, websocket.CloseGoingAway, websocket.CloseNormalClosure) { fmt.Printf(&quot;unexpected read error: %v\\n&quot;, err) } // 通知主goroutine关闭 done &lt;- struct{}{} break } fmt.Printf(&quot;recv: %v\\n&quot;, m) } }() i := 0 for { // 每200ms发送一条消息，如果在200ms内收到done信号则退出 select { case &lt;-time.After(200 * time.Millisecond): case &lt;-done: return } i++ err := c.WriteJSON(map[string]string{ &quot;message&quot;: &quot;hello&quot;, &quot;msgid&quot;: strconv.Itoa(i), }) if err != nil { fmt.Printf(&quot;write error: %v\\n&quot;, err) } }} 设计原理Go 语言中最常见的、也是经常被人提及的设计模式就是：不要通过共享内存的方式进行通信，而是应该通过通信的方式共享内存。在很多主流的编程语言中，多个线程传递数据的方式一般都是共享内存，为了解决线程竞争，我们需要限制同一时间能够读写这些变量的线程数量，然而这与 Go 语言鼓励的设计并不相同。 虽然我们在 Go 语言中也能使用共享内存加互斥锁进行通信，但是 Go 语言提供了一种不同的并发模型，即通信顺序进程（Communicating sequential processes，CSP）1。Goroutine 和 Channel 分别对应 CSP 中的实体和传递信息的媒介，Goroutine 之间会通过 Channel 传递数据。 上图中的两个 Goroutine，一个会向 Channel 中发送数据，另一个会从 Channel 中接收数据，它们两者能够独立运行并不存在直接关联，但是能通过 Channel 间接完成通信。 先入先出 目前的 Channel 收发操作均遵循了先进先出的设计，具体规则如下： 先从 Channel 读取数据的 Goroutine 会先接收到数据； 先向 Channel 发送数据的 Goroutine 会得到先发送数据的权利； 数据结构Go 语言的 Channel 在运行时使用 runtime.hchan 结构体表示。我们在 Go 语言中创建新的 Channel 时，实际上创建的都是如下所示的结构： 1234567891011121314151617181920212223242526type hchan struct { // chan 里元素数量 qcount uint // chan 底层循环数组的长度 dataqsiz uint // 指向底层循环数组的指针 // 只针对有缓冲的 channel buf unsafe.Pointer // chan 中元素大小 elemsize uint16 // chan 是否被关闭的标志 closed uint32 // chan 中元素类型 elemtype *_type // element type // 已发送元素在循环数组中的索引 sendx uint // send index // 已接收元素在循环数组中的索引 recvx uint // receive index // 等待接收的 goroutine 队列 recvq waitq // list of recv waiters // 等待发送的 goroutine 队列 sendq waitq // list of send waiters // 保护 hchan 中所有字段 lock mutex} buf 指向底层循环数组，只有缓冲型的 channel 才有。 sendx，recvx 均指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组）。 sendq，recvq 分别表示被阻塞的 goroutine，这些 goroutine 由于尝试读取 channel 或向 channel 发送数据而被阻塞。 waitq 是 sudog 的一个双向链表，而 sudog 实际上是对 goroutine 的一个封装 lock 用来保证每个读 channel 或写 channel 的操作都是原子的。 例如，创建一个容量为 6 的，元素为 int 型的 channel 数据结构如下 ：","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91Channel/"},{"title":"【Go】Context","text":"点击阅读更多查看文章内容 简介上下文 context.Context Go 语言中用来设置截止日期、同步信号，传递请求相关值的结构体。上下文与 Goroutine 有比较密切的关系，是 Go 语言中独特的设计，在其他编程语言中我们很少见到类似的概念。 context.Context 是 Go 语言在 1.7 版本中引入标准库的接口，该接口定义了四个需要实现的方法，其中包括： Deadline — 返回 context.Context 被取消的时间，也就是完成工作的截止日期； Done — 返回一个 Channel，这个 Channel 会在当前工作完成或者上下文被取消后关闭，多次调用 Done 方法会返回同一个 Channel； Err — 返回 context.Context 结束的原因，它只会在 Done 方法对应的 Channel 关闭时返回非空的值； 如果 context.Context 被取消，会返回 Canceled 错误； 如果 context.Context 超时，会返回 DeadlineExceeded 错误； Value — 从 context.Context 中获取键对应的值，对于同一个上下文来说，多次调用 Value 并传入相同的 Key 会返回相同的结果，该方法可以用来传递请求特定的数据； 123456type Context interface { Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct{} Err() error Value(key interface{}) interface{}} context 包中提供的 context.Background、context.TODO、context.WithDeadline 和 context.WithValue 函数会返回实现该接口的私有结构体，我们会在后面详细介绍它们的工作原理。 设计原理在 Goroutine 构成的树形结构中对信号进行同步以减少计算资源的浪费是 context.Context 的最大作用。Go 服务的每一个请求都是通过单独的 Goroutine 处理的，HTTP/RPC 请求的处理器会启动新的 Goroutine 访问数据库和其他服务。 如下图所示，我们可能会创建多个 Goroutine 来处理一次请求，而 context.Context 的作用是在不同 Goroutine 之间同步请求特定数据、取消信号以及处理请求的截止日期。 每一个 context.Context 都会从最顶层的 Goroutine 一层一层传递到最下层。context.Context 可以在上层 Goroutine 执行出现错误时，将信号及时同步给下层。 如上图所示，当最上层的 Goroutine 因为某些原因执行失败时，下层的 Goroutine 由于没有接收到这个信号所以会继续工作；但是当我们正确地使用 context.Context 时，就可以在下层及时停掉无用的工作以减少额外资源的消耗： 我们可以通过一个代码片段了解 context.Context 是如何对信号进行同步的。在这段代码中，我们创建了一个过期时间为 1s 的上下文，并向上下文传入 handle 函数，该方法会使用 500ms 的时间处理传入的请求： 12345678910111213141516171819func main() { ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second) defer cancel() go handle(ctx, 500*time.Millisecond) select { case &lt;-ctx.Done(): fmt.Println(&quot;main&quot;, ctx.Err()) }}func handle(ctx context.Context, duration time.Duration) { select { case &lt;-ctx.Done(): fmt.Println(&quot;handle&quot;, ctx.Err()) case &lt;-time.After(duration): fmt.Println(&quot;process request with&quot;, duration) }} 因为过期时间大于处理时间，所以我们有足够的时间处理该请求，运行上述代码会打印出下面的内容： 123$ go run context.goprocess request with 500msmain context deadline exceeded handle 函数没有进入超时的 select 分支，但是 main 函数的 select 却会等待 context.Context 超时并打印出 main context deadline exceeded。 如果我们将处理请求时间增加至 1500ms，整个程序都会因为上下文的过期而被中止，： 123$ go run context.gomain context deadline exceededhandle context deadline exceeded 相信这两个例子能够帮助各位读者理解 context.Context 的使用方法和设计原理 — 多个 Goroutine 同时订阅 ctx.Done() 管道中的消息，一旦接收到取消信号就立刻停止当前正在执行的工作。 context.Background、context.TODOcontext 包中最常用的方法还是 context.Background、context.TODO，这两个方法都会返回预先初始化好的私有变量 background 和 todo，它们会在同一个 Go 程序中被复用： context.Background和context.TODO 都通过 emptyCtx 结构体实现了四个空方法没有任何功能 context.Background 是上下文的默认值，所有其他的上下文都应该从它衍生出来； context.TODO 应该仅在不确定应该使用哪种上下文时使用； 在多数情况下，如果当前函数没有上下文作为入参，我们都会使用 context.Background 作为起始的上下文向下传递。 1234567891011121314151617type emptyCtx struct{}func (emptyCtx) Deadline() (deadline time.Time, ok bool) { return}func (emptyCtx) Done() &lt;-chan struct{} { return nil}func (emptyCtx) Err() error { return nil}func (emptyCtx) Value(key any) any { return nil} context.WithCancelcontext.WithCancel 函数能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数。一旦我们执行返回的取消函数，当前上下文以及它的子上下文都会被取消，所有的 Goroutine 都会同步收到这一取消信号。 我们直接从 context.WithCancel 函数的实现来看它到底做了什么： 12345678910111213func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := withCancel(parent) return c, func() { c.cancel(true, Canceled, nil) }}func withCancel(parent Context) *cancelCtx { if parent == nil { panic(&quot;cannot create context from nil parent&quot;) } c := &amp;cancelCtx{} c.propagateCancel(parent, c) return c} context.propagateCancel 会构建父子上下文之间的关联，当父上下文被取消时，子上下文也会被取消 除了 context.WithCancel 之外，context 包中的另外两个函数 context.WithDeadline 和 context.WithTimeout 也都能创建可以被取消的计时器上下文 context.timerCtx： context.WithValue在最后我们需要了解如何使用上下文传值，context 包中的 context.WithValue 能从父上下文中创建一个子上下文，传值的子上下文使用 context.valueCtx 类型 123456789101112func WithValue(parent Context, key, val any) Context { if parent == nil { panic(&quot;cannot create context from nil parent&quot;) } if key == nil { panic(&quot;nil key&quot;) } if !reflectlite.TypeOf(key).Comparable() { panic(&quot;key is not comparable&quot;) } return &amp;valueCtx{parent, key, val}} 小结Go 语言中的 context.Context 的主要作用还是在多个 Goroutine 组成的树中同步取消信号以减少对资源的消耗和占用，虽然它也有传值的功能，但是这个功能我们还是很少用到。 在真正使用传值的功能时我们也应该非常谨慎，使用 context.Context 传递请求的所有参数一种非常差的设计，比较常见的使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91Context/"},{"title":"【Go】GMP模型","text":"点击阅读更多查看文章内容 线程一个线程需要在内核态与用户态之间进行切换，并且切换是受到操作系统控制的，可能这个现在需要等待多个时间片才能切换到内核态再调用操作系统底层的接口 那么我们是否可以用两个线程分别处理这两种状态呢？两个线程之间再做好绑定，当用户线程将任务提交给内核线程后，就可以不用堵塞了，可以去执行其他的任务了 对于CPU来说（多核CPU），不需要关注线程切换的问题，只需要分配系统资源给内核线程进行调度即可，我们来给用户线程换个名字——协程（co-runtine） 如果是一比一的关系的话，上下文切换涉及用户态和内核态的切换，开销较大。 所以可以设计为N 比 1的形式，多个协程可以将任务一股脑的交给内核线程去完成，但是这样又有问题，如果其中一个问题在提交任务的过程中，堵塞住了，就会影响其他线程的工作，且无法利用多核CPU 所以一般为M 比 N的关系 早期的GMP为了解决传统内核级的线程的创建、切换、销毁开销较大的问题，Go 语言将线程分为了两种类型：内核级线程 M （Machine），轻量级的用户态的协程 Goroutine，至此，Go 语言调度器的三个核心概念出现了两个： M： Machine的缩写，代表了内核线程 OS Thread，CPU调度的基本单元； G： Goroutine的缩写，用户态、轻量级的协程，一个 G 代表了对一段需要被执行的 Go 语言程序的封装；每个 Goroutine 都有自己独立的栈存放自己程序的运行状态；分配的栈大小 2KB，可以按需扩缩容； 在早期，Go 将传统线程拆分为了 M 和 G 之后，为了充分利用轻量级的 G 的低内存占用、低切换开销的优点，会在当前一个M上绑定多个 G，某个正在运行中的 G 执行完成后，Go 调度器会将该 G 切换走，将其他可以运行的 G 放入 M 上执行，这时一个 Go 程序中只有一个 M 线程： 这个方案的优点是用户态的 G 可以快速切换，不会陷入内核态，缺点是每个 Go 程序都用不了硬件的多核加速能力，并且 G 阻塞会导致跟 G 绑定的 M 阻塞，其他 G 也用不了 M 去执行自己的程序了。 为了解决这些不足，Go 后来快速上线了多线程调度器： 多个 M 对应多个 G 每个Go程序，都有多个 M 线程对应多个 G 协程，该方案有以下缺点： 1）全局锁、中心化状态带来的锁竞争导致的性能下降；在 GM 模型中，所有的 G 协程都存储在一个全局队列中，所有的 M 线程需要从全局队列中获取 G 来执行。； 2）M 会频繁交接 G，导致额外开销、性能下降；每个 M 都得能执行任意的 runnable 状态的 G； 3）每个 M 都需要处理内存缓存，导致大量的内存占用并影响数据局部性； 4）系统调用频繁阻塞和解除阻塞正在运行的线程，增加了额外开销； 当前的GMP模型为了解决多线程调度器的问题，Go 开发者 Dmitry Vyokov 在已有 G、M 的基础上，引入了 P 处理器，由此产生了当前 Go 中经典的 GMP 调度模型。 P：Processor的缩写，代表一个虚拟的处理器，它维护一个局部的可运行的 G 队列，可以通过 CAS 的方式无锁访问，工作线程 M 优先使用自己的局部运行队列中的 G，只有必要时才会去访问全局运行队列，这大大减少了锁冲突，提高了大量 G 的并发性。每个 G 要想真正运行起来，首先需要被分配一个 P。 如图 1.5 所示，是当前 Go 采用的 GMP 调度模型。可运行的 G 是通过处理器 P 和线程 M 绑定起来的，M 的执行是由操作系统调度器将 M 分配到 CPU 上实现的，Go 运行时调度器负责调度 G 到 M 上执行，主要在用户态运行，跟操作系统调度器在内核态运行相对应。 需要说明的是，Go 调度器也叫 Go 运行时调度器，或 Goroutine 调度器，指的是由运行时在用户态提供的多个函数组成的一种机制，目的是为了高效地调度 G 到 M上去执行。可以跟操作系统的调度器 OS Scheduler 对比来看，后者负责将 M 调度到 CPU 上运行。从操作系统层面来看，运行在用户态的 Go 程序只是一个请求和运行多个线程 M 的普通进程，操作系统不会直接跟上层的 G 打交道。 至于为什么不直接将本地队列放在 M 上、而是要放在 P 上呢？ 这是因为当一个线程 M 阻塞（可能执行系统调用或 IO请求）的时候，可以将和它绑定的 P 上的 G 转移到其他线程 M 去执行，如果直接把可运行 G 组成的本地队列绑定到 M，则万一当前 M 阻塞，它拥有的 G 就不能给到其他 M 去执行了。 基于 GMP 模型的 Go 调度器的核心思想是： 尽可能复用线程 M：避免频繁的线程创建和销毁； 利用多核并行能力：限制同时运行（不包含阻塞）的 M 线程数为 N，N 等于 CPU 的核心数目，这里通过设置 P 处理器的个数为 GOMAXPROCS 来保证，GOMAXPROCS 一般为 CPU 核数，因为 M 和 P 是一一绑定的，没有找到 P 的 M 会放入空闲 M 列表，没有找到 M 的 P 也会放入空闲 P 列表； Work Stealing 任务窃取机制：M 优先执行其所绑定的 P 的本地队列的 G，如果本地队列为空，可以从全局队列获取 G 运行，也可以从其他 M 偷取 G 来运行；为了提高并发执行的效率，M 可以从其他 M 绑定的 P 的运行队列偷取 G 执行，这种 GMP 调度模型也叫任务窃取调度模型，这里，任务就是指 G； Hand Off 交接机制：M 阻塞，会将 M 上 P 的运行队列交给其他 M 执行，交接效率要高，才能提高 Go 程序整体的并发度； 基于协作的抢占机制：每个真正运行的G，如果不被打断，将会一直运行下去，为了保证公平，防止新创建的 G 一直获取不到 M 执行造成饥饿问题，Go 程序会保证每个 G 运行10ms 就要让出 M，交给其他 G 去执行； 基于信号的真抢占机制：尽管基于协作的抢占机制能够缓解长时间 GC 导致整个程序无法工作和大多数 Goroutine 饥饿问题，但是还是有部分情况下，Go调度器有无法被抢占的情况，例如，for 循环或者垃圾回收长时间占用线程，为了解决这些问题， Go1.14 引入了基于信号的抢占式调度机制，能够解决 GC 垃圾回收和栈扫描时存在的问题。","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91GMP%E6%A8%A1%E5%9E%8B/"},{"title":"【Go】atomic原子操作","text":"点击阅读更多查看文章内容 简介在 Go 语言中，atomic 包提供了一系列的原子操作函数，用于在并发环境中安全地操作共享变量。原子操作是不可分割的操作，即在执行过程中不会被其他 goroutine 打断，从而避免了数据竞争（Data Race）和并发问题。atomic 包是 Go 标准库的一部分，常用于实现高性能的并发控制。 原子操作的核心概念 原子性： 原子操作是不可分割的，要么全部执行成功，要么全部不执行。且在执行过程中，不会被其他 goroutine 打断。 无锁编程： 原子操作通常基于硬件指令（如 CAS, Compare-And-Swap）实现，无需使用锁（如 sync.Mutex）。 适用场景： 原子操作适用于简单的共享变量操作（如计数器、标志位等）。对于复杂的共享资源操作，仍然需要使用锁或其他同步机制。 atomic 包的主要功能atomic 包提供了对以下类型的原子操作支持： int32 int64 uint32 uint64 uintptr unsafe.Pointer 以下是 atomic 包中常用的函数： 加载（Load）： 原子地读取变量的值。 示例： 1value := atomic.LoadInt32(&amp;counter) 存储（Store）： 原子地设置变量的值。 示例： 1atomic.StoreInt32(&amp;counter, 10) 增加（Add）： 原子地增加变量的值。 示例： 1atomic.AddInt32(&amp;counter, 1) 比较并交换（Compare-And-Swap, CAS）： 如果变量的值等于预期值，则设置为新值。 示例： 1swapped := atomic.CompareAndSwapInt32(&amp;counter, 10, 20) 交换（Swap）： 原子地设置变量的值，并返回旧值。 示例： 1oldValue := atomic.SwapInt32(&amp;counter, 20) 示例1234567891011121314func main() { var n int32 var wg sync.WaitGroup wg.Add(1000) for i := 0; i &lt; 1000; i++ { go func() { atomic.AddInt32(&amp;n, 1) wg.Done() }() } wg.Wait() fmt.Println(atomic.LoadInt32(&amp;n)) // 1000} 以上代码n能正确的返回1000，但如果不使用原子操作，使用n++的话由于并发执行线程不安全结果无法正确返回","link":"/2025/03/20/gonote/%E3%80%90Go%E3%80%91atomic%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"title":"【Go】defer和os.Exit()","text":"点击阅读更多查看文章内容 defer和os.Exit问题：在使用os.Exit退出后，defer func() {…}()没有执行 原因：os.Exit函数描述如上，不会执行deferred functions","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91defer%E5%92%8Cos.Exit()/"},{"title":"【Go】gin学习","text":"点击阅读更多查看文章内容 gin的helloworld体验Gin 是一个用 Go 语言编写的轻量级 Web 框架，专为高性能和易用性设计 启动一个gin的server对象，当接收到get方法的/ping请求时，调用pong方法 12345678910111213141516171819package mainimport ( &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;)func pong(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ &quot;message&quot;: &quot;pong&quot;, })}func main() { //实例化一个gin的server对象 r := gin.Default() r.GET(&quot;/ping&quot;, pong) r.Run(&quot;:8083&quot;) // listen and serve on 0.0.0.0:8080} 使用New和Default初始化路由器的区别使用 gin.new() 只创建一个路由器不附带任何中间件，使用 gin.Default() 使用默认中间件（logger and recovery ）创建路由器，logger在请求时会打印日志，recovery在程序panic时会返回500状态码 配置不同方法，不同路径的处理逻辑，在restful接口中非常有用 1234567router.GET(&quot;/someGet&quot;, getting)router.POST(&quot;/somePost&quot;, posting)router.PUT(&quot;/somePut&quot;, putting)router.DELETE(&quot;/someDelete&quot;, deleting)router.PATCH(&quot;/somePatch&quot;, patching)router.HEAD(&quot;/someHead&quot;, head)router.OPTIONS(&quot;/someOptions&quot;, options) 路由分组将相同前缀的url提取为一个分组，简化路径表述 1234567router := gin.Default()goodsGroup := router.Group(&quot;/goods&quot;){ goodsGroup.GET(&quot;/list&quot;, goodsList) goodsGroup.GET(&quot;/1&quot;, goodsDetail) //获取商品id为1的详细信息 goodsGroup.POST(&quot;/add&quot;, createGoods)} 等同于 1234router := gin.Default()router.GET(&quot;/goods/list&quot;, goodsList)router.GET(&quot;/goods/1&quot;, goodsDetail)router.POST(&quot;/goods/add&quot;, createGoods) 获取url中的变量将传入的对应的url的值赋值给id 1goodsGroup.GET(&quot;/:id&quot;, goodsDetail) 通过 c.Param(“id”) 取出 id 的值 123456func goodsDetail(c *gin.Context) { id := c.Param(&quot;id&quot;) c.JSON(http.StatusOK, gin.H{ &quot;id&quot;: id, })} 星号匹配 goodsGroup.GET(&quot;/:id/*action&quot;, goodsDetail) 冒号匹配 goodsGroup.GET(&quot;/:id/:action/add&quot;, goodsDetail) 约束url 传入的url需要id和name，其中id需要为int类型，name需要为string类型，否则会返回404错误 123456789101112131415161718192021222324252627package mainimport ( &quot;github.com/gin-gonic/gin&quot; &quot;net/http&quot;)type Person struct { ID int `uri:&quot;id&quot; binding:&quot;required&quot;` Name string `uri:&quot;name&quot; binding:&quot;required&quot;`}func main() { router := gin.Default() router.GET(&quot;/:name/:id&quot;, func(c *gin.Context) { var person Person if err := c.ShouldBindUri(&amp;person); err != nil { c.Status(404) return } c.JSON(http.StatusOK, gin.H{ &quot;name&quot;: person.Name, &quot;id&quot;: person.ID, }) }) router.Run(&quot;:8083&quot;)} 获取get和post表单信息获取get请求的参数：c.DefaultQuery（在没有参数时设置默认值） 12345678910router.GET(&quot;/welcome&quot;, welcome)func welcome(c *gin.Context) { firstName := c.DefaultQuery(&quot;firstname&quot;, &quot;bobby&quot;) lastName := c.DefaultQuery(&quot;lastname&quot;, &quot;imooc&quot;) c.JSON(http.StatusOK, gin.H{ &quot;first_name&quot;: firstName, &quot;last_name&quot;: lastName, })} 获取post请求的参数：c.DefaultPostForm（没有参数时指定默认值）不需要指定默认值则使用 c.PostForm 12345678910router.POST(&quot;/form_post&quot;, formPost)func formPost(c *gin.Context) { message := c.PostForm(&quot;message&quot;) nick := c.DefaultPostForm(&quot;nick&quot;, &quot;anonymous&quot;) c.JSON(http.StatusOK, gin.H{ &quot;message&quot;: message, &quot;nik&quot;: nick, })} gin返回json和protobuf返回json： 通过gin.H 12345678func welcome(c *gin.Context) { firstName := c.DefaultQuery(&quot;firstname&quot;, &quot;bobby&quot;) lastName := c.DefaultQuery(&quot;lastname&quot;, &quot;imooc&quot;) c.JSON(http.StatusOK, gin.H{ &quot;first_name&quot;: firstName, &quot;last_name&quot;: lastName, })} 通过struct 123456789101112func moreJSON(c *gin.Context) { var msg struct { Name string `json:&quot;user&quot;` Message string Number int } msg.Name = &quot;bobby&quot; msg.Message = &quot;这是一个测试json&quot; msg.Number = 20 c.JSON(http.StatusOK, msg)} 返回protobuf 12345678func returnProto(c *gin.Context) { course := []string{&quot;python&quot;, &quot;go&quot;, &quot;微服务&quot;} user := &amp;proto.Teacher{ Name: &quot;bobby&quot;, Course: course, } c.ProtoBuf(http.StatusOK, user)} 登录的表单验证Gin使用 go-playground/validator 验证参数，查看完整文档。 Must bind Methods - Bind, BindJSON, BindXML, BindQuery, BindYAML Behavior - 这些方法底层使用 MustBindWith，如果存在绑定错误，请求将被以下指令中止 c.AbortWithError(400, err).SetType(ErrorTypeBind)，响应状态代码会被设置为400，请求头Content-Type被设置为text/plain; charset=utf-8。注意，如果你试图在此之后设置响应代码，将会发出一个警告 [GIN-debug] [WARNING] Headers were already written. Wanted to override status code 400 with 422，如果你希望更好地控制行为，请使用ShouldBind相关的方法 Should bind Methods - ShouldBind, ShouldBindJSON, ShouldBindXML, ShouldBindQuery, ShouldBindYAML Behavior - 这些方法底层使用 ShouldBindWith，如果存在绑定错误，则返回错误，开发人员可以正确处理请求和错误 当我们使用绑定方法时，Gin会根据Content-Type推断出使用哪种绑定器，如果你确定你绑定的是什么，你可以使用MustBindWith或者BindingWith。 通过struct的标签添加验证条件 User的form key为user或json key为user，必填，最小长度为3，最大长度为10 Password的json字段为password，必填 通过 c.ShouldBind(&amp;loginForm) 验证 12345678910111213141516171819202122232425262728package mainimport ( &quot;github.com/gin-gonic/gin&quot; &quot;net/http&quot;)type LoginForm struct { User string `form:&quot;user&quot; json:&quot;user&quot; binding:&quot;required,min=3,max=10&quot;` Password string `json:&quot;password&quot; binding:&quot;required&quot;`}func main() { router := gin.Default() router.POST(&quot;/loginJSON&quot;, func(c *gin.Context) { var loginForm LoginForm if err := c.ShouldBind(&amp;loginForm); err != nil { c.JSON(http.StatusBadRequest, gin.H{ &quot;error&quot;: err.Error(), }) return } c.JSON(http.StatusOK, gin.H{ &quot;msg&quot;: &quot;登录成功&quot;, }) }) _ = router.Run(&quot;:8083&quot;)} 在form-data中添加password是无效的 需要在raw中添加json 注册的表单验证1234567891011121314151617181920 type SignUpParam struct { Age uint8 `json:&quot;age&quot; binding:&quot;gte=1,lte=130&quot;` Name string `json:&quot;name&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot; binding:&quot;required,email&quot;` Password string `json:&quot;password&quot; binding:&quot;required&quot;` RePassword string `json:&quot;re_password&quot; binding:&quot;required,eqfield=Password&quot;` }router.POST(&quot;/signup&quot;, func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(&amp;u); err != nil { c.JSON(http.StatusOK, gin.H{ &quot;msg&quot;: err.Error(), }) return } // 保存入库等业务逻辑代码... c.JSON(http.StatusOK, &quot;success&quot;)}) 表单验证错误翻译成中文1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package mainimport ( &quot;fmt&quot; &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot; &quot;github.com/gin-gonic/gin/binding&quot; &quot;github.com/go-playground/locales/en&quot; &quot;github.com/go-playground/locales/zh&quot; ut &quot;github.com/go-playground/universal-translator&quot; &quot;github.com/go-playground/validator/v10&quot; enTranslations &quot;github.com/go-playground/validator/v10/translations/en&quot; zhTranslations &quot;github.com/go-playground/validator/v10/translations/zh&quot;)// 定义一个全局翻译器Tvar trans ut.Translator// InitTrans 初始化翻译器func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // locale 通常取决于 http 请求头的 'Accept-Language' var ok bool // 也可以使用 uni.FindTranslator(...) 传入多个locale进行查找 trans, ok = uni.GetTranslator(locale) if !ok { return fmt.Errorf(&quot;uni.GetTranslator(%s) failed&quot;, locale) } // 注册翻译器 switch locale { case &quot;en&quot;: err = enTranslations.RegisterDefaultTranslations(v, trans) case &quot;zh&quot;: err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) } return } return}type SignUpParam struct { Age uint8 `json:&quot;age&quot; binding:&quot;gte=1,lte=130&quot;` Name string `json:&quot;name&quot; binding:&quot;required&quot;` Email string `json:&quot;email&quot; binding:&quot;required,email&quot;` Password string `json:&quot;password&quot; binding:&quot;required&quot;` RePassword string `json:&quot;re_password&quot; binding:&quot;required,eqfield=Password&quot;`}func main() { if err := InitTrans(&quot;zh&quot;); err != nil { fmt.Printf(&quot;init trans failed, err:%v\\n&quot;, err) return } r := gin.Default() r.POST(&quot;/signup&quot;, func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(&amp;u); err != nil { // 获取validator.ValidationErrors类型的errors errs, ok := err.(validator.ValidationErrors) if !ok { // 非validator.ValidationErrors类型错误直接返回 c.JSON(http.StatusOK, gin.H{ &quot;msg&quot;: err.Error(), }) return } // validator.ValidationErrors类型错误则进行翻译 c.JSON(http.StatusOK, gin.H{ &quot;msg&quot;: errs.Translate(trans), }) return } // 保存入库等具体业务逻辑代码... c.JSON(http.StatusOK, &quot;success&quot;) }) _ = r.Run(&quot;:8999&quot;)} 表单中文翻译的json格式化细节错误中的字段仍然是go语言中定义的结构体字段名称，并且带有SignUpParam前缀 将字段名称修改为实际的json字段：在初始化翻译器获取到validator引擎后，注册tag方法，获取tag中json的值并根据逗号分隔获取第一个即可 12345678if v, ok := binding.Validator.Engine().(*validator.Validate); ok { v.RegisterTagNameFunc(func(fld reflect.StructField) string { name := strings.SplitN(fld.Tag.Get(&quot;json&quot;), &quot;,&quot;, 2)[0] if name == &quot;-&quot; { return &quot;&quot; } return name }) 去除前缀：去除map key中的前缀，获取.的位置，只保留.之后的内容 1234567func removeTopStruct(fields map[string]string) map[string]string { rsp := map[string]string{} for field, err := range fields { rsp[field[strings.Index(field, &quot;.&quot;)+1:]] = err } return rsp} 对返回值应用以上方法处理： 123c.JSON(http.StatusOK, gin.H{ &quot;msg&quot;: removeTopStruct(errs.Translate(trans)),}) 自定义gin中间件使用中间件 123router := gin.New()// 使用logger和recovery中间件 全局所有router.Use(gin.Logger(),gin.Recovery()) 中间件函数签名 12// HandlerFunc defines the handler used by gin middleware as return value.type HandlerFunc func(*Context) 为/goods开头的url添加自定义中间件 12345router := gin.Default()authrized:=router.Group(&quot;/goods&quot;)authrized.Use(func(context *gin.Context) { ...}) 自定义中间件的使用： 12345678910111213141516171819202122232425func MyLogger() gin.HandlerFunc { return func(c *gin.Context) { t := time.Now() c.Set(&quot;example&quot;, &quot;123456&quot;) //让原本改执行的逻辑继续执行 c.Next() end := time.Since(t) fmt.Printf(&quot;耗时:%V\\n&quot;, end) status := c.Writer.Status() fmt.Println(&quot;状态&quot;, status) }}func main() { router := gin.Default() router.Use(MyLogger()) router.GET(&quot;/ping&quot;, func(c *gin.Context) { e, _ := c.Get(&quot;example&quot;) c.JSON(http.StatusOK, gin.H{ &quot;message&quot;: e, }) }) router.Run(&quot;:8083&quot;)} 通过abort终止中间件后续逻辑的执行添加验证token的中间件，如果token不符则终止后续逻辑的执行 需要使用c.Abort()，不能通过return结束，具体原因在于中间件的执行逻辑，gin会维护一个要执行的函数的队列，并通过index指明当前要执行的函数，执行c.Next()时会将index++执行下一个函数，而执行return只会退出TokenRequired，后面的函数仍在队列中并且index没有改变，所以中间件结束后，index仍会++，只是不再由c.Next()驱动而是由gin驱动继续向后执行。 调用c.Abort()时会将index指向一个大数 math.MaxInt8 / 2，此时后面没有待执行的函数就终止了后续逻辑的执行 1234567891011121314151617func TokenRequired() gin.HandlerFunc { return func(c *gin.Context) { var token string for k, v := range c.Request.Header { if k == &quot;X-Token&quot; { token = v[0] } } if token != &quot;bobby&quot; { c.JSON(http.StatusUnauthorized, gin.H{ &quot;msg&quot;: &quot;未登录&quot;, }) c.Abort() } c.Next() }} gin返回html模板：非前后端分离的系统中，后端接收到请求后，会将数据填充到模板html中，再将html返回给前端显示 官方地址：https://golang.org/pkg/html/template/翻译： [译]Golang template 小抄 使用以下代码直接运行会报错，找不到文件，这是因为goland在执行代码时会将生成的exe文件放在临时目录下，相对于该临时目录的路径找不到文件，解决方法要么使用绝对路径，要么在代码目录下使用 go build 生成exe文件执行 1234567891011121314151617func main() { router := gin.Default() //为什么我们通过goland运行main.go的时候并没有生成main.exe文件 dir, _ := filepath.Abs(filepath.Dir(os.Args[0])) fmt.Println(dir) router.LoadHTMLFiles(&quot;templates/index.tmpl&quot;) //如果没有在模板中使用define定义 那么我们就可以使用默认的文件名来找 router.GET(&quot;/index&quot;, func(c *gin.Context) { c.HTML(http.StatusOK, &quot;index.tmpl&quot;, gin.H{ &quot;title&quot;: &quot;慕课网&quot;, }) }) router.Run(&quot;:8083&quot;)} 模板文件：模板文件中使用.title取出title字段的值 12345678910111213.tmpl&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt; {{ .title }} &lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 加载多个html文件加载两个文件 1router.LoadHTMLFiles(&quot;templates/index.tmpl&quot;,&quot;templates/goods.html&quot;) 加载templates目录下所有目录的所有文件（只会加载二级目录的文件，templates目录下的文件不会加载） 1router.LoadHTMLGlob(&quot;templates/**/*&quot;) 在定义html时如果多个目录下的文件重名，则使用define定义一个名称 12345678910111213{{define &quot;goods/list.html&quot;}}&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;/static/css/style.css&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;商品列表页&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;{{end}} 在返回时，使用定义的名称返回 12345router.GET(&quot;/goods/list&quot;, func(c *gin.Context) { c.HTML(http.StatusOK, &quot;goods/list.html&quot;, gin.H{ &quot;title&quot;: &quot;慕课网&quot;, })}) static静态文件的处理静态文件：图片、CSS html页面要使用css文件 直接访问该页面会报以下错误： 此时需要通过router.Static()加载静态文件，添加如下语句以/mystatic开头的url都去当前目录下的static目录下查找 gin的优雅退出优雅退出，当我们关闭程序的时候应该做的后续处理 1234567891011121314151617181920func main() { router := gin.Default() router.GET(&quot;/&quot;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ &quot;msg&quot;: &quot;pong&quot;, }) }) go func() { router.Run(&quot;:8080&quot;) }() //优雅退出 quit := make(chan os.Signal) signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM) //接收到关闭信号 &lt;-quit fmt.Println(&quot;关闭server中......&quot;) fmt.Println(&quot;注销服务......&quot;)}","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91gin%E5%AD%A6%E4%B9%A0/"},{"title":"【Go】go-redis使用","text":"点击阅读更多查看文章内容 go-redisredis/go-redis: Redis Go client 文档：Golang Redis客户端 安装：go get github.com/redis/go-redis/v9 建立连接： 12345rdb := redis.NewClient(&amp;redis.Options{ Addr: &quot;localhost:6379&quot;, Password: &quot;&quot;, // 没有密码，默认值 DB: 0, // 默认DB 0}) Set/Get： 123456789ctx := context.Background()err := rdb.Set(ctx, &quot;key&quot;, &quot;value&quot;, 10*time.Second).Err()if err != nil { panic(err)}val, err := rdb.Get(ctx, &quot;key&quot;).Result()if err != nil { panic(err)}","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91go-redis%E4%BD%BF%E7%94%A8/"},{"title":"【Go】gorm学习","text":"点击阅读更多查看文章内容 什么是ORMORM（Object-Relational Mapping，面向对象关系映射）是一种程序设计技术，它将面向对象编程中的对象和关系型数据库中的表格结构进行映射。通过ORM，开发者可以使用面向对象的方式来操作数据库，而不需要编写复杂的SQL语句。 具体来说，ORM提供了一个抽象层，允许开发者通过类和对象来表示数据库表和记录，通常这种映射是自动完成的，ORM框架会负责将对象的属性与数据库中的字段对应起来，并生成相应的SQL语句执行数据库操作。 go-gorm/gorm: The fantastic ORM library for Golang, aims to be developer friendly GORM 指南 | GORM - The fantastic ORM library for Golang, aims to be developer friendly. gorm连接数据库12345678910111213141516package mainimport ( &quot;database/sql&quot; &quot;gorm.io/driver/mysql&quot; &quot;gorm.io/gorm&quot;)func main() { // 参考 https://github.com/go-sql-driver/mysql#dsn-data-source-name 获取详情 dsn := &quot;root:root@tcp(127.0.0.1:3306)/gorm_test?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&quot; _, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{}) if err != nil { panic(err) }} 生成表结构db.AutoMigrate(&amp;Product{})，根据Product结构体建表 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( &quot;database/sql&quot; &quot;gorm.io/driver/mysql&quot; &quot;gorm.io/gorm&quot; &quot;gorm.io/gorm/logger&quot; &quot;log&quot; &quot;os&quot; &quot;time&quot;)type Product struct { gorm.Model Code sql.NullString Price uint}func main() { // 参考 https://github.com/go-sql-driver/mysql#dsn-data-source-name 获取详情 dsn := &quot;root:shn001221@tcp(127.0.0.1:3306)/gorm_test?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&quot; //设置全局的logger，这个logger在我们执行每个sql语句的时候会打印每一行sql //sql才是最重要的，本着这个原则我尽量的给大家看到每个api背后的sql语句是什么 newLogger := logger.New( log.New(os.Stdout, &quot;\\r\\n&quot;, log.LstdFlags), // io writer logger.Config{ SlowThreshold: time.Second, // 慢 SQL 阈值 LogLevel: logger.Info, // Log level Colorful: true, // 禁用彩色打印 }, ) // 全局模式 db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{ Logger: newLogger, }) if err != nil { panic(err) } //定义一个表结构， 将表结构直接生成对应的表 - migrations // 迁移 schema _ = db.AutoMigrate(&amp;Product{}) //此处应该有sql语句} 输出内容（实际执行语句） 执行结果： 模型gorm.Model 在定义持久化模型 PO(persist object) 时，推荐组合使用 gorm.Model 中预定义的几个通用字段，包括主键、增删改时间等： 1234567891011121314type PO struct { gorm.Model}package gormtype Model struct { // 主键 id ID uint `gorm:&quot;primarykey&quot;` // 创建时间 CreatedAt time.Time // 更新时间 UpdatedAt time.Time // 删除时间 DeletedAt DeletedAt `gorm:&quot;index&quot;`} 值得一提的是，在 gorm 体系中，一个 po 模型只要启用了 deletedAt 字段，则默认会开启软删除机制：在执行删除操作时，不会立刻物理删除数据，而是仅仅将 po 的 deletedAt 字段置为非空. 标签123456789101112type PO struct{ // 组合使用 gorm Model，引用 id、createdAt、updatedAt、deletedAt 等字段 gorm.Model // 列名为 name；列类型字符串；使用该列作为唯一索引 Name string `gorm:&quot;column:name;type:varchar(15);unique_index&quot;` // 该列默认值为 18 Age int `gorm:&quot;default:18&quot;` // 该列值不为空 Email string `gorm:&quot;not null&quot;` // 该列的数值逐行递增 Num int `gorm:&quot;auto_increment&quot;` } 几类常用的标签及对应的用途展示如下表： 标签 作用 primarykey 主键 unique_index 唯一键 index 键 auto_increment 自增列 column 列名 type 列类型 default 默认值 not null 非空 零值在 golang 中一些基础类型都存在对应的零值，即便用户未显式给字段赋值，字段在初始化时也会首先赋上零值. 比如 bool 类型的零值为 false；string 类型为 “”，int 类型为 0. 这样就会导致，在我们执行创建、更新等操作时，倘若 po 模型中存在零值字段，此时 gorm 无法区分到底是用户显式声明的零值，还是未显式声明而被编译器默认赋予的零值. 在无法区分的情况下，gorm 会统一按照后者，采取忽略处理的方式. 为什么只能更新非零值字段？如果我们去更新一个product 只设置了price：200，那么其他字段默认为零值，也就是说在更新数据库时会将其他字段都更新为零值，因此选择将零值忽略掉。 倘若此时我们想要明确是显式将字段设置为零值的，对应可以采取以下两种处理方式： 使用指针类型： 我们将 age 字段类型设定为 *int，只要指针非空，就代表使用方进行了显式赋值. 1234type PO struct{ gorm.Model Age *int `gorm:&quot;column:age&quot;` // 默认值为 18} 使用 sql.Nullxx 类型： 我们将 age 字段类型设定为 sql.NullInt64，只要 Valid 标识为 true，就代表使用方进行了显式赋值. 12345678910type PO struct{ gorm.Model Age sql.NullInt64 `gorm:&quot;column:age&quot;` // 默认值为 18}type NullInt64 struct { Int64 int64 Valid bool // Valid is true if Int64 is not NULL} 增删改查123// 创建单个记录user := User{Name: &quot;John&quot;, Age: 30}result := db.Create(&amp;user) 12// 查询多个记录db.Where(&quot;age &gt; ?&quot;, 25).Find(&amp;users) // 带条件查询 12// 更新多个字段db.Model(&amp;user).Updates(User{Name: &quot;Jane&quot;, Age: 31}) 12// 删除单个记录db.Delete(&amp;user) 在 GORM 中，表名通常是通过模型（结构体）自动推断的，而不是直接在语句中指定的。GORM 会根据模型的结构体名称和约定规则自动推断表名。 增：db.Create(&amp;Product{Code: sql.NullString{“D42”, true}, Price: 100}) INSERT INTO products (created_at,updated_at,deleted_at,code,price) VALUES (‘2025-02-06 23:22:57.421’,’2025-02-06 23:22:57.421’,NULL,’D42’,100) 删：db.Delete(&amp;product) （删除product对应的id的记录） UPDATE products SET deleted_at=’2025-02-06 23:26:32.629’ WHERE products.id = 3 AND products.deleted_at IS NULL 改：db.Model(&amp;product).Update(“Price”, 200) （修改product对应的id的记录） UPDATE products SET price=200,updated_at=’2025-02-06 23:24:49.857’ WHERE id = 3 查：db.First(&amp;product, “code = ?”, “D42”) （查找 code 字段值为 D42 的记录 赋值给 product） SELECT * FROM products WHERE code = ‘D42’ AND products.deleted_at IS NULL ORDER BY products.id LIMIT 1 表结构定义细节通过字段标签声明表结构定义的细节（字段标签） 定义user表 将userid设为主键 将name列名设置为user_name，类型设置为varchar(50)，设置索引idx_user_name，设置唯一索引，设置默认值“bobby” 1234type User struct { UserID uint `gorm:&quot;primarykey&quot;` Name string `gorm:&quot;column:user_name;type:varchar(50);index:idx_user_name;unique;default:'bobby'&quot;`} 插入记录1234567user := User{Name: &quot;Jinzhu&quot;, Age: 18, Birthday: time.Now()}result := db.Create(&amp;user) // 通过数据的指针来创建user.ID // 返回插入数据的主键result.Error // 返回 errorresult.RowsAffected // 返回插入记录的条数 批量插入 要高效地插入大量记录，请将切片传递给Create方法。 GORM 将生成一条 SQL 来插入所有数据 123456var users = []User{{Name: &quot;jinzhu1&quot;}, {Name: &quot;jinzhu2&quot;}, {Name: &quot;jinzhu3&quot;}}db.Create(&amp;users)for _, user := range users { user.ID // 1,2,3} 你可以通过db.CreateInBatches方法来指定批量插入的批次大小，以下代币会执行两次insert，第一次插入两条，第二次插入一条 sql语句有长度限制，一次性插入的数据是有上限的，所以需要限制每次插入的数量 1234var users = []User{{Name: &quot;jinzhu1&quot;}, {Name: &quot;jinzhu2&quot;}, {Name: &quot;jinzhu3&quot;}}// batch size 100db.CreateInBatches(users, 2) 通过map插入 GORM支持通过 map[string]interface{} 与 []map[string]interface{}{}来创建记录。 123456789db.Model(&amp;User{}).Create(map[string]interface{}{ &quot;Name&quot;: &quot;jinzhu&quot;, &quot;Age&quot;: 18,})// batch insert from `[]map[string]interface{}{}`db.Model(&amp;User{}).Create([]map[string]interface{}{ {&quot;Name&quot;: &quot;jinzhu_1&quot;, &quot;Age&quot;: 18}, {&quot;Name&quot;: &quot;jinzhu_2&quot;, &quot;Age&quot;: 20},}) 查询记录检索单个对象 GORM 提供了 First、Take、Last 方法，以便从数据库中检索单个对象。当查询数据库时它添加了 LIMIT 1 条件，且没有找到记录时，它会返回 ErrRecordNotFound 错误 12345678910111213141516171819var user User// 获取第一条记录（主键升序）db.First(&amp;user)// SELECT * FROM users ORDER BY id LIMIT 1;// 获取一条记录，没有指定排序字段db.Take(&amp;user)// SELECT * FROM users LIMIT 1;// 获取最后一条记录（主键降序）db.Last(&amp;user)// SELECT * FROM users ORDER BY id DESC LIMIT 1;result := db.First(&amp;user)result.RowsAffected // 返回找到的记录数result.Error // returns error or nil// 检查 ErrRecordNotFound 错误errors.Is(result.Error, gorm.ErrRecordNotFound) 检索全部对象 1234567 var users []User result := db.Find(&amp;users)// SELECT * FROM users; fmt.Println(&quot;总共记录:&quot;, result.RowsAffected) for _, user := range users { fmt.Println(user.ID) } gorm的基本查询String 条件 where设置查询条件，First指定表名以及limit 1，find不会添加limit 123456789101112131415161718192021222324252627// Get first matched recorddb.Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).First(&amp;user)// SELECT * FROM users WHERE name = 'jinzhu' ORDER BY id LIMIT 1;// Get all matched recordsdb.Where(&quot;name &lt;&gt; ?&quot;, &quot;jinzhu&quot;).Find(&amp;users)// SELECT * FROM users WHERE name &lt;&gt; 'jinzhu';// INdb.Where(&quot;name IN ?&quot;, []string{&quot;jinzhu&quot;, &quot;jinzhu 2&quot;}).Find(&amp;users)// SELECT * FROM users WHERE name IN ('jinzhu','jinzhu 2');// LIKEdb.Where(&quot;name LIKE ?&quot;, &quot;%jin%&quot;).Find(&amp;users)// SELECT * FROM users WHERE name LIKE '%jin%';// ANDdb.Where(&quot;name = ? AND age &gt;= ?&quot;, &quot;jinzhu&quot;, &quot;22&quot;).Find(&amp;users)// SELECT * FROM users WHERE name = 'jinzhu' AND age &gt;= 22;// Timedb.Where(&quot;updated_at &gt; ?&quot;, lastWeek).Find(&amp;users)// SELECT * FROM users WHERE updated_at &gt; '2000-01-01 00:00:00';// BETWEENdb.Where(&quot;created_at BETWEEN ? AND ?&quot;, lastWeek, today).Find(&amp;users)// SELECT * FROM users WHERE created_at BETWEEN '2000-01-01 00:00:00' AND '2000-01-08 00:00:00'; Struct &amp; Map 条件 1234567891011// Structdb.Where(&amp;User{Name: &quot;jinzhu&quot;, Age: 20}).First(&amp;user)// SELECT * FROM users WHERE name = &quot;jinzhu&quot; AND age = 20 ORDER BY id LIMIT 1;// Mapdb.Where(map[string]interface{}{&quot;name&quot;: &quot;jinzhu&quot;, &quot;age&quot;: 20}).Find(&amp;users)// SELECT * FROM users WHERE name = &quot;jinzhu&quot; AND age = 20;// Slice of primary keysdb.Where([]int64{20, 21, 22}).Find(&amp;users)// SELECT * FROM users WHERE id IN (20, 21, 22); 更新记录Save更新 Save 会保存所有的字段，即使字段是零值 123456db.First(&amp;user)user.Name = &quot;jinzhu 2&quot;user.Age = 100db.Save(&amp;user)// UPDATE users SET name='jinzhu 2', age=100, birthday='2016-01-01', updated_at = '2013-11-17 21:34:10' WHERE id=111; Save 是一个组合函数。 如果保存值不包含主键，它将执行 Create，否则它将执行 Update (包含所有字段)。 12345db.Save(&amp;User{Name: &quot;jinzhu&quot;, Age: 100})// INSERT INTO `users` (`name`,`age`,`birthday`,`update_at`) VALUES (&quot;jinzhu&quot;,100,&quot;0000-00-00 00:00:00&quot;,&quot;0000-00-00 00:00:00&quot;)db.Save(&amp;User{ID: 1, Name: &quot;jinzhu&quot;, Age: 100})// UPDATE `users` SET `name`=&quot;jinzhu&quot;,`age`=100,`birthday`=&quot;0000-00-00 00:00:00&quot;,`update_at`=&quot;0000-00-00 00:00:00&quot; WHERE `id` = 1 更新单个列 Model中传入空的User则指定表名，如果user有值则传入where子句 1234567891011// 根据条件更新db.Model(&amp;User{}).Where(&quot;active = ?&quot;, true).Update(&quot;name&quot;, &quot;hello&quot;)// UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE active=true;// User 的 ID 是 `111`db.Model(&amp;user).Update(&quot;name&quot;, &quot;hello&quot;)// UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE id=111;// 根据条件和 model 的值进行更新db.Model(&amp;user).Where(&quot;active = ?&quot;, true).Update(&quot;name&quot;, &quot;hello&quot;)// UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE id=111 AND active=true; gorm的软删除细节删除一条记录时，删除对象需要指定主键，否则会触发 批量删除，例如： 1234567// Email 的 ID 是 `10`db.Delete(&amp;email)// DELETE from emails where id = 10;// 带额外条件的删除db.Where(&quot;name = ?&quot;, &quot;jinzhu&quot;).Delete(&amp;email)// DELETE from emails where id = 10 AND name = &quot;jinzhu&quot;; 软删除 如果你的模型包含了 gorm.DeletedAt字段（该字段也被包含在gorm.Model中），那么该模型将会自动获得软删除的能力！ 当调用Delete时，GORM并不会从数据库中删除该记录，而是将该记录的DeleteAt设置为当前时间，而后的一般查询方法将无法查找到此条记录。 1234567891011// user's ID is `111`db.Delete(&amp;user)// UPDATE users SET deleted_at=&quot;2013-10-29 10:23&quot; WHERE id = 111;// Batch Deletedb.Where(&quot;age = ?&quot;, 20).Delete(&amp;User{})// UPDATE users SET deleted_at=&quot;2013-10-29 10:23&quot; WHERE age = 20;// Soft deleted records will be ignored when queryingdb.Where(&quot;age = 20&quot;).Find(&amp;user)// SELECT * FROM users WHERE age = 20 AND deleted_at IS NULL; 如果你并不想嵌套gorm.Model，你也可以像下方例子那样开启软删除特性： 12345type User struct { ID int Deleted gorm.DeletedAt Name string} 查找被软删除的记录 你可以使用Unscoped来查询到被软删除的记录 12db.Unscoped().Where(&quot;age = 20&quot;).Find(&amp;users)// SELECT * FROM users WHERE age = 20; 永久删除 你可以使用 Unscoped来永久删除匹配的记录 12db.Unscoped().Delete(&amp;order)// DELETE FROM orders WHERE id=10;","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91gorm%E5%AD%A6%E4%B9%A0/"},{"title":"【Go】map的声明与初始化问题","text":"点击阅读更多查看文章内容 map的声明与初始化问题描述：在使用以下代码生成map并赋值时会报panic: assignment to entry in nil map 1234func main() { var a map[int]int a[0] = 1} 出现原因：var只是声明没有初始化 在 Go 中，使用 var 声明一个变量时，变量本身会被分配内存地址并初始化为零值 例如 var a int 这里 a 的值为 0 但对于复合数据类型（如 map、slice 和 channel），它们的零值是 nil。这意味着使用 var 声明的 map 变量虽然有地址，但它指向的底层数据结构尚未被分配内存。 因此当使用**var a map[int]int**：声明了一个 map 类型的变量，其初始值为 nil，此时没有底层数据结构支持存储键值对。试图对 nil 的 map 进行写操作时，会导致 panic。 解决方法 使用 make 初始化 map：var a = make(map[int]int) 使用 a:=map[int]int{},它在声明的同时对 map 进行了初始化。其效果等同于a := make(map[int]int)","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91map%E7%9A%84%E5%A3%B0%E6%98%8E%E4%B8%8E%E5%88%9D%E5%A7%8B%E5%8C%96%E9%97%AE%E9%A2%98/"},{"title":"【Go】var与:&#x3D;定义变量的地址问题","text":"点击阅读更多查看文章内容 var与:=定义变量时如何分配地址空间使用var声明变量时会为变量本身分配地址，但不会为变量指向的底层指针分配地址 使用:=初始化变量会为变量本身以及其指向的底层指针分配地址 这种区别主要体现在引用类型中（如切片、map、channel、指针等） 在值类型中 int/float/bool/string/struct 使用两个方法都没有区别，都会为变量分配地址 在引用类型中 切片： 12345678910func main() { var a []int fmt.Println(a == nil) // true fmt.Printf(&quot;%p\\n&quot;, &amp;a) // 变量 a 的地址 fmt.Printf(&quot;%p\\n&quot;, a) // 输出 0x0（因为底层数组是 nil） m2 := map[string]int{} fmt.Println(m2 == nil) // false m2[&quot;key&quot;] = 10 // ✅ 正常运行} map： 123456789func main() { var m map[string]int fmt.Println(m == nil) // true m[&quot;key&quot;] = 10 // 运行时报错：panic: assignment to entry in nil map m2 := map[string]int{} fmt.Println(m2 == nil) // false m2[&quot;key&quot;] = 10 // ✅ 正常运行} channel： 12345678func main() { var ch chan int fmt.Println(ch == nil) // true ch &lt;- 1 // ❌ panic: send on nil channel ch2 := make(chan int, 1) fmt.Println(ch2 == nil) // false ch2 &lt;- 1 // ✅ 正常运行} 指针： 12345678910func main() { var p *int fmt.Println(p == nil) // true *p = 100 // ❌ panic: invalid memory address p2 := new(int) fmt.Println(p2 == nil) // false *p2 = 100 // ✅ 正常运行 fmt.Println(*p2) // 100}","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91var%E4%B8%8E:=%E5%AE%9A%E4%B9%89%E5%8F%98%E9%87%8F%E7%9A%84%E5%9C%B0%E5%9D%80%E9%97%AE%E9%A2%98/"},{"title":"【Go】内存对齐","text":"点击阅读更多查看文章内容 什么是内存对齐在 Go 语言中，内存对齐（Memory Alignment）是指数据在内存中的存储位置需要满足特定的对齐要求。内存对齐的目的是提高 CPU 访问内存的效率，避免因为数据未对齐而导致的性能损失。以下是关于 Go 内存对齐机制的详细介绍： 内存对齐是指数据在内存中的起始地址必须是某个值的整数倍。这个值通常是数据类型的 对齐边界（Alignment Boundary），由 CPU 架构和数据类型的大小决定。 对齐边界： 例如，在 64 位系统上，int64 的对齐边界通常是 8 字节。 未对齐的后果： 如果数据未对齐，CPU 可能需要多次访问内存才能读取或写入数据，导致性能下降。 CPU 以 4 字节为单位访问内存。内存地址从 0 开始，每 4 字节为一个块（例如 0-3、4-7、8-11 等）。 我们需要读取一个 4 字节的整数，但它没有对齐，起始地址为 2，那么需要两次读取 0-3 4-7，才能拼接出2-5 如果内存对齐，那么4字节的整数，起始地址为4，只需1次读取4-7即可 在某些硬件架构上，未对齐的访问甚至会导致程序崩溃。 内存对齐规则基本数据类型的对齐边界 数据类型 大小（字节） 对齐边界（字节） bool 1 1 int8, byte 1 1 int16 2 2 int32, rune 4 4 int64 8 8 float32 4 4 float64 8 8 complex64 8 4 complex128 16 8 pointer 8 (64位系统) 8 string 16 (64位系统) 8 slice 24 (64位系统) 8 map 8 (64位系统) 8 channel 8 (64位系统) 8 结构体的对齐规则 字段的对齐边界： 每个字段的起始地址必须是其对齐边界的整数倍。 结构体的对齐边界： 结构体的对齐边界是其成员中最大对齐边界的值。 例如，如果结构体包含 int32 和 int64，则结构体的对齐边界是 8。 结构体的大小： 结构体的大小必须是其对齐边界的整数倍。 编译器可能会在结构体中插入 填充字节（Padding）以满足对齐要求。 结构体内存对齐示例以下是一个结构体内存对齐的示例： 12345type Example struct { a bool // 1 字节 b int32 // 4 字节 c int64 // 8 字节} 对齐分析： a 的对齐边界是 1，占用 1 字节。 b 的对齐边界是 4，因此编译器会在 a 和 b 之间插入 3 字节的填充。 c 的对齐边界是 8，直接跟在 b 后面。 内存布局： 1| a (1) | padding (3) | b (4) | c (8) | 结构体大小： 总大小为 16 字节。 优化结构体布局通过调整结构体成员的顺序，可以减少填充字节，从而节省内存。 优化前12345type Unoptimized struct { a bool // 1 字节 b int64 // 8 字节 c int32 // 4 字节} 内存布局： 1| a (1) | padding (7) | b (8) | c (4) | padding (4) | 结构体大小： 总大小为 24 字节。 优化后12345type Optimized struct { b int64 // 8 字节 c int32 // 4 字节 a bool // 1 字节} 内存布局： 1| b (8) | c (4) | a (1) | padding (3) | 结构体大小： 总大小为 16 字节。 查看内存对齐信息可以使用 unsafe 包查看结构体的大小和对齐边界 12fmt.Println(&quot;Size of Example:&quot;, unsafe.Sizeof(Example{})) fmt.Println(&quot;Alignment of Example:&quot;, unsafe.Alignof(Example{}))","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/"},{"title":"【Go】切片扩容","text":"点击阅读更多查看文章内容 切片切片的实现Go 中的切片本质上是一个结构体，包含以下三个部分： 指向底层数组的指针（array）：切片指向一个底层数组，数组中存储着切片的数据。 切片的长度（len）：切片中当前元素的个数。 切片的容量（cap）：底层数组的总容量，即底层数组能够存储的元素个数。 12345type slice struct { array unsafe.Pointer len int cap int} 切片的扩容 切片在添加元素（如append操作）时，如果切片的长度大于容量，那么会重新分配一个新的容量更大的底层数组来存储新切片 切片在初始化的时候长度等于容量，当向切片添加元素时切片的长度就会大于容量，此时就会为其分配一个新的底层数组 12345678910111213func main() { t := []int{1, 2, 3} fmt.Println(cap(t)) fmt.Printf(&quot;%p\\n&quot;, t) t = append(t, 1) fmt.Println(cap(t)) fmt.Printf(&quot;%p\\n&quot;, t) //3 //0xc0000120a8 //6 //0xc00000c360} 在该示例中，初始化切片的长度为3，容量也为3，切片的底层数组的地址为0xc0000120a8，当向其添加一个元素后，切片的容量为6，并指向了一个新的地址0xc00000c360 Tips：使用 fmt.Printf(&quot;%p\\n&quot;, t) 获得的是切片指向的底层数组的地址与 fmt.Printf(&quot;%p\\n&quot;, unsafe.Pointer(&amp;t[0])) 的值相同，使用 fmt.Printf(&quot;%p\\n&quot;, &amp;t) 获得的是切片变量本身的地址 我们可以使用make()创建一个容量大于长度的切片，这样在向切片添加元素时，长度就不会超过容量，就不会分配新的数组 12345678910111213141516func main() { t := make([]int, 3, 5) fmt.Println(len(t)) fmt.Println(cap(t)) fmt.Printf(&quot;%p\\n&quot;, t) t = append(t, 1) fmt.Println(cap(t)) fmt.Printf(&quot;%p\\n&quot;, t) //3 //5 //0xc00000c360 //5 //0xc00000c360} 在该示例中，我们使用make([]int, 3, 5)创建了一个长度为3，容量为5的切片，随后我们向其添加了一个元素，长度为4没有超过容量，此时底层数组的地址与添加元素前的地址一致，并没有分配新的数组。 切片扩容的实现在第一个示例中，当我们向一个容量为3的切片添加一个元素后，新分配的切片容量为6，这个是如何得出的呢？ 切片扩容的代码为 growslice： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110func growslice(oldPtr unsafe.Pointer, newLen, oldCap, num int, et *_type) slice { oldLen := newLen - num if raceenabled { callerpc := getcallerpc() racereadrangepc(oldPtr, uintptr(oldLen*int(et.Size_)), callerpc, abi.FuncPCABIInternal(growslice)) } if msanenabled { msanread(oldPtr, uintptr(oldLen*int(et.Size_))) } if asanenabled { asanread(oldPtr, uintptr(oldLen*int(et.Size_))) } if newLen &lt; 0 { panic(errorString(&quot;growslice: len out of range&quot;)) } if et.Size_ == 0 { // append should not create a slice with nil pointer but non-zero len. // We assume that append doesn't need to preserve oldPtr in this case. return slice{unsafe.Pointer(&amp;zerobase), newLen, newLen} } newcap := nextslicecap(newLen, oldCap) var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.Size. // For 1 we don't need any division/multiplication. // For goarch.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. noscan := !et.Pointers() switch { case et.Size_ == 1: lenmem = uintptr(oldLen) newlenmem = uintptr(newLen) capmem = roundupsize(uintptr(newcap), noscan) overflow = uintptr(newcap) &gt; maxAlloc newcap = int(capmem) case et.Size_ == goarch.PtrSize: lenmem = uintptr(oldLen) * goarch.PtrSize newlenmem = uintptr(newLen) * goarch.PtrSize capmem = roundupsize(uintptr(newcap)*goarch.PtrSize, noscan) overflow = uintptr(newcap) &gt; maxAlloc/goarch.PtrSize newcap = int(capmem / goarch.PtrSize) case isPowerOfTwo(et.Size_): var shift uintptr if goarch.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.TrailingZeros64(uint64(et.Size_))) &amp; 63 } else { shift = uintptr(sys.TrailingZeros32(uint32(et.Size_))) &amp; 31 } lenmem = uintptr(oldLen) &lt;&lt; shift newlenmem = uintptr(newLen) &lt;&lt; shift capmem = roundupsize(uintptr(newcap)&lt;&lt;shift, noscan) overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift) newcap = int(capmem &gt;&gt; shift) capmem = uintptr(newcap) &lt;&lt; shift default: lenmem = uintptr(oldLen) * et.Size_ newlenmem = uintptr(newLen) * et.Size_ capmem, overflow = math.MulUintptr(et.Size_, uintptr(newcap)) capmem = roundupsize(capmem, noscan) newcap = int(capmem / et.Size_) capmem = uintptr(newcap) * et.Size_ } // The check of overflow in addition to capmem &gt; maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // type T [1&lt;&lt;27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d) // print(len(s), &quot;\\n&quot;) // } if overflow || capmem &gt; maxAlloc { panic(errorString(&quot;growslice: len out of range&quot;)) } var p unsafe.Pointer if !et.Pointers() { p = mallocgc(capmem, nil, false) // The append() that calls growslice is going to overwrite from oldLen to newLen. // Only clear the part that will not be overwritten. // The reflect_growslice() that calls growslice will manually clear // the region not cleared here. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can't use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) if lenmem &gt; 0 &amp;&amp; writeBarrier.enabled { // Only shade the pointers in oldPtr since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. // // It's safe to pass a type to this function as an optimization because // from and to only ever refer to memory representing whole values of // type et. See the comment on bulkBarrierPreWrite. bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(oldPtr), lenmem-et.Size_+et.PtrBytes, et) } } memmove(p, oldPtr, lenmem) return slice{p, newLen, newcap}} oldPtr unsafe.Pointer：指向当前切片的底层数组的指针。 newLen int：扩展后的切片的目标长度。 oldCap int：当前切片的容量。 num int：额外需要的空间量，通常用于处理切片扩容时的新数据量。 et *_type：元素的类型，用来确定切片元素的大小和是否是指针类型（如 int、*struct）。 首先处理一些边界条件，随后调用nextslicecap方法计算新切片的容量，具体细节如下 123456789101112131415161718192021222324252627282930313233func nextslicecap(newLen, oldCap int) int { newcap := oldCap doublecap := newcap + newcap if newLen &gt; doublecap { return newLen } const threshold = 256 if oldCap &lt; threshold { return doublecap } for { // Transition from growing 2x for small slices // to growing 1.25x for large slices. This formula // gives a smooth-ish transition between the two. newcap += (newcap + 3*threshold) &gt;&gt; 2 // We need to check `newcap &gt;= newLen` and whether `newcap` overflowed. // newLen is guaranteed to be larger than zero, hence // when newcap overflows then `uint(newcap) &gt; uint(newLen)`. // This allows to check for both with the same comparison. if uint(newcap) &gt;= uint(newLen) { break } } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 { return newLen } return newcap} 如果 newLen &gt; doublecap ，则直接返回newlen 如果 oldCap &lt; threshold，其中门限值为256，则直接扩容为两倍 如果 oldCap &gt;= threshold，则进行平滑扩容：newcap += (newcap + 3*threshold) &gt;&gt; 2 可以在在 2倍扩容 和 1.25倍扩容 之间平滑过渡，&gt;&gt; 2可以看作是除4， 已知newcap大于threshold，如果newcap稍大于threshold，那么(newcap + 3*threshold) &gt;&gt; 2 约为 threshold 此时 newcap+=threshold约等于2倍扩容 如果newcap远大于threshold，那么(newcap + 3*threshold)&gt;&gt; 2 约为 newcap/4， 此时 newcap+=newcap/4约等于1.25倍扩容 注意，以上计算出的容量并不是新切片最终的容量，在接下来的33行的switch中，还会进行一些内存管理的操作，因为内存都是成块分配的，所以实际分配的容量可能会由于内存对齐等原因大于nextslicecap计算出的newcap； 最后使用mallogc分配实际的内存大小capmem 切片传参go语言中只有值传递，没有引用传递，也就是说任何变量在传递时都会复制一份副本 12345678910111213141516func main() { t := []int{1, 2, 3} fmt.Printf(&quot;slice array address: %p\\n&quot;, t) fmt.Printf(&quot;slice address: %p\\n&quot;, &amp;t) test(t) //slice array address: 0xc0000120a8 //slice address: 0xc000008030 //slice array address(in function): 0xc0000120a8 //slice address(in function): 0xc000008060}func test(t []int) { fmt.Printf(&quot;slice array address(in function): %p\\n&quot;, t) fmt.Printf(&quot;slice address(in function): %p\\n&quot;, &amp;t)} 以上示例可以看到函数内外的切片地址并不相同，但是他们指向的底层数组是相同的，这符合值传递的特征。 这里我们在结合之前提到的切片扩容进行分析 12345678910111213141516func main() { t := []int{1, 2, 3} fmt.Printf(&quot;%p\\n&quot;, t) test(t) fmt.Printf(&quot;%p\\n&quot;, t) //0xc0000120a8 //0xc0000120a8 //0xc00000c360 //0xc0000120a8}func test(t []int) { fmt.Printf(&quot;%p\\n&quot;, t) t = append(t, 1) fmt.Printf(&quot;%p\\n&quot;, t)} 以上示例中，方法中接收的切片在开始时与原始切片指向同一个数组，但是在添加一个元素后，切片的容量超过了长度，此时为方法内的切片分配了一个新的底层数组，但是由于是值传递，两个切片本身指向不同的地址，所以方法外的切片的数组并没有改变。 12345678910111213141516func main() { t := make([]int, 3, 10) fmt.Printf(&quot;%p\\n&quot;, t) test(t) fmt.Printf(&quot;%p\\n&quot;, t) //0xc000014140 //0xc000014140 //0xc000014140 //0xc000014140}func test(t []int) { fmt.Printf(&quot;%p\\n&quot;, t) t = append(t, 1) fmt.Printf(&quot;%p\\n&quot;, t)} 以上示例中切片的容量足够，所以不会分配新的数组，但是要注意的是虽然没有分配新的数组，但是切片的长度发生了改变。 123456789101112func main() { t := make([]int, 3, 10) test(t) fmt.Println(t) //[0 0 0 1] //[0 0 0]}func test(t []int) { t = append(t, 1) fmt.Println(t)} 以上示例可以看出，在函数内外输出的切片并不一致，这是因为值传递，函数内的切片的长度发生了改变并不会改变函数外的切片长度 12345678910111213141516func main() { t := make([]int, 3, 10) test(t) fmt.Println(t) newt := t[0:4] fmt.Println(newt) //[0 0 0 1] //[0 0 0] //[0 0 0 1]}func test(t []int) { t = append(t, 1) fmt.Println(t)} 这里我们通过将t赋值给一个新的切片来取出它的第4个元素可以看到与函数内的修改一致，证明他们确实是同一个底层数组，注意这里不能通过下标的方式直接取值会报越界错误。","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E5%88%87%E7%89%87%E6%89%A9%E5%AE%B9/"},{"title":"【Go】垃圾回收","text":"点击阅读更多查看文章内容 1. 什么是 GC，有什么作用？GC，全称 Garbage Collection，即垃圾回收，是一种自动内存管理的机制。 当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。而负责垃圾回收的程序组件，即为垃圾回收器。 2. 根对象到底是什么？根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括： 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 栈上的局部变量：每个 goroutine 的栈上分配的局部变量也是根对象。这些变量包括函数参数、局部变量以及当前正在执行的函数的临时变量 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。 3. 常见的 GC 实现方式有哪些？Go 语言的 GC 使用的是什么？所有的 GC 算法其存在形式可以归结为追踪（Tracing）和引用计数（Reference Counting）这两种形式的混合运用。 追踪式 GC 从根对象出发，根据对象之间的引用信息，一步步推进直到扫描完毕整个堆并确定需要保留的对象，从而回收所有可回收的对象。Go、 Java、V8 对 JavaScript 的实现等均为追踪式 GC。 引用计数式 GC 每个对象自身包含一个被引用的计数器，当计数器归零时自动得到回收。因为此方法缺陷较多，在追求高性能时通常不被应用。Python、Objective-C 等均为引用计数式 GC。 4. 三色标记法是什么？理解三色标记法的关键是理解对象的三色抽象以及波面（wavefront）推进这两个概念。三色抽象只是一种描述追踪式回收器的方法用于追踪和标记活跃对象，在实践中并没有实际含义，它的重要作用在于从逻辑上严密推导标记清理这种垃圾回收方法的正确性。也就是说，当我们谈及三色标记法时，通常指标记清扫的垃圾回收。 从垃圾回收器的视角来看，三色抽象规定了三种不同类型的对象，并用不同的颜色相称： 白色对象（可能死亡）：未被回收器访问到的对象。在回收开始阶段，所有对象均为白色，当回收结束后，白色对象均不可达。 灰色对象（波面）：已被回收器访问到的对象，但回收器需要对其中的一个或多个指针进行扫描，因为他们可能还指向白色对象。 黑色对象（确定存活）：已被回收器访问到的对象，其中所有字段都已被扫描，黑色对象中任何一个指针都不可能直接指向白色对象。 这样三种不变性所定义的回收过程其实是一个波面不断前进的过程，这个波面同时也是黑色对象和白色对象的边界，灰色对象就是这个波面。 当垃圾回收开始时，只有白色对象。随着标记过程开始进行时，灰色对象开始出现（着色），这时候波面便开始扩大。当一个对象的所有子节点均完成扫描时，会被着色为黑色。当整个堆遍历完成时，只剩下黑色和白色对象，这时的黑色对象为可达对象，即存活；而白色对象为不可达对象，即死亡。这个过程可以视为以灰色对象为波面，将黑色对象和白色对象分离，使波面不断向前推进，直到所有可达的灰色对象都变为黑色对象为止的过程。如下图所示： 5. STW 是什么意思？STW 可以是 Stop the World 的缩写，也可以是 Start the World 的缩写。通常意义上指指代从 Stop the World 这一动作发生时到 Start the World 这一动作发生时这一段时间间隔，即万物静止。STW 在垃圾回收过程中为了保证实现的正确性、防止无止境的内存增长等问题而不可避免的需要停止赋值器进一步操作对象图的一段过程。 6. 并发标记清除法的难点是什么？在没有用户态代码并发修改三色抽象的情况下，回收可以正常结束。但是并发回收的根本问题在于，用户态代码在回收过程中会并发地更新对象图，从而造成赋值器和回收器可能对对象图的结构产生不同的认知。这时以一个固定的三色波面作为回收过程前进的边界则不再合理。 初始状态：假设某个黑色对象 C 指向某个灰色对象 A ，而 A 指向白色对象 B； C.ref3 = C.ref2.ref1：赋值器并发地将黑色对象 C 指向（ref3）了白色对象 B； A.ref1 = nil：移除灰色对象 A 对白色对象 B 的引用（ref2）； 最终状态：在继续扫描的过程中，白色对象 B 永远不会被标记为黑色对象了（回收器不会重新扫描黑色对象），进而对象 B 被错误地回收。 7. 写屏障要讲清楚写屏障，就需要理解三色标记清除算法中的强弱不变性以及赋值器的颜色，理解他们需要一定的抽象思维。写屏障是一个在并发垃圾回收器中才会出现的概念，垃圾回收器的正确性体现在：不应出现对象的丢失，也不应错误的回收还不需要回收的对象。 可以证明，当以下两个条件同时满足时会破坏垃圾回收器的正确性： 条件 1: 赋值器修改对象图，导致某一黑色对象引用白色对象； 条件 2: 从灰色对象出发，到达白色对象的、未经访问过的路径被赋值器破坏。 只要能够避免其中任何一个条件，则不会出现对象丢失的情况，因为： 如果条件 1 被避免，则所有白色对象均被灰色对象引用，没有白色对象会被遗漏； 如果条件 2 被避免，即便白色对象的指针被写入到黑色对象中，但从灰色对象出发，总存在一条没有访问过的路径，从而找到到达白色对象的路径，白色对象最终不会被遗漏。 我们不妨将三色不变性所定义的波面根据这两个条件进行削弱： 当满足原有的三色不变性定义（或上面的两个条件都不满足时）的情况称为强三色不变性（strong tricolor invariant） 当赋值器令黑色对象引用白色对象时（满足条件 1 时）的情况称为弱三色不变性（weak tricolor invariant） 当赋值器进一步破坏灰色对象到达白色对象的路径时（进一步满足条件 2 时），即打破弱三色不变性， 也就破坏了回收器的正确性；或者说，在破坏强弱三色不变性时必须引入额外的辅助操作。 弱三色不变形的好处在于：只要存在未访问的能够到达白色对象的路径，就可以将黑色对象指向白色对象。 赋值器的写屏障作为一种同步机制，使赋值器在进行指针写操作时，能够“通知”回收器，进而不会破坏弱三色不变性。 有两种非常经典的写屏障：Dijkstra 插入屏障和 Yuasa 删除屏障。 Dijkstra插入屏障灰色赋值器的 Dijkstra 插入屏障的基本思想是避免满足条件 1：当一个对象引用另外一个对象时，将另外一个对象标记为灰色。 12345// 灰色赋值器 Dijkstra 插入屏障func DijkstraWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) { shade(ptr) *slot = ptr} 为了防止黑色对象指向白色对象，应该假设 *slot 可能会变为黑色，为了确保 ptr 不会在被赋值到 *slot 前变为白色，shade(ptr) 会先将指针 ptr 标记为灰色，进而避免了条件 1。如图所示： Dijkstra 插入屏障的好处在于可以立刻开始并发标记。但存在两个缺点： 由于 Dijkstra 插入屏障的“保守”，在一次回收过程中可能会残留一部分对象没有回收成功，只有在下一个回收过程中才会被回收； 在标记阶段中，每次进行指针赋值操作时，都需要引入写屏障，这无疑会增加大量性能开销；为了避免造成性能问题，Go 团队在最终实现时，没有为所有栈上的指针写操作，启用写屏障，而是当发生栈上的写操作时，将栈标记为灰色，但此举产生了灰色赋值器，将会需要标记终止阶段 STW 时对这些栈进行重新扫描 Yuasa删除屏障其基本思想是避免满足条件 2：被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。白色对象始终会被灰色对象保护 12345// 黑色赋值器 Yuasa 屏障func YuasaWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) { shade(*slot) *slot = ptr} 上述代码会在老对象的引用被删除时，将白色的老对象涂成灰色，这样删除写屏障就可以保证弱三色不变性，老对象引用的下游对象一定可以被灰色对象引用。 假设我们在应用程序中使用 Yuasa 提出的删除写屏障，在一个垃圾收集器和用户程序交替运行的场景中会出现如上图所示的标记过程： 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色； 用户程序将 A 对象原本指向 B 的指针指向 C，触发删除写屏障，但是因为 B 对象已经是灰色的，所以不做改变； 用户程序将 B 对象原本指向 C 的指针删除，触发删除写屏障，白色的 C 对象被涂成灰色（如果没有删除写屏障C对象将始终为白色）； 垃圾收集器依次遍历程序中的其他灰色对象，将它们分别标记成黑色； 上述过程中的第三步触发了 Yuasa 删除写屏障的着色，因为用户程序删除了 B 指向 C 对象的指针，所以 C 和 D 两个对象会分别违反强三色不变性和弱三色不变性： 强三色不变性 — 黑色的 A 对象直接指向白色的 C 对象； 弱三色不变性 — 垃圾收集器无法从某个灰色对象出发，经过几个连续的白色对象访问白色的 C 和 D 两个对象； Yuasa 删除写屏障通过对 C 对象的着色，保证了 C 对象和下游的 D 对象能够在这一次垃圾收集的循环中存活，避免发生悬挂指针以保证用户程序的正确性。 混合写屏障规则Go 在 1.8 的时候为了简化 GC 的流程，同时减少标记终止阶段的重扫成本，将 Dijkstra 插入屏障和 Yuasa 删除屏障进行混合，形成混合写屏障。该屏障提出时的基本思想是：对正在被覆盖的对象进行着色，且如果当前栈未扫描完成，则同样对指针进行着色。 1、GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)， 2、GC期间，任何在栈上创建的新对象，均为黑色。 3、被删除的对象标记为灰色。 4、被添加的对象标记为灰色。","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"},{"title":"【Go】make和new的区别","text":"点击阅读更多查看文章内容 make和new的区别深入理解make和new，从底层到应用！ new 1234567891011121314151617181920package mainimport &quot;fmt&quot;//定义一个结构体，age字段为指针type Student struct { age *int}//获取结构体对象指针func getStudent() *Student { s := new(Student) return s}func main() { s := getStudent() *(s.age) = 10 fmt.Println(s.age)} 执行以上代码会发生panic panic: runtime error: invalid memory address or nil pointer dereference[signal 0xc0000005 code=0x1 addr=0x0 pc=0x34bffa] new的函数声明 1func new(Type) *Type Type是指变量的类型，new会根据变量类型返回一个指向该类型的指针。 new底层调用的是runtime.newobject申请内存空间 123func newobject(typ *_type) unsafe.Pointer { return mallocgc(typ.size, typ, true)} newobject的底层调用mallocgc在堆上按照typ.size的大小申请内存，因此new只会为结构体Student申请一片内存空间，不会为结构体中的指针age申请内存空间，所以 *(s.age) 的解引用操作就因为访问无效的内存空间而出现panic。 对于结构体指针，工作中一般使用s:=&amp;Stuent{age:=new(int)}的方式赋值，这样能够清晰的知道结构体中的每一个字段是什么，避免不必要的错误！ make 123456789package mainimport &quot;fmt&quot;func main() { nums := new([]int) (*nums)[0] = 1 fmt.Println((*nums)[0])} 以上程序在运行时也会出现panic，slice的底层实现为： 12345type slice struct { array unsafe.Pointer //指向用于存储切片数据的指针 len int cap int} 这就和上面的例子一样了，new只会为结构体slice申请内存，而不会为当中的array字段申请内存，因此用(*nums)[0]取值会发生panic。 如果需要对slice、map、channel进行内存申请，则必须使用make申请内存，下面看一下make函数声明 1func make(t Type, size ...IntegerType) Type 可以看到make返回的是复合类型本身，将错误代码修改如下 12345678910package mainimport &quot;fmt&quot;func main() { //为了让make在堆上申请内存，这里将容量写大一点 nums := make([]int, 8192) nums[0] = 1 fmt.Println(nums[0], nums[1])} 分析make的实现 12345678910111213func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) //做合法检查 if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap { mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem &gt; maxAlloc || len &lt; 0 { panicmakeslicelen() } panicmakeslicecap() } //做内存申请 return mallocgc(mem, et, true)} 可以看到makeslice申请内存底层调用的也是mallocgc，从这点看和new一样，但是细看new中mallocgc第一个参数（申请内存大小）用的是type.size，而make中的mallocgc第一个参数是mem，从MulUintptr源码中可以看出mem是slice的容量cap乘以type.size，因此使用makeslice可以成功的为切片申请内存。 make为map和channel申请内存底层分别是runtime.makemap_small，runtime.makechan，也是同样调用mallocgc，这里就不继续讨论了 更进一步举个例子，以下示例中，a的内存占用为8因为new([]int) 创建一个指向 []int 类型的指针，并返回该指针。指针的大小是 ​8 字节。 *a解指针得到的就是指针实际指向的切片包含三部分ptr：指向底层数组的指针（8 字节）。len：切片的长度（8 字节）。cap：切片的容量（8 字节）。一共24字节，b的内存占用就是24字节因为make([]int, 0)返回的就是切片本身 12345678910func main() { a := new([]int) b := make([]int, 0) fmt.Println(unsafe.Sizeof(a)) fmt.Println(unsafe.Sizeof(*a)) fmt.Println(unsafe.Sizeof(b)) //8 //24 //24} make和new的区别 相同点 都是Go语言中用于内存申请的关键字 底层都是通过mallocgc申请内存 不同点 make返回点是复合结构体本身而new返回的是指向变量内存的指针 make只能为channel，slice，map申请内存空间","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91make%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"【Go】堆和栈变量","text":"点击阅读更多查看文章内容 在 Go 语言中，变量的分配位置（堆或栈）是由 编译器 根据变量的生命周期和使用方式自动决定的。以下是堆栈分配的基本规则和常见情况： 1. 栈分配的变量栈分配的变量通常具有 确定且较短的生命周期，例如局部变量。栈分配速度快，但空间有限。 栈分配的典型情况： 局部变量： 在函数内部声明的变量，且未逃逸到函数外部。 示例： 1234func foo() { x := 10 // x 分配在栈上 fmt.Println(x)} 函数参数： 传递给函数的参数变量。 示例： 123func bar(y int) { fmt.Println(y) // y 分配在栈上} 2. 堆分配的变量堆分配的变量通常具有 不确定或较长的生命周期，例如逃逸到函数外部的变量或动态分配的内存。堆分配速度较慢，但空间较大。 堆分配的典型情况： 全局变量 动态分配的内存：使用 new 或 make 分配的内存通常分配到堆上。 逃逸到函数外部的变量： 如果变量的地址被返回或传递到函数外部，编译器会将其分配到堆上。 示例： 1234func escape() *int { x := 10 // x 逃逸到堆上 return &amp;x} 大对象： 较大的对象（如大数组或结构体）可能会分配到堆上，以避免栈溢出。 示例： 1234func large() { var arr [100000]int // arr 可能分配到堆上 fmt.Println(arr[0])} 闭包捕获的变量： 被闭包捕获的变量会分配到堆上，因为闭包可能在函数返回后继续使用这些变量。 示例： 123456func closure() func() int { x := 10 // x 逃逸到堆上 return func() int { return x }} 3. 逃逸分析（Escape Analysis）Go 编译器通过 逃逸分析 决定变量是否分配到堆上。逃逸分析的目标是尽可能将变量分配到栈上，以提高性能。 栈分配：如果变量的生命周期仅限于函数内部，编译器会将其分配在栈上。栈分配速度快，且不需要垃圾回收。 堆分配：如果变量的生命周期超出了函数范围（例如返回给调用者或存储到全局变量中），编译器会将其分配在堆上。堆分配需要垃圾回收器管理。 逃逸的常见场景 函数内的变量被函数外使用： 变量的地址被传递到函数外部（函数返回变量指针） 函数内的变量赋值给全局变量 函数内的变量传递给另一个函数 变量被闭包捕获 变量大小超出栈的范围： 较大的变量可能分配到堆上，以避免栈溢出。 变量的生命周期： 生命周期较长的变量可能分配到堆上。 4. 堆栈分配的总结 特性 栈分配 堆分配 生命周期 确定且较短 不确定或较长 分配速度 快 慢 空间限制 较小 较大 典型情况 局部变量、函数参数、临时变量 逃逸变量、动态内存、大对象、闭包变量","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E5%A0%86%E5%92%8C%E6%A0%88%E5%8F%98%E9%87%8F/"},{"title":"【Go】反射reflect","text":"点击阅读更多查看文章内容 1 反射简介反射（Reflection）指的是程序在运行时能够检查自身结构、动态获取类型信息以及修改变量和调用方法的能力。Go 语言通过内置的 reflect 包提供这一功能，使得我们能够在运行时对任意对象进行“自省”。这种能力常用于构建通用框架（如 ORM、依赖注入、序列化工具等），但同时也带来性能开销和代码复杂性的问题。 2 核心原理与重要组件2.1 接口与反射对象Go 中的任意值都可以看作由两部分组成：类型信息和数据值。当我们使用空接口 interface{} 存储一个具体变量时，实际上内部存储了该变量的类型信息和实际值。反射正是基于这一点，通过调用： **reflect.TypeOf(x)**：返回值的类型信息（ reflect.Type 接口）。 **reflect.ValueOf(x)**：返回值的运行时表示（reflect.Value 结构体）。 123var x int = 42fmt.Println(&quot;Type:&quot;, reflect.TypeOf(x)) // 输出：intfmt.Println(&quot;Value:&quot;, reflect.ValueOf(x)) // 输出：42 2.2 反射中的核心类型和方法 reflect.Type本身是一个接口，代表一个类型，通过其方法可以获取类型名称、种类（Kind）等信息。需要注意的是，自定义类型与其底层类型在 Name() 与 Kind() 上可能不同，例如自定义类型 type MyInt int，其 Name() 返回 “MyInt”，而 Kind() 返回底层的 int。 reflect.Value本身是一个结构体，表示一个运行时值，除了可以获取内部数据外，还提供了设置值的方法（前提是该值必须“可设置”，即 settable）。例如： 123var a int64 = 100v := reflect.ValueOf(&amp;a).Elem() // 通过 Elem() 获取指针指向的值v.SetInt(200) // 将 a 的值更新为 200 这两者构成了反射操作的基础，允许我们动态查询变量的类型和数据 3 反射三定律在 Go 官方博客文章 laws-of-reflection 中，叙述了反射的 3 定律： 第一定律：反射是从接口值到反射对象 在一般情况下，反射是一种检查存储在接口变量中的类型和值的机制。 这其实从 reflect 包中的 TypeOf 和 ValueOf 函数就可以知道。在本文第二节中有讲，这 2 个函数的接收参数就是 **interface{}**。 比如 reflect.TypeOf(6.4)，调用 reflect.TypeOf(x) 时（这里的 x 表示 6.4），x 首先存储在一个空接口 interface{} 中，作为参数传递，reflect.TypeOf 对该接口进行类型信息解码，获取类型详细信息。 第二定律：从反射对象可以获取接口值 通过 Value.Interface() 可以将 reflect.Value 还原为原始接口值。 123v := reflect.ValueOf(6.4)y := v.Interface()fmt.Println(reflect.TypeOf(y)) 知道数据类型直接获取值方法，不知道数据类型用 Interface() 获取数据然后断言值 第三定律：要修改反射对象的值，其值必须可以设置 123var x float64 = 3.4v := reflect.ValueOf(x)v.SetFloat(7.1) // Error: will panic. 此处设置v的值会报错，Value 的 CanSet 方法可以获取值是否可设置，如： 1234var x float64 = 3.4v := reflect.ValueOf(x)fmt.Println(&quot;settability of v:&quot;, v.CanSet())// settability of v: false 为什么有可设置性？ 因为 reflect.ValueOf(x) 这个 x 传递的是一个原数据的副本，上面代码 v.SetFloat(7.1) 如果设置成功，那么更新的是副本值，原始值 x 并没有更新。这就会造成原值和新值的混乱，可设置属性就是避免这个问题。 传递的是一个副本，而不是值本身。如果希望能直接修改 x，那么必须把 x 的地址传递给函数，即指向 x 的指针： 123456var x float64 = 3.4p := reflect.ValueOf(&amp;x) // Note: take the address of x.fmt.Println(&quot;type of p:&quot;, p.Type())fmt.Println(&quot;settability of p:&quot;, p.CanSet())// type of p: *float64// settability of p: false 还是 false，为什么？ 反射对象 p 不可设置，它并不是我们要设置的 p，它实际上是 *p。为了得到 p 所指向的东西，我们需要调用 Value 的 Elem 方法，通过指针进行简介寻址，然后将结果保存在一个名为 v 的反射 Value 中： 123v := p.Elem()fmt.Println(&quot;settability of v:&quot;, v.CanSet())// settability of v: true 然后我们可以用 v.SetFloat() 设置值： 12345v.SetFloat(7.1)fmt.Println(v.Interface())fmt.Println(x)// 7.1// 7.1 4 常用反射操作4.1 获取类型与数值利用 reflect.TypeOf(x) 可以获取变量的类型信息，而 reflect.ValueOf(x) 则用于获取变量值。例如： 12345辑var s string = &quot;hello&quot;t := reflect.TypeOf(s)v := reflect.ValueOf(s)fmt.Printf(&quot;Type: %v, Kind: %v\\n&quot;, t.Name(), t.Kind()) // 输出 &quot;string&quot;, &quot;string&quot;fmt.Println(&quot;Value:&quot;, v.String()) // 输出 &quot;hello&quot; 4.2 结构体字段与标签反射可以用来遍历结构体字段，获取字段名称、类型以及 struct tag。例如： 1234567891011type Student struct { Name string `json:&quot;name&quot;` Score int `json:&quot;score&quot;`}stu := Student{&quot;小王子&quot;, 90}t := reflect.TypeOf(stu)for i := 0; i &lt; t.NumField(); i++ { field := t.Field(i) fmt.Printf(&quot;字段名：%s, 类型：%v, Tag：%v\\n&quot;, field.Name, field.Type, field.Tag.Get(&quot;json&quot;))} 这种方式常用于 ORM 框架中自动解析结构体字段 4.3 动态方法调用通过反射，我们可以动态地调用对象的方法。首先通过 MethodByName 获取方法对应的反射对象，再用 Call 方法调用它： 12345678910type Person struct { Name string}func (p Person) SayHello() { fmt.Println(&quot;Hello, my name is&quot;, p.Name)}p := Person{&quot;Alice&quot;}v := reflect.ValueOf(p)method := v.MethodByName(&quot;SayHello&quot;)method.Call(nil) // 输出 &quot;Hello, my name is Alice&quot; 这种动态调用常用于插件化架构或 RPC 框架中 4.4 设置变量值如需修改变量值，必须传入变量地址并使用 Elem() 获取可设置的值： 123456var num int64 = 100v := reflect.ValueOf(&amp;num).Elem()if v.CanSet() { v.SetInt(200)}fmt.Println(num) // 输出 200 4.5 比较slice、map等是否相等在比较数组是否相等时可以直接使用 == ，因为数组的大小和元素类型是固定的，== 比较的是数组的每个元素是否相等。 但是，切片（slice）不支持使用 == 直接比较，因为切片是动态的，底层数组可能共享或者切片的容量和长度不同，所以 Go 语言并不允许直接比较切片（同理map也无法比较）。但是可以使用反射 reflect.DeepEqual 获取运行时的值来进行比较。 1234567var a []int = []int{1, 2, 3}var b []int = []int{1, 2, 3}if reflect.DeepEqual(a, b) { fmt.Println(true)} else { fmt.Println(false)} 5 反射的优缺点与使用场景优点 灵活性与动态性允许在运行时对未知类型进行操作，便于编写通用库或框架，如 ORM、依赖注入和序列化工具​ 解耦设计通过反射可以减少硬编码，使代码更加模块化和可配置。 缺点 性能开销反射操作比直接调用要慢一个甚至两个数量级，不适用于性能敏感的场景。 代码可读性和维护性下降反射代码通常较难理解和调试，容易引入运行时错误。 适用场景 框架开发：如 web 框架、ORM、序列化工具等需要处理多种类型时。 依赖注入和插件架构：运行时动态加载和调用模块功能。 通用工具库：如 JSON 编解码、日志系统等需要处理结构体标签和字段信息的场景","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E5%8F%8D%E5%B0%84reflect/"},{"title":"【Go】空结构体赋值问题","text":"点击阅读更多查看文章内容 结构体空值 {} 赋值问题问题描述：t1 := make(map[string]struct{}) 定义了一个map，随后使用 t1[“a”] = struct{}{} 为a赋值一个空结构体 t2 := map[string]struct{}{“a”: {}} 初始化一个结构体，为a赋值{} 以上代码都是为a赋值一个空结构体，但是第一种方法必须使用struct{}{}来表示空结构体，如果仅使用{}则会报错，但是第二种方法可以使用{}来表示空结构体 123456789101112package mainimport &quot;fmt&quot;func main() { t1 := make(map[string]struct{}) t1[&quot;a&quot;] = struct{}{} fmt.Println(t1) t2 := map[string]struct{}{&quot;a&quot;: {}} fmt.Println(t2)} 为什么 t[&quot;a&quot;] = {} 会报错12t := make(map[string]struct{})t[&quot;a&quot;] = {} // 错误：不能直接使用 `{}` 赋值 原因： 如果只使用 {} 的话，Go 无法推断 {} 的类型，例如 {} 还可以表示空的数组，空的切片等。Go 在编译时必须知道你赋值的值的具体类型，而 {} 本身没有明确的类型信息。所以使用 struct{}{} 来显示地创建一个空结构体值。 struct{}{} 是一个类型化的空结构体字面量。其中struct{}表示一个没有任何字段的结构体的类型，struct{}{}则是这个结构体的一个实例，它明确指定了创建一个空的 struct{} 类型的值。 为什么 t2 := map[string]struct{}{&quot;a&quot;: {}} 可以正常工作：1t2 := map[string]struct{}{&quot;a&quot;: {}} // 正确：可以直接使用 {} 这里初始化了一个 map 并在字面量中直接指定了值。Go 语言支持这种方式直接初始化 map。在这种情况下，Go 可以推断 {} 的类型是 struct{}，因为已经在 map 的类型中明确了值的类型是 struct{}。这是 Go 的语法糖，允许在初始化 map 时直接使用空结构体 {}，Go 会自动推断出它是 struct{} 类型的。 空结构体的作用在map中将值的类型设置为空结构体struct{}，空结构体在 Go 语言中占用零字节的存储空间，因此在内存使用方面非常高效。当你只需要存储键而不需要关联任何值时，使用空结构体作为值类型是一种常见的做法。（其他类型比如指针即使赋空值nil，它本身仍是一个指向 nil 的指针，通常占用 8 字节（在 64 位系统上）） 总结：单纯使用{}不能明确表示到底是什么类型，空结构体？空切片？空数组？，因此当要表示空结构体时需要明确指定类型为 struct{}{}","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E7%A9%BA%E7%BB%93%E6%9E%84%E4%BD%93%E8%B5%8B%E5%80%BC%E9%97%AE%E9%A2%98/"},{"title":"【Go】接口","text":"点击阅读更多查看文章内容 接口在 Golang（Go）中，接口（interface）是一种抽象类型，用于定义方法的集合。实现接口的关键在于：一个类型只要实现了接口中定义的所有方法，就被认为实现了该接口。Go 的接口实现是隐式的，不需要显式声明“实现了某个接口”。 以下是 Golang 实现接口的详细讲解： 1. 定义接口接口是通过 type 关键字定义的，接口中包含若干方法的声明。 示例：定义一个接口123456789package mainimport &quot;fmt&quot;// 定义一个接口type Shape interface { Area() float64 // 计算面积 Perimeter() float64 // 计算周长} 这里定义了一个接口 Shape，包含两个方法：Area 和 Perimeter。 2. 实现接口在 Go 中，一个类型只需要实现接口中声明的所有方法即可认为实现了该接口。 示例：实现接口123456789101112131415// 定义一个结构体type Rectangle struct { Width float64 Height float64}// 实现 Area 方法func (r Rectangle) Area() float64 { return r.Width * r.Height}// 实现 Perimeter 方法func (r Rectangle) Perimeter() float64 { return 2 * (r.Width + r.Height)} 实现方法：只要结构体 Rectangle 提供了 Area 和 Perimeter 方法的实现，它就自动实现了 Shape 接口。 3. 使用接口接口可以用作函数参数或返回值，用来接受实现了该接口的任何类型。 示例：使用接口12345678910func PrintShapeInfo(s Shape) { fmt.Printf(&quot;Area: %.2f, Perimeter: %.2f\\n&quot;, s.Area(), s.Perimeter())}func main() { rect := Rectangle{Width: 5, Height: 3} // 传递实现了 Shape 接口的 Rectangle 类型 PrintShapeInfo(rect)} 运行输出： 1Area: 15.00, Perimeter: 16.00 这里，PrintShapeInfo 函数接收一个 Shape 类型的参数，任何实现了 Shape 接口的类型都可以传递给它。 4. 空接口空接口（interface{}）是一个特殊的接口类型，它没有任何方法，因此所有类型都实现了空接口。可以用空接口来表示任意值。 示例：空接口的使用123456789func PrintAnything(v interface{}) { fmt.Printf(&quot;Value: %v, Type: %T\\n&quot;, v, v)}func main() { PrintAnything(42) // 输出：Value: 42, Type: int PrintAnything(&quot;hello&quot;) // 输出：Value: hello, Type: string PrintAnything([]int{1, 2}) // 输出：Value: [1 2], Type: []int} 5. 类型断言当使用接口时，可以通过类型断言将接口类型转换为具体类型。 示例：类型断言123456789func Describe(s Shape) { fmt.Println(&quot;Area:&quot;, s.Area()) fmt.Println(&quot;Type assertion:&quot;) if rect, ok := s.(Rectangle); ok { fmt.Printf(&quot;Rectangle width: %.2f\\n&quot;, rect.Width) } else { fmt.Println(&quot;Not a Rectangle&quot;) }} 这里，通过 s.(Rectangle) 判断接口变量是否是 Rectangle 类型。 6. 多态实现接口可以实现多态行为，即多个类型可以实现同一个接口，通过接口变量调用方法时，会自动执行实际类型的方法。 示例：多态123456789101112131415161718192021type Circle struct { Radius float64}func (c Circle) Area() float64 { return 3.14 * c.Radius * c.Radius}func (c Circle) Perimeter() float64 { return 2 * 3.14 * c.Radius}func main() { rect := Rectangle{Width: 5, Height: 3} circle := Circle{Radius: 4} shapes := []Shape{rect, circle} for _, shape := range shapes { PrintShapeInfo(shape) }} 运行输出： 12Area: 15.00, Perimeter: 16.00Area: 50.24, Perimeter: 25.12 7. 接口组合Go 的接口支持组合（嵌套），可以通过定义一个接口包含另一个接口的方式，实现更复杂的接口。 示例：接口组合1234567891011121314151617181920type AdvancedShape interface { Shape Volume() float64 // 新增方法}type Cube struct { Side float64}func (c Cube) Area() float64 { return 6 * c.Side * c.Side}func (c Cube) Perimeter() float64 { return 12 * c.Side}func (c Cube) Volume() float64 { return c.Side * c.Side * c.Side} 总结 接口定义：使用 type &lt;接口名&gt; interface {} 定义接口。 实现接口：类型通过实现接口的所有方法，自动实现该接口。 接口使用：接口可以用作参数和返回值，实现动态多态行为。 空接口：interface{} 表示任意类型。 组合接口：接口可以嵌套定义，实现更复杂的接口行为。 Go 的接口设计简洁、强大，通过它可以轻松实现灵活的抽象和多态。","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E6%8E%A5%E5%8F%A3/"},{"title":"【Go】内存管理","text":"点击阅读更多查看文章内容 自动内存管理 管理动态内存：动态内存是程序在运行时根据需求动态分配的内存：malloc() 堆是用于动态内存分配的区域，其生命周期由程序员或垃圾回收器管理。 栈是用于存储函数调用上下文和局部变量的区域，其生命周期与函数调用相关。栈内存由编译器自动管理，无需程序员干预。 自动内存管理（垃圾回收）：由程序语言的运行时系统回收动态内存 避免手动内存管理，专注于实现业务逻辑 保证内存使用的正确性和安全性 三个任务： 为新对象分配空间 找到存活对象 回收死亡对象的内存空间 相关概念： Mutator：业务线程，分配新对象，修改对象指向关系 Collector：GC线程，找到存活对象，回收死亡对象的内存空间 三种GC模式 Serial GC：只有一个collector Parallel GC：支持多个collectors同时回收的GC算法 Concurrent GC：mutator(s)和collector(s)可以同时执行 同时执行中Collector必须能够感知对象指向关系的改变！如下图如果GC过程中o指向了一个新的对象b，那么b必须被标记为存活（因为o到b可达） GC算法的评价 安全性：不能回收存活的对象（基本要求） 吞吐率：1 - （GC时间/程序执行总时间 ）（花在GC上的时间） 暂停时间：stop the world（STW）（业务是否感知） 内存开销：GC元数据开销 标记清除对象被回收的条件：指针指向关系不可达的对象 标记根对象 静态变量、全局变量、常量、线程等 标记可达对象 从根对象出发，找到所有可达对象 清理所有不可达对象 将存活对象复制到另外的内存空间（Copying GC）：将存活对象移走，清空原来的内存空间 将死亡对象的内存标记为“可分配”（Mark-sweep GC）：将死亡对象的内存空间通过free list管理起来，接下来分配free list中的内存 移动并整理存活对象（Mark-compact GC）：原地整理对象，将存活对象拷贝到空间开始，然后分配之后空间 根据对象的生命周期，使用不同的标记和清理策略 可达对象是什么意思？ 可达性分析是从根对象出发，通过引用链遍历所有可以被访问到的对象的过程 123456789101112131415161718192021222324package mainimport &quot;fmt&quot;type Node struct { value int next *Node}func main() { // 根对象：局部变量 root root := &amp;Node{value: 1} root.next = &amp;Node{value: 2} root.next.next = &amp;Node{value: 3} // 此时，root 及其 next 链上的所有节点都是可达的 fmt.Println(root.value, root.next.value, root.next.next.value) // 断开引用链 root.next = nil // 此时，root 仍然可达，但 root.next 和 root.next.next 不可达 fmt.Println(root.value)} 可达性分析： 初始时，root 是根对象，root.next 和 root.next.next 通过引用链可达。 当 root.next = nil 执行后，root.next 和 root.next.next 不再被引用，变为不可达。 垃圾回收器会回收这些不可达的对象。 分代GC（Generational GC）根据对象的生命周期，使用不同的标记和清理策略 分代假说：大多数的对象在刚分配出来后很快就不再使用了 每个对象都有年龄：经历过GC的次数 目的：针对年轻和老年的对象，制定不同的GC策略，降低整体内存管理的开销 不同年龄的对象处于heap的不同区域 针对年轻代对象 常规的对象分配，可能很快就不再使用 由于存活对象很少，可以采用copying collection GC吞吐率很高 针对老年代对象 对象趋向于一直活着，反复复制开销较大 可以采用 mark-sweep collection 引用计数每个对象都有一个与之关联的引用数目 对象存活的条件：当且仅当引用数大于0 优点： 内存管理的操作被平摊到程序执行过程中，在程序执行中可以随时判断对象的引用数是否为0 内存管理不需要了解runtime的实现细节: C++ 智能指针(smart pointer) 缺点： 维护引用计数的开销较大：通过原子操作保证对引用计数操作的原子性和可见性 无法回收环形数据结构（右侧红色的环无法回收） —— weak reference 内存开销：每个对象都引入的额外内存空间存储引用数目 回收较大的内存时依然可能引发暂停（将左侧绿色的对象设为null，那么其所连的三个引用链全都会回收） 三色标记为了解决原始标记清除算法带来的长时间 STW，多数现代的追踪式垃圾收集器都会实现三色标记算法的变种以缩短 STW 的时间（可以并发执行）。三色标记算法将程序中的对象分成白色、黑色和灰色三类。 白色对象（可能死亡）：未被回收器访问到的对象。在回收开始阶段，所有对象均为白色，当回收结束后，白色对象均不可达。 灰色对象（波面）：已被回收器访问到的对象，但回收器需要对其中的一个或多个指针进行扫描，因为他们可能还指向白色对象。 黑色对象（确定存活）：已被回收器访问到的对象，其中所有字段都已被扫描，黑色对象中任何一个指针都不可能直接指向白色对象。 在垃圾收集器开始工作时，程序中不存在任何的黑色对象，垃圾收集的根对象会被标记成灰色，垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。 执行过程三色标记垃圾收集器的工作原理很简单，我们可以将其归纳成以下几个步骤： 从灰色对象的集合中选择一个灰色对象并将其标记成黑色； 将黑色对象指向的所有对象都标记成灰色，保证该对象和被该对象引用的对象都不会被回收； 重复上述两个步骤直到对象图中不存在灰色对象； 当三色的标记清除的标记阶段结束之后，应用程序的堆中就不存在任何的灰色对象，我们只能看到黑色的存活对象以及白色的垃圾对象，垃圾收集器可以回收这些白色的垃圾，下面是使用三色标记垃圾收集器执行标记后的堆内存，堆中只有对象 D 为待回收的垃圾： 因为用户程序可能在标记执行的过程中修改对象的指针，所以三色标记清除算法本身是不可以并发或者增量执行的，它仍然需要 STW，在如下所示的三色标记过程中，用户程序建立了从 A 对象到 D 对象的引用，但是因为A已经为黑色所以D的颜色不会改变会被垃圾收集器错误地回收。 并发标记——屏障技术本来不应该被回收的对象却被回收了，这在内存管理中是非常严重的错误，我们将这种错误称为悬挂指针，即指针没有指向特定类型的合法对象，影响了内存的安全性，想要并发或者增量地标记对象还是需要使用屏障技术。 内存屏障技术是一种屏障指令，它可以让 CPU 或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，但是该技术能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存屏障后执行的操作。 想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的一种： 强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象；（插入写屏障） 弱三色不变性 — 黑色对象可以引用白色对象，但必须存在一条从灰色对象到白色对象的路径。（删除写屏障） 上图分别展示了遵循强三色不变性和弱三色不变性的堆内存，遵循上述两个不变性中的任意一个，我们都能保证垃圾收集算法的正确性，而屏障技术就是在并发或者增量标记过程中保证三色不变性的重要技术。 垃圾收集中的屏障技术是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。 我们在这里想要介绍的是 Go 语言中使用的两种写屏障技术，分别是 Dijkstra 提出的插入写屏障和 Yuasa 提出的删除写屏障，这里会分析它们如何保证三色不变性和垃圾收集器的正确性。 插入写屏障通过如下所示的写屏障，用户程序和垃圾收集器可以在交替工作的情况下保证程序执行的正确性： 在添加引用时，将新添加的对象标记为灰色，确保它会被垃圾回收器扫描。 触发时机 当用户程序将一个对象的引用从 A -&gt; nil 修改为 A -&gt; B 时，插入写屏障会捕获这一修改，并将新添加的对象 B 标记为灰色。 优点 减少多标：只标记新添加的对象，避免不必要的扫描。 适合精确控制：在某些场景下，插入写屏障可以更精确地控制标记过程。 缺点 实现复杂：逻辑较为复杂，性能开销较高。 可能导致漏标：如果引用关系被频繁修改，可能会导致某些对象未被正确标记。 假设我们在应用程序中使用 Dijkstra 提出的插入写屏障，在一个垃圾收集器和用户程序交替运行的场景中会出现如上图所示的标记过程： 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色； 用户程序修改 A 对象的指针，将原本指向 B 对象的指针指向 C 对象，这时触发写屏障将 C 对象标记成灰色； 垃圾收集器依次遍历程序中的其他灰色对象，将它们分别标记成黑色； Dijkstra 的插入写屏障是一种相对保守的屏障技术，它会将有存活可能的对象都标记成灰色以满足强三色不变性。在如上所示的垃圾收集过程中，实际上不再存活的 B 对象最后没有被回收；而如果我们在第二和第三步之间将指向 C 对象的指针改回指向 B，垃圾收集器仍然认为 C 对象是存活的，这些被错误标记的垃圾对象只有在下一个循环才会被回收。 插入式的 Dijkstra 写屏障虽然实现非常简单并且也能保证强三色不变性，但是它也有明显的缺点。因为栈上的对象在垃圾收集中也会被认为是根对象，所以为了保证内存的安全，Dijkstra 必须为栈上的对象增加写屏障或者在标记阶段完成重新对栈上的对象进行扫描，这两种方法各有各的缺点，前者会大幅度增加写入指针的额外开销，后者重新扫描栈对象时需要暂停程序，垃圾收集算法的设计者需要在这两者之间做出权衡。 删除写屏障该算法会使用如下所示的写屏障保证增量或者并发执行垃圾收集时程序的正确性： 在删除引用时，将被删除的对象标记为灰色，确保它不会被错误地回收。 触发时机 当用户程序将一个对象的引用从 A -&gt; B 修改为 A -&gt; C 时，删除写屏障会捕获这一修改，并将被删除的对象 B 标记为灰色。 优点 减少漏标：确保被删除的对象及其引用的对象不会被错误地回收。 实现简单：逻辑清晰，性能开销较低。 适合并发标记：与三色标记法配合良好，能够有效减少 STW 时间。 缺点 可能导致多标：被删除的对象可能会被多扫描一次，增加垃圾回收的开销。 假设我们在应用程序中使用 Yuasa 提出的删除写屏障，在一个垃圾收集器和用户程序交替运行的场景中会出现如上图所示的标记过程： 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色； 用户程序将 A 对象原本指向 B 的指针指向 C，触发删除写屏障，但是因为 B 对象已经是灰色的，所以不做改变； 用户程序将 B 对象原本指向 C 的指针删除，触发删除写屏障，白色的 C 对象被涂成灰色（如果没有删除写屏障C对象将始终为白色）； 垃圾收集器依次遍历程序中的其他灰色对象，将它们分别标记成黑色； 上述过程中的第三步触发了 Yuasa 删除写屏障的着色，因为用户程序删除了 B 指向 C 对象的指针，所以 C 和 D 两个对象会分别违反强三色不变性和弱三色不变性： 强三色不变性 — 黑色的 A 对象直接指向白色的 C 对象； 弱三色不变性 — 垃圾收集器无法从某个灰色对象出发，经过几个连续的白色对象访问白色的 C 和 D 两个对象； Yuasa 删除写屏障通过对 C 对象的着色，保证了 C 对象和下游的 D 对象能够在这一次垃圾收集的循环中存活，避免发生悬挂指针以保证用户程序的正确性。 Go内存分配分块目的：为对象在heap上分配内存 提前将内存分块： 调用系统调用mmap()向OS申请一大块内存，例如4 MB 先将内存划分成大块，例如8 KB，称作mspan 再将大块继续划分成特定大小（如：8B、16B、24B）的小块，用于对象分配 mspan可以分为两类 noscan mspan：分配不包含指针的对象 —— GC 不需要扫描 scan mspan: 分配包含指针的对象 —— GC需要扫描 对象分配：根据对象的大小，选择最合适的块返回 缓存 TCMalloc: thread caching 每个p包含一个mcache用于快速分配，用于为绑定于p上的g分配对象 mcache管理一组mspan 当mcache中的mspan分配完毕，向mcentral申请带有未分配块的mspan 当mspan中没有分配的对象，mspan会被缓存在mcentral中，而不是立刻释放并归还给OS Go内存管理优化 对象分配是非常高频的操作:每秒分配GB级别的内存 小对象占比较高 Go内存分配比较耗时 分配路径长: g-&gt; m -&gt; p -&gt; mcache -&gt; mspan -&gt; memory block -&gt; return pointer pprof: 对象分配的函数是最频繁调用的函数之一","link":"/2025/03/03/gonote/%E3%80%90Go%E3%80%91%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"title":"【redis】数据类型","text":"点击阅读更多查看文章内容 StringString 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 512M。 内部实现String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。 SDS 和我们认识的 C 字符串不太一样，之所以没有使用 C 语言的字符串表示，因为 SDS 相比于 C 的原生字符串： SDS 不仅可以保存文本数据，还可以保存二进制数据。因为 SDS 使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[] 数组里的数据。 SDS 获取字符串长度的时间复杂度是 O(1)。因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。 Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。 字符串对象的内部编码（encoding）有 3 种 ：int、raw和 embstr。 如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面（将void*转换成 long），并将字符串对象的编码设置为int。 如果字符串对象保存的是一个字符串，并且这个字符申的长度小于等于 32 字节（redis 2.+版本），那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为embstr， embstr编码是专门用于保存短字符串的一种优化编码方式： 如果字符串对象保存的是一个字符串，并且这个字符串的长度大于 32 字节（redis 2.+版本），那么字符串对象将使用一个简单动态字符串（SDS)来保存这个字符串，并将对象的编码设置为raw embstr和raw编码都会使用SDS来保存值，但不同之处在于embstr会通过一次内存分配函数来分配一块连续的内存空间来保存redisObject和SDS，而raw编码会通过调用两次内存分配函数来分别分配两块空间来保存redisObject和SDS。Redis这样做会有很多好处 embstr编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次； 释放 embstr编码的字符串对象同样只需要调用一次内存释放函数； 因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。 但是 embstr 也有缺点的： 如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，所以embstr编码的字符串对象实际上是只读的，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令 应用场景 缓存对象 使用 String 来缓存对象有两种方式： 直接缓存整个对象的 JSON 采用将 key 进行分离为 user:ID:属性，采用 MSET 存储，用 MGET 获取各属性值 常规计数 因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等 分布式锁 SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁： ListList 列表是简单的字符串列表，按照插入顺序排序，可以从头部或尾部向 List 列表添加元素。 列表的最大长度为 2^32 - 1，也即每个列表支持超过 40 亿个元素。 内部实现List 类型的底层数据结构是由双向链表或压缩列表实现的： 如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用压缩列表作为 List 类型的底层数据结构； 如果列表的元素不满足上面的条件，Redis 会使用双向链表作为 List 类型的底层数据结构； 但是在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist 实现了，替代了双向链表和压缩列表。 应用场景消息队列 HashHash 是一个键值对（key - value）集合，其中 value 的形式如： value=[{field1，value1}，…{fieldN，valueN}]。Hash 特别适合用于存储对象。 Hash 与 String 对象的区别如下图所示： 内部实现内部实现 Hash 类型的底层数据结构是由压缩列表或哈希表实现的： 如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构； 如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的 底层数据结构。 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。 应用场景缓存对象 Hash 类型的 （key，field， value） 的结构与对象的（对象id， 属性， 值）的结构相似，也可以用来存储对象。 我们以用户信息为例，它在关系型数据库中的结构是这样的： 我们可以使用如下命令，将用户对象的信息存储到 Hash 类型： 123456789101112# 存储一个哈希表uid:1的键值&gt; HMSET uid:1 name Tom age 152# 存储一个哈希表uid:2的键值&gt; HMSET uid:2 name Jerry age 132# 获取哈希表用户id为1中所有的键值&gt; HGETALL uid:11) &quot;name&quot;2) &quot;Tom&quot;3) &quot;age&quot;4) &quot;15 Redis Hash 存储其结构如下图： SetSet 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。 一个集合最多可以存储 2^32-1 个元素。概念和数学中个的集合基本类似，可以交集，并集，差集等等，所以 Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集 内部实现Set 类型的底层数据结构是由哈希表或整数集合实现的： 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用整数集合作为 Set 类型的底层数据结构； 如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。 应用场景Set 类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集等，当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。 但是要提醒你一下，这里有一个潜在的风险。Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。在主从集群中，可以选择一个从库完成聚合统计。 点赞 Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id。 uid:1 、uid:2、uid:3 三个用户分别对 article:1 文章点赞了。 123456789# uid:1 用户对文章 article:1 点赞&gt; SADD article:1 uid:1(integer) 1# uid:2 用户对文章 article:1 点赞&gt; SADD article:1 uid:2(integer) 1# uid:3 用户对文章 article:1 点赞&gt; SADD article:1 uid:3(integer) 1 共同关注 Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。 key 可以是用户id，value 则是已关注的公众号的id。 抽奖活动 存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。 key为抽奖活动名，value为员工名称，把所有员工名称放入抽奖箱 如果允许重复中奖，可以使用 SRANDMEMBER 命令从集合中抽取 如果不允许重复中奖，可以使用 SPOP 命令从集合中抽取 ZsetZset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 ZSet 来说，每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。 有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是，有序集合中的元素可以排序。 内部实现Zset 类型的底层数据结构是由压缩列表或跳表实现的： 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用压缩列表作为 Zset 类型的底层数据结构； 如果有序集合的元素不满足上面的条件，Redis 会使用跳表作为 Zset 类型的底层数据结构； 在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了 应用场景 排行榜 有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。 电话、姓名排序 使用有序集合的 ZRANGEBYLEX 或 ZREVRANGEBYLEX 可以帮助我们实现电话号码或姓名的排序，我们以 ZRANGEBYLEX （返回指定成员区间内的成员，按 key 正序排列，分数必须相同）为例。 1234567891011121314151617181920212223242526获取所有号码:&gt; ZRANGEBYLEX phone - +1) &quot;13100111100&quot;2) &quot;13110114300&quot;3) &quot;13132110901&quot;4) &quot;13200111100&quot;5) &quot;13210414300&quot;6) &quot;13252110901&quot;7) &quot;13300111100&quot;8) &quot;13310414300&quot;9) &quot;13352110901&quot;获取 132 号段的号码：&gt; ZRANGEBYLEX phone [132 (1331) &quot;13200111100&quot;2) &quot;13210414300&quot;3) &quot;13252110901&quot;获取132、133号段的号码：&gt; ZRANGEBYLEX phone [132 (1341) &quot;13200111100&quot;2) &quot;13210414300&quot;3) &quot;13252110901&quot;4) &quot;13300111100&quot;5) &quot;13310414300&quot;6) &quot;13352110901&quot; BitMapBitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。 由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用二值统计的场景。 内部实现Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。 String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组。 bitmap 基本操作： 123456789# 设置值，其中value只能是 0 和 1SETBIT key offset value# 获取值GETBIT key offset# 获取指定范围内值为 1 的个数# start 和 end 以字节为单位BITCOUNT key start end 应用场景 签到统计 在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。 签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位。 假设我们要统计 ID 100 的用户在 2022 年 6 月份的签到情况，就可以按照下面的步骤进行操作。 第一步，执行下面的命令，记录该用户 6 月 3 号已签到。 1SETBIT uid:sign:100:202206 2 1 HyperLogLogRedis HyperLogLog 是 Redis 2.8.9 版本新增的数据类型，是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。 所以，简单来说 HyperLogLog 提供不精确的去重计数。 HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。 应用场景 百万级网页 UV 计数 Redis HyperLogLog 优势在于只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。 GEORedis GEO 是 Redis 3.2 版本新增的数据类型，主要用于存储地理位置信息，并对存储的信息进行操作。 在日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中。 应用场景 滴滴叫车 这里以滴滴叫车的场景为例，介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。 假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。 12345# 执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：GEOADD cars:locations 116.034579 39.030452 33# 当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。# 例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10 StreamRedis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。","link":"/2025/03/15/interview/redis/%E3%80%90redis%E3%80%91%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}],"tags":[{"name":"c++ 蓝桥杯 c语言","slug":"c-蓝桥杯-c语言","link":"/tags/c-%E8%93%9D%E6%A1%A5%E6%9D%AF-c%E8%AF%AD%E8%A8%80/"},{"name":"网络 服务器 网络协议","slug":"网络-服务器-网络协议","link":"/tags/%E7%BD%91%E7%BB%9C-%E6%9C%8D%E5%8A%A1%E5%99%A8-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"区块链","slug":"区块链","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"c++ 排序算法 快速排序","slug":"c-排序算法-快速排序","link":"/tags/c-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"name":"c++ 算法 几何学","slug":"c-算法-几何学","link":"/tags/c-%E7%AE%97%E6%B3%95-%E5%87%A0%E4%BD%95%E5%AD%A6/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"服务器 运维","slug":"服务器-运维","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8-%E8%BF%90%E7%BB%B4/"},{"name":"golang http 开发语言","slug":"golang-http-开发语言","link":"/tags/golang-http-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80/"},{"name":"go语言","slug":"go语言","link":"/tags/go%E8%AF%AD%E8%A8%80/"},{"name":"golang 开发语言 后端","slug":"golang-开发语言-后端","link":"/tags/golang-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80-%E5%90%8E%E7%AB%AF/"},{"name":"golang 容器 开发语言","slug":"golang-容器-开发语言","link":"/tags/golang-%E5%AE%B9%E5%99%A8-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80/"},{"name":"fabric 学习 docker","slug":"fabric-学习-docker","link":"/tags/fabric-%E5%AD%A6%E4%B9%A0-docker/"},{"name":"fabric 学习 系统架构","slug":"fabric-学习-系统架构","link":"/tags/fabric-%E5%AD%A6%E4%B9%A0-%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"},{"name":"区块链 fabric 分布式账本","slug":"区块链-fabric-分布式账本","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-fabric-%E5%88%86%E5%B8%83%E5%BC%8F%E8%B4%A6%E6%9C%AC/"},{"name":"fabric 学习 区块链","slug":"fabric-学习-区块链","link":"/tags/fabric-%E5%AD%A6%E4%B9%A0-%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"区块链 fabric 学习","slug":"区块链-fabric-学习","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-fabric-%E5%AD%A6%E4%B9%A0/"},{"name":"区块链 分布式账本","slug":"区块链-分布式账本","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E5%88%86%E5%B8%83%E5%BC%8F%E8%B4%A6%E6%9C%AC/"},{"name":"intellij-idea java ide","slug":"intellij-idea-java-ide","link":"/tags/intellij-idea-java-ide/"},{"name":"java intellij-idea ide","slug":"java-intellij-idea-ide","link":"/tags/java-intellij-idea-ide/"},{"name":"网络 大数据","slug":"网络-大数据","link":"/tags/%E7%BD%91%E7%BB%9C-%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"1024程序员节","slug":"1024程序员节","link":"/tags/1024%E7%A8%8B%E5%BA%8F%E5%91%98%E8%8A%82/"},{"name":"leetcode 算法","slug":"leetcode-算法","link":"/tags/leetcode-%E7%AE%97%E6%B3%95/"},{"name":"leetcode 动态规划 算法","slug":"leetcode-动态规划-算法","link":"/tags/leetcode-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E7%AE%97%E6%B3%95/"},{"name":"字符串","slug":"字符串","link":"/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"leetcode 动态规划 算法 递归算法 博弈论","slug":"leetcode-动态规划-算法-递归算法-博弈论","link":"/tags/leetcode-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95-%E5%8D%9A%E5%BC%88%E8%AE%BA/"},{"name":"https ssl 安全","slug":"https-ssl-安全","link":"/tags/https-ssl-%E5%AE%89%E5%85%A8/"},{"name":"linux bash","slug":"linux-bash","link":"/tags/linux-bash/"},{"name":"算法 贪心算法","slug":"算法-贪心算法","link":"/tags/%E7%AE%97%E6%B3%95-%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"},{"name":"算法 动态规划","slug":"算法-动态规划","link":"/tags/%E7%AE%97%E6%B3%95-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"算法 队列","slug":"算法-队列","link":"/tags/%E7%AE%97%E6%B3%95-%E9%98%9F%E5%88%97/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"算法 dfs","slug":"算法-dfs","link":"/tags/%E7%AE%97%E6%B3%95-dfs/"},{"name":"dfs 算法","slug":"dfs-算法","link":"/tags/dfs-%E7%AE%97%E6%B3%95/"},{"name":"贪心算法","slug":"贪心算法","link":"/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/"},{"name":"算法 二分法","slug":"算法-二分法","link":"/tags/%E7%AE%97%E6%B3%95-%E4%BA%8C%E5%88%86%E6%B3%95/"},{"name":"dfs 算法 bfs","slug":"dfs-算法-bfs","link":"/tags/dfs-%E7%AE%97%E6%B3%95-bfs/"},{"name":"二叉树 算法","slug":"二叉树-算法","link":"/tags/%E4%BA%8C%E5%8F%89%E6%A0%91-%E7%AE%97%E6%B3%95/"},{"name":"fabric docker 运维","slug":"fabric-docker-运维","link":"/tags/fabric-docker-%E8%BF%90%E7%BB%B4/"},{"name":"css 前端 html","slug":"css-前端-html","link":"/tags/css-%E5%89%8D%E7%AB%AF-html/"},{"name":"golang 算法 开发语言","slug":"golang-算法-开发语言","link":"/tags/golang-%E7%AE%97%E6%B3%95-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80/"},{"name":"golang 算法","slug":"golang-算法","link":"/tags/golang-%E7%AE%97%E6%B3%95/"},{"name":"golang 开发语言","slug":"golang-开发语言","link":"/tags/golang-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80/"},{"name":"golang 宽度优先 开发语言","slug":"golang-宽度优先-开发语言","link":"/tags/golang-%E5%AE%BD%E5%BA%A6%E4%BC%98%E5%85%88-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80/"},{"name":"typescript javascript 前端","slug":"typescript-javascript-前端","link":"/tags/typescript-javascript-%E5%89%8D%E7%AB%AF/"},{"name":"python 开发语言","slug":"python-开发语言","link":"/tags/python-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80/"},{"name":"数据结构 算法","slug":"数据结构-算法","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/"},{"name":"b树 数据结构","slug":"b树-数据结构","link":"/tags/b%E6%A0%91-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"云计算","slug":"云计算","link":"/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"c语言 c++ visual studio 安全","slug":"c语言-c-visual-studio-安全","link":"/tags/c%E8%AF%AD%E8%A8%80-c-visual-studio-%E5%AE%89%E5%85%A8/"},{"name":"区块链 比特币 数字货币","slug":"区块链-比特币-数字货币","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E6%AF%94%E7%89%B9%E5%B8%81-%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81/"},{"name":"区块链 以太坊 数字货币","slug":"区块链-以太坊-数字货币","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E4%BB%A5%E5%A4%AA%E5%9D%8A-%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81/"},{"name":"区块链 以太坊 智能合约","slug":"区块链-以太坊-智能合约","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E4%BB%A5%E5%A4%AA%E5%9D%8A-%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"区块链 以太坊 安全","slug":"区块链-以太坊-安全","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E4%BB%A5%E5%A4%AA%E5%9D%8A-%E5%AE%89%E5%85%A8/"},{"name":"区块链 数据结构 比特币","slug":"区块链-数据结构-比特币","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%AF%94%E7%89%B9%E5%B8%81/"},{"name":"区块链 网络 比特币","slug":"区块链-网络-比特币","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E7%BD%91%E7%BB%9C-%E6%AF%94%E7%89%B9%E5%B8%81/"},{"name":"区块链 学习 笔记","slug":"区块链-学习-笔记","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE-%E5%AD%A6%E4%B9%A0-%E7%AC%94%E8%AE%B0/"},{"name":"同态加密 区块链 算法 安全","slug":"同态加密-区块链-算法-安全","link":"/tags/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86-%E5%8C%BA%E5%9D%97%E9%93%BE-%E7%AE%97%E6%B3%95-%E5%AE%89%E5%85%A8/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"wireshark 网络安全 网络协议","slug":"wireshark-网络安全-网络协议","link":"/tags/wireshark-%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"数据结构 c++","slug":"数据结构-c","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-c/"},{"name":"机器学习 神经网络","slug":"机器学习-神经网络","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"git github","slug":"git-github","link":"/tags/git-github/"},{"name":"微信小程序 小程序","slug":"微信小程序-小程序","link":"/tags/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F-%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"网络 运维 服务器","slug":"网络-运维-服务器","link":"/tags/%E7%BD%91%E7%BB%9C-%E8%BF%90%E7%BB%B4-%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"java 开发语言 后端 操作系统","slug":"java-开发语言-后端-操作系统","link":"/tags/java-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80-%E5%90%8E%E7%AB%AF-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"os","slug":"os","link":"/tags/os/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"os 操作系统","slug":"os-操作系统","link":"/tags/os-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"链表 算法 数据结构","slug":"链表-算法-数据结构","link":"/tags/%E9%93%BE%E8%A1%A8-%E7%AE%97%E6%B3%95-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"数据结构 栈","slug":"数据结构-栈","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88/"},{"name":"程序设计 算法","slug":"程序设计-算法","link":"/tags/%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1-%E7%AE%97%E6%B3%95/"},{"name":"算法 排序算法 leetcode","slug":"算法-排序算法-leetcode","link":"/tags/%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95-leetcode/"},{"name":"算法 链表 数据结构","slug":"算法-链表-数据结构","link":"/tags/%E7%AE%97%E6%B3%95-%E9%93%BE%E8%A1%A8-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法 c++ 数据结构","slug":"算法-c-数据结构","link":"/tags/%E7%AE%97%E6%B3%95-c-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法 leetcode 数据结构","slug":"算法-leetcode-数据结构","link":"/tags/%E7%AE%97%E6%B3%95-leetcode-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"c++ 算法","slug":"c-算法","link":"/tags/c-%E7%AE%97%E6%B3%95/"},{"name":"算法 c++","slug":"算法-c","link":"/tags/%E7%AE%97%E6%B3%95-c/"},{"name":"c++ 算法 素数筛","slug":"c-算法-素数筛","link":"/tags/c-%E7%AE%97%E6%B3%95-%E7%B4%A0%E6%95%B0%E7%AD%9B/"},{"name":"网络 运维","slug":"网络-运维","link":"/tags/%E7%BD%91%E7%BB%9C-%E8%BF%90%E7%BB%B4/"},{"name":"web安全 网络 安全","slug":"web安全-网络-安全","link":"/tags/web%E5%AE%89%E5%85%A8-%E7%BD%91%E7%BB%9C-%E5%AE%89%E5%85%A8/"},{"name":"web安全 安全","slug":"web安全-安全","link":"/tags/web%E5%AE%89%E5%85%A8-%E5%AE%89%E5%85%A8/"},{"name":"web安全 安全 网络","slug":"web安全-安全-网络","link":"/tags/web%E5%AE%89%E5%85%A8-%E5%AE%89%E5%85%A8-%E7%BD%91%E7%BB%9C/"},{"name":"web安全 哈希算法 安全","slug":"web安全-哈希算法-安全","link":"/tags/web%E5%AE%89%E5%85%A8-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95-%E5%AE%89%E5%85%A8/"},{"name":"web安全 网络 系统安全","slug":"web安全-网络-系统安全","link":"/tags/web%E5%AE%89%E5%85%A8-%E7%BD%91%E7%BB%9C-%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8/"},{"name":"网络 p2p 服务器","slug":"网络-p2p-服务器","link":"/tags/%E7%BD%91%E7%BB%9C-p2p-%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"网络 运维 安全架构","slug":"网络-运维-安全架构","link":"/tags/%E7%BD%91%E7%BB%9C-%E8%BF%90%E7%BB%B4-%E5%AE%89%E5%85%A8%E6%9E%B6%E6%9E%84/"},{"name":"云计算 docker 运维","slug":"云计算-docker-运维","link":"/tags/%E4%BA%91%E8%AE%A1%E7%AE%97-docker-%E8%BF%90%E7%BB%B4/"},{"name":"网络 网络协议 udp 计算机网络","slug":"网络-网络协议-udp-计算机网络","link":"/tags/%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-udp-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"网络 网络协议 计算机网络","slug":"网络-网络协议-计算机网络","link":"/tags/%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"网络 网络协议","slug":"网络-网络协议","link":"/tags/%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"网络 网络协议 java","slug":"网络-网络协议-java","link":"/tags/%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-java/"},{"name":"网络 网络协议 udp","slug":"网络-网络协议-udp","link":"/tags/%E7%BD%91%E7%BB%9C-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-udp/"},{"name":"网络 http 网络协议","slug":"网络-http-网络协议","link":"/tags/%E7%BD%91%E7%BB%9C-http-%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"网络 安全架构 安全","slug":"网络-安全架构-安全","link":"/tags/%E7%BD%91%E7%BB%9C-%E5%AE%89%E5%85%A8%E6%9E%B6%E6%9E%84-%E5%AE%89%E5%85%A8/"},{"name":"服务器 网络 云计算","slug":"服务器-网络-云计算","link":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8-%E7%BD%91%E7%BB%9C-%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"网络 安全","slug":"网络-安全","link":"/tags/%E7%BD%91%E7%BB%9C-%E5%AE%89%E5%85%A8/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"golang","slug":"golang","link":"/tags/golang/"},{"name":"开发","slug":"开发","link":"/tags/%E5%BC%80%E5%8F%91/"},{"name":"性能优化","slug":"性能优化","link":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"消息队列","slug":"消息队列","link":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"},{"name":"go","slug":"go","link":"/tags/go/"},{"name":"接口","slug":"接口","link":"/tags/%E6%8E%A5%E5%8F%A3/"},{"name":"DNS","slug":"DNS","link":"/tags/DNS/"},{"name":"命令","slug":"命令","link":"/tags/%E5%91%BD%E4%BB%A4/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"流量控制","slug":"流量控制","link":"/tags/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6/"},{"name":"环境变量","slug":"环境变量","link":"/tags/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/"},{"name":"锁","slug":"锁","link":"/tags/%E9%94%81/"},{"name":"博客搭建","slug":"博客搭建","link":"/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"区块链审计","slug":"区块链审计","link":"/tags/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AE%A1%E8%AE%A1/"},{"name":"完整性验证","slug":"完整性验证","link":"/tags/%E5%AE%8C%E6%95%B4%E6%80%A7%E9%AA%8C%E8%AF%81/"},{"name":"翻墙","slug":"翻墙","link":"/tags/%E7%BF%BB%E5%A2%99/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"ip","slug":"ip","link":"/tags/ip/"},{"name":"tcp","slug":"tcp","link":"/tags/tcp/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"}],"categories":[{"name":"刷题集","slug":"刷题集","link":"/categories/%E5%88%B7%E9%A2%98%E9%9B%86/"},{"name":"杂项","slug":"杂项","link":"/categories/%E6%9D%82%E9%A1%B9/"},{"name":"区块链","slug":"区块链","link":"/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"Fabric","slug":"Fabric","link":"/categories/Fabric/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"Shell脚本","slug":"Shell脚本","link":"/categories/Shell%E8%84%9A%E6%9C%AC/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"比特币","slug":"比特币","link":"/categories/%E6%AF%94%E7%89%B9%E5%B8%81/"},{"name":"以太坊","slug":"以太坊","link":"/categories/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"},{"name":"密码学","slug":"密码学","link":"/categories/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"小程序","slug":"小程序","link":"/categories/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"网络安全","slug":"网络安全","link":"/categories/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"计算机网络","slug":"计算机网络","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"bytedance","slug":"bytedance","link":"/categories/bytedance/"},{"name":"技术总结","slug":"技术总结","link":"/categories/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/"},{"name":"学术","slug":"学术","link":"/categories/%E5%AD%A6%E6%9C%AF/"},{"name":"其它","slug":"技术总结/其它","link":"/categories/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/%E5%85%B6%E5%AE%83/"},{"name":"知识点整理","slug":"知识点整理","link":"/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/"},{"name":"操作系统","slug":"知识点整理/操作系统","link":"/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"计算机网络","slug":"知识点整理/计算机网络","link":"/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"mysql","slug":"知识点整理/mysql","link":"/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/mysql/"},{"name":"redis","slug":"知识点整理/redis","link":"/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/redis/"}],"pages":[{"title":"AboutMe","text":"专门留给自己一页想写些东西，但发现自己好像并没有什么可写的，前二十年学生生涯都是按部就班的度过，实在想不出什么值得分享的内容，但还是先给自己留一页吧，以后应该会有机会慢慢填补。","link":"/about/index.html"}]}